
@book{agirre.edmonds_2007a,
  title = {Word {{Sense Disambiguation}}. {{Algorithms}} and {{Applications}}},
  editor = {Agirre, Eneko and Edmonds, Philip},
  date = {2007},
  series = {Text, Speech, and Language Technology},
  volume = {33},
  publisher = {{Springer}},
  isbn = {9781402048084},
  langid = {english}
}

@inproceedings{apidianaki.vandecruys_2011,
  title = {A {{Quantitative Evaluation}} of {{Global Word Sense Induction}}},
  booktitle = {Computational {{Linguistics}} and {{Intelligent Text Processing}}},
  author = {Apidianaki, Marianna and Van de Cruys, Tim},
  editor = {Gelbukh, Alexander F.},
  date = {2011},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {6608},
  pages = {253--264},
  location = {{Tokyo, Japan}},
  doi = {10.1007/978-3-642-19400-9_20},
  abstract = {Word sense induction (WSI) is the task aimed at automatically identifying the senses of words in texts, without the need for handcrafted resources or annotated data. Up till now, most WSI algorithms extract the different senses of a word ‘locally’ on a per-word basis, i.e. the different senses for each word are determined separately. In this paper, we compare the performance of such algorithms to an algorithm that uses a ‘global’ approach, i.e. the different senses of a particular word are determined by comparing them to, and demarcating them from, the senses of other words in a full-blown word space model. We adopt the evaluation framework proposed in the SemEval-2010 Word Sense Induction \& Disambiguation task. All systems that participated in this task use a local scheme for determining the different senses of a word. We compare their results to the ones obtained by the global approach, and discuss the advantages and weaknesses of both approaches.},
  isbn = {978-3-642-19399-6 978-3-642-19400-9},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\YPXMUNDX\\Apidianaki and Van de Cruys - 2011 - A Quantitative Evaluation of Global Word Sense Ind.pdf}
}

@article{arppe.etal_2010,
  title = {Cognitive {{Corpus Linguistics}}: Five Points of Debate on Current Theory and Methodology},
  shorttitle = {Cognitive {{Corpus Linguistics}}},
  author = {Arppe, Antti and Gilquin, Gaëtanelle and Glynn, Dylan and Hilpert, Martin and Zeschel, Arne},
  date = {2010-05},
  journaltitle = {Corpora},
  volume = {5},
  number = {1},
  pages = {1--27},
  issn = {1749-5032, 1755-1676},
  langid = {english}
}

@incollection{barcelona_2015,
  title = {Metonymy},
  booktitle = {Handbook of {{Cognitive Linguistics}}},
  author = {Barcelona, Antonio},
  editor = {Dabrowska, Ewa and Divjak, Dagmar},
  date = {2015-01-31},
  pages = {143--167},
  publisher = {{De Gruyter}},
  location = {{Berlin; München; Boston}},
  isbn = {978-3-11-029202-2}
}

@inproceedings{baroni.etal_2014,
  title = {Don't Count, Predict! {{A}} Systematic Comparison of Context-Counting vs. Context-Predicting Semantic Vectors},
  booktitle = {Proceedings of the 52nd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: Long {{Papers}})},
  author = {Baroni, Marco and Dinu, Georgiana and Kruszewski, Germán},
  date = {2014},
  pages = {238--247},
  publisher = {{Association for Computational Linguistics}},
  location = {{Baltimore, Maryland}},
  abstract = {Context-predicting models (more commonly known as embeddings or neural language models) are the new kids on the distributional semantics block. Despite the buzz surrounding these models, the literature is still lacking a systematic comparison of the predictive models with classic, count-vector-based distributional semantic approaches. In this paper, we perform such an extensive evaluation, on a wide range of lexical semantics tasks and across many parameter settings. The results, to our own surprise, show that the buzz is fully justified, as the context-predicting models obtain a thorough and resounding victory against their count-based counterparts.},
  eventtitle = {Proceedings of the 52nd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: Long {{Papers}})},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\8NE8WIHL\\Baroni et al. - 2014 - Don't count, predict! A systematic comparison of c.pdf}
}

@inproceedings{baroni.lenci_2011,
  title = {How We {{BLESSed}} Distributional Semantic Evaluation},
  booktitle = {Proceedings of the {{GEMS}} 2011 {{Workshop}} on {{Geometrical Models}} of {{Natural Language Semantics}}},
  author = {Baroni, Marco and Lenci, Alessandro},
  date = {2011-07-31},
  pages = {1--10},
  publisher = {{Association for Computational Linguistics}},
  location = {{Edinburgh, Scotland, UK}},
  abstract = {We introduce BLESS, a data set specifically designed for the evaluation of distributional semantic models. BLESS contains a set of tuples instantiating different, explicitly typed semantic relations, plus a number of controlled random tuples. It is thus possible to assess the ability of a model to detect truly related word pairs, as well as to perform in-depth analyses of the types of semantic relations that a model favors. We discuss the motivations for BLESS, describe its construction and structure, and present examples of its usage in the evaluation of distributional semantic models.},
  eventtitle = {{{EMNLP}} 2011},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Documents\\Bibliography\\Baroni y Lenci - How we BLESSed distributional semantic evaluation.pdf}
}

@online{BERT,
  title = {{{BERT}}: Pre-Training of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  date = {2019-05-24},
  eprint = {1810.04805},
  eprinttype = {arxiv},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\JPIUWCYQ\\Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf;C\:\\Users\\u0118974\\Zotero\\storage\\85K98SLY\\1810.html}
}

@book{biber.etal_1998,
  title = {Corpus Linguistics: Investigating Language Structure and Use},
  shorttitle = {Corpus Linguistics},
  author = {Biber, Douglas and Conrad, Susan and Reppen, Randi},
  date = {1998},
  series = {Cambridge Approaches to Linguistics},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge; New York}},
  isbn = {978-0-521-49622-3 978-0-521-49957-6},
  pagetotal = {300},
  keywords = {Computational linguistics,Corpora (Linguistics),Linguistic analysis (Linguistics)}
}

@book{bolognesi_2020,
  title = {Where {{Words Get}} Their {{Meaning}}: Cognitive Processing and Distributional Modelling of Word Meaning in First and Second Language},
  shorttitle = {Where {{Words Get}} Their {{Meaning}}},
  author = {Bolognesi, Marianna},
  date = {2020-11-15},
  series = {Converging {{Evidence}} in {{Language}} and {{Communication Research}}},
  publisher = {{John Benjamins Publishing Company}},
  location = {{Amsterdam}},
  isbn = {978-90-272-0801-9 978-90-272-6042-0},
  langid = {english}
}

@article{bostock.etal_2011,
  title = {{{D}}³ {{Data}}-{{Driven Documents}}},
  author = {Bostock, M. and Ogievetsky, V. and Heer, J.},
  date = {2011-12},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  shortjournal = {IEEE Trans. Visual. Comput. Graphics},
  volume = {17},
  number = {12},
  pages = {2301--2309},
  issn = {1077-2626},
  abstract = {Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\ZK8DLG2A\\Bostock e.a. - 2011 - D³ Data-Driven Documents.pdf}
}

@article{bullinaria.levy_2007,
  title = {Extracting Semantic Representations from Word Co-Occurrence Statistics: A Computational Study},
  shorttitle = {Extracting Semantic Representations from Word Co-Occurrence Statistics},
  author = {Bullinaria, John A. and Levy, Joseph P.},
  date = {2007-08-01},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behavior Research Methods},
  volume = {39},
  number = {3},
  pages = {510--526},
  issn = {1554-3528},
  abstract = {The idea that at least some aspects of word meaning can be induced from patterns of word co-occurrence is becoming increasingly popular. However, there is less agreement about the precise computations involved, and the appropriate tests to distinguish between the various possibilities. It is important that the effect of the relevant design choices and parameter values are understood if psychological models using these methods are to be reliably evaluated and compared. In this article, we present a systematic exploration of the principal computational possibilities for formulating and validating representations of word meanings from word co-occurrence statistics. We find that, once we have identified the best procedures, a very simple approach is surprisingly successful and robust over a range of psychologically relevant evaluation measures.},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\INNN5B2A\\Bullinaria y Levy - 2007 - Extracting semantic representations from word co-o.pdf}
}

@inproceedings{campello.etal_2013,
  title = {Density-{{Based Clustering Based}} on {{Hierarchical Density Estimates}}},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Campello, Ricardo J. G. B. and Moulavi, Davoud and Sander, Joerg},
  editor = {Pei, Jian and Tseng, Vincent S. and Cao, Longbing and Motoda, Hiroshi and Xu, Guandong},
  date = {2013},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {160--172},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  abstract = {We propose a theoretically and practically improved density-based, hierarchical clustering method, providing a clustering hierarchy from which a simplified tree of significant clusters can be constructed. For obtaining a “flat” partition consisting of only the most significant clusters (possibly corresponding to different density thresholds), we propose a novel cluster stability measure, formalize the problem of maximizing the overall stability of selected clusters, and formulate an algorithm that computes an optimal solution to this problem. We demonstrate that our approach outperforms the current, state-of-the-art, density-based clustering methods on a wide variety of real world data.},
  isbn = {978-3-642-37456-2},
  langid = {english},
  keywords = {Cluster Tree,Core Object,Density Threshold,Hierarchical Cluster Method,Minimum Span Tree},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\S5V7562X\\Campello et al. - 2013 - Density-Based Clustering Based on Hierarchical Den.pdf}
}

@book{card.etal_1999,
  title = {Readings in Information Visualization: Using Vision to Think},
  shorttitle = {Readings in Information Visualization},
  author = {Card, Stuart K. and Mackinlay, Jock D. and Shneiderman, Ben},
  date = {1999},
  series = {The {{Morgan Kaufmann}} Series in Interactive Technologies},
  publisher = {{Morgan Kaufmann Publishers}},
  location = {{San Francisco, Calif}},
  isbn = {978-1-55860-533-6},
  keywords = {Computer graphics,Image processing,Information visualization}
}

@inproceedings{church.hanks_1989,
  title = {Word Association Norms, Mutual Information, and Lexicography},
  booktitle = {{{ACL}} '89: Proceedings of the 27th Annual Meeting on {{Association}} for {{Computational Linguistic}}},
  author = {Church, Kenneth Ward and Hanks, Patrick},
  date = {1989-06},
  pages = {76--83},
  publisher = {{Association for Computational Linguistics}},
  abstract = {The term word association is used in a very particular sense in the psycholinguistic literature. (Generally speaking, subjects respond quicker than normal to the word nurse if it follows a highly associated word such as doctor.) We will extend the term to provide the basis for a statistical description of a variety of interesting linguistic phenomena, ranging from semantic relations of the doctor/nurse type (content word/content word) to lexico-syntactic co-occurrence constraints between verbs and prepositions (content word/function word). This paper will propose an objective measure based on the information theoretic notion of mutual information, for estimating word association norms from computer readable corpora. (The standard method of obtaining word association norms, testing a few thousand :mbjects on a few hundred words, is both costly and unreliable.) The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words.},
  langid = {english}
}

@incollection{cox.cox_2008,
  title = {Multidimensional {{Scaling}}},
  booktitle = {Handbook of Data Visualization},
  author = {Cox, Michael A. A. and Cox, Trevor F.},
  editor = {Chen, Chun-houh and Härdle, Wolfgang and Unwin, Antony},
  date = {2008},
  series = {Springer Handbooks of Computational Statistics},
  pages = {315--348},
  publisher = {{Springer}},
  location = {{Berlin}},
  isbn = {978-3-540-33036-3},
  keywords = {Information visualization},
  annotation = {OCLC: ocm76799021}
}

@incollection{croft_2003,
  title = {The Role of Domains in the Interpretation of Metaphors and Metonymies},
  booktitle = {Metaphor and Metonymy in Comparison and Contrast},
  author = {Croft, William},
  editor = {Dirven, René and Pörings, Ralf},
  date = {2003},
  series = {Mouton Reader},
  pages = {161--206},
  publisher = {{Mouton de Gruyter}},
  location = {{Berlin; New York, NY}},
  isbn = {978-3-11-017374-1 3-11-017374-3 978-3-11-017374-1},
  langid = {english},
  keywords = {11.1a;12.1a;11.3a,Aufsatzsammlung,Kognitive Linguistik,Metapher,Metaphor,Metonymie,Metonyms}
}

@thesis{depascale_2019,
  type = {PhD Dissertation},
  title = {Token-Based Vector Space Models as Semantic Control in Lexical Lectometry},
  author = {De Pascale, S.},
  date = {2019},
  institution = {{KU Leuven}},
  location = {{Leuven}},
  abstract = {Type-based distributional semantics as embodied in vector space models has proven to be a successful method for the retrieval of near-synonyms in large corpora. These words have then been used as variants of lexical sociolinguistic variables (e.g.: return and winst for the concept profit) in lectometric studies, that is, the aggregate-level study of lexical distances between linguistic varieties, in particular pluricentric languages such as Dutch. However, a limitation of type-based vector space models is that all senses of a word are lumped together into one vector representation, making it harder to control for polysemy and subtle contextual distinctions. In addition, operating at the lexeme level, these type-based vector space models are not able to pick out the relevant corpus occurrences that are the input for the lectometric distance calculations. The main goal of this PhD project is to introduce token-based vector space models in lexical lectometric research, in order to gain better semantic control during the composition of lexical variables. Token-based vector space models address the abovementioned shortcomings by disambiguating different senses of lexical variants. This technique is able to model the semantics of individual tokens (i.e. 'usage occurrences') of a word in a corpus and to represent them as token clouds in multidimensional vector space, with clusters of tokens revealing distinct senses of the word. By superimposing the token clouds of the lexical variants, one can distinguish which meanings are shared by near-synonyms and determine the 'semantic envelope of variation' of the lexical alternation. For instance, the variant return is polysemous in Netherlandic Dutch, with the two readings 'profit' and 'return game', but not in Belgian Dutch, where only the 'profit' sense is found. By isolating the cluster of tokens with the meaning 'profit' one can identify the near-synonymous tokens of the variants winst and return. The fine-tuning of vector space model-based lectometry targeted in this PhD contributes to the scaling up of lexical variationist research, by providing methods for dealing with corpora whose size exceeds manual analysis. At the same time, token-based models comply with the need of detailed analysis by allowing to zoom in on the behavior of individual tokens in order to determine more subtle contextual distinctions. This PhD project is situated in a larger research endeavor ("Nephological Semantics - Using token clouds for meaning detection in variationist linguistics", BOF C1 project 3H150305) that aims at detailed understanding of token-based vector representations for lexical, semantic and variational research.},
  editora = {Marzo, S. and Speelman, D.},
  editoratype = {collaborator},
  langid = {english}
}

@book{desaussure_1971,
  title = {Cours de Linguistique Génerale},
  author = {de Saussure, Ferdinand},
  editor = {Bally, Charles and Sechehaye, Albert},
  options = {useprefix=true},
  date = {1971},
  origdate = {1916},
  publisher = {{Payot}},
  location = {{Paris}}
}

@online{devries.etal_2019,
  title = {{{BERTje}}: A {{Dutch BERT Model}}},
  shorttitle = {{{BERTje}}},
  author = {de Vries, Wietse and van Cranenburgh, Andreas and Bisazza, Arianna and Caselli, Tommaso and van Noord, Gertjan and Nissim, Malvina},
  options = {useprefix=true},
  date = {2019-12-19},
  eprint = {1912.09582},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {The transformer-based pre-trained language model BERT has helped to improve state-of-the-art performance on many natural language processing (NLP) tasks. Using the same architecture and parameters, we developed and evaluated a monolingual Dutch BERT model called BERTje. Compared to the multilingual BERT model, which includes Dutch but is only based on Wikipedia text, BERTje is based on a large and diverse dataset of 2.4 billion tokens. BERTje consistently outperforms the equally-sized multilingual BERT model on downstream NLP tasks (part-of-speech tagging, named-entity recognition, semantic role labeling, and sentiment analysis). Our pre-trained Dutch BERT model is made available at https://github.com/wietsedv/bertje.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\NMLQUI35\\de Vries et al. - 2019 - BERTje A Dutch BERT Model.pdf;C\:\\Users\\u0118974\\Zotero\\storage\\IN2WYIBF\\1912.html}
}

@incollection{divjak.fieller_2014,
  title = {Cluster Analysis: Finding Structure in Linguistic Data},
  booktitle = {Corpus Methods for Semantics: Quantitative Studies in Polysemy and Synonymy},
  author = {Divjak, Dagmar and Fieller, Nick},
  editor = {Glynn, Dylan and Robinson, Justyna A.},
  date = {2014},
  series = {Human Cognitive Processing},
  number = {volume 43},
  pages = {405--441},
  publisher = {{John Benjamins Publishing Company}},
  location = {{Amsterdam; Philadelphia}},
  isbn = {978-90-272-2397-5},
  keywords = {Cognitive grammar,Computational linguistics,Corpora (Linguistics),Polysemy,Semantics}
}

@incollection{evert_2009,
  title = {58. {{Corpora}} and Collocations},
  booktitle = {Corpus {{Linguistics}}. {{An International Handbook}}},
  author = {Evert, Stefan},
  editor = {Lüdeling, Anke and Kytö, Merja},
  date = {2009-03-18},
  series = {Handbooks of {{Linguistics}} and {{Communication Science}}},
  volume = {2},
  pages = {1212--1248},
  publisher = {{Mouton de Gruyter}},
  location = {{Berlin; New York}},
  isbn = {978-3-11-021388-1}
}

@incollection{firth_1957a,
  title = {A Synopsis of Linguistic Theory 1930-1955},
  booktitle = {Studies in {{Linguistic Analysis}}},
  author = {Firth, John Rupert},
  editor = {Firth, John Rupert},
  date = {1957},
  series = {Special Volume of the {{Philological Society}}},
  pages = {1--32},
  publisher = {{Blackwell}},
  location = {{Oxford}},
  isbn = {978-0-631-11300-3},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\QXEJHCGN\\lecture1-firth.pdf}
}

@article{fleiss_1971,
  title = {Measuring Nominal Scale Agreement among Many Raters.},
  author = {Fleiss, Joseph L.},
  date = {1971},
  journaltitle = {Psychological Bulletin},
  shortjournal = {Psychological Bulletin},
  volume = {76},
  number = {5},
  pages = {378--382},
  issn = {0033-2909},
  langid = {english}
}

@article{gablasova.etal_2017,
  title = {Collocations in {{Corpus}}-{{Based Language Learning Research}}: Identifying, {{Comparing}}, and {{Interpreting}} the {{Evidence}}: Collocations in {{Corpus}}-{{Based Language Learning Research}}},
  shorttitle = {Collocations in {{Corpus}}-{{Based Language Learning Research}}},
  author = {Gablasova, Dana and Brezina, Vaclav and McEnery, Tony},
  date = {2017-02},
  journaltitle = {Language Learning},
  issn = {00238333},
  abstract = {This article focuses on the use of collocations in language learning research (LLR). Collocations, as units of formulaic language, are becoming prominent in our understanding of language learning and use; however, while the number of corpus-based LLR studies of collocations is growing, there is still a need for a deeper understanding of factors that play a role in establishing that two words in a corpus can be considered to be collocates. In this article we critically review both the application of measures used to identify collocability between words and the nature of the relationship between two collocates. Particular attention is paid to the comparison of collocability across different corpora representing different genres, registers, or modalities. Several issues involved in the interpretation of collocational patterns in the production of first language and second language users are also considered. Reflecting on the current practices in the field, further directions for collocation research are proposed.},
  langid = {english}
}

@incollection{geeraerts_1988,
  title = {Where Does Prototypicality Come From?},
  booktitle = {Current {{Issues}} in {{Linguistic Theory}}},
  author = {Geeraerts, Dirk},
  editor = {Rudzka-Ostyn, Brygida},
  date = {1988},
  volume = {50},
  pages = {207--229},
  publisher = {{John Benjamins Publishing Company}},
  location = {{Amsterdam}},
  isbn = {978-90-272-3544-2 978-90-272-8619-2},
  langid = {english}
}

@article{geeraerts_1993,
  title = {Vagueness's Puzzles, Polysemy's Vagaries},
  author = {Geeraerts, Dirk},
  date = {1993},
  journaltitle = {Cognitive Linguistics},
  volume = {4},
  pages = {223--272}
}

@book{geeraerts_1997,
  title = {Diachronic Prototype Semantics: A Contribution to Historical Lexicology},
  shorttitle = {Diachronic Prototype Semantics},
  author = {Geeraerts, Dirk},
  date = {1997},
  series = {Oxford Studies in Lexicography and Lexicology},
  publisher = {{Clarendon Press; Oxford University Press}},
  location = {{Oxford; New York}},
  isbn = {978-0-19-823652-8},
  keywords = {Cognitive grammar,Linguistic change,Semantics; Historical}
}

@incollection{geeraerts_1999,
  title = {Idealist and Empiricist Tendencies in {{Cognitive Linguistics}}},
  booktitle = {Cognitive {{Linguistics}}: Foundations, {{Scope}}, and {{Methodology}}},
  author = {Geeraerts, Dirk},
  editor = {Janssen, Theo and Redeker, Gisela},
  date = {1999},
  pages = {163--194},
  publisher = {{Mouton de Gruyter}},
  location = {{Berlin}}
}

@incollection{geeraerts_2003,
  title = {The Interaction of Metaphor and Metonymy in Composite Expressions},
  booktitle = {Metaphor and Metonymy in Comparison and Contrast},
  author = {Geeraerts, Dirk},
  editor = {Dirven, René and Pörings, Ralf},
  date = {2003},
  series = {Mouton Reader},
  pages = {435--466},
  publisher = {{Mouton de Gruyter}},
  location = {{Berlin; New York, NY}},
  isbn = {978-3-11-017374-1 3-11-017374-3 978-3-11-017374-1},
  langid = {english},
  keywords = {11.1a;12.1a;11.3a,Aufsatzsammlung,Kognitive Linguistik,Metapher,Metaphor,Metonymie,Metonyms}
}

@incollection{geeraerts_2005,
  title = {Lectal Variation and Empirical Data in {{Cognitive Linguistics}}},
  booktitle = {Cognitive Linguistics: Internal Dynamics and Interdisciplinary Interaction},
  author = {Geeraerts, Dirk},
  editor = {Ruiz de Mendoza Ibáñez, Francisco José and Peña Cervel, M. Sandra},
  date = {2005},
  series = {Cognitive Linguistics Research},
  number = {32},
  pages = {163--189},
  publisher = {{Mouton de Gruyter}},
  location = {{Berlin; New York}},
  isbn = {978-3-11-018617-8 3-11-018617-9},
  keywords = {Cognitive grammar}
}

@incollection{geeraerts_2006b,
  title = {Methodology in {{Cognitive Linguistics}}},
  booktitle = {Cognitive Linguistics: Current Applications and Future Perspectives},
  author = {Geeraerts, Dirk},
  editor = {Kristiansen, Gitte and Achard, Michel and Dirven, René and Ruiz de Mendoza Ibáñez, Francisco José},
  date = {2006},
  series = {Applications of Cognitive Linguistics},
  number = {1},
  pages = {21--49},
  publisher = {{Mouton de Gruyter}},
  location = {{Berlin}},
  isbn = {978-3-11-018950-6 3-11-018951-8 978-3-11-018951-3 3-11-018950-X 978-3-11-018950-6},
  langid = {english},
  keywords = {Aufsatzsammlung,Cognitive grammar,Cognitive grammar Methodology,Kognitive Linguistik,Methodology}
}

@book{geeraerts_2006e,
  title = {Words and Other Wonders: Papers on Lexical and Semantic Topics},
  shorttitle = {Words and Other Wonders},
  author = {Geeraerts, Dirk},
  date = {2006},
  series = {Cognitive Linguistics Research},
  number = {33},
  publisher = {{Mouton de Gruyter}},
  location = {{Berlin; New York}},
  isbn = {978-3-11-019042-7},
  keywords = {Lexicology,Semantics}
}

@incollection{geeraerts_2010,
  title = {The Doctor and the Semantician},
  booktitle = {Quantitative Methods in Cognitive Semantics: Corpus-Driven Approaches},
  author = {Geeraerts, Dirk},
  editor = {Glynn, Dylan and Fischer, Kerstin},
  date = {2010},
  series = {Cognitive Linguistics Research},
  number = {46},
  pages = {63--78},
  publisher = {{De Gruyter Mouton}},
  location = {{Berlin; New York}},
  isbn = {978-3-11-022641-6},
  keywords = {Cognitive grammar,Computational linguistics,Kongress,Semantics}
}

@book{geeraerts_2010a,
  title = {Theories of Lexical Semantics},
  author = {Geeraerts, Dirk},
  date = {2010},
  publisher = {{Oxford University Press}},
  location = {{Oxford; New York}},
  isbn = {978-0-19-870031-9 978-0-19-870030-2},
  pagetotal = {341},
  keywords = {Methodology,Semantics}
}

@incollection{geeraerts_2015a,
  title = {Lexical Semantics},
  booktitle = {Handbook of {{Cognitive Linguistics}}},
  author = {Geeraerts, Dirk},
  editor = {Dabrowska, Ewa and Divjak, Dagmar},
  date = {2015-01-31},
  pages = {273--295},
  publisher = {{De Gruyter}},
  location = {{Berlin; München; Boston}},
  isbn = {978-3-11-029202-2}
}

@incollection{geeraerts_2015b,
  title = {Sense Individuation},
  booktitle = {The {{Routledge Handbook}} of {{Semantics}}},
  author = {Geeraerts, Dirk},
  editor = {Riemer, Nick},
  date = {2015-07-30},
  edition = {1},
  pages = {233--247},
  publisher = {{Routledge}},
  location = {{London}},
  isbn = {978-1-315-68553-3}
}

@article{geeraerts_2016a,
  title = {The Sociosemiotic Commitment},
  author = {Geeraerts, Dirk},
  date = {2016-11-01},
  journaltitle = {Cognitive Linguistics},
  volume = {27},
  number = {4},
  pages = {527--542},
  issn = {0936-5907, 1613-3641},
  abstract = {Abstract             Cognitive Linguistics should complement the Cognitive Commitment with a Sociosemiotic Commitment: a commitment to make one’s account of human language accord with the status of language as a social semiotic, i.\,e., as an intersubjective, historically and socially variable tool, and to base that account on a methodology that likewise transcends the individual. By looking at defining features of Cognitive Linguistics (its cognitive orientation, and its usage-based character), it is argued that the relevance of the Sociosemiotic Commitment derives from the very essence of Cognitive Linguistics.}
}

@incollection{geeraerts_2017,
  title = {Distributionalism, Old and New},
  booktitle = {Each Venture a New Beginning: Studies in Honor of {{Laura A}}. {{Janda}}},
  author = {Geeraerts, Dirk},
  editor = {Makarova, Anastasiia and Dickey, Stephen M. and Divjak, Dagmar},
  date = {2017},
  pages = {29--38},
  publisher = {{Slavica}},
  location = {{Bloomington, Indiana}},
  abstract = {"This volume of essays in Slavic linguistics is presented in honor of Laura A. Janda, Professor of Russian Linguistics at the University of Tromsø, Norway. The majority of the contributions apply the theoretical methodology of cognitive linguistics, of which Janda is one of the world's foremost practitioners, though other contributions could be properly characterized as "fellow travelers", applying different methodologies to achieve similar insights into the semantic structure of Slavic languages"--},
  isbn = {978-0-89357-478-9},
  keywords = {Cognitive grammar,Linguistic models,Slavic languages},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\WBSFNNKF\\Geeraerts - 2017 - Distributionalism, old and new.pdf}
}

@incollection{geeraerts.cuyckens_2007,
  title = {Introducing {{Cognitive Linguistics}}},
  booktitle = {The {{Oxford}} Handbook of Cognitive Linguistics},
  author = {Geeraerts, Dirk and Cuyckens, Hubert},
  editor = {Geeraerts, Dirk and Cuyckens, Hubert},
  date = {2007},
  series = {Oxford Handbooks},
  pages = {3--22},
  publisher = {{Oxford University Press}},
  location = {{Oxford; New York}},
  isbn = {978-0-19-514378-2},
  langid = {english},
  keywords = {Cognitive grammar}
}

@book{geeraerts.cuyckens_2007a,
  title = {The {{Oxford}} Handbook of Cognitive Linguistics},
  editor = {Geeraerts, Dirk and Cuyckens, Hubert},
  date = {2007},
  series = {Oxford Handbooks},
  publisher = {{Oxford University Press}},
  location = {{Oxford; New York}},
  isbn = {978-0-19-514378-2},
  langid = {english},
  keywords = {Cognitive grammar},
  file = {C\:\\Users\\u0118974\\Documents\\Bibliography\\The Oxford Handbook of Cognitive Linguistics.pdf}
}

@book{geeraerts.etal_1994,
  title = {The {{Structure}} of {{Lexical Variation}}: Meaning, {{Naming}}, and {{Context}}},
  shorttitle = {The {{Structure}} of {{Lexical Variation}}},
  author = {Geeraerts, Dirk and Grondelaers, Stefan and Bakema, Peter},
  date = {1994-01-31},
  publisher = {{De Gruyter Mouton}},
  location = {{Berlin; New York}},
  isbn = {978-3-11-087306-1},
  file = {C\:\\Users\\u0118974\\Documents\\Bibliography\\Geeraerts et al. - 1994 - The Structure of Lexical Variation Meaning, Namin.pdf}
}

@book{geeraerts.etal_1999,
  title = {Convergentie en divergentie in de Nederlandse woordenschat: een onderzoek naar kleding- en voetbaltermen},
  shorttitle = {Convergentie en divergentie in de Nederlandse woordenschat},
  author = {Geeraerts, Dirk and Grondelaers, Stefan and Speelman, Dirk},
  date = {1999},
  series = {Publikaties van het Meertens-Instituut},
  number = {31},
  publisher = {{Meertens-Instituut}},
  location = {{Amsterdam}},
  isbn = {978-90-70389-60-4},
  langid = {dutch},
  file = {C\:\\Users\\u0118974\\Documents\\Bibliography\\1999 Convergentie en divergentie in de Nederlandse woordenschat.pdf}
}

@book{gibbs_2008,
  title = {The {{Cambridge}} Handbook of Metaphor and Thought},
  editor = {Gibbs Jr., Raymond W.},
  date = {2008},
  publisher = {{Cambridge University Press}},
  location = {{New York}},
  isbn = {978-0-521-84106-1},
  langid = {english},
  keywords = {Language and culture,Metaphor,Nonverbal communication,Psycholinguistics}
}

@book{gibbs.steen_1999,
  title = {Metaphor in Cognitive Linguistics: Selected Papers from the {{Fifth International Cognitive Linguistics Conference}}, {{Amsterdam}}, {{July}} 1997},
  shorttitle = {Metaphor in Cognitive Linguistics},
  editor = {Gibbs, Jr., Raymond W. and Steen, Gerard},
  date = {1999},
  series = {Amsterdam Studies in the Theory and History of Linguistic Science {{Ser}}. 4},
  number = {175},
  publisher = {{Benjamins}},
  location = {{Amsterdam}},
  isbn = {978-90-272-3681-4 978-1-55619-892-2 978-90-272-3728-6 978-1-58811-126-5},
  langid = {english},
  keywords = {Cognitive grammar,Kognitive Linguistik,Kongress,Language and culture,Metapher,Metaphor}
}

@article{giora_1997,
  title = {Understanding Figurative and Literal Language: The Graded Salience Hypothesis},
  shorttitle = {Understanding Figurative and Literal Language},
  author = {Giora, Rachel},
  date = {1997-01},
  journaltitle = {Cognitive Linguistics},
  volume = {8},
  number = {3},
  pages = {183--206},
  issn = {0936-5907, 1613-3641}
}

@incollection{glynn_2010,
  title = {Corpus-Driven {{Cognitive Semantics}}. {{Introduction}} to the Field},
  booktitle = {Quantitative Methods in Cognitive Semantics: Corpus-Driven Approaches},
  author = {Glynn, Dylan},
  editor = {Glynn, Dylan and Fischer, Kerstin},
  date = {2010},
  series = {Cognitive Linguistics Research},
  number = {46},
  pages = {1--42},
  publisher = {{De Gruyter Mouton}},
  location = {{Berlin; New York}},
  isbn = {978-3-11-022641-6},
  keywords = {Cognitive grammar,Computational linguistics,Kongress,Semantics}
}

@incollection{glynn_2014c,
  title = {The Many Uses of {\emph{Run}}: Corpus Methods and {{Socio}}-{{Cognitive Semantics}}},
  booktitle = {Corpus Methods for Semantics: Quantitative Studies in Polysemy and Synonymy},
  author = {Glynn, Dylan},
  editor = {Glynn, Dylan and Robinson, Justyna A.},
  date = {2014},
  series = {Human Cognitive Processing},
  number = {volume 43},
  pages = {117--144},
  publisher = {{John Benjamins Publishing Company}},
  location = {{Amsterdam; Philadelphia}},
  isbn = {978-90-272-2397-5},
  keywords = {Cognitive grammar,Computational linguistics,Corpora (Linguistics),Polysemy,Semantics}
}

@article{glynn_2016,
  title = {Quantifying Polysemy: Corpus Methodology for Prototype Theory},
  shorttitle = {Quantifying Polysemy},
  author = {Glynn, Dylan},
  date = {2016-11-01},
  journaltitle = {Folia Linguistica},
  volume = {50},
  number = {2},
  pages = {413--447},
  publisher = {{De Gruyter}},
  issn = {1614-7308},
  abstract = {This study addresses the methodological problem of result falsification in Cognitive Semantics, specifically in the descriptive analysis of semasiological variation, or “polysemy”. It argues that manually analysed corpus data can be used to describe models of semantic structure. The method proposed is quantified, permitting repeat analysis. The operationalisation of a semasiological structure employed in the study takes the principle of semantic features and applies them to a contextual analysis of usage-events, associated with the lexeme under scrutiny. The feature analysis, repeated on a large collection of occurrences, results in a set of metadata that constitutes the usage-profile of the lexeme. Multivariate statistics are then employed to identify patterns in those metadata. The case study examines 500 occurrences of the English lexeme annoy . Three basic senses are identified as well as a more complex array of semantic variations linked to morpho-syntactic context of usage.},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\XTYYGQ7B\\html.html}
}

@book{glynn.fischer_2010,
  title = {Quantitative Methods in Cognitive Semantics: Corpus-Driven Approaches},
  shorttitle = {Quantitative Methods in Cognitive Semantics},
  editor = {Glynn, Dylan and Fischer, Kerstin},
  date = {2010},
  series = {Cognitive Linguistics Research},
  number = {46},
  publisher = {{De Gruyter Mouton}},
  location = {{Berlin; New York}},
  isbn = {978-3-11-022641-6},
  keywords = {Cognitive grammar,Computational linguistics,Kongress,Semantics}
}

@book{glynn.robinson_2014,
  title = {Corpus Methods for Semantics: Quantitative Studies in Polysemy and Synonymy},
  shorttitle = {Corpus Methods for Semantics},
  editor = {Glynn, Dylan and Robinson, Justyna A.},
  date = {2014},
  series = {Human Cognitive Processing},
  number = {volume 43},
  publisher = {{John Benjamins Publishing Company}},
  location = {{Amsterdam; Philadelphia}},
  isbn = {978-90-272-2397-5},
  keywords = {Cognitive grammar,Computational linguistics,Corpora (Linguistics),Polysemy,Semantics}
}

@article{gries_2013,
  title = {50-Something Years of Work on Collocations: What Is or Should Be Next…},
  shorttitle = {50-Something Years of Work on Collocations},
  author = {Gries, Stefan Th.},
  date = {2013-05-23},
  journaltitle = {International Journal of Corpus Linguistics},
  volume = {18},
  number = {1},
  pages = {137--166},
  issn = {1384-6655, 1569-9811},
  abstract = {This paper explores ways in which research into collocation should be improved. After a discussion of the parameters underlying the notion of ‘collocation’, the paper has three main parts. First, I argue that corpus linguistics would benefit from taking more seriously the understudied fact that collocations are not necessarily symmetric, as most association measures imply. Also, I introduce an association measure from the associative learning literature that can identify asymmetric collocations and show that it can also distinguish collocations with high and low association strengths well. Second, I summarize some advantages of this measure and brainstorm about ways in which it can help re-examine previous studies as well as support further applications. Finally, I adopt a broader perspective and discuss a variety of ways in which all association measures – directional or not – in corpus linguistics should be improved in order for us to obtain better and more reliable results.},
  langid = {english}
}

@book{gries.stefanowitsch_2006,
  title = {Corpora in Cognitive Linguistics: Corpus-Based Approaches to Syntax and Lexis},
  shorttitle = {Corpora in Cognitive Linguistics},
  editor = {Gries, Stefan Thomas and Stefanowitsch, Anatol},
  date = {2006},
  series = {Trends in Linguistics. {{Studies}} and Monographs},
  number = {172},
  publisher = {{Mouton de Gruyter}},
  location = {{Berlin; New York}},
  isbn = {978-3-11-018605-5},
  keywords = {Cognitive grammar,Data processing}
}

@incollection{grondelaers.etal_2007,
  title = {A Case for a Cognitive Corpus Linguistics},
  booktitle = {Methods in Cognitive Linguistics},
  author = {Grondelaers, Stefan and Geeraerts, Dirk and Speelman, Dirk},
  editor = {Gonzalez-Marquez, Monica and Mittelberg, Irene and Coulson, Seana and Spivey, Michael J.},
  date = {2007},
  series = {Human Cognitive Processing},
  number = {v. 18},
  pages = {149--168},
  publisher = {{John Benjamins Pub}},
  location = {{Amsterdam ; Philadelphia}},
  isbn = {978-90-272-2371-5 978-90-272-2372-2},
  keywords = {Cognitive grammar,Research Methodology}
}

@article{harris_1954,
  title = {Distributional Structure},
  author = {Harris, Zellig S.},
  date = {1954},
  journaltitle = {Word},
  volume = {10},
  number = {2-3},
  pages = {146--162},
  publisher = {{Taylor \& Francis}}
}

@inproceedings{heylen.etal_2012,
  title = {Looking at Word Meaning. {{An}} Interactive Visualization of {{Semantic Vector Spaces}} for {{Dutch}} Synsets},
  booktitle = {Proceedings of the Eacl 2012 {{Joint Workshop}} of {{LINGVIS}} \& {{UNCLH}}},
  author = {Heylen, Kris and Speelman, Dirk and Geeraerts, Dirk},
  date = {2012},
  pages = {16--24},
  location = {{Avignon}},
  abstract = {In statistical NLP, Semantic Vector Spaces (SVS) are the standard technique for the automatic modeling of lexical semantics. However, it is largely unclear how these black-box techniques exactly capture word meaning. To explore the way an SVS structures the individual occurrences of words, we use a non-parametric MDS solution of a token-by-token similarity matrix. The MDS solution is visualized in an interactive plot with the Google Chart Tools. As a case study, we look at the occurrences of 476 Dutch nouns grouped in 214 synsets.},
  eventtitle = {{{EACL}}},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\UU62B9N7\\Heylen et al. - Looking at word meaning. An interactive visualizat.pdf}
}

@article{heylen.etal_2015,
  title = {Monitoring Polysemy: Word Space Models as a Tool for Large-Scale Lexical Semantic Analysis},
  shorttitle = {Monitoring Polysemy},
  author = {Heylen, Kris and Wielfaert, Thomas and Speelman, Dirk and Geeraerts, Dirk},
  date = {2015-04},
  journaltitle = {Lingua},
  volume = {157},
  pages = {153--172},
  issn = {00243841},
  langid = {english}
}

@article{hilpert.correiasaavedra_2017,
  title = {Using Token-Based Semantic Vector Spaces for Corpus-Linguistic Analyses: From Practical Applications to Tests of Theoretical Claims},
  shorttitle = {Using Token-Based Semantic Vector Spaces for Corpus-Linguistic Analyses},
  author = {Hilpert, Martin and Correia Saavedra, David},
  date = {2017-09-26},
  journaltitle = {Corpus Linguistics and Linguistic Theory},
  volume = {16},
  number = {2},
  issn = {1613-7027, 1613-7035},
  abstract = {This paper presents token-based semantic vector spaces as a tool that can be applied in corpus-linguistic analyses such as word sense comparisons, comparisons of synonymous lexical items, and matching of concordance lines with a given text. We demonstrate how token-based semantic vector spaces are created, and we illustrate the kinds of result that can be obtained with this approach. Our main argument is that token-based semantic vector spaces are not only useful for practical corpus-linguistic applications but also for the investigation of theory-driven questions. We illustrate this point with a discussion of the asymmetric priming hypothesis (Jäger and Rosenbach 2008). The asymmetric priming hypothesis, which states that grammaticalizing constructions will be primed by their lexical sources but not vice versa, makes a number of empirically testable predictions. We operationalize and test these predictions, concluding that token-based semantic vector spaces yield conclusions that are relevant for linguistic theory-building.},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\RKE3RQAB\\Hilpert y Correia Saavedra - 2017 - Using token-based semantic vector spaces for corpu.pdf}
}

@article{hilpert.flach_2020,
  title = {Disentangling Modal Meanings with Distributional Semantics},
  author = {Hilpert, Martin and Flach, Susanne},
  date = {2020-05-13},
  journaltitle = {Digital Scholarship in the Humanities},
  shortjournal = {Digital Scholarship in the Humanities},
  issn = {2055-7671},
  abstract = {This article investigates the collocational behavior of English modal auxiliaries such as may and might with the aim of finding corpus-based measures that distinguish between different modal expressions and that allow insights into why speakers may choose one over another in a given context. The analysis uses token-based semantic vector space modeling (Heylen et al., 2015, Monitoring polysemy. Word space models as a tool for large-scale lexical semantic analysis. Lingua, 157: 153–72; Hilpert and Correia Saavedra, 2017, Using token-based semantic vector spaces for corpus-linguistic analyses: From practical applications to tests of theoretical claims. Corpus Linguistics and Linguistic Theory) in order to determine whether different modal auxiliaries can be distinguished in terms of their collocational profiles. The analysis further examines whether different senses of the same auxiliary exhibit divergent collocational preferences. The results indicate that near-synonymous pairs of modal expressions, such as may and might or must and have to, differ in their distributional characteristics. Also, different senses of the same modal expression, such as deontic and epistemic uses of may, can be distinguished on the basis of distributional information. We discuss these results against the background of previous empirical findings (Hilpert, 2016, Construction Grammar and its Application to English, 2nd edn. Edinburgh: Edinburgh University Press, Flach, in press, Beyond modal idioms and modal harmony: a corpus-based analysis of gradient idiomaticity in modal-adverb collocations. English Language and Linguistics) and theoretical issues such as degrees of grammaticalization (Correia Saavedra, 2019, Measurements of Grammaticalization: Developing a Quantitative Index for the Study of Grammatical Change. PhD Dissertation, Université de Neuchâtel) and the avoidance of synonymy (Bolinger, 1968, Entailment and the meaning of structures. Glossa, 2(2): 119–27).},
  issue = {fqaa014},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\PFI628UU\\Hilpert en Flach - 2020 - Disentangling modal meanings with distributional s.pdf;C\:\\Users\\u0118974\\Zotero\\storage\\YXNIE5BL\\5836757.html}
}

@article{hothorn.etal_2006,
  title = {Unbiased {{Recursive Partitioning}}: A {{Conditional Inference Framework}}},
  shorttitle = {Unbiased {{Recursive Partitioning}}},
  author = {Hothorn, Torsten and Hornik, Kurt and Zeileis, Achim},
  date = {2006-09},
  journaltitle = {Journal of Computational and Graphical Statistics},
  shortjournal = {Journal of Computational and Graphical Statistics},
  volume = {15},
  number = {3},
  pages = {651--674},
  issn = {1061-8600, 1537-2715},
  doi = {10.1198/106186006X133933},
  langid = {english}
}

@book{ibarretxe-antunano.valenzuela_2016,
  title = {Lingüística cognitiva},
  editor = {Ibarretxe-Antuñano, Iraide and Valenzuela, Javier},
  date = {2016},
  series = {Autores, textos y temas Filosofía},
  edition = {2da},
  publisher = {{Anthropos Ed}},
  location = {{Barcelona}},
  isbn = {978-84-15260-37-0},
  langid = {spanish},
  keywords = {Kognitive Linguistik},
  annotation = {OCLC: 813204430},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\K273DUQZ\\Ibarretxe-Antuñano - 2012 - Lingüística cognitiva.pdf}
}

@incollection{ibarretxe-antunano.valenzuela_2016a,
  title = {Lingüística cognitiva: origen, principios y tendencias},
  booktitle = {Lingüística cognitiva},
  author = {Ibarretxe-Antuñano, Iraide and Valenzuela, Javier},
  editor = {Ibarretxe-Antuñano, Iraide and Valenzuela, Javier},
  date = {2016},
  series = {Autores, textos y temas Filosofía},
  edition = {2da},
  pages = {13--38},
  publisher = {{Anthropos Ed}},
  location = {{Barcelona}},
  isbn = {978-84-15260-37-0},
  langid = {spanish},
  keywords = {Kognitive Linguistik},
  annotation = {OCLC: 813204430}
}

@book{jurafsky.martin_2020,
  title = {Speech and {{Language Processing}}},
  author = {Jurafsky, Daniel and Martin, James H.},
  date = {2020},
  edition = {3},
  file = {C\:\\Users\\u0118974\\Documents\\Bibliography\\Jurafsky_Martin_2020.pdf}
}

@inbook{kaufman.rousseeuw_1990,
  title = {Partitioning {{Around Medoids}} ({{Program PAM}})},
  booktitle = {Finding {{Groups}} in {{Data}}: An {{Introduction}} to {{Cluster Analysis}}},
  author = {Kaufman, Leonard and Rousseeuw, Peter J.},
  date = {1990-03-08},
  series = {Wiley {{Series}} in {{Probability}} and {{Statistics}}},
  pages = {68--125},
  publisher = {{John Wiley \& Sons, Inc.}},
  location = {{Hoboken, NJ, USA}},
  bookauthor = {Kaufman, Leonard and Rousseeuw, Peter J.},
  isbn = {978-0-470-31680-1 978-0-471-87876-6},
  langid = {english}
}

@inproceedings{kiela.clark_2014,
  title = {A {{Systematic Study}} of {{Semantic Vector Space Model Parameters}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Continuous Vector Space Models}} and Their {{Compositionality}}},
  author = {Kiela, Douwe and Clark, Stephen},
  date = {2014},
  pages = {21--30},
  publisher = {{ACL}},
  location = {{Gothenburg}},
  abstract = {We present a systematic study of parameters used in the construction of semantic vector space models. Evaluation is carried out on a variety of similarity tasks, including a compositionality dataset, using several source corpora. In addition to recommendations for optimal parameters, we present some novel findings, including a similarity metric that outperforms the alternatives on all tasks considered.},
  eventtitle = {{{EACL}} 2014}
}

@article{kilgarriff_1997,
  title = {"{{I}} Don't Believe in Word Senses"},
  author = {Kilgarriff, Adam},
  date = {1997},
  journaltitle = {Computers and the Humanities},
  volume = {31},
  number = {2},
  pages = {91--113},
  doi = {10.1515/9783110895698.361},
  abstract = {Word sense disambiguation assumes word senses. Within the lexicography and lingu literature, they are known to be very slippery entities. The paper looks at problems with ex accounts of 'word sense' and describes the various kinds of ways in which a word's meani deviate from its core meaning. An analysis is presented in which word senses are abstraction clusters of corpus citations, in accordance with current lexicographic practice. The corpus cit not the word senses, are the basic objects in the ontology. The corpus citations will be cluster senses according to the purposes of whoever or whatever does the clustering. In the absence purposes, word senses do not exist. Word sense disambiguation also needs a set of word senses to disambiguate between. In recent work, the set has been taken from a general-purpose lexical resource, with the assu that the lexical resource describes the word senses of English/French/..., between whi applications will need to disambiguate. The implication of the paper is, by contrast, that word exist only relative to a task.},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\K85FHZWU\\Kilgarriff - 2003 - I don't believe in word senses.pdf}
}

@incollection{koptjevskaja-tamm.sahlgren_2014,
  title = {Temperature in the Word Space: Sense Exploration of Temperature Expressions Using Word-Space Modelling},
  shorttitle = {Temperature in the Word Space},
  booktitle = {Aggregating {{Dialectology}}, {{Typology}}, and {{Register Analysis}}},
  author = {Koptjevskaja-Tamm, Maria and Sahlgren, Magnus},
  editor = {Szmrecsanyi, Benedikt and Wälchli, Bernhard},
  date = {2014-01-17},
  pages = {231--267},
  publisher = {{De Gruyter}},
  location = {{Berlin, Boston}},
  isbn = {978-3-11-031755-8},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\5YCM5DQ7\\Koptjevskaja-Tamm en Sahlgren - 2014 - Temperature in the word space Sense exploration o.pdf}
}

@book{kovecses_2000,
  title = {Metaphor and Emotion: Language, Culture, and Body in Human Feeling},
  shorttitle = {Metaphor and Emotion},
  author = {Kövecses, Zoltán},
  date = {2000},
  series = {Studies in Emotion and Social Interaction},
  publisher = {{Cambridge University Press ; Editions de la Maison des sciences de l'homme}},
  location = {{Cambridge, U.K.; New York: Paris}},
  isbn = {0-521-64163-2},
  langid = {english},
  keywords = {Emotions,Emotions and cognition,Language and emotions,Sociological aspects}
}

@book{kovecses_2002,
  title = {Metaphor: A Practical Introduction},
  shorttitle = {Metaphor},
  author = {Kövecses, Zoltán},
  date = {2002},
  publisher = {{Oxford University Press}},
  location = {{New York}},
  isbn = {0-19-514510-0},
  langid = {english},
  keywords = {Metaphor}
}

@book{kovecses_2015,
  title = {Where Metaphors Come from: Reconsidering Context in Metaphor},
  shorttitle = {Where Metaphors Come From},
  author = {Kövecses, Zoltán},
  date = {2015},
  publisher = {{Oxford University Press}},
  location = {{New York, NY}},
  isbn = {978-0-19-022486-8 978-0-19-022487-5 978-0-19-022488-2},
  keywords = {Cognitive grammar,Discourse analysis,Language and languages,Metaphor,Variation}
}

@book{kristiansen.etal_2006,
  title = {Cognitive Linguistics: Current Applications and Future Perspectives},
  shorttitle = {Cognitive Linguistics},
  editor = {Kristiansen, Gitte and Achard, Michel and Dirven, René and Ruiz de Mendoza Ibáñez, Francisco José},
  date = {2006},
  series = {Applications of Cognitive Linguistics},
  number = {1},
  publisher = {{Mouton de Gruyter}},
  location = {{Berlin}},
  isbn = {978-3-11-018950-6 3-11-018951-8 978-3-11-018951-3 3-11-018950-X 978-3-11-018950-6},
  langid = {english},
  keywords = {Aufsatzsammlung,Cognitive grammar,Cognitive grammar Methodology,Kognitive Linguistik,Methodology},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\DEI6J2PS\\Kristiansen - 2006 - Cognitive linguistics current applications and fu.pdf}
}

@article{kruskal_1964,
  title = {Multidimensional Scaling by Optimizing Goodness of Fit to a Nonmetric Hypothesis},
  author = {Kruskal, J. B},
  date = {1964-03},
  journaltitle = {Psychometrika},
  volume = {29},
  number = {1},
  pages = {1--27}
}

@book{lakoff.johnson_2003,
  title = {Metaphors We Live By},
  author = {Lakoff, George and Johnson, Mark},
  date = {2003},
  origdate = {1980},
  publisher = {{University of Chicago Press}},
  location = {{Chicago}},
  isbn = {0-226-46801-1},
  langid = {english},
  keywords = {Concepts,Language and languages,Metaphor,Philosophy,Truth}
}

@article{landauer.dumais_1997,
  title = {A Solution to {{Plato}}'s Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.},
  shorttitle = {A Solution to {{Plato}}'s Problem},
  author = {Landauer, Thomas K. and Dumais, Susan T.},
  date = {1997},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {104},
  number = {2},
  pages = {211--240},
  issn = {1939-1471, 0033-295X},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\WXN9GZJY\\Landauer and Dumais - 1997 - A solution to Plato's problem The latent semantic.pdf}
}

@incollection{langacker_1988,
  title = {An Overview of Cognitive Grammar},
  booktitle = {Current {{Issues}} in {{Linguistic Theory}}},
  author = {Langacker, Ronald W.},
  editor = {Rudzka-Ostyn, Brygida},
  date = {1988},
  volume = {50},
  pages = {3--48},
  publisher = {{John Benjamins Publishing Company}},
  location = {{Amsterdam}},
  isbn = {978-90-272-3544-2 978-90-272-8619-2},
  langid = {english}
}

@book{langacker_2008a,
  title = {Cognitive Grammar: A Basic Introduction},
  shorttitle = {Cognitive Grammar},
  author = {Langacker, Ronald W.},
  date = {2008},
  publisher = {{Oxford University Press}},
  location = {{Oxford; New York}},
  isbn = {978-0-19-533196-7 0-19-533196-6 978-0-19-533195-0 0-19-533195-8},
  keywords = {Cognitive grammar}
}

@inproceedings{lapesa.evert_2013,
  title = {Evaluating {{Neighbor Rank}} and {{Distance Measures}} as {{Predictors}} of {{Semantic Priming}}},
  booktitle = {Proceedings of the {{Fourth Annual Workshop}} on {{Cognitive Modeling}} and {{Computational Linguistics}} ({{CMCL}})},
  author = {Lapesa, Gabriella and Evert, Stefan},
  date = {2013-08},
  pages = {66--74},
  publisher = {{Association for Computational Linguistics}},
  location = {{Sofia, Bulgaria}},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\8GBI63C4\\Lapesa y Evert - 2013 - Evaluating Neighbor Rank and Distance Measures as .pdf}
}

@article{lapesa.evert_2014,
  title = {A {{Large Scale Evaluation}} of {{Distributional Semantic Models}}: Parameters, {{Interactions}} and {{Model Selection}}},
  shorttitle = {A {{Large Scale Evaluation}} of {{Distributional Semantic Models}}},
  author = {Lapesa, Gabriella and Evert, Stefan},
  date = {2014-12-01},
  journaltitle = {Transactions of the Association for Computational Linguistics},
  shortjournal = {Transactions of the Association for Computational Linguistics},
  volume = {2},
  pages = {531--546},
  issn = {2307-387X},
  abstract = {This paper presents the results of a large-scale evaluation study of window-based Distributional Semantic Models on a wide variety of tasks. Our study combines a broad coverage of model parameters with a model selection methodology that is robust to overfitting and able to capture parameter interactions. We show that our strategy allows us to identify parameter configurations that achieve good performance across different datasets and tasks.},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\38LFFRYM\\Lapesa and Evert - 2014 - A Large Scale Evaluation of Distributional Semanti.pdf;C\:\\Users\\u0118974\\Zotero\\storage\\98QUEUFB\\A-Large-Scale-Evaluation-of-Distributional.html}
}

@incollection{lemmens_2015,
  title = {Cognitive Semantics},
  booktitle = {The {{Routledge Handbook}} of {{Semantics}}},
  author = {Lemmens, Maarten},
  editor = {Riemer, Nick},
  date = {2015-07-30},
  edition = {1},
  pages = {90--105},
  publisher = {{Routledge}},
  location = {{London}},
  isbn = {978-1-315-68553-3}
}

@article{lenci_2008,
  title = {Distributional Semantics in Linguistic and Cognitive Research},
  author = {Lenci, Alessandro},
  editor = {Lenci, Alessandro},
  date = {2008},
  journaltitle = {Italian Journal of Linguistics},
  volume = {20},
  number = {1},
  pages = {1--31},
  issn = {2499-8125},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\D4HFZBX4\\Lenci - Distributional semantics in linguistic and cogniti.pdf}
}

@article{lenci_2018,
  title = {Distributional {{Models}} of {{Word Meaning}}},
  author = {Lenci, Alessandro},
  date = {2018-01-14},
  journaltitle = {Annual Review of Linguistics},
  volume = {4},
  number = {1},
  pages = {151--171},
  issn = {2333-9683, 2333-9691},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\YRSW9EUM\\Lenci - 2018 - Distributional Models of Word Meaning.pdf}
}

@book{levshina_2015,
  title = {How to Do Linguistics with {{R}}: Data Exploration and Statistical Analysis},
  shorttitle = {How to Do Linguistics with {{R}}},
  author = {Levshina, Natalia},
  date = {2015},
  publisher = {{John Benjamins Publishing Company}},
  location = {{Amsterdam; Philadelphia}},
  isbn = {978-90-272-1224-5 978-90-272-1225-2},
  pagetotal = {443},
  keywords = {Computational linguistics,Linguistics,Methodology,Software,Statistical methods}
}

@article{levy.etal_2015,
  title = {Improving {{Distributional Similarity}} with {{Lessons Learned}} from {{Word Embeddings}}},
  author = {Levy, Omer and Goldberg, Yoav and Dagan, Ido},
  date = {2015},
  journaltitle = {Transactions of the Association for Computational Linguistics},
  volume = {3},
  pages = {211--225},
  abstract = {Recent trends suggest that neural-network-inspired word embedding models outperform traditional count-based distributional models on word similarity and analogy detection tasks. We reveal that much of the performance gains of word embeddings are due to certain system design choices and hyperparameter optimizations, rather than the embedding algorithms themselves. Furthermore, we show that these modifications can be transferred to traditional distributional models, yielding similar gains. In contrast to prior reports, we observe mostly local or insignificant performance differences between the methods, with no global advantage to any single approach over the others.},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\WBH54C2Q\\Levy et al. - 2015 - Improving Distributional Similarity with Lessons L.pdf}
}

@book{manning.schutze_1999,
  title = {Foundations of Statistical Natural Language Processing},
  author = {Manning, Christopher D. and Schütze, Hinrich},
  date = {1999},
  publisher = {{MIT Press}},
  location = {{Cambridge, Mass}},
  isbn = {978-0-262-13360-9},
  pagetotal = {680},
  keywords = {Computational linguistics,Statistical methods}
}

@book{mcenery.etal_2010,
  title = {Corpus-Based Language Studies: An Advanced Resource Book},
  shorttitle = {Corpus-Based Language Studies},
  author = {McEnery, Tony and Xiao, Richard and Tono, Yukio},
  date = {2010},
  series = {Routledge Applied Linguistics},
  edition = {Reprinted},
  publisher = {{Routledge}},
  location = {{London}},
  isbn = {978-0-415-28623-7},
  langid = {english},
  keywords = {Aufsatzsammlung,Computational linguistics,Corpora (Linguistics),Englisch,Korpus,Lehrbuch,Linguistics Methodology},
  annotation = {OCLC: 642930078},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\EUMQ27M5\\McEnery et al. - 2010 - Corpus-based language studies an advanced resourc.pdf}
}

@book{mcenery.hardie_2012,
  title = {Corpus Linguistics: Method, Theory and Practice},
  shorttitle = {Corpus Linguistics},
  author = {McEnery, Tony and Hardie, Andrew},
  date = {2012},
  series = {Cambridge Textbooks in Linguistics},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge; New York}},
  abstract = {"Corpus linguistics is the study of language data on a large scale - the computer-aided analysis of very extensive collections of transcribed utterances or written texts. This textbook outlines the basic methods of corpus linguistics, explains how the discipline of corpus linguistics developed, and surveys the major approaches to the use of corpus data. It uses a broad range of examples to show how corpus data has led to methodological and theoretical innovation in linguistics in general. Clear and detailed explanations lay out the key issues of method and theory in contemporary corpus linguistics. A structured and coherent narrative links the historical development of the field to current topics in 'mainstream' linguistics. Practical activities and questions for discussion at the end of each chapter encourage students to test their understanding of what they have read and an extensive glossary provides easy access to definitions of technical terms used in the text"--},
  isbn = {978-0-521-83851-1 978-0-521-54736-9},
  keywords = {Corpora (Linguistics)}
}

@online{mcinnes.etal_2016,
  title = {How {{HDBSCAN Works}} — Hdbscan 0.8.1 Documentation},
  author = {McInnes, Leland and Healy, John and Astels, Steve},
  date = {2016},
  url = {https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html},
  urldate = {2021-04-30},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\3RQD77MC\\how_hdbscan_works.html}
}

@online{mcinnes.etal_2020,
  title = {{{UMAP}}: Uniform {{Manifold Approximation}} and {{Projection}} for {{Dimension Reduction}}},
  shorttitle = {{{UMAP}}},
  author = {McInnes, Leland and Healy, John and Melville, James},
  date = {2020-09-17},
  eprint = {1802.03426},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Geometry,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\BMKPHHQG\\McInnes et al. - 2020 - UMAP Uniform Manifold Approximation and Projectio.pdf;C\:\\Users\\u0118974\\Zotero\\storage\\636HTZJW\\1802.html}
}

@online{mikolov.etal_2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  date = {2013-09-06},
  eprint = {1301.3781},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\5BUQJ7V7\\Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf;C\:\\Users\\u0118974\\Zotero\\storage\\XZ9HNWEV\\1301.html}
}

@incollection{mittelberg_2007,
  title = {Methodology for Multimodality: One Way of Working with Speech and Gesture Data},
  booktitle = {Methods in Cognitive Linguistics},
  author = {Mittelberg, Irene},
  editor = {Gonzalez-Marquez, Monica and Mittelberg, Irene and Coulson, Seana and Spivey, Michael J.},
  date = {2007},
  series = {Human Cognitive Processing},
  number = {v. 18},
  pages = {225--249},
  publisher = {{John Benjamins Pub}},
  location = {{Amsterdam; Philadelphia}},
  isbn = {978-90-272-2371-5 978-90-272-2372-2},
  keywords = {Cognitive grammar,Research Methodology},
  annotation = {OCLC: ocm73743935}
}

@thesis{montes_2016,
  type = {Trabajo final monográfico de licenciatura},
  title = {Uso metaforico della temperatura nell'italiano scritto contemporaneo},
  author = {Montes, Mariana},
  date = {2016},
  institution = {{Universidad Nacional de Córdoba}},
  location = {{Córdoba}},
  editora = {Bortolon, Mariela},
  editoratype = {collaborator},
  langid = {italian}
}

@incollection{montes.heylen_2022,
  title = {Visualizing {{Distributional Semantics}}},
  booktitle = {Data {{Analytics}} in {{Cognitive Linguistics}}. {{Methods}} and {{Insights}}},
  author = {Montes, Mariana and Heylen, Kris},
  editor = {Tay, Dennis and Pan, Molly Xie},
  date = {2022},
  publisher = {{Mouton De Gruyter}},
  isbn = {978-3-11-068734-7},
  langid = {english},
  pubstate = {Accepted},
  annotation = {Submitted Date: 2020-12-30 Accepted Date: 2021-08-12}
}

@software{montes.qlvl_2021,
  title = {{{QLVL}}/{{NephoVis}}: Stratocumulus},
  shorttitle = {{{QLVL}}/{{NephoVis}}},
  author = {Montes, Mariana and QLVL},
  date = {2021-04-29},
  doi = {10.5281/ZENODO.4726926},
  abstract = {Relatively viable version, especially for levels 1 and 2.},
  organization = {{Zenodo}},
  version = {0.0.1}
}

@article{newman_2011,
  title = {Corpora and Cognitive Linguistics},
  author = {Newman, John},
  date = {2011},
  journaltitle = {Revista Brasileira de Linguística Aplicada},
  shortjournal = {Rev. bras. linguist. apl.},
  volume = {11},
  number = {2},
  pages = {521--559},
  issn = {1984-6398},
  abstract = {Corpora are a natural source of data for cognitive linguists, since corpora, more than any other source of data, reflect "usage" - a notion which is often claimed to be of critical importance to the field of cognitive linguistics. Corpora are relevant to all the main topics of interest in cognitive linguistics: metaphor, polysemy, synonymy, prototypes, and constructional analysis. I consider each of these topics in turn and offer suggestions about which methods of analysis can be profitably used with available corpora to explore these topics further. In addition, I consider how the design and content of currently used corpora need to be rethought if corpora are to provide all the types of usage data that cognitive linguists require.           ,              Corpora são uma fonte natural de dados para a linguística cognitiva, uma vez que, estes, mais que qualquer outra fonte de dados, refletem "o uso" - a noção que é frequentemente apontada como tendo importância crítica para o campo da linguística cognitiva. Corpora são relevantes para todos os principais tópicos de interesse da linguística cognitiva: metáfora, polissemia, sinonímia, protótipos e análise construcional. Neste artigo, considerarei cada um desses tópicos e oferecerei sugestões sobre quais os métodos de análise podem ser utilizados com os corpora disponíveis para melhor se explorarem esses tópicos. Adicionalmente, discuto como a arquitetura e o conteúdo dos corpora atualmente disponíveis necessitam ser repensados se pretenderem oferecer todos os tipos de dados de uso necessários às análises da linguística cognitiva.},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\2RGIUC35\\Newman - 2011 - Corpora and cognitive linguistics.pdf}
}

@incollection{newman_2015,
  title = {Semantic Shift},
  booktitle = {The {{Routledge Handbook}} of {{Semantics}}},
  author = {Newman, John},
  editor = {Riemer, Nick},
  date = {2015-07-30},
  edition = {1},
  pages = {266--280},
  publisher = {{Routledge}},
  location = {{London}},
  isbn = {978-1-315-68553-3}
}

@online{okabe.ito_2002,
  title = {Color {{Universal Design}} ({{CUD}}). {{How}} to Make Figures and Presentations That Are Friendly to {{Colorblind}} People},
  author = {Okabe, Masataka and Ito, Kei},
  date = {2002-11-20},
  url = {https://jfly.uni-koeln.de/color/},
  urldate = {2021-07-13},
  organization = {{J*Fly Data Depository for Drosophila researchers}},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\APCF9CQU\\color.html}
}

@article{ordelman.etal_2007,
  title = {{{TwNC}}: A Multifaceted Dutch News Corpus},
  author = {Ordelman, Roeland J.F. and de Jong, Franciska M.G. and van Hessen, Adrianus J. and Hondorp, G.H.W.},
  options = {useprefix=true},
  date = {2007},
  journaltitle = {ELRA Newsletter},
  volume = {12},
  number = {3-4},
  abstract = {This contribution describes the Twente News Corpus (TwNC), a multifaceted corpus for Dutch that is being deployed in a number of NLP research projects among which tracks within the Dutch national research programme MultimediaN, the NWO programme CATCH, and the Dutch-Flemish programme STEVIN. The development of the corpus started in 1998 within a predecessor project DRUID and has currently a size of 530M words. The text part has been built from texts of four different sources: Dutch national newspapers, television subtitles, teleprompter (auto-cues) files, and both manually and automatically generated broadcast news transcripts along with the broadcast news audio. TwNC plays a crucial role in the development and evaluation of a wide range of tools and applications for the domain of multimedia indexing, such as large vocabulary speech recognition, cross-media indexing, cross-language information retrieval etc. Part of the corpus was fed into the Dutch written text corpus in the context of the Dutch-Belgian STEVIN project D-COI that was completed in 2007. The sections below will describe the rationale that was the starting point for the corpus development; it will outline the cross-media linking approach adopted within MultimediaN, and finally provide some facts and figures about the corpus.},
  langid = {english},
  keywords = {EWI-15098,HMI-MR: MULTIMEDIA RETRIEVAL,IR-68090,Multimedia Retrieval,Speech Recognition,Text corpora}
}

@online{oskolkov_2021,
  title = {How {{Exactly UMAP Works}}},
  author = {Oskolkov, Nikolay},
  date = {2021-03-10T20:32:25},
  url = {https://towardsdatascience.com/how-exactly-umap-works-13e3040e1668},
  urldate = {2021-05-07},
  abstract = {And why exactly it is better than tSNE},
  langid = {english},
  organization = {{Medium}},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\2RHABLHP\\how-exactly-umap-works-13e3040e1668.html}
}

@inproceedings{pantel.lin_2002,
  title = {Discovering Word Senses from Text},
  booktitle = {Proceedings of the Eighth {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining  - {{KDD}} '02},
  author = {Pantel, Patrick and Lin, Dekang},
  date = {2002},
  pages = {613},
  publisher = {{ACM Press}},
  location = {{Edmonton, Alberta, Canada}},
  eventtitle = {The Eighth {{ACM SIGKDD}} International Conference},
  isbn = {978-1-58113-567-1},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\GBI9RSSP\\Pantel and Lin - 2002 - Discovering word senses from text.pdf}
}

@book{panther.etal_2009,
  title = {Metonymy and Metaphor in Grammar},
  editor = {Panther, Klaus-Uwe and Thornburg, Linda L. and Barcelona, Antonio},
  date = {2009},
  series = {Human Cognitive Processing},
  number = {v. 25},
  publisher = {{John Benjamins Pub. Co}},
  location = {{Amsterdam; Philadelphia}},
  isbn = {978-90-272-2379-1 978-90-272-8935-3},
  pagetotal = {423},
  keywords = {Metaphor,Metonyms}
}

@article{parodi_2008,
  title = {Lingüística de corpus: una introducción al ámbito.},
  author = {Parodi, Giovanni},
  date = {2008},
  journaltitle = {Revista de Lingüística Teórica y Aplicada},
  volume = {46},
  number = {1},
  pages = {93--119},
  langid = {spanish}
}

@article{perek_2016,
  title = {Using Distributional Semantics to Study Syntactic Productivity in Diachrony: A Case Study},
  shorttitle = {Using Distributional Semantics to Study Syntactic Productivity in Diachrony},
  author = {Perek, Florent},
  date = {2016-01-01},
  journaltitle = {Linguistics},
  volume = {54},
  number = {1},
  pages = {149--188},
  publisher = {{De Gruyter Mouton}},
  issn = {0024-3949, 1613-396X},
  abstract = {{$<$}section class="abstract"{$><$}h2 class="abstractTitle text-title my-1" id="d1015e2"{$>$}Abstract{$<$}/h2{$><$}p{$>$}This paper investigates syntactic productivity in diachrony with a data-driven approach. Previous research indicates that syntactic productivity (the property of grammatical constructions to attract new lexical fillers) is largely driven by semantics, which calls for an operationalization of lexical meaning in the context of empirical studies. It is suggested that distributional semantics can fulfill this role by providing a measure of semantic similarity between words that is derived from lexical co-occurrences in large text corpora. On the basis of a case study of the construction “V {$<$}em{$>$}the hell out of{$<$}/em{$>$} NP”, e.g., {$<$}em{$>$}You scared the hell out of me{$<$}/em{$>$}, it is shown that distributional semantics not only appropriately captures how the verbs in the distribution of the construction are related, but also enables the use of visualization techniques and statistical modeling to analyze the semantic development of a construction over time and identify the determinants of syntactic productivity in naturally occurring data.{$<$}/p{$><$}/section{$>$}},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\WBDDWTVV\\Perek - 2016 - Using distributional semantics to study syntactic .pdf;C\:\\Users\\u0118974\\Zotero\\storage\\PSNWLMMP\\article-p149.html}
}

@article{perek_2018,
  title = {Recent Change in the Productivity and Schematicity of the Way-Construction: A Distributional Semantic Analysis},
  shorttitle = {Recent Change in the Productivity and Schematicity of the Way-Construction},
  author = {Perek, Florent},
  date = {2018-04-25},
  journaltitle = {Corpus Linguistics and Linguistic Theory},
  volume = {14},
  number = {1},
  pages = {65--97},
  publisher = {{De Gruyter Mouton}},
  issn = {1613-7027, 1613-7035},
  abstract = {{$<$}section class="abstract"{$><$}h2 class="abstractTitle text-title my-1" id="d1175e2"{$>$}Abstract{$<$}/h2{$><$}p{$>$}This paper presents a corpus-based study of recent change in the English {$<$}em{$>$}way{$<$}/em{$>$}-construction, drawing on data from the 1830s to the 2000s. Semantic change in the distribution of the construction is characterized by means of a distributional semantic model, which captures semantic similarity between verbs through their co-occurrence frequency with other words in the corpus. By plotting and comparing the semantic domain of the three senses of the construction at different points in time, it is found that they all have gained in semantic diversity. These findings are interpreted in terms of increases in schematicity, either of the verb slot or the motion component contributed by the construction.{$<$}/p{$><$}/section{$>$}},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\5VLYNBJI\\Perek - 2018 - Recent change in the productivity and schematicity.pdf;C\:\\Users\\u0118974\\Zotero\\storage\\N27TPI3A\\article-p65.html}
}

@article{perek.hilpert_2017,
  title = {A Distributional Semantic Approach to the Periodization of Change in the Productivity of Constructions},
  author = {Perek, Florent and Hilpert, Martin},
  date = {2017-01-01},
  journaltitle = {International Journal of Corpus Linguistics},
  volume = {22},
  number = {4},
  pages = {490--520},
  publisher = {{John Benjamins}},
  issn = {1384-6655, 1569-9811},
  abstract = {This paper describes a method to automatically identify stages of language change in diachronic corpus data, combining variability-based neighbour clustering, which offers objective and reproducible criteria for periodization, and distributional semantics as a representation of lexical meaning. This method partitions the history of a grammatical construction according to qualitative stages of productivity corresponding to different semantic sets of lexical items attested in it. Two case studies are presented. The first case study on the hell-construction (“Verb the hell out of NP”) shows that the semantic development of a construction does not always match that of its quantitative aspects, like token or type frequency. The second case study on the way-construction compares the results of the present method with those of collostructional analysis. It is shown that the former measures semantic changes and their chronology with greater precision. In sum, this method offers a promising approach to exploring semantic variation in the lexical fillers of constructions and to modelling constructional change.},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\AYFCU3UI\\Perek en Hilpert - 2017 - A distributional semantic approach to the periodiz.pdf}
}

@manual{R-irr,
  type = {manual},
  title = {Irr: Various Coefficients of Interrater Reliability and Agreement},
  author = {Gamer, Matthias and Lemon, Jim and Fellows, Ian and Singh, Puspendra},
  date = {2019},
  url = {https://CRAN.R-project.org/package=irr}
}

@inproceedings{raganato.etal_2017,
  title = {Word {{Sense Disambiguation}}: A {{Unified Evaluation Framework}} and {{Empirical Comparison}}},
  shorttitle = {Word {{Sense Disambiguation}}},
  booktitle = {Proceedings of the 15th {{Conference}} of the {{European Chapter}} of the           {{Association}} for {{Computational Linguistics}}: Volume 1, {{Long Papers}}},
  author = {Raganato, Alessandro and Camacho-Collados, Jose and Navigli, Roberto},
  date = {2017},
  pages = {99--110},
  publisher = {{Association for Computational Linguistics}},
  location = {{Valencia, Spain}},
  abstract = {Word Sense Disambiguation is a longstanding task in Natural Language Processing, lying at the core of human language understanding. However, the evaluation of automatic systems has been problematic, mainly due to the lack of a reliable evaluation framework. In this paper we develop a unified evaluation framework and analyze the performance of various Word Sense Disambiguation systems in a fair setup. The results show that supervised systems clearly outperform knowledge-based models. Among the supervised systems, a linear classifier trained on conventional local features still proves to be a hard baseline to beat. Nonetheless, recent approaches exploiting neural networks on unlabeled corpora achieve promising results, surpassing this hard baseline in most test sets.},
  eventtitle = {Proceedings of the 15th {{Conference}} of the {{European Chapter}} of the           {{Association}} for {{Computational Linguistics}}: Volume 1, {{Long Papers}}},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\PMMEBWW5\\Raganato et al. - 2017 - Word Sense Disambiguation A Unified Evaluation Fr.pdf}
}

@incollection{rohrer_2007,
  title = {Embodiment and Experientialism},
  booktitle = {The {{Oxford}} Handbook of Cognitive Linguistics},
  author = {Rohrer, Tim},
  editor = {Geeraerts, Dirk and Cuyckens, H.},
  date = {2007},
  series = {Oxford Handbooks},
  pages = {25--47},
  publisher = {{Oxford University Press}},
  location = {{Oxford; New York}},
  isbn = {978-0-19-514378-2},
  langid = {english},
  keywords = {Cognitive grammar}
}

@incollection{rosch_1978,
  title = {Principles of Categorization},
  booktitle = {Cognition and {{Categorization}}},
  author = {Rosch, Eleanor},
  editor = {Rosch, Eleanor and Lloyd, Barbara B.},
  date = {1978},
  pages = {27--48},
  publisher = {{Lawrence Erlbaum Associates}},
  location = {{Hillsdale, New Jersey}}
}

@article{rousseeuw_1987,
  title = {Silhouettes: A Graphical Aid to the Interpretation and Validation of Cluster Analysis},
  shorttitle = {Silhouettes},
  author = {Rousseeuw, Peter J.},
  date = {1987-11},
  journaltitle = {Journal of Computational and Applied Mathematics},
  shortjournal = {Journal of Computational and Applied Mathematics},
  volume = {20},
  pages = {53--65},
  issn = {03770427},
  abstract = {A new graphical display is proposed for partitioning techniques. Each cluster is represented by a so-called silhouette, which is based on the comparison of its tightness and separation. This silhouette shows which objects he well within their cluster, and which ones are merely somewhere in between clusters. The entire clustering is displayed by combining the silhouettes into a single plot, allowing an appreciation of the relative quality of the clusters and an overview of the data configuration. The average silhouette width provides an evaluation of clustering validity, and might be used to select an ‘appropriate’ number of clusters.},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\JLLNNN4N\\Rousseeuw - 1987 - Silhouettes A graphical aid to the interpretation.pdf}
}

@book{rudzka-ostyn_1988,
  title = {Topics in {{Cognitive Linguistics}}},
  editor = {Rudzka-Ostyn, Brygida},
  date = {1988-01-01},
  series = {Current {{Issues}} in {{Linguistic Theory}}},
  volume = {50},
  publisher = {{John Benjamins Publishing Company}},
  location = {{Amsterdam}},
  isbn = {978-90-272-3544-2 978-90-272-8619-2},
  langid = {english}
}

@thesis{sahlgren_2006,
  title = {The Word-Space Model: Using Distributional Analysis to Represent Syntagmatic and Paradigmatic Relations between Words in High-Dimensional Vector Spaces},
  shorttitle = {The Word-Space Model},
  author = {Sahlgren, Magnus},
  date = {2006},
  institution = {{Dep. of Linguistics, Stockholm Univ. [u.a.]}},
  location = {{Stockholm}},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\XJFN3AZD\\Sahlgren - 2006 - The word-space model using distributional analysi.pdf}
}

@article{sahlgren_2008,
  title = {The Distributional Hypothesis},
  author = {Sahlgren, Magnus},
  date = {2008},
  journaltitle = {Italian Journal of Linguistics},
  volume = {20},
  number = {1},
  pages = {33--53},
  issn = {2499-8125},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\I267JSGY\\Sahlgren - The distributional hypothesis.pdf}
}

@article{schutze_1998,
  title = {Automatic {{Word Sense Discrimination}}},
  author = {Schütze, Hinrich},
  date = {1998-03},
  journaltitle = {Computational Linguistics},
  volume = {24},
  number = {1},
  pages = {97--123},
  issn = {0891-2017},
  abstract = {This paper presents context-group discrimination, a disambiguation algorithm based on clustering. Senses are interpreted as groups (or clusters) of similar contexts of the ambiguous word. Words, contexts, and senses are represented in Word Space, a high-dimensional, real-valued space in which closeness corresponds to semantic similarity. Similarity in Word Space is based on second-order co-occurrence: two tokens (or contexts) of the ambiguous word are assigned to the same sense cluster if the words they co-occur with in turn occur with similar words in a training corpus. The algorithm is automatic and unsupervised in both training and application: senses are induced from a corpus without labeled training instances or other external knowledge sources. The paper demonstrates good performance of context-group discrimination for a sample of natural and artificial ambiguous words.},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\HMM4UICW\\Schütze - 1998 - Automatic Word Sense Discrimination.pdf}
}

@book{semino_2008,
  title = {Metaphor in Discourse},
  author = {Semino, Elena},
  date = {2008},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge, UK; New York}},
  isbn = {978-0-521-86730-6},
  langid = {english},
  keywords = {Metaphor}
}

@inproceedings{shneiderman_1996,
  title = {The {{Eyes Have It}}: A {{Task}} by {{Data Type Taxonomy}} for {{Information Visualizations}}},
  booktitle = {{{IEEE Visual Languages}}},
  author = {Shneiderman, Ben},
  date = {1996},
  pages = {96--13}
}

@book{sinclair_1991,
  title = {Corpus, Concordance, Collocation},
  author = {Sinclair, John},
  date = {1991},
  series = {Describing {{English}} Language},
  edition = {3. impr},
  publisher = {{Oxford Univ. Press}},
  location = {{Oxford}},
  isbn = {978-0-19-437144-5},
  langid = {english},
  keywords = {Computerlinguistik,Englisch,Kollokation,Korpus},
  annotation = {OCLC: 174383705},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\WJIXUDHQ\\Sinclair - 1995 - Corpus, concordance, collocation.pdf}
}

@incollection{sinclair_1998,
  title = {The {{Lexical Item}}},
  booktitle = {Contrastive Lexical Semantics},
  author = {Sinclair, John},
  editor = {Weigand, Edda},
  date = {1998},
  series = {Amsterdam Studies in the Theory and History of Linguistic Science {{Series}} 4, {{Current}} Issues in Linguistic Theory},
  number = {171},
  pages = {1--24},
  publisher = {{Benjamins}},
  location = {{Amsterdam}},
  isbn = {978-90-272-3676-0 978-1-55619-887-8},
  langid = {english}
}

@inproceedings{smilkov.etal_2016,
  title = {Embedding {{Projector}}: Interactive {{Visualization}} and {{Interpretation}} of {{Embeddings}}},
  author = {Smilkov, Daniel and Thorat, Nikhil and Nicholson, Charles and Reif, Emily and Viégas, Fernanda B. and Wattenberg, Martin},
  date = {2016},
  url = {arXiv:1611.05469},
  eventtitle = {{{NIPS}} 2016 {{Workshop}} on {{Interpretable Machine Learning}} in {{Complex Systems}}}
}

@incollection{speelman.heylen_2017,
  title = {From Dialectometry to Semantics},
  booktitle = {From {{Semantics}} to {{Dialectometry}} ({{Festschrift John Nerbonne}})},
  author = {Speelman, Dirk and Heylen, Kris},
  editor = {Wieling, Martijn and Bouma, Gosse and van Noord, Gertjan},
  options = {useprefix=true},
  date = {2017},
  pages = {325--334},
  publisher = {{University of Groningen}},
  location = {{Groningen}},
  file = {C\:\\Users\\u0118974\\Documents\\Bibliography\\Speelman & Heylen (2017).pdf}
}

@incollection{stefanowitsch_2010,
  title = {Empirical Cognitive Semantics: Some Thoughts},
  booktitle = {Quantitative Methods in Cognitive Semantics: Corpus-Driven Approaches},
  author = {Stefanowitsch, Anatol},
  editor = {Glynn, Dylan and Fischer, Kerstin},
  date = {2010},
  series = {Cognitive Linguistics Research},
  number = {46},
  pages = {355--380},
  publisher = {{De Gruyter Mouton}},
  location = {{Berlin; New York}},
  isbn = {978-3-11-022641-6},
  keywords = {Cognitive grammar,Computational linguistics,Kongress,Semantics},
  annotation = {OCLC: ocn664354356}
}

@article{stubbs_1995,
  title = {Collocations and Semantic Profiles: On the Cause of the Trouble with Quantitative Studies},
  shorttitle = {Collocations and Semantic Profiles},
  author = {Stubbs, Michael},
  date = {1995},
  journaltitle = {Functions of Language},
  volume = {2},
  number = {1},
  pages = {23--55},
  issn = {0929-998X, 1569-9765},
  abstract = {Current work on lexical collocations uses two ideas: (i) words have distinctive semantic profiles or "prosodies"; and (ii) the strength of association between words can be measured in quantitative terms. These ideas can be combined to provide comparative semantic profiles of words, which show the frequent and characteristic collocates of node words, and make explicit the semantic relations between the collocates. Using data from corpora of up to 120 million words, it is shown that the lemma CAUSE occurs in predominantly "unpleasant" collocations, such as cause of the trouble and cause of death. A case study of this lemma is used to illustrate quantitative methods for investigating collocations. Various methods proposed in the literature are of great practical value in establishing collocational sets, but their theoretical basis is less clear. Brief comparative semantic profiles are given for related lemmas, e.g. REASON and CONSEQUENCE. Implications for the relation between system and use are discussed.},
  langid = {english}
}

@article{stubbs_2009,
  title = {Memorial {{Article}}: John {{Sinclair}} (1933–2007)},
  shorttitle = {Memorial {{Article}}},
  author = {Stubbs, Michael},
  date = {2009-03},
  journaltitle = {Applied Linguistics},
  volume = {30},
  number = {1},
  pages = {115--137},
  issn = {1477-450X, 0142-6001},
  langid = {english}
}

@incollection{stubbs_2015,
  title = {Corpus Semantics},
  booktitle = {The {{Routledge Handbook}} of {{Semantics}}},
  author = {Stubbs, Michael},
  editor = {Riemer, Nick},
  date = {2015-07-30},
  edition = {1},
  pages = {106--122},
  publisher = {{Routledge}},
  location = {{London}},
  isbn = {978-1-315-68553-3}
}

@book{tognini-bonelli_2001,
  title = {Corpus Linguistics at Work},
  author = {Tognini-Bonelli, Elena},
  date = {2001},
  publisher = {{J. Benjamins}},
  location = {{Amsterdam; Philadelphia}},
  langid = {english}
}

@article{turney.pantel_2010,
  title = {From {{Frequency}} to {{Meaning}}: Vector {{Space Models}} of {{Semantics}}},
  author = {Turney, Peter D and Pantel, Patrick},
  date = {2010},
  journaltitle = {Journal of Artificial Intelligence Research},
  volume = {37},
  pages = {141--188},
  abstract = {Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term–document, word–context, and pair–pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a specific open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the field.},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\K6IMW9S3\\Turney y Pantel - From Frequency to Meaning Vector Space Models of .pdf}
}

@book{vandale_groot,
  title = {Van {{Dale}} Groot Woordenboek van Hedendaags {{Nederlands}}},
  editor = {van Sterkenburg, Piet},
  date = {1991},
  series = {Van {{Dale}} Woordenboeken Voor Hedendaags Taalgebruik},
  edition = {2. dr},
  publisher = {{van @Dale Lexicografie}},
  location = {{Utrecht}},
  isbn = {978-90-6648-128-2}
}

@book{vandale_klein,
  title = {Van Dale klein woordenboek van de Nederlandse taal},
  author = {den Boon, Ton and Geeraerts, Dirk and Arts, Marjan},
  date = {2007},
  publisher = {{Van Dale}},
  location = {{Utrecht}},
  isbn = {978-90-6648-432-0},
  langid = {dutch},
  annotation = {OCLC: 851785979}
}

@inproceedings{vandecruys_2008,
  title = {A {{Comparison}} of {{Bag}} of {{Words}} and {{Syntax}}-Based {{Approaches}} for {{Word Categorization}}},
  booktitle = {Lexical Semantics: Bridging the Gap between Semantic Theory and Computational Simulations},
  author = {Van De Cruys, Tim},
  editor = {Baroni, Marco and Evert, Stefan and Lenci, Alessandro},
  date = {2008},
  pages = {47--54},
  location = {{Hamburg, Germany}},
  eventtitle = {20th {{European Summer School}} in {{Logic}}, {{Languageand Information}} ({{ESSLLI}} 2008)}
}

@inproceedings{vandecruys.apidianaki_2011,
  title = {Latent {{Semantic Word Sense Induction}} and {{Disambiguation}}},
  booktitle = {Proceedings of the 49th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Van de Cruys, Tim and Apidianaki, Marianna},
  date = {2011-06},
  pages = {1476--1485},
  publisher = {{Association for Computational Linguistics}},
  location = {{Portland, Oregon}},
  abstract = {In this paper, we present a unified model for the automatic induction of word senses from text, and the subsequent disambiguation of particular word instances using the automatically extracted sense inventory. The induction step and the disambiguation step are based on the same principle: words and contexts are mapped to a limited number of topical dimensions in a latent semantic word space. The intuition is that a particular sense is associated with a particular topic, so that different senses can be discriminated through their association with particular topical dimensions; in a similar vein, a particular instance of a word can be disambiguated by determining its most important topical dimensions. The model is evaluated on the SEMEVAL-2010 word sense induction and disambiguation task, on which it reaches stateof-the-art results.},
  eventtitle = {49th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\ABWQANAD\\de Cruys and Apidianaki - Latent Semantic Word Sense Induction and Disambigu.pdf}
}

@inproceedings{vandecruys.etal_2011,
  title = {Latent {{Vector Weighting}} for {{Word Meaning}} in {{Context}}},
  booktitle = {Proceedings of the 2011 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Van de Cruys, Tim and Poibeau, Thierry and Korhonen, Anna},
  date = {2011-07},
  pages = {1012--1022},
  publisher = {{Association for Computational Linguistics}},
  location = {{Edinburgh, Scotland, UK}},
  abstract = {This paper presents a novel method for the computation of word meaning in context. We make use of a factorization model in which words, together with their window-based context words and their dependency relations, are linked to latent dimensions. The factorization model allows us to determine which dimensions are important for a particular context, and adapt the dependency-based feature vector of the word accordingly. The evaluation on a lexical substitution task – carried out for both English and French – indicates that our approach is able to reach better results than state-of-the-art methods in lexical substitution, while at the same time providing more accurate meaning representations.},
  eventtitle = {2011 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\8R296ST5\\de Cruys et al. - Latent Vector Weighting for Word Meaning in Contex.pdf}
}

@inproceedings{vandecruys.etal_2013,
  title = {A {{Tensor}}-Based {{Factorization Model}} of {{Semantic Compositionality}}},
  booktitle = {Proceedings of {{NAACL}} 2013},
  author = {Van de Cruys, Tim and Poibeau, Thierry and Korhonen, Anna},
  date = {2013},
  pages = {1142--1151},
  location = {{Atlanta, Georgia, USA}},
  abstract = {In this paper, we present a novel method for the computation of compositionality within a distributional framework. The key idea is that compositionality is modeled as a multi-way interaction between latent factors, which are automatically constructed from corpus data. We use our method to model the composition of subject verb object triples. The method consists of two steps. First, we compute a latent factor model for nouns from standard co-occurrence data. Next, the latent factors are used to induce a latent model of three-way subject verb object interactions. Our model has been evaluated on a similarity task for transitive phrases, in which it exceeds the state of the art.},
  eventtitle = {{{NAACL}} 2013},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\G4KFAZBM\\de Cruys et al. - A Tensor-based Factorization Model of Semantic Com.pdf}
}

@inproceedings{vannoord_2006,
  title = {At {{Last Parsing Is Now Operational}}},
  booktitle = {Actes de La 13ème Conférence Sur Le {{Traitement Automatique}} Des {{Langues Naturelles}}. {{Conférences}} Invitées},
  author = {van Noord, Gertjan},
  options = {useprefix=true},
  date = {2006-04},
  pages = {20--42},
  publisher = {{ATALA}},
  location = {{Leuven, Belgium}},
  abstract = {Natural language analysis systems which combine knowledge-based and corpus-based methods are now becoming accurate enough to be used in various applications. We describe one such parsing system for Dutch, known as Alpino, and we show how corpus-based methods are essential to obtain accurate knowledge-based parsers. In particular we show a variety of cases where large amounts of parser output are used to improve the parser.},
  eventtitle = {{{JEP}}/{{TALN}}/{{RECITAL}} 2006},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\VDPJ53AM\\van Noord - 2006 - At Last Parsing Is Now Operational.pdf}
}

@inproceedings{vieu.etal_2015,
  title = {Quantitative Methods for Identifying Systematic Polysemy Classes},
  author = {Vieu, Laure and Jezek, Elisabetta and di Pavia, Universita and Van de Cruys, Tim},
  options = {useprefix=true},
  date = {2015},
  location = {{Tübingen, Germany}},
  abstract = {In this paper we report the results of four experiments conducted to extract lists of nouns that exhibit inherent polysemy from corpus data following semiautomatic and automatic procedures. We compare the methods used and the results obtained. We argue that quantitative methods can be used to distinguish different classes of polysemous nouns in the language on the basis of the variability of copredication contexts.},
  eventtitle = {6th {{Conference}} on {{Quantitative Investigations}} in {{Theoretical Linguistics}} ({{QITL}}-6)},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\AIUWXWIZ\\Vieu et al. - Quantitative methods for identifying systematic po.pdf}
}

@article{wattenberg.etal_2016,
  title = {How to {{Use}} T-{{SNE Effectively}}},
  author = {Wattenberg, Martin and Viégas, Fernanda and Johnson, Ian},
  date = {2016-10-13},
  journaltitle = {Distill},
  shortjournal = {Distill},
  volume = {1},
  number = {10},
  pages = {e2},
  issn = {2476-0757},
  abstract = {Although extremely useful for visualizing high-dimensional data, t-SNE plots can sometimes be mysterious or misleading.},
  langid = {english},
  file = {C\:\\Users\\u0118974\\Zotero\\storage\\FQNR2CIH\\misread-tsne.html}
}

@incollection{waugh.etal_2007,
  title = {Multiple Empirical Approaches to a Complex Analysis of Discourse},
  booktitle = {Methods in Cognitive Linguistics},
  author = {Waugh, Linda and Fonseca-Greber, Bonnie and Vickers, Caroline and Eröz, Betil},
  editor = {Gonzalez-Marquez, Monica and Mittelberg, Irene and Coulson, Seana and Spivey, Michael J.},
  date = {2007},
  series = {Human Cognitive Processing},
  number = {v. 18},
  pages = {120--148},
  publisher = {{John Benjamins Pub}},
  location = {{Amsterdam; Philadelphia}},
  isbn = {978-90-272-2371-5 978-90-272-2372-2},
  keywords = {Cognitive grammar,Research Methodology}
}

@incollection{wielfaert.etal_2019,
  title = {Visual {{Analytics}} for {{Parameter Tuning}} of {{Semantic Vector Space Models}}},
  booktitle = {{{LingVis}}: Visual Analytics for Linguistics},
  author = {Wielfaert, Thomas and Heylen, Kris and Speelman, Dirk and Geeraerts, Dirk},
  editor = {Butt, Miriam and Hautli-Janisz, Annette and Lyding, Verena},
  date = {2019},
  series = {{{CSLI}} Lecture Notes},
  number = {no. 220},
  pages = {215--245},
  publisher = {{CSLI Publications, Center for the Study of Language and Information}},
  location = {{Stanford, California}},
  isbn = {978-1-68400-034-0 978-1-68400-033-3 978-1-68400-035-7},
  keywords = {Information visualization,LANGUAGE ARTS & DISCIPLINES / Linguistics / General,Linguistics,Visual analytics}
}

@book{wittgenstein_1958,
  title = {Philosophical Investigations},
  shorttitle = {Philosophical Investigations},
  author = {Wittgenstein, Ludwig},
  translator = {Anscombe, G. E. M.},
  date = {1958},
  origdate = {1953},
  edition = {2nd ed., repr},
  publisher = {{Blackwell}},
  location = {{Cambridge, Mass}},
  isbn = {978-0-631-20569-2},
  langid = {english},
  origtitle = {Philosophische {{Untersuchungen}}}
}

@inproceedings{yarowsky_1995,
  title = {Unsupervised Word Sense Disambiguation Rivaling Supervised Methods},
  booktitle = {33rd Annual Meeting of the Association for Computational Linguistics},
  author = {Yarowsky, David},
  date = {1995-06},
  pages = {189--196},
  publisher = {{Association for Computational Linguistics}},
  location = {{Cambridge, Massachusetts, USA}},
  file = {C\:\\Users\\u0118974\\Documents\\Bibliography\\Yarowsky (1995).pdf}
}


