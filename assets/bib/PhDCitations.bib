
@book{geeraerts.cuyckens_2007a,
	address = {Oxford ; New York},
	series = {Oxford handbooks},
	title = {The {Oxford} handbook of cognitive linguistics},
	isbn = {978-0-19-514378-2},
	language = {en},
	publisher = {Oxford University Press},
	editor = {Geeraerts, Dirk and Cuyckens, Hubert},
	year = {2007},
	keywords = {Cognitive grammar},
	file = {The Oxford Handbook of Cognitive Linguistics.pdf:C\:\\Users\\u0118974\\Documents\\Bibliography\\The Oxford Handbook of Cognitive Linguistics.pdf:application/pdf},
}

@incollection{divjak.fieller_2014,
	address = {Amsterdam ; Philadelphia},
	series = {Human cognitive processing},
	title = {Cluster analysis: {Finding} structure in linguistic data},
	isbn = {978-90-272-2397-5},
	number = {volume 43},
	booktitle = {Corpus methods for semantics: quantitative studies in polysemy and synonymy},
	publisher = {John Benjamins Publishing Company},
	author = {Divjak, Dagmar and Fieller, Nick},
	editor = {Glynn, Dylan and Robinson, Justyna A.},
	year = {2014},
	keywords = {Cognitive grammar, Computational linguistics, Corpora (Linguistics), Polysemy, Semantics},
	pages = {405--441},
}

@incollection{glynn_2014c,
	address = {Amsterdam ; Philadelphia},
	series = {Human cognitive processing},
	title = {The many uses of \textit{run}: {Corpus} methods and {Socio}-{Cognitive} {Semantics}},
	isbn = {978-90-272-2397-5},
	number = {volume 43},
	booktitle = {Corpus methods for semantics: quantitative studies in polysemy and synonymy},
	publisher = {John Benjamins Publishing Company},
	author = {Glynn, Dylan},
	editor = {Glynn, Dylan and Robinson, Justyna A.},
	year = {2014},
	keywords = {Cognitive grammar, Computational linguistics, Corpora (Linguistics), Polysemy, Semantics},
	pages = {117--144},
}

@book{glynn.robinson_2014,
	address = {Amsterdam ; Philadelphia},
	series = {Human cognitive processing},
	title = {Corpus methods for semantics: quantitative studies in polysemy and synonymy},
	isbn = {978-90-272-2397-5},
	shorttitle = {Corpus methods for semantics},
	number = {volume 43},
	publisher = {John Benjamins Publishing Company},
	editor = {Glynn, Dylan and Robinson, Justyna A.},
	year = {2014},
	keywords = {Cognitive grammar, Computational linguistics, Corpora (Linguistics), Polysemy, Semantics},
}

@article{heylen.etal_2015,
	title = {Monitoring polysemy: {Word} space models as a tool for large-scale lexical semantic analysis},
	volume = {157},
	issn = {00243841},
	shorttitle = {Monitoring polysemy},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0024384114002770},
	doi = {10.1016/j.lingua.2014.12.001},
	language = {en},
	urldate = {2017-08-23},
	journal = {Lingua},
	author = {Heylen, Kris and Wielfaert, Thomas and Speelman, Dirk and Geeraerts, Dirk},
	month = apr,
	year = {2015},
	pages = {153--172},
}

@article{schutze_1998,
	title = {Automatic {Word} {Sense} {Discrimination}},
	volume = {24},
	issn = {0891-2017},
	abstract = {This paper presents context-group discrimination, a disambiguation algorithm based on clustering. Senses are interpreted as groups (or clusters) of similar contexts of the ambiguous word. Words, contexts, and senses are represented in Word Space, a high-dimensional, real-valued space in which closeness corresponds to semantic similarity. Similarity in Word Space is based on second-order co-occurrence: two tokens (or contexts) of the ambiguous word are assigned to the same sense cluster if the words they co-occur with in turn occur with similar words in a training corpus. The algorithm is automatic and unsupervised in both training and application: senses are induced from a corpus without labeled training instances or other external knowledge sources. The paper demonstrates good performance of context-group discrimination for a sample of natural and artificial ambiguous words.},
	number = {1},
	journal = {Computational Linguistics},
	author = {Schütze, Hinrich},
	month = mar,
	year = {1998},
	pages = {97--123},
	file = {ACM Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\HMM4UICW\\Schütze - 1998 - Automatic Word Sense Discrimination.pdf:application/pdf},
}

@book{panther.etal_2009,
	address = {Amsterdam ; Philadelphia},
	series = {Human cognitive processing},
	title = {Metonymy and metaphor in grammar},
	isbn = {978-90-272-2379-1 978-90-272-8935-3},
	number = {v. 25},
	publisher = {John Benjamins Pub. Co},
	editor = {Panther, Klaus-Uwe and Thornburg, Linda L. and Barcelona, Antonio},
	year = {2009},
	keywords = {Metaphor, Metonyms},
}

@article{giora_1997,
	title = {Understanding figurative and literal language: {The} graded salience hypothesis},
	volume = {8},
	issn = {0936-5907, 1613-3641},
	shorttitle = {Understanding figurative and literal language},
	url = {http://www.degruyter.com/view/j/cogl.1997.8.issue-3/cogl.1997.8.3.183/cogl.1997.8.3.183.xml?format=INT},
	doi = {10.1515/cogl.1997.8.3.183},
	number = {3},
	urldate = {2012-06-25},
	journal = {Cognitive Linguistics},
	author = {Giora, Rachel},
	month = jan,
	year = {1997},
	pages = {183--206},
}

@book{langacker_2008a,
	address = {Oxford ; New York},
	title = {Cognitive grammar: a basic introduction},
	isbn = {978-0-19-533196-7 0-19-533196-6 978-0-19-533195-0 0-19-533195-8},
	shorttitle = {Cognitive grammar},
	publisher = {Oxford University Press},
	author = {Langacker, Ronald W.},
	year = {2008},
	keywords = {Cognitive grammar},
}

@book{kristiansen.etal_2006,
	address = {Berlin},
	series = {Applications of cognitive linguistics},
	title = {Cognitive linguistics: current applications and future perspectives},
	isbn = {978-3-11-018950-6 3-11-018951-8 978-3-11-018951-3 3-11-018950-X 978-3-11-018950-6},
	shorttitle = {Cognitive linguistics},
	language = {eng},
	number = {1},
	publisher = {Mouton de Gruyter},
	editor = {Kristiansen, Gitte and Achard, Michel and Dirven, René and Ruiz de Mendoza Ibáñez, Francisco José},
	year = {2006},
	keywords = {Cognitive grammar, Aufsatzsammlung, Cognitive grammar Methodology, Kognitive Linguistik, Methodology},
	file = {Table of Contents PDF:C\:\\Users\\u0118974\\Zotero\\storage\\DEI6J2PS\\Kristiansen - 2006 - Cognitive linguistics current applications and fu.pdf:application/pdf},
}

@book{kovecses_2000,
	address = {Cambridge, U.K. ; New York : Paris},
	series = {Studies in emotion and social interaction},
	title = {Metaphor and emotion: language, culture, and body in human feeling},
	isbn = {0-521-64163-2},
	shorttitle = {Metaphor and emotion},
	language = {en},
	publisher = {Cambridge University Press ; Editions de la Maison des sciences de l'homme},
	author = {Kövecses, Zoltán},
	year = {2000},
	keywords = {Emotions, Emotions and cognition, Language and emotions, Sociological aspects},
}

@book{kovecses_2002,
	address = {New York},
	title = {Metaphor: a practical introduction},
	isbn = {0-19-514510-0},
	shorttitle = {Metaphor},
	language = {en},
	publisher = {Oxford University Press},
	author = {Kövecses, Zoltán},
	year = {2002},
	keywords = {Metaphor},
}

@incollection{rohrer_2007,
	address = {Oxford ; New York},
	series = {Oxford handbooks},
	title = {Embodiment and experientialism},
	isbn = {978-0-19-514378-2},
	language = {en},
	booktitle = {The {Oxford} handbook of cognitive linguistics},
	publisher = {Oxford University Press},
	author = {Rohrer, Tim},
	editor = {Geeraerts, Dirk and Cuyckens, H.},
	year = {2007},
	keywords = {Cognitive grammar},
	pages = {25--47},
}

@book{semino_2008,
	address = {Cambridge, UK ; New York},
	title = {Metaphor in discourse},
	isbn = {978-0-521-86730-6},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Semino, Elena},
	year = {2008},
	keywords = {Metaphor},
}

@book{gibbs_2008,
	address = {New York},
	title = {The {Cambridge} handbook of metaphor and thought},
	isbn = {978-0-521-84106-1},
	language = {en},
	publisher = {Cambridge University Press},
	editor = {Gibbs Jr., Raymond W.},
	year = {2008},
	keywords = {Metaphor, Language and culture, Psycholinguistics, Nonverbal communication},
}

@article{parodi_2008,
	title = {Lingüística de corpus: una introducción al ámbito.},
	volume = {46},
	language = {es},
	number = {1},
	journal = {Revista de Lingüística Teórica y Aplicada},
	author = {Parodi, Giovanni},
	year = {2008},
	pages = {93--119},
}

@incollection{geeraerts.cuyckens_2007,
	address = {Oxford ; New York},
	series = {Oxford handbooks},
	title = {Introducing {Cognitive} {Linguistics}},
	isbn = {978-0-19-514378-2},
	language = {en},
	booktitle = {The {Oxford} handbook of cognitive linguistics},
	publisher = {Oxford University Press},
	author = {Geeraerts, Dirk and Cuyckens, Hubert},
	editor = {Geeraerts, Dirk and Cuyckens, Hubert},
	year = {2007},
	keywords = {Cognitive grammar},
	pages = {3--22},
}

@incollection{geeraerts_2003,
	address = {Berlin ;New York, NY},
	series = {Mouton reader},
	title = {The interaction of metaphor and metonymy in composite expressions},
	isbn = {978-3-11-017374-1 3-11-017374-3 978-3-11-017374-1},
	language = {eng},
	booktitle = {Metaphor and metonymy in comparison and contrast},
	publisher = {Mouton de Gruyter},
	author = {Geeraerts, Dirk},
	editor = {Dirven, René and Pörings, Ralf},
	year = {2003},
	keywords = {Metaphor, Metonyms, Aufsatzsammlung, Kognitive Linguistik, Metapher, 11.1a;12.1a;11.3a, Metonymie},
	pages = {435--466},
}

@incollection{geeraerts_2005,
	address = {Berlin ; New York},
	series = {Cognitive linguistics research},
	title = {Lectal variation and empirical data in {Cognitive} {Linguistics}},
	isbn = {978-3-11-018617-8 3-11-018617-9},
	number = {32},
	booktitle = {Cognitive linguistics: internal dynamics and interdisciplinary interaction},
	publisher = {Mouton de Gruyter},
	author = {Geeraerts, Dirk},
	editor = {Ruiz de Mendoza Ibáñez, Francisco José and Peña Cervel, M. Sandra},
	year = {2005},
	keywords = {Cognitive grammar},
	pages = {163--189},
}

@article{arppe.etal_2010,
	title = {Cognitive {Corpus} {Linguistics}: five points of debate on current theory and methodology},
	volume = {5},
	issn = {1749-5032, 1755-1676},
	shorttitle = {Cognitive {Corpus} {Linguistics}},
	url = {http://www.euppublishing.com/doi/abs/10.3366/cor.2010.0001},
	doi = {10.3366/cor.2010.0001},
	language = {en},
	number = {1},
	urldate = {2016-06-14},
	journal = {Corpora},
	author = {Arppe, Antti and Gilquin, Gaëtanelle and Glynn, Dylan and Hilpert, Martin and Zeschel, Arne},
	month = may,
	year = {2010},
	pages = {1--27},
}

@book{biber.etal_1998,
	address = {Cambridge ; New York},
	series = {Cambridge approaches to linguistics},
	title = {Corpus linguistics: investigating language structure and use},
	isbn = {978-0-521-49622-3 978-0-521-49957-6},
	shorttitle = {Corpus linguistics},
	publisher = {Cambridge University Press},
	author = {Biber, Douglas and Conrad, Susan and Reppen, Randi},
	year = {1998},
	keywords = {Computational linguistics, Corpora (Linguistics), Linguistic analysis (Linguistics)},
}

@book{kovecses_2015,
	address = {New York, NY},
	title = {Where metaphors come from: reconsidering context in metaphor},
	isbn = {978-0-19-022486-8 978-0-19-022487-5 978-0-19-022488-2},
	shorttitle = {Where metaphors come from},
	publisher = {Oxford University Press},
	author = {Kövecses, Zoltán},
	year = {2015},
	keywords = {Cognitive grammar, Language and languages, Metaphor, Variation, Discourse analysis},
}

@incollection{mittelberg_2007,
	address = {Amsterdam ; Philadelphia},
	series = {Human cognitive processing},
	title = {Methodology for multimodality: {One} way of working with speech and gesture data},
	isbn = {978-90-272-2371-5 978-90-272-2372-2},
	number = {v. 18},
	booktitle = {Methods in cognitive linguistics},
	publisher = {John Benjamins Pub},
	author = {Mittelberg, Irene},
	editor = {Gonzalez-Marquez, Monica and Mittelberg, Irene and Coulson, Seana and Spivey, Michael J.},
	year = {2007},
	note = {OCLC: ocm73743935},
	keywords = {Cognitive grammar, Research Methodology},
	pages = {225--249?},
}

@incollection{grondelaers.etal_2007,
	address = {Amsterdam ; Philadelphia},
	series = {Human cognitive processing},
	title = {A case for a cognitive corpus linguistics},
	isbn = {978-90-272-2371-5 978-90-272-2372-2},
	number = {v. 18},
	booktitle = {Methods in cognitive linguistics},
	publisher = {John Benjamins Pub},
	author = {Grondelaers, Stefan and Geeraerts, Dirk and Speelman, Dirk},
	editor = {Gonzalez-Marquez, Monica and Mittelberg, Irene and Coulson, Seana and Spivey, Michael J.},
	year = {2007},
	note = {OCLC: ocm73743935},
	keywords = {Cognitive grammar, Research Methodology},
	pages = {149--168?},
}

@incollection{waugh.etal_2007,
	address = {Amsterdam ; Philadelphia},
	series = {Human cognitive processing},
	title = {Multiple empirical approaches to a complex analysis of discourse},
	isbn = {978-90-272-2371-5 978-90-272-2372-2},
	number = {v. 18},
	booktitle = {Methods in cognitive linguistics},
	publisher = {John Benjamins Pub},
	author = {Waugh, Linda and Fonseca-Greber, Bonnie and Vickers, Caroline and Eröz, Betil},
	editor = {Gonzalez-Marquez, Monica and Mittelberg, Irene and Coulson, Seana and Spivey, Michael J.},
	year = {2007},
	note = {OCLC: ocm73743935},
	keywords = {Cognitive grammar, Research Methodology},
	pages = {120--148?},
}

@book{lakoff.johnson_2003,
	address = {Chicago},
	title = {Metaphors we live by},
	isbn = {0-226-46801-1},
	language = {en},
	publisher = {University of Chicago Press},
	author = {Lakoff, George and Johnson, Mark},
	year = {2003},
	note = {Original date: 1980},
	keywords = {Language and languages, Metaphor, Philosophy, Concepts, Truth},
}

@book{gries.stefanowitsch_2006,
	address = {Berlin ; New York},
	series = {Trends in linguistics. {Studies} and monographs},
	title = {Corpora in cognitive linguistics: corpus-based approaches to syntax and lexis},
	isbn = {978-3-11-018605-5},
	shorttitle = {Corpora in cognitive linguistics},
	number = {172},
	publisher = {Mouton de Gruyter},
	editor = {Gries, Stefan Thomas and Stefanowitsch, Anatol},
	year = {2006},
	keywords = {Cognitive grammar, Data processing},
}

@book{mcenery.hardie_2012,
	address = {Cambridge ; New York},
	series = {Cambridge textbooks in linguistics},
	title = {Corpus linguistics: method, theory and practice},
	isbn = {978-0-521-83851-1 978-0-521-54736-9},
	shorttitle = {Corpus linguistics},
	abstract = {"Corpus linguistics is the study of language data on a large scale - the computer-aided analysis of very extensive collections of transcribed utterances or written texts. This textbook outlines the basic methods of corpus linguistics, explains how the discipline of corpus linguistics developed, and surveys the major approaches to the use of corpus data. It uses a broad range of examples to show how corpus data has led to methodological and theoretical innovation in linguistics in general. Clear and detailed explanations lay out the key issues of method and theory in contemporary corpus linguistics. A structured and coherent narrative links the historical development of the field to current topics in 'mainstream' linguistics. Practical activities and questions for discussion at the end of each chapter encourage students to test their understanding of what they have read and an extensive glossary provides easy access to definitions of technical terms used in the text"--},
	publisher = {Cambridge University Press},
	author = {McEnery, Tony and Hardie, Andrew},
	year = {2012},
	note = {OCLC: ocn732967848},
	keywords = {Corpora (Linguistics)},
}

@article{gries_2013,
	title = {50-something years of work on collocations: {What} is or should be next …},
	volume = {18},
	issn = {1384-6655, 1569-9811},
	shorttitle = {50-something years of work on collocations},
	url = {http://www.jbe-platform.com/content/journals/10.1075/ijcl.18.1.09gri},
	doi = {10.1075/ijcl.18.1.09gri},
	abstract = {This paper explores ways in which research into collocation should be improved. After a discussion of the parameters underlying the notion of ‘collocation’, the paper has three main parts. First, I argue that corpus linguistics would benefit from taking more seriously the understudied fact that collocations are not necessarily symmetric, as most association measures imply. Also, I introduce an association measure from the associative learning literature that can identify asymmetric collocations and show that it can also distinguish collocations with high and low association strengths well. Second, I summarize some advantages of this measure and brainstorm about ways in which it can help re-examine previous studies as well as support further applications. Finally, I adopt a broader perspective and discuss a variety of ways in which all association measures – directional or not – in corpus linguistics should be improved in order for us to obtain better and more reliable results.},
	language = {en},
	number = {1},
	urldate = {2017-02-22},
	journal = {International Journal of Corpus Linguistics},
	author = {Gries, Stefan Th.},
	month = may,
	year = {2013},
	pages = {137--166},
}

@article{gablasova.etal_2017,
	title = {Collocations in {Corpus}-{Based} {Language} {Learning} {Research}: {Identifying}, {Comparing}, and {Interpreting} the {Evidence}: {Collocations} in {Corpus}-{Based} {Language} {Learning} {Research}},
	issn = {00238333},
	shorttitle = {Collocations in {Corpus}-{Based} {Language} {Learning} {Research}},
	url = {http://doi.wiley.com/10.1111/lang.12225},
	doi = {10.1111/lang.12225},
	abstract = {This article focuses on the use of collocations in language learning research (LLR).
Collocations, as units of formulaic language, are becoming prominent in our understanding
of language learning and use; however, while the number of corpus-based LLR
studies of collocations is growing, there is still a need for a deeper understanding of
factors that play a role in establishing that two words in a corpus can be considered to
be collocates. In this article we critically review both the application of measures used
to identify collocability between words and the nature of the relationship between two
collocates. Particular attention is paid to the comparison of collocability across different
corpora representing different genres, registers, or modalities. Several issues involved
in the interpretation of collocational patterns in the production of first language and
second language users are also considered. Reflecting on the current practices in the
field, further directions for collocation research are proposed.},
	language = {en},
	urldate = {2017-02-22},
	journal = {Language Learning},
	author = {Gablasova, Dana and Brezina, Vaclav and McEnery, Tony},
	month = feb,
	year = {2017},
}

@book{mcenery.etal_2010,
	address = {London},
	edition = {Reprinted},
	series = {Routledge applied linguistics},
	title = {Corpus-based language studies: an advanced resource book},
	isbn = {978-0-415-28623-7},
	shorttitle = {Corpus-based language studies},
	language = {eng},
	publisher = {Routledge},
	author = {McEnery, Tony and Xiao, Richard and Tono, Yukio},
	year = {2010},
	note = {OCLC: 642930078},
	keywords = {Computational linguistics, Corpora (Linguistics), Aufsatzsammlung, Englisch, Korpus, Lehrbuch, Linguistics Methodology},
	file = {Table of Contents PDF:C\:\\Users\\u0118974\\Zotero\\storage\\EUMQ27M5\\McEnery et al. - 2010 - Corpus-based language studies an advanced resourc.pdf:application/pdf},
}

@article{stubbs_1995,
	title = {Collocations and semantic profiles: {On} the cause of the trouble with quantitative studies},
	volume = {2},
	issn = {0929-998X, 1569-9765},
	shorttitle = {Collocations and semantic profiles},
	url = {http://www.jbe-platform.com/content/journals/10.1075/fol.2.1.03stu},
	doi = {10.1075/fol.2.1.03stu},
	abstract = {Current work on lexical collocations uses two ideas: (i) words have
distinctive semantic profiles or "prosodies"; and (ii) the strength of
association between words can be measured in quantitative terms.
These ideas can be combined to provide comparative semantic
profiles of words, which show the frequent and characteristic collocates
of node words, and make explicit the semantic relations between
the collocates.
Using data from corpora of up to 120 million words, it is shown
that the lemma CAUSE occurs in predominantly "unpleasant" collocations,
such as cause of the trouble and cause of death. A case study
of this lemma is used to illustrate quantitative methods for investigating
collocations. Various methods proposed in the literature are
of great practical value in establishing collocational sets, but their
theoretical basis is less clear. Brief comparative semantic profiles
are given for related lemmas, e.g. REASON and CONSEQUENCE.
Implications for the relation between system and use are discussed.},
	language = {en},
	number = {1},
	urldate = {2017-02-15},
	journal = {Functions of Language},
	author = {Stubbs, Michael},
	year = {1995},
	pages = {23--55},
}

@inproceedings{church.hanks_1989,
	title = {Word association norms, mutual information, and lexicography},
	url = {http://portal.acm.org/citation.cfm?doid=981623.981633},
	doi = {10.3115/981623.981633},
	abstract = {The term word association is used in a very particular sense in the psycholinguistic literature.
(Generally speaking, subjects respond quicker than normal to the word nurse if it follows a highly associated word such as doctor.)
We will extend the term to provide the basis for a statistical description of a variety of interesting linguistic phenomena, ranging from semantic relations of the doctor/nurse type (content word/content word)
to lexico-syntactic co-occurrence constraints between verbs and prepositions (content word/function word).
This paper will propose an objective measure based on the information theoretic notion of mutual information, for estimating word association norms from computer readable corpora.
(The standard method of obtaining word association norms, testing a few thousand :mbjects on a few hundred words, is both costly and unreliable.)
The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words.},
	language = {en},
	urldate = {2017-02-15},
	booktitle = {{ACL} '89: {Proceedings} of the 27th annual meeting on {Association} for {Computational} {Linguistic}},
	publisher = {Association for Computational Linguistics},
	author = {Church, Kenneth Ward and Hanks, Patrick},
	month = jun,
	year = {1989},
	pages = {76--83},
}

@book{sinclair_1991,
	address = {Oxford},
	edition = {3. impr},
	series = {Describing {English} language},
	title = {Corpus, concordance, collocation},
	isbn = {978-0-19-437144-5},
	language = {eng},
	publisher = {Oxford Univ. Press},
	author = {Sinclair, John},
	year = {1991},
	note = {OCLC: 174383705},
	keywords = {Englisch, Korpus, Computerlinguistik, Kollokation},
	file = {Table of Contents PDF:C\:\\Users\\u0118974\\Zotero\\storage\\WJIXUDHQ\\Sinclair - 1995 - Corpus, concordance, collocation.pdf:application/pdf},
}

@incollection{geeraerts_2006b,
	address = {Berlin},
	series = {Applications of cognitive linguistics},
	title = {Methodology in {Cognitive} {Linguistics}},
	isbn = {978-3-11-018950-6 3-11-018951-8 978-3-11-018951-3 3-11-018950-X 978-3-11-018950-6},
	language = {eng},
	number = {1},
	booktitle = {Cognitive linguistics: current applications and future perspectives},
	publisher = {Mouton de Gruyter},
	author = {Geeraerts, Dirk},
	editor = {Kristiansen, Gitte and Achard, Michel and Dirven, René and Ruiz de Mendoza Ibáñez, Francisco José},
	year = {2006},
	keywords = {Cognitive grammar, Aufsatzsammlung, Cognitive grammar Methodology, Kognitive Linguistik, Methodology},
	pages = {21--49},
}

@incollection{barcelona_2015,
	address = {Berlin, München, Boston},
	title = {Metonymy},
	isbn = {978-3-11-029202-2},
	urldate = {2017-05-16},
	booktitle = {Handbook of {Cognitive} {Linguistics}},
	publisher = {DE GRUYTER},
	author = {Barcelona, Antonio},
	editor = {Dabrowska, Ewa and Divjak, Dagmar},
	month = jan,
	year = {2015},
	doi = {10.1515/9783110292022-008},
	pages = {143--167},
}

@incollection{geeraerts_2015a,
	address = {Berlin, München, Boston},
	title = {Lexical semantics},
	isbn = {978-3-11-029202-2},
	urldate = {2017-08-11},
	booktitle = {Handbook of {Cognitive} {Linguistics}},
	publisher = {DE GRUYTER},
	author = {Geeraerts, Dirk},
	editor = {Dabrowska, Ewa and Divjak, Dagmar},
	month = jan,
	year = {2015},
	doi = {10.1515/9783110292022-014},
	pages = {273--295},
}

@book{geeraerts_2010a,
	address = {Oxford ; New York},
	title = {Theories of lexical semantics},
	isbn = {978-0-19-870031-9 978-0-19-870030-2},
	publisher = {Oxford University Press},
	author = {Geeraerts, Dirk},
	year = {2010},
	note = {OCLC: ocn429750193},
	keywords = {Semantics, Methodology},
}

@book{geeraerts_2006e,
	address = {Berlin ; New York},
	series = {Cognitive linguistics research},
	title = {Words and other wonders: papers on lexical and semantic topics},
	isbn = {978-3-11-019042-7},
	shorttitle = {Words and other wonders},
	number = {33},
	publisher = {Mouton de Gruyter},
	author = {Geeraerts, Dirk},
	year = {2006},
	keywords = {Semantics, Lexicology},
}

@incollection{ibarretxe-antunano.valenzuela_2016a,
	address = {Barcelona},
	edition = {2da},
	series = {Autores, textos y temas {Filosofía}},
	title = {Lingüística cognitiva: origen, principios y tendencias},
	isbn = {978-84-15260-37-0},
	language = {spa},
	booktitle = {Lingüística cognitiva},
	publisher = {Anthropos Ed},
	author = {Ibarretxe-Antuñano, Iraide and Valenzuela, Javier},
	editor = {Ibarretxe-Antuñano, Iraide and Valenzuela, Javier},
	year = {2016},
	note = {OCLC: 813204430},
	keywords = {Kognitive Linguistik},
	pages = {13--38},
}

@book{ibarretxe-antunano.valenzuela_2016,
	address = {Barcelona},
	edition = {2da},
	series = {Autores, textos y temas {Filosofía}},
	title = {Lingüística cognitiva},
	isbn = {978-84-15260-37-0},
	language = {spa},
	publisher = {Anthropos Ed},
	editor = {Ibarretxe-Antuñano, Iraide and Valenzuela, Javier},
	year = {2016},
	note = {OCLC: 813204430},
	keywords = {Kognitive Linguistik},
	file = {Table of Contents PDF:C\:\\Users\\u0118974\\Zotero\\storage\\K273DUQZ\\Ibarretxe-Antuñano - 2012 - Lingüística cognitiva.pdf:application/pdf},
}

@book{gibbs.steen_1999,
	address = {Amsterdam},
	series = {Amsterdam studies in the theory and history of linguistic science {Ser}. 4},
	title = {Metaphor in cognitive linguistics: selected papers from the {Fifth} {International} {Cognitive} {Linguistics} {Conference}, {Amsterdam}, {July} 1997},
	isbn = {978-90-272-3681-4 978-1-55619-892-2 978-90-272-3728-6 978-1-58811-126-5},
	shorttitle = {Metaphor in cognitive linguistics},
	language = {eng},
	number = {175},
	publisher = {Benjamins},
	editor = {Gibbs, Jr., Raymond W. and Steen, Gerard},
	year = {1999},
	note = {OCLC: 248784237},
	keywords = {Cognitive grammar, Metaphor, Kognitive Linguistik, Kongress, Language and culture, Metapher},
}

@phdthesis{montes_2016,
	address = {Córdoba},
	type = {Trabajo final monográfico de licenciatura},
	title = {Uso metaforico della temperatura nell'italiano scritto contemporaneo},
	copyright = {All rights reserved},
	language = {it},
	school = {Universidad Nacional de Córdoba},
	author = {Montes, Mariana},
	collaborator = {Bortolon, Mariela},
	year = {2016},
}

@article{lenci_2018,
	title = {Distributional {Models} of {Word} {Meaning}},
	volume = {4},
	issn = {2333-9683, 2333-9691},
	url = {http://www.annualreviews.org/doi/10.1146/annurev-linguistics-030514-125254},
	doi = {10.1146/annurev-linguistics-030514-125254},
	language = {en},
	number = {1},
	urldate = {2018-04-12},
	journal = {Annual Review of Linguistics},
	author = {Lenci, Alessandro},
	month = jan,
	year = {2018},
	pages = {151--171},
	file = {Lenci - 2018 - Distributional Models of Word Meaning.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\YRSW9EUM\\Lenci - 2018 - Distributional Models of Word Meaning.pdf:application/pdf},
}

@inproceedings{kiela.clark_2014,
	address = {Gothenburg},
	title = {A {Systematic} {Study} of {Semantic} {Vector} {Space} {Model} {Parameters}},
	abstract = {We present a systematic study of parameters used in the construction of semantic vector space models. Evaluation is carried out on a variety of similarity tasks, including a compositionality dataset, using
several source corpora. In addition to recommendations
for optimal parameters, we present some novel findings, including a similarity metric that outperforms the alternatives on all tasks considered.},
	booktitle = {Proceedings of the 2nd {Workshop} on {Continuous} {Vector} {Space} {Models} and their {Compositionality}},
	publisher = {ACL},
	author = {Kiela, Douwe and Clark, Stephen},
	month = apr,
	year = {2014},
	pages = {21--30},
}

@book{manning.schutze_1999,
	address = {Cambridge, Mass},
	title = {Foundations of statistical natural language processing},
	isbn = {978-0-262-13360-9},
	publisher = {MIT Press},
	author = {Manning, Christopher D. and Schütze, Hinrich},
	year = {1999},
	keywords = {Computational linguistics, Statistical methods},
}

@book{agirre.edmonds_2007a,
	series = {Text, speech, and language technology},
	title = {Word {Sense} {Disambiguation}. {Algorithms} and {Applications}},
	volume = {33},
	isbn = {9781402048084},
	language = {English},
	publisher = {Springer},
	editor = {Agirre, Eneko and Edmonds, Philip},
	year = {2007},
}

@incollection{speelman.heylen_2017,
	address = {Groningen},
	title = {From dialectometry to semantics},
	booktitle = {From {Semantics} to {Dialectometry} ({Festschrift} {John} {Nerbonne})},
	publisher = {University of Groningen},
	author = {Speelman, Dirk and Heylen, Kris},
	editor = {Wieling, Martijn and Bouma, Gosse and van Noord, Gertjan},
	year = {2017},
	pages = {325--334},
	file = {Speelman & Heylen (2017).pdf:C\:\\Users\\u0118974\\Documents\\Bibliography\\Speelman & Heylen (2017).pdf:application/pdf},
}

@article{turney.pantel_2010,
	title = {From {Frequency} to {Meaning}: {Vector} {Space} {Models} of {Semantics}},
	volume = {37},
	abstract = {Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term–document, word–context, and pair–pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a speciﬁc open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the ﬁeld.},
	language = {en},
	journal = {Journal of Artificial Intelligence Research},
	author = {Turney, Peter D and Pantel, Patrick},
	year = {2010},
	pages = {141--188},
	file = {Turney y Pantel - From Frequency to Meaning Vector Space Models of .pdf:C\:\\Users\\u0118974\\Zotero\\storage\\K6IMW9S3\\Turney y Pantel - From Frequency to Meaning Vector Space Models of .pdf:application/pdf},
}

@inproceedings{heylen.etal_2012,
	address = {Avignon},
	title = {Looking at word meaning. {An} interactive visualization of {Semantic} {Vector} {Spaces} for {Dutch} synsets},
	abstract = {In statistical NLP, Semantic Vector Spaces (SVS) are the standard technique for the automatic modeling of lexical semantics. However, it is largely unclear how these black-box techniques exactly capture word meaning. To explore the way an SVS structures the individual occurrences of words, we use a non-parametric MDS solution of a token-by-token similarity matrix. The MDS solution is visualized in an interactive plot with the Google Chart Tools. As a case study, we look at the occurrences of 476 Dutch nouns grouped in 214 synsets.},
	language = {en},
	booktitle = {Proceedings of the eacl 2012 {Joint} {Workshop} of {LINGVIS} \& {UNCLH}},
	author = {Heylen, Kris and Speelman, Dirk and Geeraerts, Dirk},
	year = {2012},
	pages = {16--24},
	file = {Heylen et al. - Looking at word meaning. An interactive visualizat.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\UU62B9N7\\Heylen et al. - Looking at word meaning. An interactive visualizat.pdf:application/pdf},
}

@article{hilpert.correiasaavedra_2017,
	title = {Using token-based semantic vector spaces for corpus-linguistic analyses: {From} practical applications to tests of theoretical claims},
	volume = {16},
	issn = {1613-7027, 1613-7035},
	shorttitle = {Using token-based semantic vector spaces for corpus-linguistic analyses},
	url = {http://www.degruyter.com/view/j/cllt.ahead-of-print/cllt-2017-0009/cllt-2017-0009.xml},
	doi = {10.1515/cllt-2017-0009},
	abstract = {This paper presents token-based semantic vector spaces as a tool that can be applied in corpus-linguistic analyses such as word sense comparisons, comparisons of synonymous lexical items, and matching of concordance lines with a given text. We demonstrate how token-based semantic vector spaces are created, and we illustrate the kinds of result that can be obtained with this approach. Our main argument is that token-based semantic vector spaces are not only useful for practical corpus-linguistic applications but also for the investigation of theory-driven questions. We illustrate this point with a discussion of the asymmetric priming hypothesis (Jäger and Rosenbach 2008). The asymmetric priming hypothesis, which states that grammaticalizing constructions will be primed by their lexical sources but not vice versa, makes a number of empirically testable predictions. We operationalize and test these predictions, concluding that token-based semantic vector spaces yield conclusions that are relevant for linguistic theory-building.},
	language = {en},
	number = {2},
	urldate = {2018-11-20},
	journal = {Corpus Linguistics and Linguistic Theory},
	author = {Hilpert, Martin and Correia Saavedra, David},
	month = sep,
	year = {2017},
	file = {Hilpert y Correia Saavedra - 2017 - Using token-based semantic vector spaces for corpu.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\RKE3RQAB\\Hilpert y Correia Saavedra - 2017 - Using token-based semantic vector spaces for corpu.pdf:application/pdf},
}

@book{levshina_2015,
	address = {Amsterdam ; Philadelphia},
	title = {How to do linguistics with {R}: data exploration and statistical analysis},
	isbn = {978-90-272-1224-5 978-90-272-1225-2},
	shorttitle = {How to do linguistics with {R}},
	publisher = {John Benjamins Publishing Company},
	author = {Levshina, Natalia},
	year = {2015},
	keywords = {Computational linguistics, Linguistics, Methodology, Statistical methods, Software},
}

@phdthesis{depascale_2019,
	address = {Leuven},
	type = {{PhD} {Dissertation}},
	title = {Token-based vector space models as semantic control in lexical lectometry},
	url = {https://lirias.kuleuven.be/retrieve/549451},
	abstract = {Type-based distributional semantics as embodied in vector space models has proven to be a successful method for the retrieval of near-synonyms in large corpora. These words have then been used as variants of lexical sociolinguistic variables (e.g.: return and winst for the concept profit) in lectometric studies, that is, the aggregate-level study of lexical distances between linguistic varieties, in particular pluricentric languages such as Dutch. However, a limitation of type-based vector space models is that all senses of a word are lumped together into one vector representation, making it harder to control for polysemy and subtle contextual distinctions. In addition, operating at the lexeme level, these type-based vector space models are not able to pick out the relevant corpus occurrences that are the input for the lectometric distance calculations. The main goal of this PhD project is to introduce token-based vector space models in lexical lectometric research, in order to gain better semantic control during the composition of lexical variables. Token-based vector space models address the abovementioned shortcomings by disambiguating different senses of lexical variants. This technique is able to model the semantics of individual tokens (i.e. 'usage occurrences') of a word in a corpus and to represent them as token clouds in multidimensional vector space, with clusters of tokens revealing distinct senses of the word. By superimposing the token clouds of the lexical variants, one can distinguish which meanings are shared by near-synonyms and determine the 'semantic envelope of variation' of the lexical alternation. For instance, the variant return is polysemous in Netherlandic Dutch, with the two readings 'profit' and 'return game', but not in Belgian Dutch, where only the 'profit' sense is found. By isolating the cluster of tokens with the meaning 'profit' one can identify the near-synonymous tokens of the variants winst and return. The fine-tuning of vector space model-based lectometry targeted in this PhD contributes to the scaling up of lexical variationist research, by providing methods for dealing with corpora whose size exceeds manual analysis. At the same time, token-based models comply with the need of detailed analysis by allowing to zoom in on the behavior of individual tokens in order to determine more subtle contextual distinctions. This PhD project is situated in a larger research endeavor ("Nephological Semantics - Using token clouds for meaning detection in variationist linguistics", BOF C1 project 3H150305) that aims at detailed understanding of token-based vector representations for lexical, semantic and variational research.},
	language = {eng},
	urldate = {2019-11-08},
	school = {KU Leuven},
	author = {De Pascale, S.},
	collaborator = {Marzo, S. and Speelman, D.},
	year = {2019},
}

@article{wattenberg.etal_2016,
	title = {How to {Use} t-{SNE} {Effectively}},
	volume = {1},
	issn = {2476-0757},
	url = {http://distill.pub/2016/misread-tsne},
	doi = {10.23915/distill.00002},
	abstract = {Although extremely useful for visualizing high-dimensional data, t-SNE plots can sometimes be mysterious or misleading.},
	language = {en},
	number = {10},
	urldate = {2020-02-27},
	journal = {Distill},
	author = {Wattenberg, Martin and Viégas, Fernanda and Johnson, Ian},
	month = oct,
	year = {2016},
	pages = {e2},
	file = {Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\FQNR2CIH\\misread-tsne.html:text/html},
}

@book{geeraerts.etal_1994,
	address = {Berlin, New York},
	title = {The {Structure} of {Lexical} {Variation}: {Meaning}, {Naming}, and {Context}},
	isbn = {978-3-11-087306-1},
	shorttitle = {The {Structure} of {Lexical} {Variation}},
	url = {https://www.degruyter.com/doi/10.1515/9783110873061},
	urldate = {2020-06-04},
	publisher = {DE GRUYTER MOUTON},
	author = {Geeraerts, Dirk and Grondelaers, Stefan and Bakema, Peter},
	month = jan,
	year = {1994},
	doi = {10.1515/9783110873061},
	file = {Geeraerts et al. - 1994 - The Structure of Lexical Variation Meaning, Namin.pdf:C\:\\Users\\u0118974\\Documents\\Bibliography\\Geeraerts et al. - 1994 - The Structure of Lexical Variation Meaning, Namin.pdf:application/pdf},
}

@incollection{lemmens_2015,
	address = {London},
	edition = {1},
	title = {Cognitive semantics},
	isbn = {978-1-315-68553-3},
	url = {https://www.taylorfrancis.com/books/9781315685533},
	urldate = {2020-06-05},
	booktitle = {The {Routledge} {Handbook} of {Semantics}},
	publisher = {Routledge},
	author = {Lemmens, Maarten},
	editor = {Riemer, Nick},
	month = jul,
	year = {2015},
	doi = {10.4324/9781315685533},
	pages = {90--105?},
}

@incollection{stubbs_2015,
	address = {London},
	edition = {1},
	title = {Corpus semantics},
	isbn = {978-1-315-68553-3},
	url = {https://www.taylorfrancis.com/books/9781315685533},
	urldate = {2020-06-05},
	booktitle = {The {Routledge} {Handbook} of {Semantics}},
	publisher = {Routledge},
	author = {Stubbs, Michael},
	editor = {Riemer, Nick},
	month = jul,
	year = {2015},
	doi = {10.4324/9781315685533},
	pages = {106--122?},
}

@incollection{geeraerts_2015b,
	address = {London},
	edition = {1},
	title = {Sense individuation},
	isbn = {978-1-315-68553-3},
	booktitle = {The {Routledge} {Handbook} of {Semantics}},
	publisher = {Routledge},
	author = {Geeraerts, Dirk},
	editor = {Riemer, Nick},
	month = jul,
	year = {2015},
	doi = {10.4324/9781315685533},
	pages = {233--247},
}

@incollection{newman_2015,
	address = {London},
	edition = {1},
	title = {Semantic shift},
	isbn = {978-1-315-68553-3},
	url = {https://www.taylorfrancis.com/books/9781315685533},
	urldate = {2020-06-05},
	booktitle = {The {Routledge} {Handbook} of {Semantics}},
	publisher = {Routledge},
	author = {Newman, John},
	editor = {Riemer, Nick},
	month = jul,
	year = {2015},
	doi = {10.4324/9781315685533},
	pages = {266--280?},
}

@book{card.etal_1999,
	address = {San Francisco, Calif},
	series = {The {Morgan} {Kaufmann} series in interactive technologies},
	title = {Readings in information visualization: using vision to think},
	isbn = {978-1-55860-533-6},
	shorttitle = {Readings in information visualization},
	publisher = {Morgan Kaufmann Publishers},
	author = {Card, Stuart K. and Mackinlay, Jock D. and Shneiderman, Ben},
	year = {1999},
	keywords = {Information visualization, Computer graphics, Image processing},
}

@inproceedings{shneiderman_1996,
	title = {The {Eyes} {Have} {It}: {A} {Task} by {Data} {Type} {Taxonomy} for {Information} {Visualizations}},
	booktitle = {{IEEE} {Visual} {Languages}},
	author = {Shneiderman, Ben},
	year = {1996},
	pages = {96--13},
}

@incollection{wielfaert.etal_2019,
	address = {Stanford, California},
	series = {{CSLI} lecture notes},
	title = {Visual {Analytics} for {Parameter} {Tuning} of {Semantic} {Vector} {Space} {Models}},
	isbn = {978-1-68400-034-0 978-1-68400-033-3 978-1-68400-035-7},
	number = {no. 220},
	booktitle = {{LingVis}: visual analytics for linguistics},
	publisher = {CSLI Publications, Center for the Study of Language and Information},
	author = {Wielfaert, Thomas and Heylen, Kris and Speelman, Dirk and Geeraerts, Dirk},
	editor = {Butt, Miriam and Hautli-Janisz, Annette and Lyding, Verena},
	year = {2019},
	keywords = {Linguistics, Information visualization, LANGUAGE ARTS \& DISCIPLINES / Linguistics / General, Visual analytics},
	pages = {215--245},
}

@article{newman_2011,
	title = {Corpora and cognitive linguistics},
	volume = {11},
	issn = {1984-6398},
	url = {http://www.scielo.br/scielo.php?script=sci_arttext&pid=S1984-63982011000200010&lng=en&tlng=en},
	doi = {10.1590/S1984-63982011000200010},
	abstract = {Corpora are a natural source of data for cognitive linguists, since corpora, more than any other source of data, reflect "usage" - a notion which is often claimed to be of critical importance to the field of cognitive linguistics. Corpora are relevant to all the main topics of interest in cognitive linguistics: metaphor, polysemy, synonymy, prototypes, and constructional analysis. I consider each of these topics in turn and offer suggestions about which methods of analysis can be profitably used with available corpora to explore these topics further. In addition, I consider how the design and content of currently used corpora need to be rethought if corpora are to provide all the types of usage data that cognitive linguists require.
          , 
            Corpora são uma fonte natural de dados para a linguística cognitiva, uma vez que, estes, mais que qualquer outra fonte de dados, refletem "o uso" - a noção que é frequentemente apontada como tendo importância crítica para o campo da linguística cognitiva. Corpora são relevantes para todos os principais tópicos de interesse da linguística cognitiva: metáfora, polissemia, sinonímia, protótipos e análise construcional. Neste artigo, considerarei cada um desses tópicos e oferecerei sugestões sobre quais os métodos de análise podem ser utilizados com os corpora disponíveis para melhor se explorarem esses tópicos. Adicionalmente, discuto como a arquitetura e o conteúdo dos corpora atualmente disponíveis necessitam ser repensados se pretenderem oferecer todos os tipos de dados de uso necessários às análises da linguística cognitiva.},
	number = {2},
	urldate = {2020-09-22},
	journal = {Revista Brasileira de Linguística Aplicada},
	author = {Newman, John},
	year = {2011},
	pages = {521--559},
	file = {Texto completo:C\:\\Users\\u0118974\\Zotero\\storage\\2RGIUC35\\Newman - 2011 - Corpora and cognitive linguistics.pdf:application/pdf},
}

@inproceedings{smilkov.etal_2016,
	title = {Embedding {Projector}: {Interactive} {Visualization} and {Interpretation} of {Embeddings}},
	url = {arXiv:1611.05469},
	author = {Smilkov, Daniel and Thorat, Nikhil and Nicholson, Charles and Reif, Emily and Viégas, Fernanda B. and Wattenberg, Martin},
	year = {2016},
	note = {\_eprint: 1611.05469},
}

@inproceedings{baroni.etal_2014,
	address = {Baltimore, Maryland},
	title = {Don't count, predict! {A} systematic comparison of context-counting vs. context-predicting semantic vectors},
	url = {http://aclweb.org/anthology/P14-1023},
	doi = {10.3115/v1/P14-1023},
	abstract = {Context-predicting models (more commonly known as embeddings or neural language models) are the new kids on the distributional semantics block. Despite the buzz surrounding these models, the literature is still lacking a systematic comparison of the predictive models with classic, count-vector-based distributional semantic approaches. In this paper, we perform such an extensive evaluation, on a wide range of lexical semantics tasks and across many parameter settings. The results, to our own surprise, show that the buzz is fully justiﬁed, as the context-predicting models obtain a thorough and resounding victory against their count-based counterparts.},
	language = {en},
	urldate = {2020-11-09},
	booktitle = {Proceedings of the 52nd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Baroni, Marco and Dinu, Georgiana and Kruszewski, Germán},
	year = {2014},
	pages = {238--247},
	file = {Baroni et al. - 2014 - Don't count, predict! A systematic comparison of c.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\8NE8WIHL\\Baroni et al. - 2014 - Don't count, predict! A systematic comparison of c.pdf:application/pdf},
}

@inproceedings{baroni.lenci_2011,
	address = {Edinburgh, Scotland, UK},
	title = {How we {BLESSed} distributional semantic evaluation},
	abstract = {We introduce BLESS, a data set speciﬁcally designed for the evaluation of distributional semantic models. BLESS contains a set of tuples instantiating different, explicitly typed semantic relations, plus a number of controlled random tuples. It is thus possible to assess the ability of a model to detect truly related word pairs, as well as to perform in-depth analyses of the types of semantic relations that a model favors. We discuss the motivations for BLESS, describe its construction and structure, and present examples of its usage in the evaluation of distributional semantic models.},
	language = {en},
	booktitle = {Proceedings of the {GEMS} 2011 {Workshop} on {Geometrical} {Models} of {Natural} {Language} {Semantics}},
	publisher = {Association for Computational Linguistics},
	author = {Baroni, Marco and Lenci, Alessandro},
	month = jul,
	year = {2011},
	pages = {1--10},
	file = {Baroni y Lenci - How we BLESSed distributional semantic evaluation.pdf:C\:\\Users\\u0118974\\Documents\\Bibliography\\Baroni y Lenci - How we BLESSed distributional semantic evaluation.pdf:application/pdf},
}

@article{bullinaria.levy_2007,
	title = {Extracting semantic representations from word co-occurrence statistics: {A} computational study},
	volume = {39},
	issn = {1554-3528},
	shorttitle = {Extracting semantic representations from word co-occurrence statistics},
	url = {https://doi.org/10.3758/BF03193020},
	doi = {10.3758/BF03193020},
	abstract = {The idea that at least some aspects of word meaning can be induced from patterns of word co-occurrence is becoming increasingly popular. However, there is less agreement about the precise computations involved, and the appropriate tests to distinguish between the various possibilities. It is important that the effect of the relevant design choices and parameter values are understood if psychological models using these methods are to be reliably evaluated and compared. In this article, we present a systematic exploration of the principal computational possibilities for formulating and validating representations of word meanings from word co-occurrence statistics. We find that, once we have identified the best procedures, a very simple approach is surprisingly successful and robust over a range of psychologically relevant evaluation measures.},
	language = {en},
	number = {3},
	urldate = {2020-11-10},
	journal = {Behavior Research Methods},
	author = {Bullinaria, John A. and Levy, Joseph P.},
	month = aug,
	year = {2007},
	pages = {510--526},
	file = {Springer Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\INNN5B2A\\Bullinaria y Levy - 2007 - Extracting semantic representations from word co-o.pdf:application/pdf},
}

@inproceedings{lapesa.evert_2013,
	address = {Sofia, Bulgaria},
	title = {Evaluating {Neighbor} {Rank} and {Distance} {Measures} as {Predictors} of {Semantic} {Priming}},
	url = {https://www.aclweb.org/anthology/W13-2608},
	urldate = {2020-11-10},
	booktitle = {Proceedings of the {Fourth} {Annual} {Workshop} on {Cognitive} {Modeling} and {Computational} {Linguistics} ({CMCL})},
	publisher = {Association for Computational Linguistics},
	author = {Lapesa, Gabriella and Evert, Stefan},
	month = aug,
	year = {2013},
	pages = {66--74},
	file = {Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\8GBI63C4\\Lapesa y Evert - 2013 - Evaluating Neighbor Rank and Distance Measures as .pdf:application/pdf},
}

@article{bostock.etal_2011,
	title = {D³ {Data}-{Driven} {Documents}},
	volume = {17},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/6064996/},
	doi = {10.1109/TVCG.2011.185},
	abstract = {Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-speciﬁc abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efﬁciency and retaining powerful declarative components. Immediate evaluation of operators further simpliﬁes debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.},
	language = {en},
	number = {12},
	urldate = {2020-12-08},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Bostock, M. and Ogievetsky, V. and Heer, J.},
	month = dec,
	year = {2011},
	pages = {2301--2309},
	file = {Bostock e.a. - 2011 - D³ Data-Driven Documents.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\ZK8DLG2A\\Bostock e.a. - 2011 - D³ Data-Driven Documents.pdf:application/pdf},
}

@article{hilpert.flach_2020,
	title = {Disentangling modal meanings with distributional semantics},
	issn = {2055-7671},
	url = {https://doi.org/10.1093/llc/fqaa014},
	doi = {10.1093/llc/fqaa014},
	abstract = {This article investigates the collocational behavior of English modal auxiliaries such as may and might with the aim of finding corpus-based measures that distinguish between different modal expressions and that allow insights into why speakers may choose one over another in a given context. The analysis uses token-based semantic vector space modeling (Heylen et al., 2015, Monitoring polysemy. Word space models as a tool for large-scale lexical semantic analysis. Lingua, 157: 153–72; Hilpert and Correia Saavedra, 2017, Using token-based semantic vector spaces for corpus-linguistic analyses: From practical applications to tests of theoretical claims. Corpus Linguistics and Linguistic Theory) in order to determine whether different modal auxiliaries can be distinguished in terms of their collocational profiles. The analysis further examines whether different senses of the same auxiliary exhibit divergent collocational preferences. The results indicate that near-synonymous pairs of modal expressions, such as may and might or must and have to, differ in their distributional characteristics. Also, different senses of the same modal expression, such as deontic and epistemic uses of may, can be distinguished on the basis of distributional information. We discuss these results against the background of previous empirical findings (Hilpert, 2016, Construction Grammar and its Application to English, 2nd edn. Edinburgh: Edinburgh University Press, Flach, in press, Beyond modal idioms and modal harmony: a corpus-based analysis of gradient idiomaticity in modal-adverb collocations. English Language and Linguistics) and theoretical issues such as degrees of grammaticalization (Correia Saavedra, 2019, Measurements of Grammaticalization: Developing a Quantitative Index for the Study of Grammatical Change. PhD Dissertation, Université de Neuchâtel) and the avoidance of synonymy (Bolinger, 1968, Entailment and the meaning of structures. Glossa, 2(2): 119–27).},
	number = {fqaa014},
	urldate = {2020-12-08},
	journal = {Digital Scholarship in the Humanities},
	author = {Hilpert, Martin and Flach, Susanne},
	month = may,
	year = {2020},
	file = {Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\PFI628UU\\Hilpert en Flach - 2020 - Disentangling modal meanings with distributional s.pdf:application/pdf;Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\YXNIE5BL\\5836757.html:text/html},
}

@article{perek_2018,
	title = {Recent change in the productivity and schematicity of the way-construction: {A} distributional semantic analysis},
	volume = {14},
	issn = {1613-7027, 1613-7035},
	shorttitle = {Recent change in the productivity and schematicity of the way-construction},
	url = {http://www.degruyter.com/view/journals/cllt/14/1/article-p65.xml},
	doi = {10.1515/cllt-2016-0014},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d1175e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}This paper presents a corpus-based study of recent change in the English {\textless}em{\textgreater}way{\textless}/em{\textgreater}-construction, drawing on data from the 1830s to the 2000s. Semantic change in the distribution of the construction is characterized by means of a distributional semantic model, which captures semantic similarity between verbs through their co-occurrence frequency with other words in the corpus. By plotting and comparing the semantic domain of the three senses of the construction at different points in time, it is found that they all have gained in semantic diversity. These findings are interpreted in terms of increases in schematicity, either of the verb slot or the motion component contributed by the construction.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {en},
	number = {1},
	urldate = {2020-12-08},
	journal = {Corpus Linguistics and Linguistic Theory},
	author = {Perek, Florent},
	month = apr,
	year = {2018},
	note = {Publisher: De Gruyter Mouton
Section: Corpus Linguistics and Linguistic Theory},
	pages = {65--97},
	file = {Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\5VLYNBJI\\Perek - 2018 - Recent change in the productivity and schematicity.pdf:application/pdf;Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\N27TPI3A\\article-p65.html:text/html},
}

@incollection{cox.cox_2008,
	address = {Berlin},
	series = {Springer handbooks of computational statistics},
	title = {Multidimensional {Scaling}},
	isbn = {978-3-540-33036-3},
	booktitle = {Handbook of data visualization},
	publisher = {Springer},
	author = {Cox, Michael A. A. and Cox, Trevor F.},
	editor = {Chen, Chun-houh and Härdle, Wolfgang and Unwin, Antony},
	year = {2008},
	note = {OCLC: ocm76799021},
	keywords = {Information visualization},
	pages = {315--348*},
}

@article{perek_2016,
	title = {Using distributional semantics to study syntactic productivity in diachrony: {A} case study},
	volume = {54},
	issn = {0024-3949, 1613-396X},
	shorttitle = {Using distributional semantics to study syntactic productivity in diachrony},
	url = {http://www.degruyter.com/view/journals/ling/54/1/article-p149.xml},
	doi = {10.1515/ling-2015-0043},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d1015e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}This paper investigates syntactic productivity in diachrony with a data-driven approach. Previous research indicates that syntactic productivity (the property of grammatical constructions to attract new lexical fillers) is largely driven by semantics, which calls for an operationalization of lexical meaning in the context of empirical studies. It is suggested that distributional semantics can fulfill this role by providing a measure of semantic similarity between words that is derived from lexical co-occurrences in large text corpora. On the basis of a case study of the construction “V {\textless}em{\textgreater}the hell out of{\textless}/em{\textgreater} NP”, e.g., {\textless}em{\textgreater}You scared the hell out of me{\textless}/em{\textgreater}, it is shown that distributional semantics not only appropriately captures how the verbs in the distribution of the construction are related, but also enables the use of visualization techniques and statistical modeling to analyze the semantic development of a construction over time and identify the determinants of syntactic productivity in naturally occurring data.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {en},
	number = {1},
	urldate = {2020-12-22},
	journal = {Linguistics},
	author = {Perek, Florent},
	month = jan,
	year = {2016},
	note = {Publisher: De Gruyter Mouton
Section: Linguistics},
	pages = {149--188},
	file = {Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\WBDDWTVV\\Perek - 2016 - Using distributional semantics to study syntactic .pdf:application/pdf;Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\PSNWLMMP\\article-p149.html:text/html},
}

@article{perek.hilpert_2017,
	title = {A distributional semantic approach to the periodization of change in the productivity of constructions},
	volume = {22},
	issn = {1384-6655, 1569-9811},
	url = {https://www.jbe-platform.com/content/journals/10.1075/ijcl.16128.per},
	doi = {10.1075/ijcl.16128.per},
	abstract = {This paper describes a method to automatically identify stages of language change in diachronic corpus data, combining variability-based neighbour clustering, which offers objective and reproducible criteria for periodization, and distributional semantics as a representation of lexical meaning. This method partitions the history of a grammatical construction according to qualitative stages of productivity corresponding to different semantic sets of lexical items attested in it. Two case studies are presented. The first case study on the hell-construction (“Verb the hell out of NP”) shows that the semantic development of a construction does not always match that of its quantitative aspects, like token or type frequency. The second case study on the way-construction compares the results of the present method with those of collostructional analysis. It is shown that the former measures semantic changes and their chronology with greater precision. In sum, this method offers a promising approach to exploring semantic variation in the lexical fillers of constructions and to modelling constructional change.},
	language = {en},
	number = {4},
	urldate = {2020-12-22},
	journal = {International Journal of Corpus Linguistics},
	author = {Perek, Florent and Hilpert, Martin},
	month = jan,
	year = {2017},
	note = {Publisher: John Benjamins},
	pages = {490--520},
	file = {Ingediende versie:C\:\\Users\\u0118974\\Zotero\\storage\\AYFCU3UI\\Perek en Hilpert - 2017 - A distributional semantic approach to the periodiz.pdf:application/pdf},
}

@book{glynn.fischer_2010,
	address = {Berlin ; New York},
	series = {Cognitive linguistics research},
	title = {Quantitative methods in cognitive semantics: corpus-driven approaches},
	isbn = {978-3-11-022641-6},
	shorttitle = {Quantitative methods in cognitive semantics},
	number = {46},
	publisher = {De Gruyter Mouton},
	editor = {Glynn, Dylan and Fischer, Kerstin},
	year = {2010},
	note = {OCLC: ocn664354356},
	keywords = {Cognitive grammar, Computational linguistics, Semantics, Kongress},
}

@incollection{geeraerts_2010,
	address = {Berlin ; New York},
	series = {Cognitive linguistics research},
	title = {The doctor and the semantician},
	isbn = {978-3-11-022641-6},
	number = {46},
	booktitle = {Quantitative methods in cognitive semantics: corpus-driven approaches},
	publisher = {De Gruyter Mouton},
	author = {Geeraerts, Dirk},
	editor = {Glynn, Dylan and Fischer, Kerstin},
	year = {2010},
	note = {OCLC: ocn664354356},
	keywords = {Cognitive grammar, Computational linguistics, Semantics, Kongress},
	pages = {63--78},
}

@incollection{stefanowitsch_2010,
	address = {Berlin ; New York},
	series = {Cognitive linguistics research},
	title = {Empirical cognitive semantics: {Some} thoughts},
	isbn = {978-3-11-022641-6},
	number = {46},
	booktitle = {Quantitative methods in cognitive semantics: corpus-driven approaches},
	publisher = {De Gruyter Mouton},
	author = {Stefanowitsch, Anatol},
	editor = {Glynn, Dylan and Fischer, Kerstin},
	year = {2010},
	note = {OCLC: ocn664354356},
	keywords = {Cognitive grammar, Computational linguistics, Semantics, Kongress},
	pages = {355--380},
}

@incollection{glynn_2010,
	address = {Berlin ; New York},
	series = {Cognitive linguistics research},
	title = {Corpus-driven {Cognitive} {Semantics}. {Introduction} to the field},
	isbn = {978-3-11-022641-6},
	number = {46},
	booktitle = {Quantitative methods in cognitive semantics: corpus-driven approaches},
	publisher = {De Gruyter Mouton},
	author = {Glynn, Dylan},
	editor = {Glynn, Dylan and Fischer, Kerstin},
	year = {2010},
	note = {OCLC: ocn664354356},
	keywords = {Cognitive grammar, Computational linguistics, Semantics, Kongress},
	pages = {1--42*},
}

@incollection{koptjevskaja-tamm.sahlgren_2014,
	address = {Berlin, Boston},
	title = {Temperature in the word space: {Sense} exploration of temperature expressions using word-space modelling},
	isbn = {978-3-11-031755-8},
	shorttitle = {Temperature in the word space},
	url = {https://www.degruyter.com/view/books/9783110317558/9783110317558.231/9783110317558.231.xml},
	urldate = {2020-12-25},
	booktitle = {Aggregating {Dialectology}, {Typology}, and {Register} {Analysis}},
	publisher = {DE GRUYTER},
	author = {Koptjevskaja-Tamm, Maria and Sahlgren, Magnus},
	editor = {Szmrecsanyi, Benedikt and Wälchli, Bernhard},
	month = jan,
	year = {2014},
	doi = {10.1515/9783110317558.231},
	pages = {231--267},
	file = {Koptjevskaja-Tamm en Sahlgren - 2014 - Temperature in the word space Sense exploration o.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\5YCM5DQ7\\Koptjevskaja-Tamm en Sahlgren - 2014 - Temperature in the word space Sense exploration o.pdf:application/pdf},
}

@article{geeraerts_1993,
	title = {Vagueness's puzzles, polysemy's vagaries},
	volume = {4},
	journal = {Cognitive Linguistics},
	author = {Geeraerts, Dirk},
	year = {1993},
	pages = {223--272},
}

@incollection{montes.heylen_Submitted,
	title = {Visualizing {Distributional} {Semantics}},
	copyright = {All rights reserved},
	isbn = {978-3-11-068734-7},
	language = {en},
	publisher = {Mouton De Gruyter},
	author = {Montes, Mariana and Heylen, Kris},
	editor = {Tay, Dennis and Pan, Molly Xie},
	note = {Status: Submitted
Submitted Date: 2020-12-30},
}

@article{rousseeuw_1987,
	title = {Silhouettes: {A} graphical aid to the interpretation and validation of cluster analysis},
	volume = {20},
	issn = {03770427},
	shorttitle = {Silhouettes},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0377042787901257},
	doi = {10.1016/0377-0427(87)90125-7},
	abstract = {A new graphical display is proposed for partitioning techniques. Each cluster is represented by a so-called silhouette, which is based on the comparison of its tightness and separation. This silhouette shows which objects he well within their cluster, and which ones are merely somewhere in between clusters. The entire clustering is displayed by combining the silhouettes into a single plot, allowing an appreciation of the relative quality of the clusters and an overview of the data configuration. The average silhouette width provides an evaluation of clustering validity, and might be used to select an ‘appropriate’ number of clusters.},
	language = {en},
	urldate = {2021-02-19},
	journal = {Journal of Computational and Applied Mathematics},
	author = {Rousseeuw, Peter J.},
	month = nov,
	year = {1987},
	pages = {53--65},
	file = {Rousseeuw - 1987 - Silhouettes A graphical aid to the interpretation.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\JLLNNN4N\\Rousseeuw - 1987 - Silhouettes A graphical aid to the interpretation.pdf:application/pdf},
}

@book{bolognesi_2020,
	address = {Amsterdam},
	series = {Converging {Evidence} in {Language} and {Communication} {Research}},
	title = {Where {Words} {Get} their {Meaning}: {Cognitive} processing and distributional modelling of word meaning in first and second language},
	isbn = {978-90-272-0801-9 978-90-272-6042-0},
	shorttitle = {Where {Words} {Get} their {Meaning}},
	url = {http://www.jbe-platform.com/content/books/9789027260420},
	language = {en},
	urldate = {2021-04-27},
	publisher = {John Benjamins Publishing Company},
	author = {Bolognesi, Marianna},
	month = nov,
	year = {2020},
	doi = {10.1075/celcr.23},
}

@phdthesis{sahlgren_2006,
	address = {Stockholm},
	title = {The word-space model: using distributional analysis to represent syntagmatic and paradigmatic relations between words in high-dimensional vector spaces},
	shorttitle = {The word-space model},
	language = {en},
	school = {Dep. of Linguistics, Stockholm Univ. [u.a.]},
	author = {Sahlgren, Magnus},
	year = {2006},
	note = {OCLC: 255579201},
	file = {Sahlgren - 2006 - The word-space model using distributional analysi.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\XJFN3AZD\\Sahlgren - 2006 - The word-space model using distributional analysi.pdf:application/pdf},
}

@article{BERT,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2021-04-27},
	journal = {arXiv:1810.04805 [cs]},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv: 1810.04805},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\u0118974\\Zotero\\storage\\JPIUWCYQ\\Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\85K98SLY\\1810.html:text/html},
}

@misc{montes.qlvl_2021,
	title = {{QLVL}/{NephoVis}: {Stratocumulus}},
	copyright = {Open Access},
	shorttitle = {{QLVL}/{NephoVis}},
	url = {https://zenodo.org/record/4726926},
	abstract = {Relatively viable version, especially for levels 1 and 2.},
	urldate = {2021-04-29},
	publisher = {Zenodo},
	author = {Montes, Mariana and QLVL},
	month = apr,
	year = {2021},
	doi = {10.5281/ZENODO.4726926},
}

@article{harris_1954,
	title = {Distributional structure},
	volume = {10},
	number = {2-3},
	journal = {Word},
	author = {Harris, Zellig S.},
	year = {1954},
	note = {Publisher: Taylor \& Francis},
	pages = {146--162},
}

@inproceedings{campello.etal_2013,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Density-{Based} {Clustering} {Based} on {Hierarchical} {Density} {Estimates}},
	isbn = {978-3-642-37456-2},
	doi = {10.1007/978-3-642-37456-2_14},
	abstract = {We propose a theoretically and practically improved density-based, hierarchical clustering method, providing a clustering hierarchy from which a simplified tree of significant clusters can be constructed. For obtaining a “flat” partition consisting of only the most significant clusters (possibly corresponding to different density thresholds), we propose a novel cluster stability measure, formalize the problem of maximizing the overall stability of selected clusters, and formulate an algorithm that computes an optimal solution to this problem. We demonstrate that our approach outperforms the current, state-of-the-art, density-based clustering methods on a wide variety of real world data.},
	language = {en},
	booktitle = {Advances in {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Springer},
	author = {Campello, Ricardo J. G. B. and Moulavi, Davoud and Sander, Joerg},
	editor = {Pei, Jian and Tseng, Vincent S. and Cao, Longbing and Motoda, Hiroshi and Xu, Guandong},
	year = {2013},
	keywords = {Cluster Tree, Core Object, Density Threshold, Hierarchical Cluster Method, Minimum Span Tree},
	pages = {160--172},
	file = {Springer Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\S5V7562X\\Campello et al. - 2013 - Density-Based Clustering Based on Hierarchical Den.pdf:application/pdf},
}

@misc{mcinnes.etal_2016,
	title = {How {HDBSCAN} {Works} — hdbscan 0.8.1 documentation},
	url = {https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html},
	urldate = {2021-04-30},
	author = {McInnes, Leland and Healy, John and Astels, Steve},
	year = {2016},
	file = {How HDBSCAN Works — hdbscan 0.8.1 documentation:C\:\\Users\\u0118974\\Zotero\\storage\\3RQD77MC\\how_hdbscan_works.html:text/html},
}

@article{levy.etal_2015,
	title = {Improving {Distributional} {Similarity} with {Lessons} {Learned} from {Word} {Embeddings}},
	volume = {3},
	url = {https://www.aclweb.org/anthology/Q15-1016},
	doi = {10.1162/tacl_a_00134},
	abstract = {Recent trends suggest that neural-network-inspired word embedding models outperform traditional count-based distributional models on word similarity and analogy detection tasks. We reveal that much of the performance gains of word embeddings are due to certain system design choices and hyperparameter optimizations, rather than the embedding algorithms themselves. Furthermore, we show that these modifications can be transferred to traditional distributional models, yielding similar gains. In contrast to prior reports, we observe mostly local or insignificant performance differences between the methods, with no global advantage to any single approach over the others.},
	urldate = {2021-04-30},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Levy, Omer and Goldberg, Yoav and Dagan, Ido},
	year = {2015},
	pages = {211--225},
	file = {Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\WBH54C2Q\\Levy et al. - 2015 - Improving Distributional Similarity with Lessons L.pdf:application/pdf},
}

@article{lapesa.evert_2014,
	title = {A {Large} {Scale} {Evaluation} of {Distributional} {Semantic} {Models}: {Parameters}, {Interactions} and {Model} {Selection}},
	volume = {2},
	issn = {2307-387X},
	shorttitle = {A {Large} {Scale} {Evaluation} of {Distributional} {Semantic} {Models}},
	url = {https://doi.org/10.1162/tacl_a_00201},
	doi = {10.1162/tacl_a_00201},
	abstract = {This paper presents the results of a large-scale evaluation study of window-based
Distributional Semantic Models on a wide variety of tasks. Our study combines a
broad coverage of model parameters with a model selection methodology that is
robust to overfitting and able to capture parameter interactions. We show that
our strategy allows us to identify parameter configurations that achieve good
performance across different datasets and tasks.},
	urldate = {2021-04-30},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Lapesa, Gabriella and Evert, Stefan},
	month = dec,
	year = {2014},
	pages = {531--546},
	file = {Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\38LFFRYM\\Lapesa and Evert - 2014 - A Large Scale Evaluation of Distributional Semanti.pdf:application/pdf;Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\98QUEUFB\\A-Large-Scale-Evaluation-of-Distributional.html:text/html},
}

@article{devries.etal_2019,
	title = {{BERTje}: {A} {Dutch} {BERT} {Model}},
	shorttitle = {{BERTje}},
	url = {http://arxiv.org/abs/1912.09582},
	abstract = {The transformer-based pre-trained language model BERT has helped to improve state-of-the-art performance on many natural language processing (NLP) tasks. Using the same architecture and parameters, we developed and evaluated a monolingual Dutch BERT model called BERTje. Compared to the multilingual BERT model, which includes Dutch but is only based on Wikipedia text, BERTje is based on a large and diverse dataset of 2.4 billion tokens. BERTje consistently outperforms the equally-sized multilingual BERT model on downstream NLP tasks (part-of-speech tagging, named-entity recognition, semantic role labeling, and sentiment analysis). Our pre-trained Dutch BERT model is made available at https://github.com/wietsedv/bertje.},
	urldate = {2021-05-01},
	journal = {arXiv:1912.09582 [cs]},
	author = {de Vries, Wietse and van Cranenburgh, Andreas and Bisazza, Arianna and Caselli, Tommaso and van Noord, Gertjan and Nissim, Malvina},
	month = dec,
	year = {2019},
	note = {arXiv: 1912.09582},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\u0118974\\Zotero\\storage\\NMLQUI35\\de Vries et al. - 2019 - BERTje A Dutch BERT Model.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\IN2WYIBF\\1912.html:text/html},
}

@article{glynn_2016,
	title = {Quantifying polysemy: {Corpus} methodology for prototype theory},
	volume = {50},
	issn = {1614-7308},
	shorttitle = {Quantifying polysemy},
	url = {http://www.degruyter.com/document/doi/10.1515/flin-2016-0016/html},
	doi = {10.1515/flin-2016-0016},
	abstract = {This study addresses the methodological problem of result falsification in Cognitive Semantics, specifically in the descriptive analysis of semasiological variation, or “polysemy”. It argues that manually analysed corpus data can be used to describe models of semantic structure. The method proposed is quantified, permitting repeat analysis. The operationalisation of a semasiological structure employed in the study takes the principle of semantic features and applies them to a contextual analysis of usage-events, associated with the lexeme under scrutiny. The feature analysis, repeated on a large collection of occurrences, results in a set of metadata that constitutes the usage-profile of the lexeme. Multivariate statistics are then employed to identify patterns in those metadata. The case study examines 500 occurrences of the English lexeme annoy . Three basic senses are identified as well as a more complex array of semantic variations linked to morpho-syntactic context of usage.},
	language = {en},
	number = {2},
	urldate = {2021-05-01},
	journal = {Folia Linguistica},
	author = {Glynn, Dylan},
	month = nov,
	year = {2016},
	note = {Publisher: De Gruyter
Section: Folia Linguistica},
	pages = {413--447},
	file = {Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\XTYYGQ7B\\html.html:text/html},
}

@incollection{firth_1957a,
	address = {Oxford},
	series = {Special volume of the {Philological} {Society}},
	title = {A synopsis of linguistic theory 1930-1955},
	isbn = {978-0-631-11300-3},
	url = {http://cs.brown.edu/courses/csci2952d/readings/lecture1-firth.pdf},
	urldate = {2021-05-03},
	booktitle = {Studies in {Linguistic} {Analysis}},
	publisher = {Blackwell},
	author = {Firth, John Rupert},
	editor = {Firth, John Rupert},
	year = {1957},
	pages = {1--32},
	file = {lecture1-firth.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\QXEJHCGN\\lecture1-firth.pdf:application/pdf},
}

@book{rudzka-ostyn_1988,
	address = {Amsterdam},
	series = {Current {Issues} in {Linguistic} {Theory}},
	title = {Topics in {Cognitive} {Linguistics}},
	volume = {50},
	isbn = {978-90-272-3544-2 978-90-272-8619-2},
	url = {http://www.jbe-platform.com/content/books/9789027286192},
	language = {en},
	urldate = {2021-05-04},
	publisher = {John Benjamins Publishing Company},
	editor = {Rudzka-Ostyn, Brygida},
	month = jan,
	year = {1988},
	doi = {10.1075/cilt.50},
}

@incollection{langacker_1988,
	address = {Amsterdam},
	title = {An overview of cognitive grammar},
	volume = {50},
	isbn = {978-90-272-3544-2 978-90-272-8619-2},
	url = {https://benjamins.com/catalog/cilt.50.03lan},
	language = {en},
	urldate = {2021-05-04},
	booktitle = {Current {Issues} in {Linguistic} {Theory}},
	publisher = {John Benjamins Publishing Company},
	author = {Langacker, Ronald W.},
	editor = {Rudzka-Ostyn, Brygida},
	year = {1988},
	doi = {10.1075/cilt.50.03lan},
	pages = {3--48},
}

@incollection{geeraerts_1988,
	address = {Amsterdam},
	title = {Where does prototypicality come from?},
	volume = {50},
	isbn = {978-90-272-3544-2 978-90-272-8619-2},
	url = {https://benjamins.com/catalog/cilt.50.09gee},
	language = {en},
	urldate = {2021-05-04},
	booktitle = {Current {Issues} in {Linguistic} {Theory}},
	publisher = {John Benjamins Publishing Company},
	author = {Geeraerts, Dirk},
	editor = {Rudzka-Ostyn, Brygida},
	year = {1988},
	doi = {10.1075/cilt.50.09gee},
	pages = {207--229},
}

@incollection{kaufman.rousseeuw_1990,
	address = {Hoboken, NJ, USA},
	series = {Wiley {Series} in {Probability} and {Statistics}},
	title = {Partitioning {Around} {Medoids} ({Program} {PAM})},
	isbn = {978-0-470-31680-1 978-0-471-87876-6},
	url = {http://doi.wiley.com/10.1002/9780470316801.ch2},
	language = {en},
	urldate = {2021-05-04},
	booktitle = {Finding {Groups} in {Data}: {An} {Introduction} to {Cluster} {Analysis}},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Kaufman, Leonard and Rousseeuw, Peter J.},
	collaborator = {Kaufman, Leonard and Rousseeuw, Peter J.},
	month = mar,
	year = {1990},
	doi = {10.1002/9780470316801.ch2},
	pages = {68--125},
}

@inproceedings{vieu.etal_2015,
	address = {Tübingen, Germany},
	title = {Quantitative methods for identifying systematic polysemy classes},
	abstract = {In this paper we report the results of four experiments conducted to extract lists of nouns that exhibit inherent polysemy from corpus data following semiautomatic and automatic procedures. We compare the methods used and the results obtained. We argue that quantitative methods can be used to distinguish different classes of polysemous nouns in the language on the basis of the variability of copredication contexts.},
	language = {en},
	author = {Vieu, Laure and Jezek, Elisabetta and di Pavia, Universita and de Cruys, Tim Van},
	year = {2015},
	file = {Vieu et al. - Quantitative methods for identifying systematic po.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\AIUWXWIZ\\Vieu et al. - Quantitative methods for identifying systematic po.pdf:application/pdf},
}

@inproceedings{decruys.etal_2013,
	address = {Atlanta, Georgia, USA},
	title = {A {Tensor}-based {Factorization} {Model} of {Semantic} {Compositionality}},
	abstract = {In this paper, we present a novel method for the computation of compositionality within a distributional framework. The key idea is that compositionality is modeled as a multi-way interaction between latent factors, which are automatically constructed from corpus data. We use our method to model the composition of subject verb object triples. The method consists of two steps. First, we compute a latent factor model for nouns from standard co-occurrence data. Next, the latent factors are used to induce a latent model of three-way subject verb object interactions. Our model has been evaluated on a similarity task for transitive phrases, in which it exceeds the state of the art.},
	language = {en},
	booktitle = {Proceedings of {NAACL} 2013},
	author = {de Cruys, Tim Van and Poibeau, Thierry and Korhonen, Anna},
	year = {2013},
	pages = {1142--1151},
	file = {de Cruys et al. - A Tensor-based Factorization Model of Semantic Com.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\G4KFAZBM\\de Cruys et al. - A Tensor-based Factorization Model of Semantic Com.pdf:application/pdf},
}

@inproceedings{decruys.etal_2011,
	address = {Edinburgh, Scotland, UK},
	title = {Latent {Vector} {Weighting} for {Word} {Meaning} in {Context}},
	abstract = {This paper presents a novel method for the computation of word meaning in context. We make use of a factorization model in which words, together with their window-based context words and their dependency relations, are linked to latent dimensions. The factorization model allows us to determine which dimensions are important for a particular context, and adapt the dependency-based feature vector of the word accordingly. The evaluation on a lexical substitution task – carried out for both English and French – indicates that our approach is able to reach better results than state-of-the-art methods in lexical substitution, while at the same time providing more accurate meaning representations.},
	language = {en},
	booktitle = {Proceedings of the 2011 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {de Cruys, Tim Van and Poibeau, Thierry and Korhonen, Anna},
	month = jul,
	year = {2011},
	pages = {1012--1022},
	file = {de Cruys et al. - Latent Vector Weighting for Word Meaning in Contex.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\8R296ST5\\de Cruys et al. - Latent Vector Weighting for Word Meaning in Contex.pdf:application/pdf},
}

@inproceedings{decruys.apidianaki_2011,
	address = {Portland, Oregon},
	title = {Latent {Semantic} {Word} {Sense} {Induction} and {Disambiguation}},
	abstract = {In this paper, we present a uniﬁed model for the automatic induction of word senses from text, and the subsequent disambiguation of particular word instances using the automatically extracted sense inventory. The induction step and the disambiguation step are based on the same principle: words and contexts are mapped to a limited number of topical dimensions in a latent semantic word space. The intuition is that a particular sense is associated with a particular topic, so that different senses can be discriminated through their association with particular topical dimensions; in a similar vein, a particular instance of a word can be disambiguated by determining its most important topical dimensions. The model is evaluated on the SEMEVAL-2010 word sense induction and disambiguation task, on which it reaches stateof-the-art results.},
	language = {en},
	booktitle = {Proceedings of the 49th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {de Cruys, Tim Van and Apidianaki, Marianna},
	month = jun,
	year = {2011},
	pages = {1476--1485},
	file = {de Cruys and Apidianaki - Latent Semantic Word Sense Induction and Disambigu.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\ABWQANAD\\de Cruys and Apidianaki - Latent Semantic Word Sense Induction and Disambigu.pdf:application/pdf},
}

@inproceedings{apidianaki.vandecruys_2011,
	address = {Tokyo, Japan},
	title = {A {Quantitative} {Evaluation} of {Global} {Word} {Sense} {Induction}},
	volume = {6608},
	isbn = {978-3-642-19399-6 978-3-642-19400-9},
	url = {http://link.springer.com/10.1007/978-3-642-19400-9_20},
	abstract = {Word sense induction (WSI) is the task aimed at automatically identifying the senses of words in texts, without the need for handcrafted resources or annotated data. Up till now, most WSI algorithms extract the diﬀerent senses of a word ‘locally’ on a per-word basis, i.e. the diﬀerent senses for each word are determined separately. In this paper, we compare the performance of such algorithms to an algorithm that uses a ‘global’ approach, i.e. the diﬀerent senses of a particular word are determined by comparing them to, and demarcating them from, the senses of other words in a full-blown word space model. We adopt the evaluation framework proposed in the SemEval-2010 Word Sense Induction \& Disambiguation task. All systems that participated in this task use a local scheme for determining the diﬀerent senses of a word. We compare their results to the ones obtained by the global approach, and discuss the advantages and weaknesses of both approaches.},
	language = {en},
	urldate = {2021-05-07},
	booktitle = {Computational {Linguistics} and {Intelligent} {Text} {Processing}},
	author = {Apidianaki, Marianna and Van de Cruys, Tim},
	editor = {Gelbukh, Alexander F.},
	year = {2011},
	doi = {10.1007/978-3-642-19400-9_20},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {253--264},
	file = {Apidianaki and Van de Cruys - 2011 - A Quantitative Evaluation of Global Word Sense Ind.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\YPXMUNDX\\Apidianaki and Van de Cruys - 2011 - A Quantitative Evaluation of Global Word Sense Ind.pdf:application/pdf},
}

@book{jurafsky.martin_2020,
	edition = {3},
	title = {Speech and {Language} {Processing}},
	url = {https://web.stanford.edu/~jurafsky/slp3/ed3book_dec302020.pdf},
	urldate = {2021-05-07},
	author = {Jurafsky, Daniel and Martin, James H.},
	year = {2020},
	file = {Jurafsky_Martin_2020.pdf:C\:\\Users\\u0118974\\Documents\\Bibliography\\Jurafsky_Martin_2020.pdf:application/pdf},
}

@misc{oskolkov_2021,
	title = {How {Exactly} {UMAP} {Works}},
	url = {https://towardsdatascience.com/how-exactly-umap-works-13e3040e1668},
	abstract = {And why exactly it is better than tSNE},
	language = {en},
	urldate = {2021-05-07},
	journal = {Medium},
	author = {Oskolkov, Nikolay},
	month = mar,
	year = {2021},
	note = {Library Catalog: towardsdatascience.com},
	file = {Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\2RHABLHP\\how-exactly-umap-works-13e3040e1668.html:text/html},
}

@article{mcinnes.etal_2020,
	title = {{UMAP}: {Uniform} {Manifold} {Approximation} and {Projection} for {Dimension} {Reduction}},
	shorttitle = {{UMAP}},
	url = {http://arxiv.org/abs/1802.03426},
	abstract = {UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
	urldate = {2021-05-07},
	journal = {arXiv:1802.03426 [cs, stat]},
	author = {McInnes, Leland and Healy, John and Melville, James},
	month = sep,
	year = {2020},
	note = {arXiv: 1802.03426},
	keywords = {Statistics - Machine Learning, Computer Science - Computational Geometry, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\u0118974\\Zotero\\storage\\BMKPHHQG\\McInnes et al. - 2020 - UMAP Uniform Manifold Approximation and Projectio.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\636HTZJW\\1802.html:text/html},
}

@inproceedings{vandecruys_2008,
	address = {Hamburg, Germany},
	title = {A {Comparison} of {Bag} of {Words} and {Syntax}-based {Approaches} for {Word} {Categorization}},
	booktitle = {Lexical semantics: bridging the gap between semantic theory and computational simulations},
	author = {Van De Cruys, Tim},
	editor = {Baroni, Marco and Evert, Stefan and Lenci, Alessandro},
	year = {2008},
	pages = {47--54},
}

@article{lenci_2008,
	title = {Distributional semantics in linguistic and cognitive research},
	volume = {20},
	issn = {2499-8125},
	url = {http://www.italian-journal-linguistics.com/italian-journal-of-linguistics-2008/},
	language = {en},
	number = {1},
	urldate = {2021-05-11},
	journal = {Italian Journal of Linguistics},
	author = {Lenci, Alessandro},
	editor = {Lenci, Alessandro},
	year = {2008},
	pages = {1--31},
	file = {Lenci - Distributional semantics in linguistic and cogniti.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\D4HFZBX4\\Lenci - Distributional semantics in linguistic and cogniti.pdf:application/pdf},
}

@article{sahlgren_2008,
	title = {The distributional hypothesis},
	volume = {20},
	issn = {2499-8125},
	url = {http://www.italian-journal-linguistics.com/italian-journal-of-linguistics-2008/},
	language = {en},
	number = {1},
	urldate = {2021-05-11},
	journal = {Italian Journal of Linguistics},
	author = {Sahlgren, Magnus},
	year = {2008},
	pages = {33--53},
	file = {Sahlgren - The distributional hypothesis.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\I267JSGY\\Sahlgren - The distributional hypothesis.pdf:application/pdf},
}

@incollection{geeraerts_2017,
	address = {Bloomington, Indiana},
	title = {Distributionalism, old and new},
	isbn = {978-0-89357-478-9},
	abstract = {"This volume of essays in Slavic linguistics is presented in honor of Laura A. Janda, Professor of Russian Linguistics at the University of Tromsø, Norway. The majority of the contributions apply the theoretical methodology of cognitive linguistics, of which Janda is one of the world's foremost practitioners, though other contributions could be properly characterized as "fellow travelers", applying different methodologies to achieve similar insights into the semantic structure of Slavic languages"--},
	booktitle = {Each venture a new beginning: studies in honor of {Laura} {A}. {Janda}},
	publisher = {Slavica},
	author = {Geeraerts, Dirk},
	editor = {Makarova, Anastasii︠a︡ and Dickey, Stephen M. and Divjak, Dagmar},
	year = {2017},
	keywords = {Cognitive grammar, Linguistic models, Slavic languages},
	pages = {29--38},
	file = {Geeraerts - 2017 - Distributionalism, old and new.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\WBSFNNKF\\Geeraerts - 2017 - Distributionalism, old and new.pdf:application/pdf},
}

@book{geeraerts_1997,
	address = {Oxford : New York},
	series = {Oxford studies in lexicography and lexicology},
	title = {Diachronic prototype semantics: a contribution to historical lexicology},
	isbn = {978-0-19-823652-8},
	shorttitle = {Diachronic prototype semantics},
	publisher = {Clarendon Press ; Oxford University Press},
	author = {Geeraerts, Dirk},
	year = {1997},
	keywords = {Cognitive grammar, Linguistic change, Semantics, Historical},
}

@incollection{evert_2009,
	address = {Berlin, New York},
	series = {Handbooks of {Linguistics} and {Communication} {Science}},
	title = {58. {Corpora} and collocations},
	volume = {2},
	isbn = {978-3-11-021388-1},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110213881.2.1212/html},
	urldate = {2021-05-11},
	booktitle = {Corpus {Linguistics}. {An} {International} {Handbook}},
	publisher = {Mouton de Gruyter},
	author = {Evert, Stefan},
	editor = {Lüdeling, Anke and Kytö, Merja},
	month = mar,
	year = {2009},
	doi = {10.1515/9783110213881.2.1212},
	pages = {1212--1248},
}

@book{geeraerts.etal_1999,
	address = {Amsterdam},
	series = {Publikaties van het {Meertens}-{Instituut}},
	title = {Convergentie en divergentie in de {Nederlandse} woordenschat: een onderzoek naar kleding- en voetbaltermen},
	isbn = {978-90-70389-60-4},
	shorttitle = {Convergentie en divergentie in de {Nederlandse} woordenschat},
	language = {nl},
	number = {31},
	publisher = {Meertens-Instituut},
	author = {Geeraerts, Dirk and Grondelaers, Stefan and Speelman, Dirk},
	year = {1999},
	note = {OCLC: 238794008},
	file = {1999 Convergentie en divergentie in de Nederlandse woordenschat.pdf:C\:\\Users\\u0118974\\Documents\\Bibliography\\1999 Convergentie en divergentie in de Nederlandse woordenschat.pdf:application/pdf},
}

@article{kilgarriff_1997,
	title = {"{I} don't believe in word senses"},
	volume = {31},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110895698.361/html},
	abstract = {Word sense disambiguation assumes word senses. Within the lexicography and lingu literature, they are known to be very slippery entities. The paper looks at problems with ex accounts of 'word sense' and describes the various kinds of ways in which a word's meani deviate from its core meaning. An analysis is presented in which word senses are abstraction clusters of corpus citations, in accordance with current lexicographic practice. The corpus cit not the word senses, are the basic objects in the ontology. The corpus citations will be cluster senses according to the purposes of whoever or whatever does the clustering. In the absence purposes, word senses do not exist. Word sense disambiguation also needs a set of word senses to disambiguate between. In recent work, the set has been taken from a general-purpose lexical resource, with the assu that the lexical resource describes the word senses of English/French/..., between whi applications will need to disambiguate. The implication of the paper is, by contrast, that word exist only relative to a task.},
	language = {en},
	number = {2},
	urldate = {2021-05-11},
	journal = {Computers and the Humanities},
	author = {Kilgarriff, Adam},
	year = {1997},
	doi = {10.1515/9783110895698.361},
	pages = {91--113},
	file = {Kilgarriff - 2003 - I don't believe in word senses.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\K85FHZWU\\Kilgarriff - 2003 - I don't believe in word senses.pdf:application/pdf},
}

@inproceedings{yarowsky_1995,
	address = {Cambridge, Massachusetts, USA},
	title = {Unsupervised word sense disambiguation rivaling supervised methods},
	url = {https://www.aclweb.org/anthology/P95-1026},
	doi = {10.3115/981658.981684},
	booktitle = {33rd annual meeting of the association for computational linguistics},
	publisher = {Association for Computational Linguistics},
	author = {Yarowsky, David},
	month = jun,
	year = {1995},
	pages = {189--196},
	file = {Yarowsky (1995).pdf:C\:\\Users\\u0118974\\Documents\\Bibliography\\Yarowsky (1995).pdf:application/pdf},
}

@article{geeraerts_2016a,
	title = {The sociosemiotic commitment},
	volume = {27},
	issn = {0936-5907, 1613-3641},
	url = {https://www.degruyter.com/document/doi/10.1515/cog-2016-0058/html},
	doi = {10.1515/cog-2016-0058},
	abstract = {Abstract
            Cognitive Linguistics should complement the Cognitive Commitment with a Sociosemiotic Commitment: a commitment to make one’s account of human language accord with the status of language as a social semiotic, i. e., as an intersubjective, historically and socially variable tool, and to base that account on a methodology that likewise transcends the individual. By looking at defining features of Cognitive Linguistics (its cognitive orientation, and its usage-based character), it is argued that the relevance of the Sociosemiotic Commitment derives from the very essence of Cognitive Linguistics.},
	number = {4},
	urldate = {2021-05-25},
	journal = {Cognitive Linguistics},
	author = {Geeraerts, Dirk},
	month = nov,
	year = {2016},
	pages = {527--542},
}

@incollection{geeraerts_1999,
	address = {Berlin},
	title = {Idealist and empiricist tendencies in {Cognitive} {Linguistics}},
	booktitle = {Cognitive {Linguistics}: {Foundations}, {Scope}, and {Methodology}},
	publisher = {Mouton de Gruyter},
	author = {Geeraerts, Dirk},
	editor = {Janssen, Theo and Redeker, Gisela},
	year = {1999},
	pages = {163--194},
}

@incollection{sinclair_1998,
	address = {Amsterdam},
	series = {Amsterdam studies in the theory and history of linguistic science {Series} 4, {Current} issues in linguistic theory},
	title = {The {Lexical} {Item}},
	isbn = {978-90-272-3676-0 978-1-55619-887-8},
	language = {eng},
	number = {171},
	booktitle = {Contrastive lexical semantics},
	publisher = {Benjamins},
	author = {Sinclair, John},
	editor = {Weigand, Edda},
	year = {1998},
	pages = {1--24},
}

@article{stubbs_2009,
	title = {Memorial {Article}: {John} {Sinclair} (1933–2007)},
	volume = {30},
	issn = {1477-450X, 0142-6001},
	shorttitle = {Memorial {Article}},
	url = {https://academic.oup.com/applij/article-lookup/doi/10.1093/applin/amn052},
	doi = {10.1093/applin/amn052},
	language = {en},
	number = {1},
	urldate = {2021-06-30},
	journal = {Applied Linguistics},
	author = {Stubbs, Michael},
	month = mar,
	year = {2009},
	pages = {115--137},
}

@book{tognini-bonelli_2001,
	address = {Amsterdam; Philadelphia [Pa.},
	title = {Corpus linguistics at work},
	url = {http://site.ebrary.com/id/10463014},
	language = {English},
	urldate = {2021-07-06},
	publisher = {J. Benjamins},
	author = {Tognini-Bonelli, Elena},
	year = {2001},
	note = {OCLC: 748933474},
}

@book{wittgenstein_1958,
	address = {Cambridge, Mass},
	edition = {2nd ed., repr},
	title = {Philosophical investigations},
	isbn = {978-0-631-20569-2},
	shorttitle = {Philosophical investigations},
	language = {eng},
	publisher = {Blackwell},
	author = {Wittgenstein, Ludwig},
	translator = {Anscombe, G. E. M.},
	year = {1958},
	note = {Original Date: 1953
Original Title: Philosophische Untersuchungen},
}

@article{kruskal_1964,
	title = {Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis},
	volume = {29},
	number = {1},
	journal = {Psychometrika},
	author = {Kruskal, J. B},
	month = mar,
	year = {1964},
	pages = {1--27},
}

@inproceedings{vannoord_2006,
	address = {Leuven, Belgique},
	title = {At {Last} {Parsing} {Is} {Now} {Operational}},
	url = {https://aclanthology.org/2006.jeptalnrecital-invite.2},
	abstract = {Natural language analysis systems which combine knowledge-based and corpus-based methods are now becoming accurate enough to be used in various applications. We describe one such parsing system for Dutch, known as Alpino, and we show how corpus-based methods are essential to obtain accurate knowledge-based parsers. In particular we show a variety of cases where large amounts of parser output are used to improve the parser.},
	urldate = {2021-07-12},
	booktitle = {Actes de la 13ème conférence sur le {Traitement} {Automatique} des {Langues} {Naturelles}. {Conférences} invitées},
	publisher = {ATALA},
	author = {van Noord, Gertjan},
	month = apr,
	year = {2006},
	pages = {20--42},
	file = {Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\VDPJ53AM\\van Noord - 2006 - At Last Parsing Is Now Operational.pdf:application/pdf},
}

@misc{okabe.ito_2002,
	title = {Color {Universal} {Design} ({CUD}). {How} to make figures and presentations that are friendly to {Colorblind} people},
	url = {https://jfly.uni-koeln.de/color/},
	urldate = {2021-07-13},
	journal = {J*Fly Data Depository for Drosophila researchers},
	author = {Okabe, Masataka and Ito, Kei},
	month = nov,
	year = {2002},
	file = {Color Universal Design (CUD) / Colorblind Barrier Free:C\:\\Users\\u0118974\\Zotero\\storage\\APCF9CQU\\color.html:text/html},
}

@article{fleiss_1971,
	title = {Measuring nominal scale agreement among many raters.},
	volume = {76},
	issn = {0033-2909},
	url = {http://content.apa.org/journals/bul/76/5/378},
	doi = {10.1037/h0031619},
	language = {en},
	number = {5},
	urldate = {2021-07-15},
	journal = {Psychological Bulletin},
	author = {Fleiss, Joseph L.},
	year = {1971},
	pages = {378--382},
}

@inproceedings{raganato.etal_2017,
	address = {Valencia, Spain},
	title = {Word {Sense} {Disambiguation}: {A} {Unified} {Evaluation} {Framework} and {Empirical} {Comparison}},
	shorttitle = {Word {Sense} {Disambiguation}},
	url = {http://aclweb.org/anthology/E17-1010},
	doi = {10.18653/v1/E17-1010},
	abstract = {Word Sense Disambiguation is a longstanding task in Natural Language Processing, lying at the core of human language understanding. However, the evaluation of automatic systems has been problematic, mainly due to the lack of a reliable evaluation framework. In this paper we develop a uniﬁed evaluation framework and analyze the performance of various Word Sense Disambiguation systems in a fair setup. The results show that supervised systems clearly outperform knowledge-based models. Among the supervised systems, a linear classiﬁer trained on conventional local features still proves to be a hard baseline to beat. Nonetheless, recent approaches exploiting neural networks on unlabeled corpora achieve promising results, surpassing this hard baseline in most test sets.},
	language = {en},
	urldate = {2021-07-16},
	booktitle = {Proceedings of the 15th {Conference} of the {European} {Chapter} of the           {Association} for {Computational} {Linguistics}: {Volume} 1, {Long} {Papers}},
	publisher = {Association for Computational Linguistics},
	author = {Raganato, Alessandro and Camacho-Collados, Jose and Navigli, Roberto},
	year = {2017},
	pages = {99--110},
	file = {Raganato et al. - 2017 - Word Sense Disambiguation A Unified Evaluation Fr.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\PMMEBWW5\\Raganato et al. - 2017 - Word Sense Disambiguation A Unified Evaluation Fr.pdf:application/pdf},
}

@article{mikolov.etal_2013,
	title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
	url = {http://arxiv.org/abs/1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	urldate = {2021-07-16},
	journal = {arXiv:1301.3781 [cs]},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = sep,
	year = {2013},
	note = {arXiv: 1301.3781},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\u0118974\\Zotero\\storage\\5BUQJ7V7\\Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\XZ9HNWEV\\1301.html:text/html},
}

@book{desaussure_1971,
	address = {Paris},
	title = {Cours de linguistique génerale},
	publisher = {Payot},
	author = {de Saussure, Ferdinand},
	editor = {Bally, Charles and Sechehaye, Albert},
	year = {1971},
	note = {original-date : 1916},
}

@incollection{rosch_1978,
	address = {Hillsdale, New Jersey},
	title = {Principles of categorization},
	booktitle = {Cognition and {Categorization}},
	publisher = {Lawrence Erlbaum Associates},
	author = {Rosch, Eleanor},
	editor = {Rosch, Eleanor and Lloyd, Barbara B.},
	year = {1978},
	pages = {27--48},
}

@article{landauer.dumais_1997,
	title = {A solution to {Plato}'s problem: {The} latent semantic analysis theory of acquisition, induction, and representation of knowledge.},
	volume = {104},
	issn = {1939-1471, 0033-295X},
	shorttitle = {A solution to {Plato}'s problem},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.104.2.211},
	doi = {10.1037/0033-295X.104.2.211},
	language = {en},
	number = {2},
	urldate = {2021-07-17},
	journal = {Psychological Review},
	author = {Landauer, Thomas K. and Dumais, Susan T.},
	year = {1997},
	pages = {211--240},
	file = {Full Text:C\:\\Users\\u0118974\\Zotero\\storage\\WXN9GZJY\\Landauer and Dumais - 1997 - A solution to Plato's problem The latent semantic.pdf:application/pdf},
}

@article{ordelman.etal_2007,
	title = {{TwNC}: a multifaceted dutch news corpus},
	volume = {12},
	abstract = {This contribution describes the Twente News Corpus (TwNC), a multifaceted corpus for Dutch that is being deployed in a number of NLP research projects among which tracks within the Dutch national research programme MultimediaN, the NWO programme CATCH, and the Dutch-Flemish programme STEVIN. The development of the corpus started in 1998 within a predecessor project DRUID and has currently a size of 530M words. The text part has been built from texts of four different sources: Dutch national newspapers, television subtitles, teleprompter (auto-cues) files, and both manually and automatically generated broadcast news transcripts along with the broadcast news audio. TwNC plays a crucial role in the development and evaluation of a wide range of tools and applications for the domain of multimedia indexing, such as large vocabulary speech recognition, cross-media indexing, cross-language information retrieval etc. Part of the corpus was fed into the Dutch written text corpus in the context of the Dutch-Belgian STEVIN project D-COI that was completed in 2007. The sections below will describe the rationale that was the starting point for the corpus development; it will outline the cross-media linking approach adopted within MultimediaN, and finally provide some facts and figures about the corpus.},
	language = {English},
	number = {3-4},
	journal = {ELRA Newsletter},
	author = {Ordelman, Roeland J.F. and de Jong, Franciska M.G. and van Hessen, Adrianus J. and Hondorp, G.H.W.},
	year = {2007},
	keywords = {EWI-15098, HMI-MR: MULTIMEDIA RETRIEVAL, IR-68090, Multimedia Retrieval, Speech Recognition, Text corpora},
}
