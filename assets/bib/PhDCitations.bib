
@article{heylen.etal_2015,
	title = {Monitoring polysemy: {Word} space models as a tool for large-scale lexical semantic analysis},
	volume = {157},
	issn = {00243841},
	shorttitle = {Monitoring polysemy},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0024384114002770},
	doi = {10.1016/j.lingua.2014.12.001},
	language = {en},
	urldate = {2017-08-23},
	journal = {Lingua},
	author = {Heylen, Kris and Wielfaert, Thomas and Speelman, Dirk and Geeraerts, Dirk},
	month = apr,
	year = {2015},
	pages = {153--172}
}

@article{schutze_1998,
	title = {Automatic {Word} {Sense} {Discrimination}},
	volume = {24},
	issn = {0891-2017},
	abstract = {This paper presents context-group discrimination, a disambiguation algorithm based on clustering. Senses are interpreted as groups (or clusters) of similar contexts of the ambiguous word. Words, contexts, and senses are represented in Word Space, a high-dimensional, real-valued space in which closeness corresponds to semantic similarity. Similarity in Word Space is based on second-order co-occurrence: two tokens (or contexts) of the ambiguous word are assigned to the same sense cluster if the words they co-occur with in turn occur with similar words in a training corpus. The algorithm is automatic and unsupervised in both training and application: senses are induced from a corpus without labeled training instances or other external knowledge sources. The paper demonstrates good performance of context-group discrimination for a sample of natural and artificial ambiguous words.},
	number = {1},
	journal = {Computational Linguistics},
	author = {Schütze, Hinrich},
	month = mar,
	year = {1998},
	pages = {97--123},
	file = {ACM Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\HMM4UICW\\Schütze - 1998 - Automatic Word Sense Discrimination.pdf:application/pdf}
}

@inproceedings{church.hanks_1989,
	title = {Word association norms, mutual information, and lexicography},
	url = {http://portal.acm.org/citation.cfm?doid=981623.981633},
	doi = {10.3115/981623.981633},
	abstract = {The term word association is used in a very particular sense in the psycholinguistic literature.
(Generally speaking, subjects respond quicker than normal to the word nurse if it follows a highly associated word such as doctor.)
We will extend the term to provide the basis for a statistical description of a variety of interesting linguistic phenomena, ranging from semantic relations of the doctor/nurse type (content word/content word)
to lexico-syntactic co-occurrence constraints between verbs and prepositions (content word/function word).
This paper will propose an objective measure based on the information theoretic notion of mutual information, for estimating word association norms from computer readable corpora.
(The standard method of obtaining word association norms, testing a few thousand :mbjects on a few hundred words, is both costly and unreliable.)
The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words.},
	language = {en},
	urldate = {2017-02-15},
	booktitle = {{ACL} '89: {Proceedings} of the 27th annual meeting on {Association} for {Computational} {Linguistic}},
	publisher = {Association for Computational Linguistics},
	author = {Church, Kenneth Ward and Hanks, Patrick},
	month = jun,
	year = {1989},
	pages = {76--83}
}

@inproceedings{kiela.clark_2014,
	address = {Gothenburg},
	title = {A {Systematic} {Study} of {Semantic} {Vector} {Space} {Model} {Parameters}},
	abstract = {We present a systematic study of parameters used in the construction of semantic vector space models. Evaluation is carried out on a variety of similarity tasks, including a compositionality dataset, using
several source corpora. In addition to recommendations
for optimal parameters, we present some novel findings, including a similarity metric that outperforms the alternatives on all tasks considered.},
	booktitle = {Proceedings of the 2nd {Workshop} on {Continuous} {Vector} {Space} {Models} and their {Compositionality}},
	publisher = {ACL},
	author = {Kiela, Douwe and Clark, Stephen},
	month = apr,
	year = {2014},
	pages = {21--30}
}

@article{turney.pantel_2010,
	title = {From {Frequency} to {Meaning}: {Vector} {Space} {Models} of {Semantics}},
	volume = {37},
	abstract = {Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term–document, word–context, and pair–pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a speciﬁc open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the ﬁeld.},
	language = {en},
	journal = {Journal of Artificial Intelligence Research},
	author = {Turney, Peter D and Pantel, Patrick},
	year = {2010},
	pages = {141--188},
	file = {Turney y Pantel - From Frequency to Meaning Vector Space Models of .pdf:C\:\\Users\\u0118974\\Zotero\\storage\\K6IMW9S3\\Turney y Pantel - From Frequency to Meaning Vector Space Models of .pdf:application/pdf}
}

@inproceedings{heylen.etal_2012,
	address = {Avignon},
	title = {Looking at word meaning. {An} interactive visualization of {Semantic} {Vector} {Spaces} for {Dutch} synsets},
	abstract = {In statistical NLP, Semantic Vector Spaces (SVS) are the standard technique for the automatic modeling of lexical semantics. However, it is largely unclear how these black-box techniques exactly capture word meaning. To explore the way an SVS structures the individual occurrences of words, we use a non-parametric MDS solution of a token-by-token similarity matrix. The MDS solution is visualized in an interactive plot with the Google Chart Tools. As a case study, we look at the occurrences of 476 Dutch nouns grouped in 214 synsets.},
	language = {en},
	booktitle = {Proceedings of the eacl 2012 {Joint} {Workshop} of {LINGVIS} \& {UNCLH}},
	author = {Heylen, Kris and Speelman, Dirk and Geeraerts, Dirk},
	year = {2012},
	pages = {16--24},
	file = {Heylen et al. - Looking at word meaning. An interactive visualizat.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\UU62B9N7\\Heylen et al. - Looking at word meaning. An interactive visualizat.pdf:application/pdf}
}

@article{hilpert.correiasaavedra_2017,
	title = {Using token-based semantic vector spaces for corpus-linguistic analyses: {From} practical applications to tests of theoretical claims},
	volume = {16},
	issn = {1613-7027, 1613-7035},
	shorttitle = {Using token-based semantic vector spaces for corpus-linguistic analyses},
	url = {http://www.degruyter.com/view/j/cllt.ahead-of-print/cllt-2017-0009/cllt-2017-0009.xml},
	doi = {10.1515/cllt-2017-0009},
	abstract = {This paper presents token-based semantic vector spaces as a tool that can be applied in corpus-linguistic analyses such as word sense comparisons, comparisons of synonymous lexical items, and matching of concordance lines with a given text. We demonstrate how token-based semantic vector spaces are created, and we illustrate the kinds of result that can be obtained with this approach. Our main argument is that token-based semantic vector spaces are not only useful for practical corpus-linguistic applications but also for the investigation of theory-driven questions. We illustrate this point with a discussion of the asymmetric priming hypothesis (Jäger and Rosenbach 2008). The asymmetric priming hypothesis, which states that grammaticalizing constructions will be primed by their lexical sources but not vice versa, makes a number of empirically testable predictions. We operationalize and test these predictions, concluding that token-based semantic vector spaces yield conclusions that are relevant for linguistic theory-building.},
	language = {en},
	number = {2},
	urldate = {2018-11-20},
	journal = {Corpus Linguistics and Linguistic Theory},
	author = {Hilpert, Martin and Correia Saavedra, David},
	month = sep,
	year = {2017},
	file = {Hilpert y Correia Saavedra - 2017 - Using token-based semantic vector spaces for corpu.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\RKE3RQAB\\Hilpert y Correia Saavedra - 2017 - Using token-based semantic vector spaces for corpu.pdf:application/pdf}
}

@book{levshina_2015,
	address = {Amsterdam ; Philadelphia},
	title = {How to do linguistics with {R}: data exploration and statistical analysis},
	isbn = {978-90-272-1224-5 978-90-272-1225-2},
	shorttitle = {How to do linguistics with {R}},
	publisher = {John Benjamins Publishing Company},
	author = {Levshina, Natalia},
	year = {2015},
	keywords = {Computational linguistics, Linguistics, Methodology, Statistical methods, Software}
}

@article{lenci_2018,
	title = {Distributional {Models} of {Word} {Meaning}},
	volume = {4},
	issn = {2333-9683, 2333-9691},
	url = {http://www.annualreviews.org/doi/10.1146/annurev-linguistics-030514-125254},
	doi = {10.1146/annurev-linguistics-030514-125254},
	abstract = {Distributional semantics is a usage-based model of meaning, based on the assumption that the statistical distribution of linguistic items in context plays a key role in characterizing their semantic behavior. Distributional models build semantic representations by extracting co-occurrences from corpora and have become a mainstream research paradigm in computational linguistics. In this review, I present the state of the art in distributional semantics, focusing on its assets and limits as a model of meaning and as a method for semantic analysis.},
	language = {en},
	number = {1},
	urldate = {2019-08-27},
	journal = {Annual Review of Linguistics},
	author = {Lenci, Alessandro},
	month = jan,
	year = {2018},
	pages = {151--171},
	file = {Lenci - 2018 - Distributional Models of Word Meaning.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\YRSW9EUM\\Lenci - 2018 - Distributional Models of Word Meaning.pdf:application/pdf}
}

@phdthesis{depascale_2019,
	address = {Leuven},
	type = {{PhD} {Dissertation}},
	title = {Token-based vector space models as semantic control in lexical lectometry},
	url = {https://lirias.kuleuven.be/retrieve/549451},
	abstract = {Type-based distributional semantics as embodied in vector space models has proven to be a successful method for the retrieval of near-synonyms in large corpora. These words have then been used as variants of lexical sociolinguistic variables (e.g.: return and winst for the concept profit) in lectometric studies, that is, the aggregate-level study of lexical distances between linguistic varieties, in particular pluricentric languages such as Dutch. However, a limitation of type-based vector space models is that all senses of a word are lumped together into one vector representation, making it harder to control for polysemy and subtle contextual distinctions. In addition, operating at the lexeme level, these type-based vector space models are not able to pick out the relevant corpus occurrences that are the input for the lectometric distance calculations. The main goal of this PhD project is to introduce token-based vector space models in lexical lectometric research, in order to gain better semantic control during the composition of lexical variables. Token-based vector space models address the abovementioned shortcomings by disambiguating different senses of lexical variants. This technique is able to model the semantics of individual tokens (i.e. 'usage occurrences') of a word in a corpus and to represent them as token clouds in multidimensional vector space, with clusters of tokens revealing distinct senses of the word. By superimposing the token clouds of the lexical variants, one can distinguish which meanings are shared by near-synonyms and determine the 'semantic envelope of variation' of the lexical alternation. For instance, the variant return is polysemous in Netherlandic Dutch, with the two readings 'profit' and 'return game', but not in Belgian Dutch, where only the 'profit' sense is found. By isolating the cluster of tokens with the meaning 'profit' one can identify the near-synonymous tokens of the variants winst and return. The fine-tuning of vector space model-based lectometry targeted in this PhD contributes to the scaling up of lexical variationist research, by providing methods for dealing with corpora whose size exceeds manual analysis. At the same time, token-based models comply with the need of detailed analysis by allowing to zoom in on the behavior of individual tokens in order to determine more subtle contextual distinctions. This PhD project is situated in a larger research endeavor ("Nephological Semantics - Using token clouds for meaning detection in variationist linguistics", BOF C1 project 3H150305) that aims at detailed understanding of token-based vector representations for lexical, semantic and variational research.},
	language = {eng},
	urldate = {2019-11-08},
	school = {KU Leuven},
	author = {De Pascale, S.},
	collaborator = {Marzo, S. and Speelman, D.},
	year = {2019}
}

@book{card.etal_1999,
	address = {San Francisco, Calif},
	series = {The {Morgan} {Kaufmann} series in interactive technologies},
	title = {Readings in information visualization: using vision to think},
	isbn = {978-1-55860-533-6},
	shorttitle = {Readings in information visualization},
	publisher = {Morgan Kaufmann Publishers},
	author = {Card, Stuart K. and Mackinlay, Jock D. and Shneiderman, Ben},
	year = {1999},
	keywords = {Information visualization, Computer graphics, Image processing}
}

@inproceedings{shneiderman_1996,
	title = {The {Eyes} {Have} {It}: {A} {Task} by {Data} {Type} {Taxonomy} for {Information} {Visualizations}},
	booktitle = {{IEEE} {Visual} {Languages}},
	author = {Shneiderman, Ben},
	year = {1996},
	pages = {96--13}
}

@incollection{wielfaert.etal_2019,
	address = {Stanford, California},
	series = {{CSLI} lecture notes},
	title = {Visual {Analytics} for {Parameter} {Tuning} of {Semantic} {Vector} {Space} {Models}},
	isbn = {978-1-68400-034-0 978-1-68400-033-3 978-1-68400-035-7},
	number = {no. 220},
	booktitle = {{LingVis}: visual analytics for linguistics},
	publisher = {CSLI Publications, Center for the Study of Language and Information},
	author = {Wielfaert, Thomas and Heylen, Kris and Speelman, Dirk and Geeraerts, Dirk},
	editor = {Butt, Miriam and Hautli-Janisz, Annette and Lyding, Verena},
	year = {2019},
	keywords = {Linguistics, Information visualization, LANGUAGE ARTS \& DISCIPLINES / Linguistics / General, Visual analytics},
	pages = {215--245}
}

@inproceedings{smilkov.etal_2016,
	title = {Embedding {Projector}: {Interactive} {Visualization} and {Interpretation} of {Embeddings}},
	url = {arXiv:1611.05469},
	author = {Smilkov, Daniel and Thorat, Nikhil and Nicholson, Charles and Reif, Emily and Viégas, Fernanda B. and Wattenberg, Martin},
	year = {2016},
	note = {\_eprint: 1611.05469}
}

@article{hilpert.flach_2020,
	title = {Disentangling modal meanings with distributional semantics},
	issn = {2055-7671},
	url = {https://doi.org/10.1093/llc/fqaa014},
	doi = {10.1093/llc/fqaa014},
	abstract = {This article investigates the collocational behavior of English modal auxiliaries such as may and might with the aim of finding corpus-based measures that distinguish between different modal expressions and that allow insights into why speakers may choose one over another in a given context. The analysis uses token-based semantic vector space modeling (Heylen et al., 2015, Monitoring polysemy. Word space models as a tool for large-scale lexical semantic analysis. Lingua, 157: 153–72; Hilpert and Correia Saavedra, 2017, Using token-based semantic vector spaces for corpus-linguistic analyses: From practical applications to tests of theoretical claims. Corpus Linguistics and Linguistic Theory) in order to determine whether different modal auxiliaries can be distinguished in terms of their collocational profiles. The analysis further examines whether different senses of the same auxiliary exhibit divergent collocational preferences. The results indicate that near-synonymous pairs of modal expressions, such as may and might or must and have to, differ in their distributional characteristics. Also, different senses of the same modal expression, such as deontic and epistemic uses of may, can be distinguished on the basis of distributional information. We discuss these results against the background of previous empirical findings (Hilpert, 2016, Construction Grammar and its Application to English, 2nd edn. Edinburgh: Edinburgh University Press, Flach, in press, Beyond modal idioms and modal harmony: a corpus-based analysis of gradient idiomaticity in modal-adverb collocations. English Language and Linguistics) and theoretical issues such as degrees of grammaticalization (Correia Saavedra, 2019, Measurements of Grammaticalization: Developing a Quantitative Index for the Study of Grammatical Change. PhD Dissertation, Université de Neuchâtel) and the avoidance of synonymy (Bolinger, 1968, Entailment and the meaning of structures. Glossa, 2(2): 119–27).},
	number = {fqaa014},
	urldate = {2020-12-08},
	journal = {Digital Scholarship in the Humanities},
	author = {Hilpert, Martin and Flach, Susanne},
	month = may,
	year = {2020},
	file = {Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\PFI628UU\\Hilpert en Flach - 2020 - Disentangling modal meanings with distributional s.pdf:application/pdf;Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\YXNIE5BL\\5836757.html:text/html}
}

@article{perek_2018,
	title = {Recent change in the productivity and schematicity of the way-construction: {A} distributional semantic analysis},
	volume = {14},
	issn = {1613-7027, 1613-7035},
	shorttitle = {Recent change in the productivity and schematicity of the way-construction},
	url = {http://www.degruyter.com/view/journals/cllt/14/1/article-p65.xml},
	doi = {10.1515/cllt-2016-0014},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d1175e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}This paper presents a corpus-based study of recent change in the English {\textless}em{\textgreater}way{\textless}/em{\textgreater}-construction, drawing on data from the 1830s to the 2000s. Semantic change in the distribution of the construction is characterized by means of a distributional semantic model, which captures semantic similarity between verbs through their co-occurrence frequency with other words in the corpus. By plotting and comparing the semantic domain of the three senses of the construction at different points in time, it is found that they all have gained in semantic diversity. These findings are interpreted in terms of increases in schematicity, either of the verb slot or the motion component contributed by the construction.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {en},
	number = {1},
	urldate = {2020-12-08},
	journal = {Corpus Linguistics and Linguistic Theory},
	author = {Perek, Florent},
	month = apr,
	year = {2018},
	note = {Publisher: De Gruyter Mouton
Section: Corpus Linguistics and Linguistic Theory},
	pages = {65--97},
	file = {Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\5VLYNBJI\\Perek - 2018 - Recent change in the productivity and schematicity.pdf:application/pdf;Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\N27TPI3A\\article-p65.html:text/html}
}

@article{perek_2016,
	title = {Using distributional semantics to study syntactic productivity in diachrony: {A} case study},
	volume = {54},
	issn = {0024-3949, 1613-396X},
	shorttitle = {Using distributional semantics to study syntactic productivity in diachrony},
	url = {http://www.degruyter.com/view/journals/ling/54/1/article-p149.xml},
	doi = {10.1515/ling-2015-0043},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d1015e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}This paper investigates syntactic productivity in diachrony with a data-driven approach. Previous research indicates that syntactic productivity (the property of grammatical constructions to attract new lexical fillers) is largely driven by semantics, which calls for an operationalization of lexical meaning in the context of empirical studies. It is suggested that distributional semantics can fulfill this role by providing a measure of semantic similarity between words that is derived from lexical co-occurrences in large text corpora. On the basis of a case study of the construction “V {\textless}em{\textgreater}the hell out of{\textless}/em{\textgreater} NP”, e.g., {\textless}em{\textgreater}You scared the hell out of me{\textless}/em{\textgreater}, it is shown that distributional semantics not only appropriately captures how the verbs in the distribution of the construction are related, but also enables the use of visualization techniques and statistical modeling to analyze the semantic development of a construction over time and identify the determinants of syntactic productivity in naturally occurring data.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {en},
	number = {1},
	urldate = {2020-12-22},
	journal = {Linguistics},
	author = {Perek, Florent},
	month = jan,
	year = {2016},
	note = {Publisher: De Gruyter Mouton
Section: Linguistics},
	pages = {149--188},
	file = {Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\WBDDWTVV\\Perek - 2016 - Using distributional semantics to study syntactic .pdf:application/pdf;Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\PSNWLMMP\\article-p149.html:text/html}
}

@article{perek_2017,
	title = {A distributional semantic approach to the periodization of change in the productivity of constructions},
	volume = {22},
	issn = {1384-6655, 1569-9811},
	url = {https://www.jbe-platform.com/content/journals/10.1075/ijcl.16128.per},
	doi = {10.1075/ijcl.16128.per},
	abstract = {This paper describes a method to automatically identify stages of language change in diachronic corpus data, combining variability-based neighbour clustering, which offers objective and reproducible criteria for periodization, and distributional semantics as a representation of lexical meaning. This method partitions the history of a grammatical construction according to qualitative stages of productivity corresponding to different semantic sets of lexical items attested in it. Two case studies are presented. The first case study on the hell-construction (“Verb the hell out of NP”) shows that the semantic development of a construction does not always match that of its quantitative aspects, like token or type frequency. The second case study on the way-construction compares the results of the present method with those of collostructional analysis. It is shown that the former measures semantic changes and their chronology with greater precision. In sum, this method offers a promising approach to exploring semantic variation in the lexical fillers of constructions and to modelling constructional change.},
	language = {en},
	number = {4},
	urldate = {2020-12-22},
	journal = {International Journal of Corpus Linguistics},
	author = {Perek, Florent and Hilpert, Martin},
	month = jan,
	year = {2017},
	note = {Publisher: John Benjamins},
	pages = {490--520},
	file = {Ingediende versie:C\:\\Users\\u0118974\\Zotero\\storage\\AYFCU3UI\\Perek en Hilpert - 2017 - A distributional semantic approach to the periodiz.pdf:application/pdf}
}

@incollection{koptjevskaja-tamm.sahlgren_2014,
	address = {Berlin, Boston},
	title = {Temperature in the word space: {Sense} exploration of temperature expressions using word-space modelling},
	isbn = {978-3-11-031755-8},
	shorttitle = {Temperature in the word space},
	url = {https://www.degruyter.com/view/books/9783110317558/9783110317558.231/9783110317558.231.xml},
	urldate = {2020-12-25},
	booktitle = {Aggregating {Dialectology}, {Typology}, and {Register} {Analysis}},
	publisher = {DE GRUYTER},
	author = {Koptjevskaja-Tamm, Maria and Sahlgren, Magnus},
	editor = {Szmrecsanyi, Benedikt and Wälchli, Bernhard},
	month = jan,
	year = {2014},
	doi = {10.1515/9783110317558.231},
	pages = {231--267},
	file = {Koptjevskaja-Tamm en Sahlgren - 2014 - Temperature in the word space Sense exploration o.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\5YCM5DQ7\\Koptjevskaja-Tamm en Sahlgren - 2014 - Temperature in the word space Sense exploration o.pdf:application/pdf}
}

@incollection{montes.heylen_Submitted,
	title = {Visualizing {Distributional} {Semantics}},
	copyright = {All rights reserved},
	isbn = {978-3-11-068734-7},
	language = {en},
	publisher = {Mouton De Gruyter},
	author = {Montes, Mariana and Heylen, Kris},
	editor = {Tay, Dennis and Pan, Molly Xie}
}

@book{bolognesi_2020,
	address = {Amsterdam},
	series = {Converging {Evidence} in {Language} and {Communication} {Research}},
	title = {Where {Words} {Get} their {Meaning}: {Cognitive} processing and distributional modelling of word meaning in first and second language},
	volume = {23},
	isbn = {978-90-272-0801-9 978-90-272-6042-0},
	shorttitle = {Where {Words} {Get} their {Meaning}},
	url = {http://www.jbe-platform.com/content/books/9789027260420},
	language = {en},
	urldate = {2021-04-27},
	publisher = {John Benjamins Publishing Company},
	author = {Bolognesi, Marianna},
	month = nov,
	year = {2020},
	doi = {10.1075/celcr.23},
	file = {Bolognesi - 2020 - Where Words Get their Meaning Cognitive processin.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\2T2CCCL8\\Bolognesi - 2020 - Where Words Get their Meaning Cognitive processin.pdf:application/pdf}
}

@phdthesis{sahlgren_2006,
	address = {Stockholm},
	title = {The word-space model: using distributional analysis to represent syntagmatic and paradigmatic relations between words in high-dimensional vector spaces},
	shorttitle = {The word-space model},
	language = {en},
	school = {Dep. of Linguistics, Stockholm Univ. [u.a.]},
	author = {Sahlgren, Magnus},
	year = {2006},
	note = {OCLC: 255579201},
	file = {Sahlgren - 2006 - The word-space model using distributional analysi.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\XJFN3AZD\\Sahlgren - 2006 - The word-space model using distributional analysi.pdf:application/pdf}
}

@article{BERT,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2021-04-27},
	journal = {arXiv:1810.04805 [cs]},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv: 1810.04805},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\u0118974\\Zotero\\storage\\JPIUWCYQ\\Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\85K98SLY\\1810.html:text/html}
}

@misc{montes.qlvl_2021,
	title = {{QLVL}/{NephoVis}: {Stratocumulus}},
	copyright = {Open Access},
	shorttitle = {{QLVL}/{NephoVis}},
	url = {https://zenodo.org/record/4726926},
	abstract = {Relatively viable version, especially for levels 1 and 2.},
	urldate = {2021-04-29},
	publisher = {Zenodo},
	author = {Montes, Mariana and QLVL},
	month = apr,
	year = {2021},
	doi = {10.5281/ZENODO.4726926}
}

@article{harris_1954,
	title = {Distributional structure},
	volume = {10},
	number = {2-3},
	journal = {Word},
	author = {Harris, Zellig S.},
	year = {1954},
	note = {Publisher: Taylor \& Francis},
	pages = {146--162}
}

@inproceedings{campello.etal_2013,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Density-{Based} {Clustering} {Based} on {Hierarchical} {Density} {Estimates}},
	isbn = {978-3-642-37456-2},
	doi = {10.1007/978-3-642-37456-2_14},
	abstract = {We propose a theoretically and practically improved density-based, hierarchical clustering method, providing a clustering hierarchy from which a simplified tree of significant clusters can be constructed. For obtaining a “flat” partition consisting of only the most significant clusters (possibly corresponding to different density thresholds), we propose a novel cluster stability measure, formalize the problem of maximizing the overall stability of selected clusters, and formulate an algorithm that computes an optimal solution to this problem. We demonstrate that our approach outperforms the current, state-of-the-art, density-based clustering methods on a wide variety of real world data.},
	language = {en},
	booktitle = {Advances in {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Springer},
	author = {Campello, Ricardo J. G. B. and Moulavi, Davoud and Sander, Joerg},
	editor = {Pei, Jian and Tseng, Vincent S. and Cao, Longbing and Motoda, Hiroshi and Xu, Guandong},
	year = {2013},
	keywords = {Cluster Tree, Core Object, Density Threshold, Hierarchical Cluster Method, Minimum Span Tree},
	pages = {160--172},
	file = {Springer Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\S5V7562X\\Campello et al. - 2013 - Density-Based Clustering Based on Hierarchical Den.pdf:application/pdf}
}

@misc{mcinnes.etal_2016,
	title = {How {HDBSCAN} {Works} — hdbscan 0.8.1 documentation},
	url = {https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html},
	urldate = {2021-04-30},
	author = {McInnes, Leland and Healy, John and Astels, Steve},
	year = {2016},
	file = {How HDBSCAN Works — hdbscan 0.8.1 documentation:C\:\\Users\\u0118974\\Zotero\\storage\\3RQD77MC\\how_hdbscan_works.html:text/html}
}
