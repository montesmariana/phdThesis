% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
  \usepackage{amssymb}
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Cloudspotting},
  pdfauthor={Mariana Montes},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[paperwidth=160mm, paperheight=240mm, margin=2cm, bindingoffset=0cm]{geometry}
\usepackage{longtable,booktabs}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage[nottoc]{tocbibind}
\usepackage{fancyhdr}
\usepackage[backend=biber,
  style=unified,
  maxcitenames=3,
  maxbibnames=99]{biblatex}
\usepackage{pdfpages}
\renewcommand*{\ppspace}{}

\DeclareFieldFormat{postnote}{#1}
\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\pagestyle{fancy}
\renewcommand{\sectionmark}[1]{ \markright{#1} }
\fancyhead[LE]{\thepage --- \nouppercase{\leftmark}}
\fancyhead[RO]{\nouppercase{\rightmark} --- \thepage}
\fancyhead[LO,RE]{}
\fancyfoot[C]{}


\newenvironment{dedication}
    {\clearpage\vspace*{30ex}\begin{quotation}\begin{center}\begin{em}}
    {\par\end{em}\end{center}\end{quotation}\clearpage}
\let\oldmaketitle\maketitle
\AtBeginDocument{\let\maketitle\relax}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[style=unified,]{biblatex}
\addbibresource{assets/bib/PhDCitations.bib}
\addbibresource{assets/bib/packages.bib}

\title{Cloudspotting}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Visual analytics for distributional semantics}
\author{Mariana Montes}
\date{}

\begin{document}
\maketitle

\includepdf{assets/covers/front-cover.pdf}

% \let\maketitle\oldmaketitle
% \maketitle

\thispagestyle{empty}
\begin{titlepage}
    \flushright
    \includegraphics[height=15mm]{assets/img/faculty_logo.png}
        
        
    \begin{center}
        \vspace*{4cm}
        \Huge
        \textbf{Cloudspotting}
            
        \vspace{0.5cm}
        \LARGE
        Visual analytics for distributional semantics
            
        \vfill
        
        \large  
        Thesis presented in partial fulfillment of the requirements\\
        for the degree of Doctor in Linguistics
        \vspace{0.8cm}
            
        \textbf{Mariana Montes}
            
        \vspace{1.5cm}
            
        Supervisor: Prof. Dr. Dirk Geeraerts\\
        Co-supervisor: Prof. Dr. Dirk Speelman\\
        Co-supervisor: Prof. Dr. Benedikt Szmrecsanyi\\
            
        \vspace{3cm}
            
        Leuven, July 2021
            
    \end{center}
\end{titlepage}

\thispagestyle{empty}

\newpage
\thispagestyle{empty}
\mbox{}
\newpage

\thispagestyle{empty}
\begin{dedication}
To Miguel and Patricia
\end{dedication}

\newpage
\thispagestyle{empty}
\mbox{}
\newpage
\frontmatter

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\listoftables
\listoffigures
\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

\fancyhead[LE]{\thepage --- \nouppercase{Preface}}
\fancyhead[RO]{\nouppercase{Preface} --- \thepage}
\fancyhead[LO,RE]{}
\fancyfoot[C]{}

The research described in this dissertation is part of the Nephological Semantics\footnote{\url{https://www.arts.kuleuven.be/ling/qlvl/projects/current/nephological-semantics}} research project at the \textsc{qlvl} research group in KU Leuven,
which aims to develop tools for large-scale corpus-based semantic analysis.
A core aspect of the project involves representing semantic structure with distributional models,
a computational tool that currently requires a deeper understanding of its inner workings
and how its results relate to cognitive theories of meaning.

Context-counting distributional models represent words\footnote{The term \emph{word} is used very loosely here to encompass different possible definitions.} as vectors of co-occurrence frequencies in a multidimensional space
\autocite{turney.pantel_2010,lenci_2018}. Basically, a word is represented by
its association strength to other words.
They can be generated at both type and token level \autocite{heylen.etal_2012,heylen.etal_2015,depascale_2019}.
At type level, two words are represented as more similar if they are attracted to the same
contextual features (e.g.~other words) and repelled by the same contextual features. This should
allow us to identify semantic fields and other relationships between words, but collapses the full
range of contexts of each word into one representation.
At token level, instead, we look at individual occurrences and define them as more similar if
the words in their contexts are attracted to and repelled by the same contextual features.
This way we should be able to map the internal variation of the behaviour of individual words,
i.e.~their semasiological structure.

Within the larger Nephological Semantics project, this particular work package is dedicated
to the understanding of token-level distributional models as a tool
for the study of polysemy. Concretely, I explored a number of parameter settings for the models
(i.e.~ways of defining the context used to represent each token) and their impact on the
resulting representation, by means of visual analytics.
Manually annotated sense tags were used as a heuristic, but without
considering them a golden standard. Instead, the aim was to map parameter settings to various
semantic phenomena coded in the annotations, such as
meaning granularity (e.g.~distinguishing homonyms and senses within the homonyms).
The distributional models, which take the form of large matrices,
can be reduced to two dimensions via different methods,
such as t-\textsc{sne} \autocite{Rtsne2008,Rtsne2014}.
These coordinates can then be mapped onto a scatterplot, resulting in a variety of
shapes, which we call \emph{clouds}.

The workflow was applied to a set of 32 Dutch nouns, verbs and adjectives exhibiting
a range of semantic phenomena. For each of them, 240-320 concordance lines were extracted
from a corpus of Dutch and Flemish newspapers,
annotated and modelled. The combination of parameter settings, some of which included syntactic
information, resulted in 200-212 different models per lemma. The models were clustered with Partition
Around Medoids \autocite{kaufman.rousseeuw_1990,R-cluster} so that a manageable, representative set could be explored
in more depth, in particular visualizing their t-\textsc{sne} representations.

The contributions of this dissertation are twofold. On the one hand, the exploration of
the possibilities and limits of distributional models to lexicological research resulted in
warnings, suggestions and guidelines for practical studies. In other words, it offers
an assessment and interpretation of distributional models from the perspective of descriptive linguistics.
On the other hand, it presents a visualization tool designed for the exploration of
token-level distributional models from such a perspective \autocite{montes.qlvl_2021a}. Its interactive quality makes
it challenging to describe it adequately in a printed text, so I would strongly
recommend visiting it in its virtual home\footnote{\url{https://qlvl.github.io/NephoVis/}} and explore it.

\hypertarget{acknowledgements}{%
\chapter*{Acknowledgements}\label{acknowledgements}}
\addcontentsline{toc}{chapter}{Acknowledgements}

\fancyhead[LE]{\thepage --- \nouppercase{Acknowledgements}}
\fancyhead[RO]{\nouppercase{Acknowledgements} --- \thepage}
\fancyhead[LO,RE]{}
\fancyfoot[C]{}

The words in these pages, the thoughts they try to convey, are the result of years of thinking, discussing, learning. My voice weaves them together,
but it draws from many sources that have encouraged my growth, stood by me, and fed my curiosity, passion and enthusiasm for everything that makes up this text.

For their support and their ideas, I would like to thank my supervisors Dirk Geeraerts, Dirk Speelman and Benedikt Szmrecsanyi. Thank you for trusting me, for allowing me to be part of this amazing research project.
Dirk Geeraerts deserves a special acknowledgement for all his patience and trust. It has been an honour to share such interesting, long discussions on semantics and research.
Every time we talked I became more excited and passionate about my research, more confident and happy. Hartelijk bedankt.
I am also grateful to Freek Van de Velde, Tim Van de Cruys, Martin Hilpert and Thomas Herbst for their willingness to participate in the jury.

Research is eminently collaborative, but it can feel lonely. I will always appreciate the company and support of my colleagues at the Linguistics Department at KU Leuven, especially my research group, \textsc{qlvl}. In particular, I would like to thank the members of the Nephological Semantics project, with whom I shared so much of the excitement and frustrations of our common project. I'd like to acknowledge Tao Chen for his amazing work in the Python code and helping me understand it and Stefania Marzo for always making me feel like I had done something right. For the past year and a half, the weekly meetings with Dirk and Dirk, Kris, Karlien, Stefano and Weiwei have been intense but have also kept me grounded. I was constantly learning, rethinking, trying new things. I am grateful for your collaboration and your advice, for being there and letting me know that this research matters. Kris has been an unstoppable source of ideas, Karlien such a great partner for spontaneous experiments, and Stefano so helpful with our shared methodological obstacles (and thank you for proofreading!).

Some colleagues become friends. The first is Danqing, who shares with me the experience of studying and making a life far from home, and who has kindly agreed to do some proofreading in spite of her busy schedule. I am also immensely grateful to Marlieke and Pedro, not only for their proofreading efforts and their invaluable help with the translations of the examples but also, and most importantly, for their company and their friendship. Thank you Ola, Caro, Araceli and Manuel for standing by me even from a distance. To Paula, thank you for challenging me, encouraging me, making me a better researcher and a better person.

From friends we move to family. I honestly wouldn't be where I am today if it weren't for my parents. They have taught me to learn and to teach, to face challenges, to not fear mathematics or programming. My siblings are my strength, thank you for being there, thank you for the mates, the talks, the hugs. My cousin Alex deserves a special acknowledgement for holding my hand while I discovered web design and helping me disentangle a whole new field. Muchas gracias, che.

Finally, I would like to thank my partner, Taihou, who has kept me alive while I was finishing this text, and has always listened to my ramblings, held me when I fell, rejoiced with me when I succeeded.

To all of you, I am forever grateful. This is thanks to you, I hope to make you proud.

\mainmatter

\fancyhead[LE]{\thepage --- \nouppercase{\leftmark}}
\fancyhead[RO]{\nouppercase{\rightmark} --- \thepage}
\fancyhead[LO,RE]{}
\fancyfoot[C]{}

\hypertarget{intro}{%
\chapter{Introduction}\label{intro}}

If meaning is found and created in use, and corpora are language in use, can we find meaning in corpora? The field of usage-based semantics is large and rich, so the answer to this question is clearly positive. Corpora offer an immense amount of usage data on which to carry analyses, even if they barely scratch the surface of the amount of language that is actually produced --- it is desirable and tempting to tap into this vast ocean to obtain the most detailed, the most reliable, the most thorough information. But there is a crucial bottleneck when it comes to semantic analysis: annotation is time- and energy-consuming. As long as we cannot instruct an automatic system to disambiguate each word in a corpus --- like we do to tokenize and lemmatize, i.e.~to identify what counts as a word and what its root is, or even to assign parts of speech or syntactic relations --- semantic annotation is performed by humans. Humans are slower than computers; we get tired, we get confused, we need to eat and think of things beyond semantic annotation as weel. We also disagree sometimes --- what is a sense? Are these two things \emph{really} the same?

Automatic disambiguation systems do exist. Word Sense Disambiguation is an important task within Natural Language Processing (\textsc{nlp}). The notion of \emph{task} is of crucial importance here: \textsc{nlp} algorithms are typically concerned with concrete applications and are evaluated in terms of those applications. There exists a correct answer that the algorithm must return. This is not so directly applicable to the situation of lexicological and lexicographical research --- the study of the meanings of words and their relationships --- especially from a Cognitive Linguistics point of view, where hard, dichotomous answers are rare. But let's suppose for a moment that we can conciliate both approaches, and what counts as \emph{the} answer from an \textsc{nlp} point of view is \emph{an} answer from the lexicological perspective. Then we could use automatic disambiguation procedures to make the heavy lifting of semantic annotation of our growing body of corpus data and use their results for a partial description of language. As long as we know \emph{which} answer the \textsc{nlp} algorithm is returning or, better yet, how to ask what we want to know. Maybe tuning the algorithm for outputs that from an \textsc{nlp} point of view would be \emph{wrong} can result in complementary answers for a richer lexicological description. Such a qualitative perspective, trying to interpret not just \emph{whether} the computational model matches a target but also \emph{how} or \emph{why} it does (not), also requires appropriate analytical tools. One such tool represents the internal semantic structure of an item, derived from computational models, as a \textsc{2d} scatterplot where instances occurring in similar context are shown together, forming clusters or \emph{clouds}.

This dissertation is concerned with the application of distributional methods to lexicological research and their exploration by means of visual analytics. The methodology will be tested and illustrated with a set of 32 Dutch lemmas, of which concordance lines will be extracted from a corpus of newspapers.
Distributional models, developed within the field of Computational Linguistics, will be introduced in Section \ref{comp}. In Section \ref{cog} we will discuss their relevance in Cognitive Semantics and Section \ref{viz} will offer an overview of the visual analytics dimension.
The study described here is part of a larger research project within the Quantitative Lexicology and Variational Linguistics research group (\textsc{qlvl}) at KU Leuven. A brief history of the project and how this dissertation fits in it will be offered in Section \ref{nephosem}. Finally, Section \ref{str} will present the structure of the dissertation.

\hypertarget{comp}{%
\section{Distributional Semantics and Computational Linguistics}\label{comp}}

Distributional semantics is a usage-based model of meaning that underlies various computational methods for semantic representation
\autocite{sahlgren_2008,lenci_2018}: it is an educational program for computers that lets them pretend they understand human languages. It relies on what is called the Distributional Hypothesis, according to which lexemes with similar meanings will have similar distributions, i.e.~will occur in similar contexts. The core idea is typically attributed to \textcite{harris_1954} and \textcite{firth_1957a}, but exactly how enthusiastic they would be at the sight of the current implementations is disputed: \textcite[157]{tognini-bonelli_2001} remarks that Firth would not be in favour of electronic corpora, and \textcite{geeraerts_2017} offers a comprehensive comparison between Harris' position and current distributional semantics. The attribution issue notwithstanding, the idea that meaning can be modelled by means of distributional information is pervasive in \textsc{nlp} and at the core of every form of Distributional Semantics. A more important question is what we mean by \emph{meaning} or \emph{semantics} to begin with \autocite{sahlgren_2006,lenci_2008}, which in this research is informed by the Cognitive Linguistics framework. Beyond the particular attention to the semantic side of distributional semantics, this dissertation sets itself apart from most mainstream computational approaches in three core aspects: its motivation, the definition of units and its reliance on context-counting models.

\hypertarget{motivation}{%
\subsection{Motivation}\label{motivation}}

Computational Linguistics is typically task-oriented: it aims to solve concrete challenges such as information retrieval, question answering, sentiment analysis, machine translation, etc. For that purpose, benchmarks or gold standards are developed and the models are tested against them. For example, \textcite{baroni.etal_2014} test different kinds of models against datasets tailored to evaluate semantic relatedness, synonym detection, concept categorization, selectional preferences and analogy; see \textcite{agirre.edmonds_2007a} and \textcite{raganato.etal_2017} for evaluation systems for sense disambiguation. This is understandable and appropriate in a task-oriented workflow: when it comes to output, it does not really matter \emph{how} the model reached the answer, as long as it is the answer that we seek. In contrast, investigating the structure of semantic representations, i.e.~the \emph{how} of this process, calls for a different approach \autocites[see for example][]{baroni.lenci_2011,wielfaert.etal_2019}. On the one hand, we do not assume that there is one correct answer because we do not assume that there is only one question. Beyond ``Are these two words similar?'', we are interested in: ``Are they synonyms?'', ``Are they co-hyponyms?'', ``Are they regionally specific expressions of the same concept?'', and so forth. Different models may focus on different dimensions of semantic structure and thus answer different questions. For that reason, the dataset collected for this research covers a wide range of semantic phenomena, in the hope of tuning distributional models to their identification. On the other hand, we are not confident that any of those questions has an unequivocal answer either. As Chapter \ref{dataset} will show, annotators often agree on the sense of an utterance, but not always. Hence, the manual annotations will serve as a guideline for the interpretation of the models, but not as a law to judge their accuracy.

\hypertarget{units-of-analysis}{%
\subsection{Units of analysis}\label{units-of-analysis}}

Whereas computational models typically work at type-level and often with word forms, this dissertation focuses on token-level models with lemmas as units.
Type-level modelling represents a lexical unit, such as \emph{word}, as the aggregated distributional behaviour of all its occurrences, e.g.~we could see that \emph{word} tends to be preceded by \emph{the}. Patterns can be found by accumulating and classifying contextual information from thousands if not millions of events. The profile of a type can subsequently be compared to the profiles of other types, e.g.~we can see that \emph{sentence} also tends to be preceded by \emph{the}, while \emph{walking} does not. Such a representation conflates the variation within the range of application of that item as part of one overall tendency, and is therefore not suited to study polysemy. Even if the context does contain disambiguating cues, such as ``Can we have a \emph{word}?'', or ``That \emph{word} is not in the dictionary'', the type-level representation will cover both. In spite of these shortcomings, some computational approaches to modelling polysemy do try to find the patterns in the type-level representations, e.g. \textcite{koptjevskaja-tamm.sahlgren_2014}. In contrast, the work presented here relies on token-level modelling, which represents individual instances, e.g.~comparing the two occurrences of \emph{word} in the examples above. This approach does originate in computational linguistics \autocite{schutze_1998} but is far less popular than type-level approaches, which are considered the default in most introductory descriptions of distributional models \autocite{lenci_2018,turney.pantel_2010,bolognesi_2020}.

Apart from the distinction between modelling types or tokens, a crucial difference between this approach and many studies in computational linguistics is that the unit of analysis is the lemma instead of the word form. On the one hand, relying on word forms avoids layers of preprocessing that already incorporate a certain interpretation in terms of what counts as a word, which different forms go together and how they are classified grammatically. \textcite{sinclair_1991} also argues along these lines for the usage of word forms as lexical units in corpus linguistics. And, admittedly, different word forms of a given lemma might exhibit diverging distributional and semantic profiles. However, from a lexicological and lexicographical perspective, centring the lemma --- the combination of stems and grammatical category --- is the common practice. Moreover, the mismatch between word forms and lemmas --- and therefore between either of them and meanings --- is highly dependent on the language we describe and the words themselves. Therefore, lemmas will be the unit of analysis in this dissertation. This is not to say that the workflow depends on this decision, in the same way that it does not depend on Dutch being the language of the corpus. The methodology presented in these pages could be applied with word forms at the centre, but the degree to which the conclusions reached here would be applicable is an empirical question.

\hypertarget{context-counting-and-context-predicting}{%
\subsection{Context-counting and context-predicting}\label{context-counting-and-context-predicting}}

Currently, the most popular approach for distributional semantics relies on neural networks, i.e.~context-predicting models. The methodology followed in this project relies instead on count-based or context-counting models: the values of the vectors, i.e.~numerical representations of lexical units, are (relatively) directly derived from frequency counts. In contrast, the approach initiated by \textcite{mikolov.etal_2013} and which has taken over \textsc{nlp}, i.e.~word embeddings, is a context-predicting architecture. Neural networks are trained to predict empty slots in a fragment of text: given a fixed window with a target item in the middle, \textsc{cbow} models are given the surrounding context in order to predict the target item, whereas skip-gram models try to predict the context based on the item in the middle. The training consists on a long sequence of trial and error: there is a right answer, i.e.~the actual corpus, the algorithm starts by guessing and receives feedback, and iteratively it adapts its guessing strategy to minimise the error. The strategy consists of weights in the hidden layer of neural network; these weights are then used to represent the target item. In other words, while a context-counting model would define the distributional profile of a word along the lines of ``it tends to co-occur with \emph{chocolate} and \emph{cookies} but not with \emph{mycorrhyza} or \emph{algorithm}'', context-predicting models say, more or less, ``this is how I feel/what my brain does when I see that word''. The latter is, in a sense, more in line with the core of meaning as an introspective experience that defies definitions and restrictions, although computational models are far from actually \emph{understanding} language. Exploring to what degree these models approximate humans' assessments lies in the purview of other research programmes involving psycholinguistic experiments. Studies have been carried out to compare the performance of context-counting and context-predicting models --- in terms, of course, of their accuracy with regards to popular benchmarks. \textcite{baroni.etal_2014} found that the word2vec architecture outperformed context-counting models, much to their disappointment. In contrast, \textcite{levy.etal_2015} fine-tuned context-counting models based on the hyperparameters from word embedding and found that performance differences where local or even insignificant.

When our purpose is to understand what of meaning, if anything, can be found in text data, the interpretation of context-counting models is much more transparent. We can trace the composition of the vectors to concrete frequencies and instances. As we will see in the second part of this dissertation, these supposedly more transparent models are already quite opaque, especially with the added transformation from type-level to token-level models. That said, most of the workflow described here can also be combined with context-predicting models.

The years since \textcite{mikolov.etal_2013} have seen a rapid and enthusiastic growth in the field of word embeddings and \textsc{nlp}, with new models continually surpassing the previous ones. One of these is \textsc{bert} \autocite{BERT}, which, in spite of its indubitable relevance to the approach proposed here, will not be explored. Bidirectional Encoder Representations from Transformers (\textsc{bert}) is a machine-learning technique that can represent individual instances and sentences: unlike other context-predicting models, it can be used for token-level representations. But like other context-predicting models, its output is somewhat less interpretable than context-counting models. It has been tested on the typical task-based benchmarks and it is so time- and resources-consuming that \textsc{nlp} researchers will typically use pre-trained embeddings and fine-tune them for specific tasks rather than generate them from scratch. In principle, combining a model of the \textsc{bert} family with the workflow described here is not impossible: as long as occurrences are represented with vectors from which we can derive pairwise distances, the rest of the analysis stays the same. However, some crucial differences remain: we do not know which elements of the context informed the models' decision, they are based on word forms and the word forms are based on a different tokenizer. For instance, a brief test of \textsc{bert}je \autocite{devries.etal_2019}, the Dutch counterpart of \textsc{bert}, on a section of the dataset used for this project revealed that (i) for some lemmas \textsc{bert}je's answer might be closer to the human perspective, (ii) for other lemmas a deeper investigation is in order and (iii) other lemmas cannot be modelled at all because of the discrepancy in the tokenization procedure\footnote{The comparison was applied to a few lemmas, including \emph{hoop} `hope/heap', \emph{dof} `dull' and \emph{heilzaam} `healthy/beneficial'. In the first case, which was particularly challenging for the context-counting models, \textsc{bert}je outperformed them; in the second, some context-counting models outperformed \textsc{bert}je; and the third was never identified as one unit by \textsc{bert}je's tokenizer.}. In other words, even if combining the methodologies is possible, the actual implementation requires some planning, specific decisions and tailoring the procedure to extract as much as we can from the backstage operations in context-predicting models.

\hypertarget{cog}{%
\section{Distributional Semantics and Cognitive Semantics}\label{cog}}

As a computational approach, distributional semantics is not intrinsically linked to any particular linguistic theory. Its usage-based essence makes it a natural fit for approaches that describe the \emph{parole} along with the \emph{langue} \autocite[in terms of][]{desaussure_1971}, such as Cognitive Linguistics. In the introduction to \emph{The Oxford Handbook of Cognitive Linguistics}, it is described as

\begin{quote}
an approach to the analysis of natural language that originated in the late seventies and early eighties in the work of George Lakoff, Ron Langacker, and Len Talmy, and that focuses on language as an instrument for organizing, processing, and conveying information. \autocite[3]{geeraerts.cuyckens_2007a}
\end{quote}

It stands in contrast to frameworks that uphold a strict separation of semantics and pragmatics, of structure and usage, of lexical knowledge and world knowledge \autocite{geeraerts_2010a}. As the introduction and composition of the \emph{Handbook} shows, as well as other compilations along these lines \autocites[such as][]{rudzka-ostyn_1988,kristiansen.etal_2006,ibarretxe-antunano.valenzuela_2016}, the diverse field of Cognitive Linguistics is guided by a number of principles derived from this central notion of language as categorization. Among these principles, three in particular constitute the theoretical cornerstones of this study: (i) an emphasis on meaning, (ii) the notion of fuzzy and prototypical categories and (iii) a usage-based approach.

\hypertarget{everything-is-semantics}{%
\subsection{Everything is semantics}\label{everything-is-semantics}}

Understanding language as categorization and its function in the organization and communication of knowledge necessarily places the focus on meaning \autocite{geeraerts.cuyckens_2007,geeraerts_2016a}. From a Cognitive Linguistics perspective, all linguistic structures --- not just lexical items but also syntactic patterns --- are considered inherently meaningful \autocite{langacker_2008a,lemmens_2015}. Moreover, meaning in Cognitive Linguistics goes beyond traditional semantics --- i.e.~distinguishing linguistic from nonlinguistic features --- and includes encyclopedic knowledge and pragmatics \autocite{glynn_2010,geeraerts_1997}. While it is crucially a cognitive phenomenon involving conceptualization, it takes place in the mind of physical, embodied beings who perceive, understand, and interact with their world: meaning is embodied and neither limited to nor separated from reference \autocite{rohrer_2007}.

The centrality of semantics in Cognitive Linguistics has led to a strong body of work on meaning and on how traditional notions fit in with cognitive principles.
For example, the line of work initiated in the '80s with \textcite{lakoff.johnson_2003} and further developed along different lines by Raymond Gibbs Jr., Gerard Steen, Zoltán Kövecses, Elena Semino and many others \autocites[see for example][]{gibbs.steen_1999,gibbs_2008,semino_2008,kovecses_2015} builds on understanding a traditional linguistic concept, i.e.~metaphor, with the tools of Cognitive Linguistics. In these terms, metaphor refers to ways of thinking, understanding, conceptualizing, that manifest in linguistic behaviour but also permeate other areas of everyday life.

Along these lines, relationships between senses are understood as cognitive mechanisms that need not be restricted to linguistic behaviour nor to extralinguistic reference. Semantic categories such as metaphor, metonymy, specialization, homonymy and prototypicality are crucial tools to make sense of the variety of relationships between what we understand as senses. They are not unique to Cognitive Linguistics, but a framework that understands meaning as a property of any linguistic structure and as covering linguistic and extralinguistic features allows us to look for meaning in distributional models without expecting them to exhaust semantic description.

Cognitive Linguistics also incorporates the combination of a semasiological and onomasiological perspective, while previous frameworks have defined either one or the other as the only possibility \autocite{geeraerts_2010a}. A semasiological perspective, which is predominant in the research described here, starts from a form or expression and investigates its range of meanings or applications, e.g.~the study of polysemy. An onomasiological perspective, on the other hand, starts from a concept and describes the forms that are used to express it, e.g.~synonymy. This dissertation takes a semasiological perspective, but token-level distributional models can be used from both perspectives, as shown in \textcite{depascale_2019}.

\hypertarget{prototypicality}{%
\subsection{Prototypicality}\label{prototypicality}}

Among the most important notions in the Cognitive Linguistics understanding of categorization we find prototypicality and salience \autocite{rosch_1978}. Categories cannot always be described in terms of necessary and sufficient conditions; instead, they may be characterized by clusters of co-occurring properties that do not apply to all members to the same degree. They may even have fuzzy boundaries, an unclear range of application. As a property of categorization, this is a property of language, which Cognitive Linguistics embraces, incorporating a quantitative dimension to the study of meaning \autocite{geeraerts_2010a}. At this point, a quantitative perspective does not immediately require statistical methods, but refers to a shift in the understanding of what counts as meaning description. The notion of prototypicality makes it interesting, if not inevitable, to look at the uneven distribution and importance of the different features or members of a category, as is done, for example, in \textcite{geeraerts.etal_1994} and \textcite{geeraerts_1997}:

\begin{quote}
\ldots the essence of prototype theory lies in the fact that it highlights the importance of flexibility (absence of clear demarcational boundaries) and salience (differences of structural weight) in the semantic structure of linguistic categories. \autocite[74]{geeraerts_2006e}
\end{quote}

Given the set of meanings that a form can express, i.e.~the intensional level, some of them are more salient than others. For example, given my current lifestyle, `device to control the cursor on a screen' is a more salient meaning of \emph{mouse} than `small rodent'; but, crucially, this might not be the case in other contexts, for other speakers. Given the range of application of a form or a meaning (i.e.~the extensional level), some may be more typical members than others. For instance, a black, minimalist computer mouse might be more typical than a wavy, wider gaming mouse with a bright green drawing of a dragon. These situations represent intensional and extensional nonequality, respectively: some senses or members of a category are better representatives of the category than others. Both dimensions may overlap: a typical computer mouse concentrates most of the typical features of the category, regarding its functionality, size, shape and colour; conversely, a typical feature is defined by occurring frequently in the members of the category. These are two of the characteristics of prototypicality, and are complemented by intensional and extensional non discreteness, i.e.~the lack of a single set of necessary and sufficient conditions and fuzzy boundaries of the categories. As could be expected, even prototypicality is a prototypical category, as these four features need not co-exist. The relative salience of the two senses of \emph{mouse} does not mean that we might find an unknown entity and be in doubt whether it is a mouse; meanwhile, discussions such as whether a tomato is a fruit might easily ensue. \textcite[Ch. 4]{geeraerts_2006e} offers a typology of salience phenomena as an application of prototype theory beyond the semasiological structure. For example, if from the semasiological perspective we are interested in describing how frequent (or salient) apples are as referents for the word \emph{fruit}, from the onomasiological perspective we are interested in how frequently the word \emph{fruit} is used to refer to apples (compared to saying \emph{apple}).

The notion of (semasiological) prototypicality will be relevant for the interpretation of the modelling in Chapter \ref{semantic-interpretation}. Until then, it also permeates the understanding of meaning that underlies this research. On the one hand, fuzzy boundaries and degrees of membership invite us to rethink the usefulness of reified senses: ambiguous examples and overlapping features are to be expected. Instead, a bottom-up procedure would rather capture configurations of features \autocite{glynn_2014c}; assigning discrete senses to corpus data imposes a categorical structure that we know to be inappropriate \autocite[see also][]{geeraerts_1993}. On the other hand, distributional models, as a quantitative approach that measures similarity between entities, is particularly adequate to such a non-discrete representation.

In this dissertation I will continue to talk about senses and I will extract discrete patterns from the non-discrete representations in terms of clusters, in order to manipulate and talk about these abstract entities, without implying that they have any ontological reality beyond the explanatory purposes. When it comes to senses, they are not considered a gold standard, an unique solution to the semasiological description of a lexical item; instead, they are guides and an operationalization of certain research questions. The clusters, on the other hand, will be generated by an algorithm that is forced to produce discrete groups but does assign its elements different degrees of membership (see Section \ref{hdbscan}). Finally, the overall approach describes tendencies, preferences, probabilities: at no level are the categories and typologies offered in this dissertation discrete and uniform. I have tried, but language resists.

\hypertarget{a-usage-based-approach}{%
\subsection{A usage-based approach}\label{a-usage-based-approach}}

Cognitive Linguistics presents itself as a usage-based approach and, as such, it is entirely compatible with a bottom-up, empirical, quantitative methodology such as distributional semantics. Quantitative cognitive semantics is now an established field, as shown by the contributions gathered in \textcite{gries.stefanowitsch_2006}, \textcite{glynn.fischer_2010} and \textcite{glynn.robinson_2014}, among others. However, not all of Cognitive Linguistics --- and especially Cognitive Semantics --- relies on empirical methods: introspection was still the main source of information in much of the foundational sources \autocite[see for example the discussion illustrated in][]{geeraerts_1999}. In practice, both introspection and empirical methods are required in scientific research, albeit applied to different stages or aspects of the investigation \autocite{geeraerts_2010}.
Interpretation is needed in order to formulate hypotheses that will guide the data collection and analysis and to interpret the results: the data does not speak for itself. The empirical steps, in contrast, facilitate reproducibility and falsifiability: by describing the concrete corpus, the method of collection and the quantitative methods applied to it, the study can be replicated by different researchers and the results compared.
At the same time, large-scale quantitative methods such as distributional semantics delegate time consuming or computationally expensive tasks, such as reading and comparing thousands of attestations of a word, to an automatic system that can perform it faster and more systematically than humans, leaving the researcher to dedicate their energies in the tasks that humans are best at: interpretation and creativity. That is precisely the long-term goal of this research: to offer an empirical, quantitative workflow that transforms huge amounts of data, finds relevant patterns and provides them to the linguist for interpretation and the formulation of hypotheses.

Empirical research in semantics can take different shapes: corpus-based methods, as is the case in this research, but also experimental and referential methods. As \textcite[242-243]{geeraerts_2015b} argues, each of these approaches captures a different aspect of meaning, namely textual patterns, on-line processing or referential properties. Meaning, especially from the maximalist perspective taken in Cognitive Linguistics, is too complex to be fully described by any one of these methods in isolation \autocites[see also][]{arppe.etal_2010,stefanowitsch_2010}. As such, we do not have such high expectations from distributional semantics --- part of the question is: \emph{what} do these models say?
Concretely, we do not expect distributional models to provide information on how we \emph{think}, but on how a community speaks and categorises: ``\,`language as cognition' encompasses shared and socially distributed knowledge and not just individual ideas and experiences'' \autocite[533]{geeraerts_2016a}. It is the pool of shared practices and knowledge that corpora offers and distributional semantics tries to model.

Moreover, despite the large corpora, the advanced quantitative techniques and the sophisticated visualization tools on which this dissertation is built, this study has its limits. It is restricted to a specific corpus, and as such to specific varieties of a specific language, to a specific genre and period in time, to written text; it is restricted to a limited set of lexical items that were investigated; it is restricted to the precise samples collected, the precise questions asked, the precise techniques used to answer them. Most importantly, I will be as thorough as possible in stating the conditions in which the research was carried out and the choices made along the way. As a result, these limits are not just warnings as to the range of applicability of the results and conclusions, but also and more importantly sources of possibilities, inspiration for similar studies facilitated by the empirical nature of the investigation.

\hypertarget{viz}{%
\section{Visual analytics}\label{viz}}

Distributional models return mathematical representations of lexical items --- or, in the case of token-level models, their attestations. These mathematical representations are arrays of numbers that, in the best-case scenario, we can interpret as co-occurrence information, as an unsorted list of collocations. We need an additional step to transform these individual representations into similarities, which operationalize the Distributional Hypothesis mentioned above. However, even then, the output is a matrix with as many rows and columns as items we are comparing; depending on the magnitude of our sample and the subtlety of its structure, scanning it visually can be taxing, if not entirely in vain. So, that is not what we do.

For word sense disambiguation, evaluation would normally involve a clustering algorithm, a benchmark and a measure of accuracy. The clustering algorithm would take the vectors or the similarity matrix and return clusters: groups of similar items that are different from each other. The measure of accuracy would report on the agreement between the clustering solution and the benchmark: the closer they are, the better the model. However, these measures say nothing about the qualitative differences between models, i.e.~whether they misclassified the same items or how they differ from the benchmark. Even if we take the gold standard as an actual ground truth and the only correct solution --- which is not the case in this study --- this is not an ideal situation.

It is responding to these concerns that a visualization tool for the exploration of token-level models was envisaged \autocite{wielfaert.etal_2019}. The tool developed by Wielfaert in the context of the Nephological Semantics project takes the output from a dimensionality reduction algorithm, i.e.~a procedure that tries to map distances based on multiple dimensions on a \textsc{2d} or \textsc{3d} space, and surrounds its visual representation with interactive features. These additional features, tailored for the exploration of distributional models, set the tool apart from a static scatterplot, or even from a default interactive plot.

To put it in \textcite[6]{card.etal_1999}'s words: ``\,`The purpose of visualization is insight, not pictures'. The main goals of this insight are \emph{discovery}, \emph{decision making} and \emph{explanation}''\footnote{Emphasis from the original.}. Indeed, the kind of qualitative exploration achieved through this tool would have been extremely hard without it, if not impossible.
In the first place, the tool sets up a workflow that goes from the exploration of the similarity \emph{between} models and the role of parameter settings through the qualitative comparison of selections models to the detailed exploration of individual models. It is built to facilitate a fluid exploration and interconnection between levels of analysis. The tool offers simultaneous, interconnected access to the actual output of a model (as coordinates on a \textsc{2d} plane), the variation of parameter settings, semantic annotation, metadata of the corpora and frequency data on the context words. The interaction of these different aspects of distributional models in a practical visual interface makes patterns and insights accessible that would not have been found any other way.

Because of this, the visualization tool is a key component of this dissertation. It is in these scatterplots that we find the clouds: clusters of similar tokens that come together in denser areas of the (reduced) semantic space. In an actual case study involving the methodological workflow presented here, a lot of the technicalities go into generating the clouds, but a large part of the analysis involves looking at them and finding shapes: cloudspotting.

\hypertarget{nephosem}{%
\section{Nephological Semantics}\label{nephosem}}

The research presented in this dissertation is part of a larger project within the \textsc{qlvl} research unit, the \textsc{bof} C1-project (3H150305) ``Nephological Semantics: using token clouds for meaning detection in variationist linguistics'', with Dr.~Prof.~Dirk Geeraerts as Principal Investigator. Both the Python module for the creation of the models, written by Tao Chen, and the visualization tools for their analysis, designed by Thomas Wielfaert and myself, are products of this project. Moreover, this dissertation would not be what it is without the integration of the case studies, questions and insights discussed here with other branches of the project, and without the feedback loop on ideas, tests and thoughts on the different techniques.

The main objective of the project is to develop --- and understand --- appropriate methods for the retrieval of semantic information from corpus data, addressing concerns that stem from a longer tradition of usage-based lexical research. \textcite{geeraerts.etal_1994} and \textcite{geeraerts.etal_1999} embark in comprehensive, detailed lexicological analyses of the lexical fields of clothing and football terms in Dutch. Their approach is referential: \textcite{geeraerts.etal_1994}, for instance, collect pictures and descriptions of garments from Dutch and Flemish magazines and describe each clothing item in terms of a variety of features, such as the length of the sleeve. Based on the relationship between the (configurations of) features and the items used to name the objects, they developed a model of lexical variation that takes into account prototypicality and salience in terms of semasiological, onomasiological and contextual variation. However, the manual and detailed identification of features at a large enough scale is painstaking and time consuming, if at all feasible. In contrast, machine-readable linguistic material is available, more or less accessible and, given the right resources, processable. It will not provide the same kind of information as a referential approach, but it is more easily scalable to large amounts of data.

In the context of this project, token-level models for semasiological research are introduced by \textcite{heylen.etal_2012} and \textcite{heylen.etal_2015}. Another work-package, culminating in \textcite{depascale_2019}'s PhD dissertation, applies the technique to lexical lectometric research, i.e.~measuring distances between language varieties based on their naming choices for different concepts. The visualization tool, as mentioned before, is first described in \textcite{wielfaert.etal_2019}. Between their work, this dissertation and further case studies taking place in the last year, the project is covering the application of token-level vector space models on semasiological, onomasiological and lectometric studies in varieties of Dutch and Mandarin, at both a synchronic and a diachronic level.

\hypertarget{str}{%
\section{Structure of the dissertation}\label{str}}

As a product of the Nephological Semantics project, this dissertation aims to contribute to both the development and understanding of distributional models for lexical semasiological research.
It brings together the theoretical perspective on semantics from Cognitive Linguistics with computational methods and visual analytics in the hope of paving the way for future research along the same lines.
With that in mind, the three chapters of the first part of this dissertation, \emph{The cloudspotter's toolkit}, will focus on the technical or methodological side of the project.
Chapter \ref{workflow} will describe the procedure to create clouds and the parameter settings explored, taking care to be thorough and specific about the technical decisions that resulted in the final models.
Then, Chapter \ref{nephovis} will showcase the visualization tool designed by Thomas Wielfaert and myself as well as a ShinyApp extension that provides additional functionalities.
Finally, Chapter \ref{dataset} will illustrate the dataset on which the models were tested: the selection of lemmas and the questions they try to address, the collection of data and the annotation procedure.

The notion behind token-level models, i.e.~that we can represent meaning differences in terms of distributional differences, and in particular the image of a scatterplot that translates these intuitions into an interpretable picture, \emph{sounds good}.
Alas, the reality is not as bright as we could have wished for, and the skies of distributional semantics have all but a stable weather. Hopefully, this dissertation can offer a guide for researchers who would dare to tread these waters. Therefore, the three chapters in the second part, \emph{The cloudspotter's handbook}, will discuss the results of the analyses, with an emphasis on crucial assumptions that clash with the data. First, Chapter \ref{shapes} debunks the idea of a perfect cloud emerging from the ocean of the corpus. Clouds come in many different shapes, caused by different phenomena of distributional behaviour, and thus this chapter offers a classification of what we might encounter. Chapter \ref{semantic-interpretation} follows with a linguistic perspective on the variation of these shapes and discusses what we can or we cannot find in these models. Finally, Chapter \ref{no-optimal} shows how no set of parameter settings offers the best solution across the board --- not even close. Instead, the same parameter settings may result in different shapes for different lemmas, and they have to be tailored \emph{to the specific lemma} to capture the relevant semantic structure.

An enthusiastic and hopeful aspiring cloudspotter might feel discouraged by the variability --- bordering on unpredictability --- of these clouds. I wouldn't blame them. However, in spite of the diversity of shapes, of semantic phenomena and of parameter settings to explore, the methodology can offer interesting insights. They are partial insights, but insights nonetheless, and once we know what to expect from clouds, we can focus on acquiring them. In that perspective, the third and final part of this dissertation, \emph{The cloudspotter's cheatsheet}, will close with a general practical guide, a summary of suggestions for further research and an overall conclusion.

\hypertarget{part-the-cloudspotters-toolkit}{%
\part{The cloudspotter's toolkit}\label{part-the-cloudspotters-toolkit}}

\hypertarget{workflow}{%
\chapter{From corpora to clouds}\label{workflow}}

The main goal of the methodological framework presented here is to explore semasiological structure from textual data.
The starting point is a corpus, i.e.~a selection of texts, and one of the most tangible outputs is what we will call \emph{clouds}: the visual representation of textual patterns as dense areas in a \textsc{2d} scatterplot.
In this chapter we will explain how to generate clouds from the raw, seemingly indomitable ocean of a corpus.

First, we will describe how token-level vector space models are created: these are mathematical representations of the occurrences of a lexical item.
We will focus on context-counting models, but this is by no means the only viable path.
Other techniques, such as BERT \autocite{BERT}\footnote{See also \textcite{devries.etal_2019} for a Dutch version.}, that can also generate vectors for individual instances of a word, could be used for the first stage of this workflow.
Section \ref{vector-creation} will describe the process and the rationale without assuming a strong mathematical background for the reader, leaving the deeper technicalities to Section \ref{formulae}. In Section \ref{params}, we will break apart the workflow into the multiple choices that the researcher needs to make and that result in a potentially infinite number of models, while Section \ref{pam} briefly presents a method to select a few representative models. Finally, Section \ref{workflow-summary} summarizes the chapter.

\hypertarget{vector-creation}{%
\section{A cloud machine}\label{vector-creation}}

At the core of vector space models, \emph{aka} distributional models, we find the Distributional Hypothesis, which is often linked to Harris's observation that ``difference of meaning correlates with difference of distribution'' \autocite*[156]{harris_1954}, but also to Firth's ``You shall know a word by the company it keeps'' \autocite*[11]{firth_1957a} and Wittgenstein's ``the meaning of a word is its use in the language''\footnote{The famous quote is preceded by an appropriate nuance: ``For a \emph{large} class of cases --- though not for all --- in which we employ the word `meaning' it can be defined thus: the meaning of a word is its use in the language''.
} \autocite*[20]{wittgenstein_1958}.
In other words, items that occur in similar contexts in a given corpus will be semantically similar, while those that occur in different contexts will be semantically different \autocites[Ch. 6]{jurafsky.martin_2020}{lenci_2018}. Crucially, this does not imply that we can describe an individual item with their distributional properties, but that comparing the distribution of two items can tell us something about their semantic relatedness \autocite[19]{sahlgren_2006}.

\textcite{firth_1957a} inspired generations of corpus linguists to look at collocations as part of the semantic description of a lemma. The Birmingham school, pioneered by John Sinclair, used co-occurrence frequency information to describe a lexical item
by the set of those context words most attracted to them. Due to the skewed distribution of word frequencies, known as Zipf's law, this attraction cannot be measured in terms of raw co-occurrence frequencies. For example, the most frequent lemma in the (Dutch) corpus used for this research, discarding punctuation, is \emph{de} `the (fem./masc.)', which occurs 28.1 million times. The second most frequent lemma, \emph{van} `from', occurs 12.6 milion times, and it is followed by \emph{het} `the (neutral)' and \emph{een} `a, an', with corresponding frequencies of 11.7 and 11.1 million times each. For every 100 words in the corpus, excluding punctuation, \(14\) are one of these four words. Of the total of 4.6 million different words, 61\% are \emph{hapax legomena}, i.e.~they occur once, and 172 lemmas cover 50\% of all the occurrences. As a consequence, co-occurrences with very frequent words are not as informative as those with less frequent words, and hence raw co-occurrence frequencies are transformed to measures of \textbf{association strength}, such as mutual information (see Section \ref{pmi}) or t-score, among others \autocites[for an overview see][]{evert_2009,gablasova.etal_2017}.
In collocational studies, researchers typically set a threshold of association strength and only look at the context words that surpass it.

At their core, context-counting \textbf{vectors} are lists of association strength values. Each word is represented by its association strength to a long array of words that it might co-occur with, as shown in Table \ref{tab:vec1}. Unlike in collocation studies, low values --- or even lack of co-occurrence --- are not excluded, but used in the comparison with other words that might. Going back to the Firthian motto, a collocational study would describe me with the list of people that I talk to the most, whereas a distributional model would compare me to someone else based on who either of us talks to and how often we talk to them. The more people we have in common, the more similar we are, but people that neither of us talks to have no impact on the comparison.

Table \ref{tab:vec1} shows small vectors representing the English nouns \emph{linguistics}, \emph{lexicography}, \emph{research} and \emph{chocolate}, as well as the adjective \emph{computational}, with co-occurrence information obtained from the GloWbE (Global Word-based English) corpus. The values are their association strength \textsc{pmi} with each of the lemmas in the columns: the higher the values, the stronger the attraction between the word in the row and the word in the column (See Section \ref{pmi}). From a collocational perspective, \emph{linguistics} is strongly attracted to both \emph{language} and \emph{English}, i.e.~they occur very often in a span of 10 words from each other, considering their individual frequencies; it is less attracted to \emph{word} and \emph{to speak}, and does not co-occur with either \emph{to eat} or \emph{Flemish} within that window, in this corpus.



\begin{table}

\caption{\label{tab:vec1}Small example of type-level vectors, with \textsc{pmi} values based on a symmetric window of 10. Frequency data extracted from GloWbE.}
\centering
\resizebox{\linewidth}{!}{
\begin{threeparttable}
\begin{tabular}[t]{lllllll}
\toprule
target & language/n & word/n & flemish/j & english/j & eat/v & speak/v\\
\midrule
linguistics/n & 4.37 & 0.99 & - & 3.16 & - & 0.41\\
lexicography/n & 3.51 & 2.18 & - & 2.19 & - & 2.09\\
computational/j & 1.6 & 0.08 & - & -1 & - & -1.8\\
research/n & 0.2 & -0.84 & 0.04 & -0.5 & -0.68 & -0.38\\
chocolate/n & -1.72 & -0.53 & 1.28 & -0.73 & 3.08 & -1.13\\
\bottomrule
\end{tabular}
\begin{tablenotes}
\item \textit{Note: } 
\item Part-of-speech is indicated after a slash: n = noun, j = adjective, v = verb
\end{tablenotes}
\end{threeparttable}}
\end{table}

Each row in Table \ref{tab:vec1} is a vector coding the distributional information of the lemma it represents. By \textbf{lemma} we refer to the combination of a stem and a part of speech, e.g.~\emph{chocolate/n} covers \emph{chocolate}, \emph{chocolates}, \emph{Chocolate}, etc.
These vectors are meant to code the distributional behaviour of the linguistic forms they represent --- in this case lemmas ---, in order to operationalize the notion of distributional similarity and, consequently, model their meaning. For example, in Table \ref{tab:vec1} the first two rows, representing \emph{linguistics} and \emph{lexicography}, are similar to each other: both words have a similar attraction to \emph{language} and to \emph{English}, even if the values for \emph{word} and \emph{to speak} are more different. More importantly, they are more similar to each other than to other rows in the table, which have lower values for those four columns and might even co-occur with \emph{Flemish} and \emph{to eat} as well.
The Distributional Hypothesis expresses the observation that words that are distributionally similar, like \emph{linguistics} and \emph{lexicography}, are semantically similar or related, whereas words that are distributionally different, like \emph{linguistics} and \emph{chocolate}, are semantically different or unrelated.

The rows in this table are \textbf{type-level vectors}: each of them aggregates over all the attestations of a given lemma in a given corpus to build an overall profile. As a result, it collapses the internal variation of the lemma, i.e.~its different senses or semasiological structure. In order to uncover such information, we need to build vectors for the individual instances or \textbf{tokens}, relying on the same principle: items occurring in similar contexts will be semantically similar. For instance, we might want to model the three (artificial) occurrences of \emph{study} in (1) through (3), where the target item is in bold and some context words are in italics.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\tightlist
\item
  Would you like to \textbf{study} \emph{lexicography}?
\item
  They \textbf{study} this in \emph{computational linguistics} as well.
\item
  I eat \emph{chocolate} while I \textbf{study}.
\end{enumerate}

Given that, at the aggregate level, a word can co-occur with thousands of different words, type-level vectors can include thousands of values. In contrast, token-level vectors can only have as many nonzero values as the individual window size comprises, which drastically reduces the chances of overlap between vectors. In fact, the three examples don't share any item other than the target. As a solution, inspired by \textcite{schutze_1998}, (a selection of) the context words around the token is replaced with their respective type-level vectors \autocite{heylen.etal_2012,heylen.etal_2015,depascale_2019}.
Concretely, example (1) is represented by the vector for its context word \emph{lexicography}, that is, the second row in Table \ref{tab:vec1}; example (2) by the sum of the vectors for \emph{linguistics} (row 1) and \emph{computational} (row 3); and example (3) by the vector for \emph{chocolate} (row 5). This not only solves the sparsity issue, ensuring overlap between the vectors, but also allows us to find similarity between (1) and (2) based on the similarity between the vectors for \emph{lexicography} and \emph{linguistics}. As we will see in Section \ref{params}, we can even use the association strength between the context words and the target type, i.e.~\emph{to study}, and give more weight to the context words that are more characteristic of the lemma we try to model.
The result of this procedure is a co-occurrence matrix like the one shown in Table \ref{tab:tokens}. Each row represents an instance of the target lemma, e.g.~\emph{to study}, and each column, a lemma occurring in the corpus\footnote{Which lemmas in particular are a matter for Section \ref{soc}, but in any case, lemmas that do not co-occur with any of the context words of the tokens will have zeros in all the rows and therefore be dropped.}; the values are the (sum of the) association strength between the words that occur around the token, i.e.~their \textbf{first-order context words}, and each of the words in the columns, i.e.~the \textbf{second-order context words}. In addition, all negative and missing values value have been set to zero, due to the unreliability of negative \textsc{pmi} values (see Section \ref{pmi}).



\begin{table}

\caption{\label{tab:tokens}Small example of token-level vectors of three artificial instances of \emph{to study}.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{lrrrrrr}
\toprule
target & language/n & word/n & english/j & speak/v & flemish/j & eat/v\\
\midrule
study$_1$ & 4.37 & 0.99 & 3.16 & 0.41 & 0.00 & 0.00\\
study$_2$ & 5.97 & 1.07 & 2.16 & 0.00 & 0.00 & 0.00\\
study$_3$ & 0.00 & 0.00 & 0.00 & 0.00 & 1.28 & 3.08\\
\bottomrule
\end{tabular}}
\end{table}

The next step in the workflow is to compare the items to each other. We can achieve this by computing cosine distances between the vectors (see Section \ref{cosine} for the technical description). The resulting distance matrix, shown in Table \ref{tab:tokdists}, tells us how different each token is to itself, which takes the minimum value of 0, and to each of the other tokens, with a maximum value of 1. We can see that (1) and (2) are very similar to each other, because they co-occur with similar context words, i.e.~\emph{linguistics} and \emph{lexicography}, but drastically different from (3), which was modelled based on \emph{chocolate}. The specific selection of context words is crucial: if we had selected \emph{computational} but not \emph{lexicography} to model (2), it would have resulted in a larger difference with (1). The series of choices that we can make and that have been made for this research project are discussed in Section \ref{params}.



\begin{table}

\caption{\label{tab:tokdists}Cosine distance matrix between the three artificial instances of \emph{to study}.}
\centering
\begin{tabular}[t]{lrrr}
\toprule
  & study$_1$ & study$_2$ & study$_3$\\
\midrule
study$_1$ & 0.00 & 0.04 & 1\\
study$_2$ & 0.04 & 0.00 & 1\\
study$_3$ & 1.00 & 1.00 & 0\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:tokdists} is small and simple, but what if we had hundreds of tokens? The more items we compare to one another, the larger and more complex the distance matrix becomes. In order to interpret it, we need more stages of processing. On the one hand, dimensionality reduction techniques such as \textsc{mds}, t-\textsc{sne} and \textsc{umap}, which will be discussed in Section \ref{dim-reduction}, offer us a way of visualizing the distances between all the models by projecting them to a \textsc{2d} space. We can then represent each model into a scatterplot, like in the plots of Figure \ref{fig:cloud1}, where each point represents a token, and their distances in \textsc{2d} space approximate their distances in the multidimensional space of the co-occurrence matrix. Visual analytics, such as the tool described in Chapter \ref{nephovis}, can then help us explore the scatterplot to figure out how tokens are distributed in space, why they form the groups they form, etc.

Word Sense Disambiguation
makes use of clustering algorithms to extract clusters of similar tokens from their models. The idea behind it is that, if distributional similarity correlates with semantic similarity, groups of similar tokens should share the same sense and have a different sense from other groups of tokens. In Chapter \ref{semantic-interpretation} we will see to what degree this assumption holds in this data and with these methods.

The final step in our workflow is, then, the combination of dimensionality reduction and clustering, which results in the right plot of Figure \ref{fig:cloud1}: by means of dimensionality reduction, tokens are located in a scatterplot so that distributional similarities are approximated as spatial similarities, and groups of similar tokens are assigned different colours.
In previous research, which did not integrate clustering procedures in this manner, the term \emph{cloud} was used to refer to a full model \autocite{heylen.etal_2015,wielfaert.etal_2019,depascale_2019,montes.heylen_Submitted}. In this study, instead, \emph{cloud} will refer to each of the clusters, identified by colours in the scatterplot.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/cloud1-1.pdf}
\caption{\label{fig:cloud1}\textsc{2d} representation of Dutch \emph{hachelijk} `dangerous/critical'.}
\end{figure}

\hypertarget{formulae}{%
\section{The chemistry of cloud making}\label{formulae}}

A typical vector space model is an item-by-feature matrix: its rows code items, its columns code features, and its cells code information related to the frequency with which the items and features co-occur. The first distributional models counted the occurrences of words in documents and represented them in word-by-document matrices; the models described here are token-by-feature matrices, in which the rows are attestations of a lexical item and the features are second-order co-occurrences, i.e.~context words of the context words of the token. \textcite{turney.pantel_2010} offer an overview of different kinds of matrices, based on the items modelled and the features used to describe them.
Besides matrices, vector space models can be tensors, which are generalisations of matrices for more dimensions and can allow for more complex interactions, e.g.~subject-verb-object triples in \textcite{vandecruys.etal_2013}; see also \textcite{lenci_2018}.

Models can be based on co-occurrence counts, as is the case in these studies, or on machine-learning algorithms trained to predict the context around a word or fill in an empty slot given a few words around it. These context-predicting models use the weights of their neural networks as features in the vectorial representations of the words they predict. A number of papers have explored which kind of models work best for different tasks, with uncertain results \autocite{baroni.etal_2014,levy.etal_2015}.
As explained before, such context-predicting models will not be explored in this dissertation, although their integration would be interesting for further avenues of research.

The workflow described in the previous section relies on mathematical principles to obtain linguistic patterns from a (mostly) raw corpus. A full understanding of the formulae that underlie each step is not necessary to grasp the gist of this methodology, but it is required for an appropriate implementation.
In this section, we will take a deeper look into the technical aspects the machinery behind the process, in particular association strengths, similarity metrics, dimensionality reduction techniques and clustering algorithms.

\hypertarget{pmi}{%
\subsection{Association strength: PMI}\label{pmi}}

The distribution of words in a corpus follows a power law: a few items are extremely frequent, and most of the items are extremely infrequent. Association measures transform raw frequency information to measure the attraction between two items while taking into account the relative frequencies with which they occur. They typically manipulate, in different ways, the frequency of the node \(f(n)\), the frequency of its collocate \(f(c)\), their frequency of co-occurrence \(f(n,c)\) and the size of the corpus \(N\). \textcite{evert_2009} and \textcite{gablasova.etal_2017} offer an overview of how different measures are computed and used in corpus linguistics; \textcite{kiela.clark_2014}
compare measures used in distributional models.

In the studies discussed here, I will only use \textbf{(positive) pointwise mutual information}, or \textsc{(p)pmi} \autocite{church.hanks_1989}, one of the most popular measures both in collocation studies and distributional semantics \autocite{bullinaria.levy_2007,kiela.clark_2014,jurafsky.martin_2020,lapesa.evert_2014}.
Its formula is shown in equation \eqref{eq:pmi}, where \(p(n) = \frac{f(n)}{N}\), i.e.~the proportion of occurrences in the corpus that correspond to \(n\).

\begin{equation}
  I(n, c) = \log \frac{p(n,c)}{p(n)p(c)} = \log \left( \frac{f(n,c)}{f(n)f(c)} N \right)
  \label{eq:pmi}
\end{equation}

Negative \textsc{pmi} values tend to be unreliable, so positive \textsc{pmi} or \textsc{ppmi} is used, in which the negative \textsc{pmi} values are turned to zeros \autocites[109]{bullinaria.levy_2007,kiela.clark_2014,depascale_2019,jurafsky.martin_2020}.
Furthermore, \textsc{pmi} is known for its bias towards infrequent events: when either \(p(n)\) or \(p(c)\) is very low, \textsc{pmi} tends to be very high. In collocation studies, this bias may be counteracted by combining \textsc{pmi} filters with other measures that favour frequent co-occurrences, such as t-scores or log-likelihood ratio \autocite{mcenery.etal_2010}. In distributional semantics, the accuracy of models that rely on \textsc{ppmi} seems not to be affected by the issue presented by this bias;
moreover, in these studies any lemma with \(f(n) < 217\), i.e.~occurring less than once every two million tokens, was excluded, to avoid too sparse, uninformative vectors.

\hypertarget{cosine}{%
\subsection{Similarities and distances: cosine}\label{cosine}}

After obtaining the token-by-feature matrices, the distances between the vectors must be computed. Typically, the implementations for the dimensionality reduction and clustering can take the item-by-feature matrices as input and compute the distances under-the-hood, but they do not necessarily offer the option of computing our distance measure of choice, cosine.

Cosine is a measure of similarity between vectors \(\mathbf{v}\) and \(\mathbf{w}\) and is defined in equation \eqref{eq:cosine}; it coincides with the normalised dot product of the vectors \autocite[105]{jurafsky.martin_2020}.

\begin{equation}
  \mathrm{cosine}(\mathbf{v}, \mathbf{w}) = \frac{\mathbf{v} \cdot \mathbf{w}}{\left|\mathbf{v}\right|\left|\mathbf{w}\right|} = \frac{\sum\limits_{i=1}^N v_iw_i}{\sqrt{\sum\limits_{i=1}^N v_i^2}\sqrt{\sum\limits_{i=1}^N w_i^2}}
  \label{eq:cosine}
\end{equation}

For positive values, e.g.~when using \textsc{ppmi}, the cosine similarity ranges between 0 and 1: it will be 1 between identical vectors and 0 for orthogonal vectors, which do not share nonzero dimensions, like study\(_1\) and study\(_3\) in Table \ref{tab:tokens}. Cosine is sensitive to the angle between the vectors, and not to their magnitude: the similarity between study\(_1\) and a vector created by multiplying all the cells in study\(_1\) by any constant will still be 1.

Cosine similarity is the most common metric in distributional models \autocite[105]{jurafsky.martin_2020} and has been shown to outperform other measures, especially when combined with \textsc{ppmi} \autocite{kiela.clark_2014,lapesa.evert_2014,bullinaria.levy_2007}\footnote{\textcite{kiela.clark_2014} also recommend a Correlation similarity.}. One of the ways in which it is used is for semantic similarity tasks: the nearest neighbours of an item are extracted, by selecting the vectors with highest cosine similarity to the target vector. In these studies, similarities are usually transformed to distances by inverting the scale (\(\mathrm{cosine}_{\mathrm{dist}} = 1- \mathrm{cosine}_{\mathrm{sim}}\)), so that identical vectors --- and each vector to itself --- have a cosine distance of 0 and orthogonal vectors have a cosine distance of 1, as shown in Table \ref{tab:tokdists}.

Before applying dimensionality reduction or clustering algorithms, the cosine distances were further transformed with the aim of giving more weight to short distances, i.e.~nearest neighbours, and decreasing the impact of long distances. For each token vector \(\mathbf{v}\) with \(n\) dimensions, we define the transformed vector \(\mathbf{v}_{\mathrm{transformed}}\) as \(\mathbf{v}_{\mathrm{transformed}_i} = \log (1 + \log rank(\mathbf{v})_i)\) for each \(i\), with \(1 \le i \le n\), and where \(rank(\mathbf{v})_i\) is the similarity rank of the \(i\)th value in \(\mathbf{v}\). For example, if originally we have the distances \(\mathbf{v} = [0, 0.2, 0.8, 0.3]\), the rank transformation returns \(rank(\mathbf{v}) = [1, 2, 4, 3]\), which after the first logarithm transformation becomes \([0, 0.693, 1.39, 1.099]\) and, after the second transformation, \(\mathbf{v}_{\mathrm{transformed}} = [0, 0.52, 0.86, 0.74]\). On the one hand, the magnitude of the distance is not as important as its ranking among the nearest neighbours. On the other, the lower the ranking, the smaller the impact: the difference between the final values for ranks 1 and 2 is larger than between ranks 2 and 3.
The new matrix, where each row \(\mathbf{v}\) has been replaced with its \(\mathbf{v}_{\mathrm{transformed}}\), is converted to euclidean distances.

While cosine distances are used to measure the similarity between token-level vectors, euclidean distances will be used to compare two vectors of the same token across models, and thus compare models to each other. Concretely, let's say we have two matrices, \(\mathbf{A}\) and \(\mathbf{B}\), which are two models of the same sample of tokens, built with different parameter settings, and we want to know how similar they are to each other, i.e.~how much of a difference those parameter settings make. Their values are already transformed cosine distances. A given token \(i\) has a vector \(\mathbf{a}_i\) in matrix \(\mathbf{A}\) and a vector \(\mathbf{b}_i\) in matrix \(\mathbf{B}\). For example, \(i\) could be example (2) above, and its vector in \(\mathbf{A}\) is based on the co-occurrence with \emph{computational} and \emph{linguistics}, as shown in Table \ref{tab:tokens}, while its vector in \(\mathbf{B}\) is only based on \emph{computational}. The euclidean distance between \(\mathbf{a}_i\) and \(\mathbf{b}_i\) is computed with the formula shown in equation \eqref{eq:eucli}. After running the same comparison for each of the tokens, the distance between the models \(\mathbf{A}\) and \(\mathbf{B}\) is then computed as the mean of those tokenwise distances across all the tokens modelled by both: \(d(\mathbf{A},\mathbf{B}) = \frac{\sum_{i=1}^nd(\mathbf{a}_i, \mathbf{b}_i)}{N}\). Alternatively, the distances between models could come from procrustes analysis\footnote{Run with \texttt{vegan::procrustes()} \autocite{R-vegan}}, like \textcite{wielfaert.etal_2019} do, which has the advantage of returning a value between 0 and 1. However, this method is much faster and returns comparable results.

\begin{equation}
    d(\mathbf{a}_i, \mathbf{b}_i) = \sqrt{\sum\limits_{i=j}^n(a_j-b_j)^2}
    \label{eq:eucli}
\end{equation}

\hypertarget{dim-reduction}{%
\subsection{Dimensionality reduction for visualization: t-SNE}\label{dim-reduction}}

Dimensionality reduction algorithms try to reduce the number of dimensions of a high-dimensional entity while retaining as much information as possible. In distributional models, they have two main applications: one that reduces thousands of dimensions to a few hundred, and one that reduces them to only two.

The first application of dimensionality reduction, with techniques like \textsc{svd} (Singular Value Decomposition), is meant to deal with the sparsity of high-dimensional vectors. Due to the frequency distribution discussed above, many words never occur in the vicinity of each other, resulting in many zeros in their context-counting representations and therefore inflated differences between the vectors. In particular, techniques like Latent Semantic Analysis \autocite{landauer.dumais_1997} are based on the observation that the dimensions obtained from this process are semantically interpretable.
It could also be used for token-level spaces, but the comparisons discussed in \textcite[246]{depascale_2019} indicate that they don't necessarily perform better than non reduced spaces.
Both dimensionality reduction techniques and neural networks are suggested as ways of condensing very long, sparse vectors \autocite{jurafsky.martin_2020,bolognesi_2020}.
We will not go into the technical aspects because these techniques have not been implemented in the studies described here. Instead, we have compared vectors of different lengths based on other selection methods for the second-order features. Combining them with \textsc{svd} is a possible avenue for future comparisons.

The second application of dimensionality reduction is used for visualization purposes. A token-by-feature matrix can be understood as a multidimensional space: each of the columns is a dimension of space and the values of cells are the coordinates of the items in each of these dimensions. That is why we can use cosine distances, which measures angles: if we draw a vector from the origin (zero in all dimensions) to the point with those coordinates, it diverges from other vectors with a given angle that grows wider as the vectors diverge, leading to larger cosine distances. We can mentally picture or even draw positions, vectors and angles in up to 3 dimensions, but distributional models have hundreds if not thousands of dimensions. These applications of dimensionality reduction, then, are built to project the distances between items in the multidimensional space to euclidean distances in a low-dimensional space that we can visualize. The different implementations can receive the token-by-feature matrix as input, but will not typically compute cosine distances between the items, so the distance matrix is provided as input instead.
The literature tends to go for either multidimensional scaling (\textsc{mds}) or t-stochastic neighbour embeddings (t-\textsc{sne}); recently, an interesting alternative called \textsc{umap} has been introduced, which I'll discuss shortly.

The first option, \textsc{mds}, is an ordination technique, like principal components analysis (\textsc{pca}). It has been used for decades in multiple areas \autocite[e.g.][]{cox.cox_2008}; its most relevant application for this case, non-metric multidimensional scaling, was developed by \textcite{kruskal_1964}. It tries out different low-dimensional configurations aiming to maximize the correlation between the pairwise distances in the high-dimensional space and those in the low-dimensional space: items that are close together in one space should stay close together in the other, and items that are far apart in one space should stay far apart in the other.
The output from \textsc{mds} can be evaluated by means of the stress level, i.e.~the complement of the correlation coefficient: the smaller the stress, the better the correlation between the measures.
Unlike \textsc{pca}, however, the dimensions are not meaningful \emph{per se}; two different runs of \textsc{mds} may result in plots that mirror each other while representing the same thing. Nonetheless, the R implementation \texttt{vegan::metaMDS()} \autocite{R-vegan} rotates the plot so that the horizontal axis represents the maximum variation.
In cognitive linguistics literature both metric \autocite{koptjevskaja-tamm.sahlgren_2014,hilpert.correiasaavedra_2017,hilpert.flach_2020}
and non-metric \textsc{mds} \autocite{heylen.etal_2012,heylen.etal_2015,perek_2016,depascale_2019} have been used.

The second technique, t-\textsc{sne} \autocite{Rtsne2008,Rtsne2014}, has also been incorporated in cognitive distributional semantics \autocite{perek_2018,depascale_2019}.
It is also popular in computational linguistics \autocite{smilkov.etal_2016,jurafsky.martin_2020}; in R, it can be implemented with \texttt{Rtsne::Rtsne()} \autocite{R-Rtsne}.
The algorithm is quite different from \textsc{mds}: it transforms distances into probability distributions and relies on different functions to approximate them. Moreover, it prioritises preserving local similarity structure rather than the global structure: items that are close together in the high-dimensional space should stay close together in the low-dimensional space, but those that are far apart in the high-dimensional space may be even farther apart in low-dimensional space.
Compared to \textsc{mds}, we obtain nicer, tighter clouds (see Figure \ref{fig:drviz}), but the distance between them is less interpretable: even if we trust that tokens that are very close to each other are also similar to each other in the high-dimensional space, we cannot extract meaningful information from the distance \emph{between} these groups.

In addition, it would seem that points that are far away in a high-dimensional space might show up close together in the low-dimensional space \autocite{oskolkov_2021}.
In contrast, Uniform Manifold Approximation and Projection, or \textsc{umap} \autocite{mcinnes.etal_2020}, penalizes this sort of discrepancies. It would be an interesting avenue for further research, but a test on the current data did not reveal substantial improvements between t-\textsc{sne} and \textsc{umap} that would warrant the replacement of the technique within the duration of this project (see Figure \ref{fig:drviz} for an example with default parameters. In other models, differences include longer shapes). Other known advantages such as increased speed were not observed in the small samples under consideration --- in fact, the R implementation of \textsc{umap} \autocite{R-umap} was even slower.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/drviz-1.pdf}
\caption{\label{fig:drviz}Two \textsc{2d} representations of the same model of \emph{hachelijk} `dangerous/critical': bound5all-\textsc{ppmi}weight-\textsc{foc}all. Non-metric \textsc{mds} on the top left, t-\textsc{sne} to its right and \textsc{umap} at the bottom. Colours indicate \textsc{hdbscan} clusters.}
\end{figure}

Unlike \textsc{mds}, t-\textsc{sne} requires setting a parameter called \textbf{perplexity}, which roughly indicates how many neighbours the preserved local structure should cover. Low values of perplexity lead to numerous small groups of items, while higher values of perplexity return more uniform, round configurations \autocite{wattenberg.etal_2016}. I have explored perplexity values of 10, 20, 30 and 50, and for this dataset 30 --- the default value in the R implementation --- has proved to be the most stable and meaningful. Unless otherwise stated, the figures in this text --- including Figure \ref{fig:cloud1} --- will illustrate t-\textsc{sne} token-level representations with perplexity of 30. To represent distances between models, instead, non-metric \textsc{mds} is used (only in Section \ref{nepho1}).

For both \textsc{mds} and t-\textsc{sne} we need to state the desired number of dimensions before running the algorithm --- for visualization purposes, the most useful choice is 2. Three dimensions are difficult to interpret if projected on a \textsc{2d} space, such as a screen or paper \autocite{card.etal_1999,wielfaert.etal_2019}.
As we mentioned before, the dimensions themselves are meaningless, hence no axes or axis ticks will be included in the plots. However, the scales of both coordinates are kept fixed: given three points \(a=(1, 1.5)\), \(b=(1, 0.5)\) and \(c=(0, 1.5)\), the distance between \(a\) and \(b\) (1 unit along the \(x\)-axis) will be the same as the distance between \(a\) and \(c\) (1 unit along the \(y\)-axis).

\hypertarget{hdbscan}{%
\subsection{Clustering: HDBSCAN}\label{hdbscan}}

In word sense disambiguation tasks, the vectorial representations of different attestations are clustered into groups of similar tokens. There is a variety of clustering algorithms, appropriate for different kinds of data and structures. I will not offer an overview of the options, but only describe the techniques used in these studies. This section is dedicated to \textsc{hdbscan}, the algorithm that returns the coloured clusters in Figures \ref{fig:cloud1} and \ref{fig:drviz}. Section \ref{pam} will discuss \textsc{pam}, which will be uses to select representative models.

Hierarchical Density-Based Spatial Clustering of Applications with Noise, \textsc{hdbscan} for the friends \autocite{campello.etal_2013}, is a clustering algorithm, i.e.~a procedure to identify groups of similar items that are different from other groups. Unlike its better-known cousins, it does not try to place \emph{all} the items in the sample in different groups, but instead assumes that the dataset might be noisy and that the items may have various degrees of membership to their respective clusters. In addition, as a density-based algorithm, it tries to discriminate between dense areas, i.e.~groups of elements that are very similar to each other, from sparse areas, i.e.~larger distances between the elements.

In \textsc{hdbscan}, the density of the area in which we find a point \(a\) is estimated by calculating its
core distance \(core_{k}(a)\), which is the distance to its \(k\) nearest neighbour, \(k\) being a parameter \(minPts - 1\).
This measure is at the base of the mutual reachability distance, shown in equation \eqref{eq:mreach}, which is used to compute a new distance matrix for a single-linkage hierarchical clustering algorithm. As a result, the items are organised in a hierarchical tree, from which clusters are selected based on the \(minPts\) requirement and their densities. A related notion to \(core_k(a)\) is \(\varepsilon\), which is defined as the radius around a point in which \(minPts - 1\) can be found.

\begin{equation}
    d_{mreach}(a,b) = \max(core_{k}(a), core_{k}(b), d(a,b))
    \label{eq:mreach}
\end{equation}

In \textsc{dbscan}, we need to set both \(minPts\) and a \(\varepsilon\) threshold; the procedure is different, but its result is equivalent to cutting the hierarchical tree from \textsc{hdbscan} at a fixed \(\varepsilon\), so that the items above that threshold are discarded as noise, and those below it are grouped into their respective clusters. In contrast, its hierarchical version, \textsc{hdbscan}, implements variable thresholds to maximize the stability of the clusters, and therefore only requires us to input \(minPts\)\footnote{For a friendly description of how the algorithm works, I recommend \textcite{mcinnes.etal_2016} or even their conference presentations in YouTube.}.

In R, the algorithm can be implemented with \texttt{dbscan::hdbscan()} \autocite{R-dbscan}. Its input can be an item-by-feature matrix or, like in this case, a distance matrix. The output includes, among other things, the cluster assignment, with noise points assigned to a cluster 0, membership probability values, which are core distances normalized per cluster, and \(\varepsilon\) values, which can be used as an estimate of density.

\hypertarget{params}{%
\section{Making it your own: parameter settings}\label{params}}

Building models implies making a number of choices, from the source of the data and the unit of analysis, to the definition of what counts as context, to the techniques and parameters for visualization and clustering. Making these decisions explicit is crucial: on the one hand, they are necessary to interpret the models themselves, but on the other, they are essential for reproducibility.

For each of the 32 lemmas studied in this project, 200-212 models were created, resulting from the combination of parameter settings meant to define the first-order and second-order contexts. Other choices have been kept fixed across all models in this study, for various reasons, among which are practicality and best performance in the literature. The parameter space is virtually infinite, and exploring even more variations did would have increased the number of models exponentially and made the kind of thorough, qualitative descriptions performed here infeasible. Admittedly, some of the variable parameters could have remained fixed, and some of the fixed parameters could have been varied. Such paths remain open for future projects.
In this section, I will discuss these decisions: both the ones that have remained fixed across all the studies and the variations that characterize the multiple models under study. Fixed decisions are not specified in the names of the models; variable parameters, which distinguish models from each other, are coded in their names. When mentioned in further sections, they will be described in three parts: first-order parameters (Section \ref{foc}), \texttt{PPMI} (Section \ref{pmisel}) and second-order parameters (Section \ref{soc}). The values of the parameter settings will be set in \texttt{monospace}.

\hypertarget{corpus}{%
\subsection{Fixed decisions}\label{corpus}}

First, the analyses presented in this dissertation were performed on a corpus of Dutch and Flemish newspapers: the mode is written and the genre, journalistic. Called the \emph{QLVLNewsCorpus} \autocite[30]{depascale_2019}, it combines parts of the Twente Nieuws Corpus of Netherlandic Dutch \autocite{ordelman.etal_2007} and the yet unpublished Leuven Nieuws Corpus. It comprises articles published between 1999 and 2004, belonging to popular and quality sources for both regions in equal proportion\footnote{The newspapers include \emph{Het Laatste Nieuws}, \emph{Het Nieuwsblad}, \emph{De Standaard} and \emph{De Morgen} as Flemish sources and \emph{Algemeen Dagblad}, \emph{Het Parool}, \emph{NRC Handelsblad} and \emph{De Volkskrant} as Netherlandic sources.} and amounting to a total of 520 million tokens, including punctuation. The corpus was lemmatized and tagged with part-of-speech and dependency relations with Alpino \autocite{vannoord_2006}.

Second, the unit of analysis, the \textbf{lemma}, was defined as a combination of stem and part-of-speech\footnote{The corpus was not lemmatized by stemmed.}. This applies to items at all levels: the definition of a target, the first-order context features and the second-order features; co-occurrence frequencies and association strength measures are always computed with the lemma as unit. Both distributional models and some traditions in collocation research may use word forms instead\footnote{See \textcite[155]{turney.pantel_2010} and \textcite[47-48]{sahlgren_2008} for a discussion and \textcite[25]{kiela.clark_2014} for performance comparisons.}. On the one hand, stemming and tagging add a layer of processing and interpretation to the text; on the other, word forms of the same lemma tend to behave in different ways. From a lexicographic and lexicological perspective, however, it makes sense to use a lemma as a unit. It is the head of dictionary entries and a more typical unit of linguistic analysis. Furthermore, the (mis)match between word forms and lemmas strongly depends on the language under study: in languages like Spanish, French, Japanese and Dutch, verbs can take many more different forms than in English; conversely, Mandarin lacks morphological variation or even spaces between what could count as words. Concretely, the word form \emph{hoop} in Dutch can correspond to the noun meaning either `hope' or `heap', or the verb meaning `to hope', which can also take other forms such as \emph{hopen}, \emph{hoopt}, \emph{hoopte} and \emph{gehoopt} depending on person, number and tense. Our interest, from a lexicological perspective, lies more in line with studying the behaviour of the noun \emph{hoop} and its meanings, than in conflating the noun with one of verbal forms of the homographic verb.

In that respect, a practical note is in order. The target items under study will be represented with dictionary forms in italics, followed by their approximate English translations in single quotation marks: e.g.~\emph{hoop} `hope/heap', \emph{heilzaam} `healthy/beneficial', \emph{herstructureren} `to restructure'. Context words might be represented in figures with the stem and part-of-speech combination used by the lemmas, e.g.~\emph{word/verb}, but when mentioned in text the part-of-speech will be excluded, e.g.~the passive auxiliary \emph{word}. The English translations will belong to the same part-of-speech as the Dutch term in italics and be as unambiguous as possible. When the Dutch term and its English translations are written in the same way, no translation will be included, e.g.~\emph{journalist}.

Third, the context words at both first-order and second-order can, in principle, have any part of speech --- except for punctuation --- and must have a minimum relative frequency of 1 in 2 million (absolute frequency of 227) after discarding punctuation from the token count in the full \emph{QLVLNewscorpus}. There are 60533 such lemmas in the corpus.

Finally, as described in Section \ref{pmi}, attraction between types were measured with \textsc{ppmi}, computed on the full co-occurrence matrix, i.e.~across the full corpus, based on a symmetric window of 4 tokens to either side, including punctuation; see \textcite{turney.pantel_2010} and \textcite{kiela.clark_2014} for alternatives. Token-level vectors are made by adding the type-level vectors of its context words.\footnote{Alternatively, they could be multiplied or averaged, but the results were not all that different.}
For vector comparison, cosine distances were used and then transformed, as explained in Section \ref{cosine}. The transformed cosine distances were used both as input for visualization techniques and the clustering algorithm. Both non-metric \textsc{mds} and t-\textsc{sne} with perplexity values of 10, 20, 30 and 50 were explored, but the analyses discussed in the second part of the dissertation are based on the output from solutions with perplexity 30. Clustering was performed with \textsc{hdbscan} setting \(minPts = 8\).

\hypertarget{foc}{%
\subsection{First-order selection parameters}\label{foc}}

The immediate context of a token is the \textbf{first order context}: therefore, first-order parameters are those that influence which elements in the immediate environment of the token will be included in modelling said token. This was performed in two stages: one dependent on whether syntactic information was used, discussed in this section, and one independent of it, shown in Section \ref{pmisel}.

The decisions were based on a mix of literature \autocite[e.g.][]{kiela.clark_2014}, tradition within the Nephological Semantics project, linguistic intuition and generalisations over the annotation of the concordance lines. As we will see in Chapter \ref{dataset}, the manual annotation procedure included selecting words in the context of each token that were the most helpful for the disambiguation. The window spans and dependency information of these chosen context words were used to inform some of the decisions below.

In a first stage, the main distinction is made between models based on bag-of-words (\texttt{BOW}), i.e.~that do not care about word order or syntactic relationship, and those based on dependency (i.e.~syntactic) information. Within the former group, models may vary based on whether sentence boundaries were respected, the length of the window size, and part-of-speech filters. The latter group includes models that select context words based on the distance between them and their target in terms of syntactic relationships (\texttt{(LEMMA)PATH} models), and models that find the context word that match specific, predefined templates (\texttt{(LEMMA)REL}). Each of these parameters will be described in more detail below.

The first split in \texttt{BOW} models distinguishes between those that include words outside the sentence of the target (\texttt{nobound}) and those that do not (\texttt{bound}). The goal was to make the models more comparable to dependency-based models, which by definition only include words in the same sentence as the target. However, models that only differ with respect to this parameter tend to be extremely similar.
More relevant is the window size: models can select context words on a symmetric window of 3, 5, or 10 tokens to either side of the target, including punctuation. Window sizes are typically larger for token-level models than for type-level models \autocites[e.g.][]{schutze_1998,depascale_2019}, but, at the same time, the great majority of the context words selected in the annotation were within the span of 3 words to either side. In practice, such a small span tends to be too restrictive.
Finally, some models refine their first-order selection with part-of-speech filters: \texttt{lex} models only include common nouns, adjectives, verbs and adverbs, while \texttt{all} models do not implement any restrictions. The selection defined for \texttt{lex} was the result of some trial and errors, but could use more refinement for future studies, e.g.~expanding the lexical set to proper names, pronouns or only certain prepositions. Moreover, it could be useful to distinguish between modal verbs and auxiliaries, on one side, and other kinds of verbs, information that is not coded in the part-of-speech tags used in this corpus. In practice, \texttt{all} models tend to behave similarly to dependency-based models, while \texttt{lex} tends to be redundant with \textsc{ppmi}-based selection, which will be described later.
Bag-of-words models will be indicated by a sequence of three values pointing to these three parameters: e.g.~\texttt{bound5all} indicates a model that respects boundaries, with a window span of 5 words to each side and no part-of-speech filter.

The distinction between \texttt{BOW} and dependency-based models doesn't depend so much on which context words are selected but on how tailored the selection is to the specific
tokens. For example, a closed-class element like a preposition may be distinctive of particular usage patterns in which a term might occur. However, such a frequent, multifunctional word could easily occur in the immediate raw context of the target without actually being related to it. Unfortunately, just narrowing the window span doesn't solve the problem, since it would also drastically reduce the number of context words available for the token and for any other token in the model.
In contrast, we might also be interested in context words that are tightly linked to the target in syntactic terms but separated by many other words in between, but widening the window to include them would imply too much noise for this token and for any other token in the model.
A dependency-based model, instead, will only include context words in a certain syntactic relationship to the target, regardless of the number of words in between from a \texttt{BOW} perspective.
To exemplify, let's look at (4), where \emph{herhalen} `to repeat', in bold, is the target, and the items in italics where captured by a \texttt{PATH} model.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{3}
\item
  \emph{Als} \emph{de} \emph{geschiedenis} \emph{zich} \emph{werkelijk} \emph{mocht} \textbf{herhalen}, zijn Vitales dagen \emph{geteld}. (\emph{De Morgen}, 2004-08-02, Art. 98)

  `\emph{If} {[}\emph{the}{]} \emph{history} \emph{really} \textbf{repeated} \emph{itself}, Vitales' days are \emph{counted}.'
\end{enumerate}

The \texttt{PATH} models count the steps between a target and all the words syntactically related to it and base the selection according to that distance. A one-step dependency path is either the head of the target or its direct dependent (the parent or the child, in kinship terms): in the case of (4) this includes the reflexive pronoun \emph{zich} and the modifying adverb \emph{werkelijk} `really', which depend directly on it \emph{herhalen} `to repeat', as well as the modal \emph{mocht}, on which the target depends.
A two-step dependency path is either the head of the head of the target (grandparent), the dependent of its dependent (grandchild), or its sibling. In (4) this includes the subject \emph{geschiedenis} `history', because it is linked to the target through the modal, and \emph{Als} `if'. All \texttt{PATH} models include the features in a one-step or two-step path from the target.
A three-step dependency path is either the head of the head of the head of the target (great-grandparent), the sibling of the head of its head (great-aunt), the dependent of the dependent of its dependent (great-grandchild), or the dependent of a sibling (niece). In (4) this corresponds to \emph{de} `the', which depends on \emph{geschiedenis} `history', and \emph{geteld} `counted', which \emph{als} `if' depends on. \texttt{PATHselection2} models do not include the three-steps path, and none of the \texttt{PATH} models include context words beyond these steps. The threshold was set based on the most frequent syntactic distance between the lemmas from the case studies and the context words selected as relevant for disambiguation. Next to \texttt{selection2}, \texttt{PATH} models take two more formats. While \texttt{selection3} models include context words up to 3 steps away from the target, \texttt{PATHweight} models also incorporate the distance information and give more weight to context words that are more directly closely to the target in the syntactic path.

Finally, \texttt{REL} models base their selection on specific, predefined patterns. For these purpose, templates tailored to the parts of speech of the target were designed, based on the relationships between the annotated types and the context words selected as most informative during the annotation process. The most restrictive model, \texttt{RELgroup1}, selects the following patterns:

\begin{itemize}
\tightlist
\item
  For nouns: modifiers and determiners of the target; items of which the target is modifier or determiner, and verbs of which the target is object or subject.
\item
  For adjectives: nouns modified by the target and direct modifiers of it (except for prepositions); subject and direct objects of the verbs of which the target is direct modifier or predicate complement, with up to one modal or auxiliary in between.
\item
  For verbs: direct objects; active and passive subjects (with up to two modals for the active one); reflexive complement, and prepositions depending directly on the target.
\end{itemize}

It is typically too restrictive: for many lemmas, it is responsible for the loss of a large proportion of tokens which do not have context words that match these patterns, while the remaining tokens often have only one or two context words left. The \texttt{RELgroup2} models expand the selection as follows:

\begin{itemize}
\tightlist
\item
  For nouns: conjuncts of the target (with or without conjunction); objects of the modifier of the target, and items on which the target depends via a modifier.
\item
  For adjectives: object of the preposition modifying the target; conjunct of the target (with or without conjunction); prepositional object of verb modified by target (as modifier or prepositional complement).
\item
  For verbs: conjuncts of the target; complementizers; nouns depending through a preposition; verbal complements, and elements of which the target is a verbal complement.
\end{itemize}

Finally, nouns also have a \texttt{RELgroup3} setting that incorporates the following relations:

\begin{itemize}
\tightlist
\item
  Objects and modifiers of items of which the target is subject or modifier; subjects and modifiers of items of which the target is object or modifier; modifiers of the modifiers of the target, and items of whose modifier the target is modifier.
\end{itemize}

All the first-order parameters procure filters to select the context words in the environment of each token that will be used to model it. Alternatively, dependency information could have been included as a feature or dimension. For example, instead of selecting \emph{zich} `itself' as context word of the token in (4) based on its bag-of-word distance, part-of-speech filter or dependency relation to the target, we could use \texttt{(zich,\ se)} i.e.~``has \emph{zich} as reflexive subject'' as a first-order feature. Its type-level vector then would have information on all the other verbs that take \emph{geschiedenis} `history' as its subject. For technical and practical reasons, this was not implemented in the studies discussed here, but would be a fruitful path for further research.

In the remainder of this dissertation, \texttt{BOW} will be used to refer to all bag-of-words based models, as opposed to the dependency-based models; \texttt{PATH} and \texttt{REL} will also be umbrella terms for the models that use the different kinds of dependency-based selection, and more specific terms, e.g.~\texttt{PATHweight} will be used for finer grained distinctions.

\hypertarget{pmisel}{%
\subsection{PPMI selection and weighting}\label{pmisel}}

The \texttt{PPMI} parameter\footnote{I use verbatim to refer to this parameter for two reasons. First, because, like \texttt{PATH}, it is also a value: the parameter itself is the association-strength-based filtering or weighting, but it was fixed to \textsc{ppmi}. Second, this way it is easier to distinguish the parameter setting from \textsc{ppmi} as a measure. It is not the best idea, but so it is coded into the current names of the models.} is taken outside the set of first-order parameters because it applies to both \texttt{BOW} and dependency-based models, although it also affects the selection of first order context words. The rationale behind it is that words in the vicinity of the target token, regardless of their part-of-speech and distance, are not equally informative of the meaning of the target. For example, in (4) \emph{geschiedenis} `history' and \emph{zich} `itself' are more informative of the meaning of \emph{herhalen} `to repeat' than \emph{werkelijk} `really' or \emph{als} `if'. Association strength measures like \textsc{ppmi} could then be used to give more influence to the more informative context words; indeed, given a symmetric windowsize of 4 for the \textsc{ppmi} computation in the \emph{QLVLNewsCorpus}, the \textsc{ppmi} of \emph{geschiedenis} `history' and \emph{zich} `itself' with \emph{herhalen} `to repeat' are 3.79 and 1.97 respectively, while the values for \emph{werkelijk} `really' and \emph{als} `if' are 0.06 and 0.112.
\textcite{heylen.etal_2015} weight the contribution of each context word by their \textsc{ppmi} with the target, and \textcite{depascale_2019} adds \textsc{ppmi} and \textsc{llr} (log-likelihood ratio) thresholds to the selection of context words. However, these measures are meant to represent the relationship \emph{between} types, not to distinguish between senses of the same type: a context word may be indicative of a sense of a word and yet not be particularly attracted to the word as a whole. An example is the English verb \emph{to go}, which due to its high frequency does not have a strong attraction to the noun \emph{church}, and yet is necessary to distinguish the specific sense of `religious service' in \emph{to go to church}.

For that reason, models can take three different settings in relation to the \texttt{PPMI} parameter: \texttt{weight}, \texttt{selection} and \texttt{no}. Both \texttt{weight} and \texttt{selection} apply an additional filter to the output from the first-order parameters and only select the context words with a positive \textsc{pmi} with the target. They are distinct from the \texttt{PPMIno} models, which do not apply such thresholds. The difference between the first two is that \texttt{weight} also multiplies the type-level vector of each context word by their \textsc{pmi} with the target, giving words that are more strongly associated to the target type a greater impact in the final vector of the target. The three settings are applied to each of the models resulting from the first-order combinations, with one exception: \texttt{PATHweight} models do not combine with \texttt{PPMIweight}.

\hypertarget{soc}{%
\subsection{Second-order selection}\label{soc}}

The selection of second-order features influences the shape of the vectors: how the selected first-order features are represented. Next to the fixed window size and association measure used to calculate the values of the vectors, there are two variable parameters. First, a part-of-speech filter may be applied. When its value is \texttt{nav}, second-order features are extracted from a pool of 13771 nouns, adjectives and verbs used in \textcite{depascale_2019}\footnote{The selection was originally made to ensure an unbiased regional distribution of the vectors for the lectometric studies performed in \textcite{depascale_2019}.}. The alternative, \texttt{all}, applies no further filters. Second, we might reduce the length of the vector, i.e.~the number of second-order features. One of the values, \texttt{5000}, selects the 5000 most frequent features from the pool remaining after the part-of-speech filter. Pilot studies have also explored models with 10000 dimensions, but they are very similar to the ones with 5000 dimensions.\footnote{\textcite{kiela.clark_2014} discourage using vectors with more than 50,000 dimensions.} The other value for the vector length is \texttt{FOC}, which stands for ``first-order context'', and it uses the union of first-order context words for all tokens as second-order dimensions. As a consequence, the second-order dimensions are tailored to the context of the sample, not necessarily so frequent, and their numbers remain in the hundreds, rarely surpassing 1500. In practice, there is not much of a difference between models with different second-order parameters, except for \texttt{5000all} models, which tend to perform the worst. Examination of the distance matrices between the type-level vectors of the context words reveals that the cosine distances between all of them are really large, probably due to the sparseness of the vectors. I that sense, it would be interesting to compare \textsc{svd} matrices based on the \texttt{5000} models with the already smaller (and presumably denser) \texttt{FOC} models.

\hypertarget{pam}{%
\section{The chosen ones: PAM}\label{pam}}

The multiple variable parameters return a large number of models: 212 for each of the nouns --- because of the additional \texttt{REL} templates --- and 200 for verbs and adjectives. As we will see in Chapter \ref{nephovis}, we can combine distances between the models with dimensionality reduction techniques to represent the similarities between the models on a \textsc{2d} space. In addition, if we only wanted to evaluate the models in relation to the manual annotation, we could rank the accuracy of their clustering solutions. However, if we want to understand the qualitative effect of the parameter settings on the modelling, and especially if we do not consider the manual annotation as a ground truth, we need to examine clouds individually, and it is not feasible for a human to look at each of the hundreds of models of each lemma.

One approach for an efficient exploration of the parameter space is to identify the settings that make the greater differences between models. For example, if we see that models with different \texttt{PPMI} settings are more different from each other than models with different vector-length settings, we would prioritize looking at models that differ on the former parameter, setting the latter to a constant value. Unfortunately, the quantitative effect of parameters is not so straightforward. First, the parameters that tend to make a big difference in the modelling include the choice between dependency and \texttt{BOW} and, within it, both window size and part-of-speech filters, as well as the distinction between \texttt{REL} and \texttt{PATH}. The resulting combinations are still too numerous to examine simultaneously (see Chapter \ref{nephovis}). Second, the relevant parameters interact with each other: \texttt{PPMI} often makes little difference among \texttt{lex} models --- it tends to be redundant, since the open-class items captured by \texttt{lex} tend to have higher \textsc{ppmi} --- but it makes a greater difference among \texttt{all} or dependency-based models. Finally, the various parameter settings do not have the same impact within each lemma, so they have to be revised for each of the lemmas under study.

The approach based on the quantitative effect of parameter settings on the distances between models does reduce the number of models to examine, but not to a great degree. Given the limited number of models that we can look at simultaneously while still making sense of them --- around 8 or 9 --- and the need to cover multiple combinations of these strong parameters, we would still need to look at four or five partially overlapping sets of 8-9 models per lemma. For example, a set of 9 models could be generated by taking \texttt{bound3} and \texttt{bound10} models with \texttt{PPMIweight} and \texttt{FOCnav} second-order vectors, in order to look at the effect of part-of-speech filter with little window-size variation, \texttt{PATH} and \texttt{REL}. Then, \texttt{PPMIweight} could be switched for \texttt{PPMIno} to look at the effect in the new conditions, resulting in 9 other models. If the effect is indeed different, which is likely, a different set of 8-9 models could then be generated with different values of \texttt{PPMI}, while keeping the part-of-speech to a constant value. These groups are not maximally different from each other: due to the interaction between parameters, many models are extremely similar, and a proper qualitative description becomes challenging. Moreover, a given set of models could reveal a pattern that was not captured in a previous set of models, and the researcher might want to go back and look for it.

An alternative approach is to use a clustering algorithm that, next to selecting groups of similar models, identifies the models that represent each of the clusters. \textbf{Partition Around Medoids}, or \textsc{pam} \autocite{kaufman.rousseeuw_1990}, implemented in R with \texttt{cluster::pam()} \autocite{R-cluster}, does exactly that. Unlike \textsc{hdbscan} and other clustering algorithms, it requires us to set a number of clusters beforehand, and then tries to find the organization that maximizes internal similarity within the cluster and distances with other clusters.
For our purpose, we have settled for 8 medoids for each lemma. The number is not meant to achieve the best clustering solutions --- no number could be applied to all the lemmas with equal success, given their variability in the differences between the models. The goal, instead, is to have a set of models that is small enough to visualize simultaneously (on a screen, in reasonable size) and big enough to cover the variation across models. For some lemmas, there might not be that much variation, and the \textbf{medoids}, i.e.~the representative models, might be redundant with each other. However, as long as we can cover (most of) the visible variation across models and the medoids are reasonably good representatives of the models in their corresponding clusters, the method is fulfilling its goal.

The representativeness of medoids for the lemmas studied here has been tested in different ways.
We don't require the clusters of models to be different from each other, as long as the medoids represent them properly. Instead, the priority was to check for patterns within the models represented by each medoid, e.g.~in terms of accuracy towards annotated senses. For example, if a medoid tends to group senses together very well (measured for example with \texttt{kNN} and \texttt{SIL}, as explained in Chapter \ref{shapes} applied to clustering solutions), the models it represents have similar tendencies as well.
More importantly, different patterns previously identified in the plots while exploring the models with the first approach were looked for in the medoid selection, to corroborate that the medoids covered at least as much variation as the more time- and energy-consuming approach. All such patterns were found. In addition, small random samples within each cluster of models were visually scanned --- but not thoroughly examined --- to assess their similarity to their representative medoid. In the great majority of the cases the comparison was satisfactory. This has a wonderful effect on the visual exploration, because it lets us focus on 8-9 models that are quite different from each other instead of multiple sets of models with less variation. Visually, the medoids approach is more informative and less tiresome.

As a result from these explorations, the qualitative analyses will be based on medoids: representative models selected by \textsc{pam}. While this is a clustering algorithm, in order to avoid confusion with clusters of tokens, which take centre stage, I will avoid referring to the clusters of models as such --- or, if I do, I will specify that they are clusters \emph{of models}. The preferred name will be ``the models represented by the medoid''. Given that the only clustering algorithm used on the tokens is \textsc{hdbscan}, \emph{medoid} will always refer to a representative model.

\hypertarget{workflow-summary}{%
\section{Summary}\label{workflow-summary}}

The process through which token-level vector space models and the clouds studied here in particular are created, takes a number of transformative steps. In this chapter we have broken down this process and detailed the layers of mathematical and linguistic processing lying between the raw corpus and the final clouds. Next to an overall description of the workflow, the technical background of the most important aspects was introduced in some detail. Afterwards, I explained the parameter settings that characterize the models analyzed in this project.
Choices have been made and alternatives have been suggested: the path taken here was one out of so many possible alternatives. In fact, at the core of this research project is the exploration of alternatives, the investigation of the effect of the variable parameters on the final linguistic representation, and the search for clues, guidelines, a recipe for the clouds we seek. This exploration combines quantitative techniques --- the heart of the process of cloud creation --- with qualitative analyses meant to describe what and how the clouds are really modelling.

By combining the vector representations with visualization techniques and/or clustering algorithms, we can make sense of patterns that would otherwise escape us. Visual analytics provides us with tools to explore the output in comfortable, intuitive --- but sometimes deceiving --- ways. In the next chapter, we will look at the two visualization tools developed within the larger project of Nephological Semantics to enable and support these qualitative analyses.

\hypertarget{nephovis}{%
\chapter{Visualization tools}\label{nephovis}}

Clouds are the prime matter of these study. They are condensed, information-rich representations of patterns found in a corpus and should, according to the Distributional Hypothesis, tell us something about the meaning of the words under examination. But they don't tell us anything by themselves: we need to develop and implement tools to extract this information. Chief among these tools is a web-based visualization tool \autocite{montes.qlvl_2021a}, originally developed by Thomas Wielfaert within the Nephological Semantics project \autocite[see][]{wielfaert.etal_2019}, and then continued by myself\footnote{The GitHub repository is linked to Zenodo, so that the released versions can be stored and identified with a \textsc{doi}. Unfortunately, even though the foundations of the code were set by Thomas Wielfaert, because of how the current repository came to be, he has no history as contributor and therefore is not assigned as author in the tool's citation.}. In this chapter we will present its rationale and the features it offers, as an elaboration of \textcite{montes.heylen_Submitted}.

Section \ref{nepho-overview} will offer an overview of the rationale behind the tool and the minimal path that a researcher could take through its levels. Sections \ref{nepho1} through \ref{nepho3} will zoom in on each of the levels, describing the current features and those that are still waiting on our wish list. Section \ref{shiny} follows with the description of a ShinyApp \autocite{R-shiny}: an extension\footnote{Currently available at \url{https://marianamontes.shinyapps.io/Level3/}} to the third level of the visualization with additional features tailored to exploring the relationship between the \textsc{2d} representations and the \textsc{hdbscan} output. Finally, we conclude with a summary in Section \ref{nepho-summary}.

\hypertarget{nepho-overview}{%
\section{Flying through the clouds}\label{nepho-overview}}

The visualization tool described here, which I will call \emph{NephoVis}, was written in Javascript, making heavy use of the \href{https://d3.js}{\textsc{d3}.js} library, which was designed for beautiful web-based data-driven visualization \autocite{bostock.etal_2011}. The \textsc{d3} library allows the designer to link elements on the page, such as circles in an \textsc{svg}, dropdown buttons and titles, to data structures such as arrays and data frames, and manipulate the visual elements based on the values of the linked data items. In addition, it offers handy functions for scaling and mapping, i.e.~to fit the relatively arbitrary ranges of the coordinates to pixels on a screen, or to map a colour palette\footnote{While \textsc{d3} offers a variety of useful colour palettes, the visualization currently relies on a --- slightly adapted --- colorblind-friendly scale by \textcite{okabe.ito_2002}. The default colour palette for most of the figures in this disseration make use of the same palette, via the R package \texttt{colorblindr} \autocite{R-colorblindr}.} to a set of categorical values.

As we have seen in Chapter \ref{workflow}, the final output of the modelling procedure is a \textsc{2d} representation of distances between tokens, which can be visualized as a scatterplot. Crucially, we are not only interested in exploring individual models, but in comparing a range of models generated by variable parameters. Section \ref{cosine} discussed a procedure to measure the distance between models, which can be provided as input for non-metric \textsc{mds}, and Section \ref{pam} presented the technique used to select representative models, or medoids. As a result, we have access to the following datasets for each of the lemmas:

\begin{itemize}
\tightlist
\item
  A distance matrix between models.
\item
  A data frame with one row per model, the \textsc{nmds} coordinates based on the distance matrix, and columns coding the different variable parameters or other pieces of useful information, such as the number of modelled tokens.
\item
  A data frame with one row per token, \textsc{2d} coordinates for each of their models and other information such as sense annotation (see Chapter \ref{dataset}), country, type of newspaper, selection of context words and concordance line.
\item
  A data frame with one row per first-order context word and useful frequency information.
\end{itemize}

In practice, the data frame for the tokens is split in multiple data frames with coordinates corresponding to different dimensionality reduction algorithms, such as \textsc{nmds} and t-\textsc{sne} with different perplexity values, and another data frame for the rest of the information. In addition, one of the most recent features of the visualization tool includes the possibility to compare an individual token-level model with the representation of the type-level modelling of its first-order context words. However, this feature is still under development within NephoVis and can be better explored in the ShinyApp extension (Section \ref{shiny}).

In order to facilitate the exploration of all this information, NephoVis is organized in three levels, following Shneiderman's Visual Information Seeking Mantra: ``Overview first, zoom and filter, then details-on-demand'' \autocite*[97]{shneiderman_1996}. The core of the tool is the interactive, zoomable scatterplot, but its goal and functionality is adapted to each of the three levels.
In Level 1 the scatterplot represents the full set of models and allows the user to explore the quantitative effect of different parameter settings and to select a small number of models for detailed exploration in Level 2.
This second level shows multiple token-level scatterplots --- one for each of the selected models ---, and therefore offers the possibility to compare the shape and organization of the groups of tokens across different models. By selecting one of these models, the user can examine it in Level 3, which focuses on only one at a time. \textcite{shneiderman_1996}'s mantra underlies both the flow across levels and the features within them: each level is a zoomed in, filtered version of the level before it; the individual plots in Levels 1 and 3 are literally zoomable; and in all cases it is possible to select items for more detailed inspection. Finally, a number of features --- tooltips and pop-up tables --- show details on demand, such as the names of the models in Level 1 and the context of the tokens in the other two levels.



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/nephovis-index} \caption{Portal of \url{https://qlvl.github.io/NephoVis/} as of July 2021.}\label{fig:nepho-index}
\end{figure}

Currently, \url{https://qlvl.github.io/NephoVis/} hosts the portal shown in Figure \ref{fig:nepho-index}, which eventually leads the user to the Level 1 page for the lemma of their choice\footnote{By knowing the lemma, it is possible to go directly to the Level 1 page by replacing \emph{lemma} in \url{https://qlvl.github.io/NephoVis/level1.html?type=lemma} with the corresponding name of the lemma, e.g.~\emph{heffen}.}, shown in Figure \ref{fig:nepho1-basic} and described in more detail in Section \ref{nepho1}. By exploring the scatterplot of models, the user can look for structure in the distribution of the parameters on the plot.
For example, colour coding may reveal that models with nouns, adjectives, verbs and adverbs as first-order context words (\texttt{lex}) are very different from those without strong filters for part-of-speech, because mapping these values to colours reveals distinct groups in the plot. In contrast, mapping the sentence boundaries restriction (\texttt{bound}/\texttt{nobound}) might result in a mix of dots of different colours, like a fallen bag of \textsc{m\&m}'s, meaning that the parameter makes little difference. Depending on whether the user wants to compare models similar or different to each other, or which parameters they would like to keep fixed, they will use individual selection or the buttons to choose models for Level 2. The
\includegraphics[width=1em,height=1em]{phdThesis_files/figure-latex/fa-icon-45b638a3f7629f31e60a18a580b73d9d.pdf} \textbf{Select medoids}
button\footnote{Incorporating this feature is less scalable than the dropdown menus or even the checkbox buttons; it works with the current pipeline, but is not so straightforward to adapt to new data that does not follow the exact same pipeline. Flexibilizing the features to allow for missing data frames is one of the items on the wish list. Ideally, future versions will implement algorithms such as \textsc{pam} to compute on the fly as well.} quickly identifies the predefined medoids. By clicking on the
\includegraphics[width=1em,height=1em]{phdThesis_files/figure-latex/fa-icon-5d063465e6f3ff6e9e5f608a6b87eb54.pdf} \textbf{LEVEL 2} button,
Level 2 is opened in a new tab, as shown in Figure \ref{fig:nepho2-basic}.

In Level 2, the user can already compare the shapes that the models take in their respective plots, the distribution of categories like sense labels, and the number of lost tokens. If multiple dimensionality reduction techniques have been used, the
\includegraphics[width=1em,height=1em]{phdThesis_files/figure-latex/fa-icon-cf0c694b2974f5e67740d5be3ec29cfb.pdf} \textbf{Switch solution} button allows the user to select one and watch the models readjust to the new coordinates in a short animation. In addition, the
\includegraphics[width=0.88em,height=1em]{phdThesis_files/figure-latex/fa-icon-b13d96907a20b3a2ff6b54307520ea5a.pdf} \textbf{Distance matrix} button offers a heatmap of the pairwise distances between the selected models.
Section \ref{nepho2} will explore the most relevant features that aid the comparison across models, such as brushing sections of a model to find the same tokens in different models and accessing a table with frequency information of the context words co-occurring with the selected tokens. Either by clicking on the name of a model or through the
\includegraphics[width=1em,height=1em]{phdThesis_files/figure-latex/fa-icon-5d063465e6f3ff6e9e5f608a6b87eb54.pdf} \textbf{Go to model} dropdown menu, the user can access Level 3 and explore the scatterplot of an individual model. As Section \ref{nepho3} will show, Level 2 and Level 3, both built around token-level scatterplots, share a large number of functionalities. The difference lies in the possibility of examining features particular of a model, such as reading annotated concordance lines highlighting the information captured by the model or selecting tokens based on the words that co-occur with it. In practice, the user would switch back and forth between Level 2 and Level 3: between comparing a number of models and digging into particular models.



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/nephovis-level1-base} \caption{\href{https://qlvl.github.io/NephoVis/level1.html?type=heffen}{Level 1 for \emph{heffen} `to levy/to lift'}.}\label{fig:nepho1-basic}
\end{figure}



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/nephovis-level2-base} \caption{Level 2 for the medoids of \emph{heffen} `to levy/to lift'.}\label{fig:nepho2-basic}
\end{figure}

Before going into the detailed description of each level, a note is in order. As already mentioned in Section \ref{dim-reduction}, the dimensions resulting from \textsc{nmds} --- used in all levels --- and t-\textsc{sne} --- used in levels 2 and 3 --- are not meaningful. In consequence, there are no axes or axis ticks in the plots. However, the units are kept constant within each plot: one unit on the \(x\)-axis has the same length in pixels as one unit on a \(y\)-axis within the same scatterplot; this equality, however, is not valid across plots. Finally, the code is open-source and available at \url{https://github.com/qlvl/NephoVis}.

\hypertarget{nepho1}{%
\section{Level 1}\label{nepho1}}

The protagonist of Level 1 is an interactive zoomable scatterplot where each glyph, by default a steel blue wye (``Y''), represents one model. This scatterplot aims to represent the similarity between models as coded by the \textsc{nmds} output and allows the user to select the models to inspect according to different criteria. Categorical variables (e.g.~whether sentence boundaries are used) can be mapped to colours and shapes, as shown in Figure \ref{fig:nepho1-colours}, and numerical variables (e.g.~number of tokens in the model) can be mapped to size.



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/nephovis-level1-colours} \caption{\href{https://qlvl.github.io/NephoVis/level1.html?type=heffen}{Level 1 for \emph{heffen} `to levy/to lift'}; the plot is colour-coded with first-order part-of-speech settings; \texttt{NA} stands for the dependency-based models.}\label{fig:nepho1-colours}
\end{figure}

A selection of buttons on the left panel, as well as the legends for colour and shape, can be used to filter models with a certain parameter setting. These options are generated automatically by reading the columns in the data frame of models and interpreting column names starting with \texttt{foc\_} as representing first-order parameter settings, and those starting with \texttt{soc\_} as second-order parameter settings. Different settings of the same parameter interact with an \texttt{OR} relationship, since they are mutually exclusive, while settings of different parameters combine in an \texttt{AND} relationship. For example, by clicking on the grey \texttt{bound} and \texttt{lex} buttons on the bottom left, only \texttt{BOW} models with part-of-speech filter and sentence boundary limits\footnote{Notice that \texttt{bound} itself, while a \texttt{BOW} parameter value, also includes the dependency-based models, since they are automatically limited to sentence boundaries.} will be selected. By clicking on both \texttt{lex} and \texttt{all}, all \texttt{BOW} models are selected, regardless of the part-of-speech filter, but dependency-based models (for which part-of-speech is not relevant) are excluded. A counter above, circled in Figure \ref{fig:nepho1-selection}, keeps track of the number of selected items, since Level 2 only allows up to 9 models for comparison\footnote{The original design, found in \url{http://tokenclouds.github.io/LeTok/}, allowed for larger selections; only 9 models would be actually shown in Level 2, but it would also be possible to remove some of them and make place to the models left on the waiting list. This makes sense when models are selected individually and in a particular order, i.e.~by clicking on them, but not so much for selections based on other criteria that we want to explore simultaneously.}. This procedure is meant to aid a selection based on relevant parameters, as described in Section \ref{pam}. In Figure \ref{fig:nepho1-selection}, instead, the \includegraphics[width=1em,height=1em]{phdThesis_files/figure-latex/fa-icon-45b638a3f7629f31e60a18a580b73d9d.pdf} \textbf{Select medoids} button was used to quickly capture the medoids obtained from \textsc{pam}.
Models can also be manually selected by clicking on the glyphs that represent them.



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/nephovis-level1-selection} \caption{\href{https://qlvl.github.io/NephoVis/level1.html?type=heffen}{Level 1 for \emph{heffen} `to levy/to lift'} with medoids highlighted.}\label{fig:nepho1-selection}
\end{figure}

\hypertarget{nepho2}{%
\section{Level 2}\label{nepho2}}

Level 2 shows an array of small scatterplots, each of which represents a token-level model. The glyphs, by default steel blue circles, stand for individual tokens, i.e.~attestations of the chosen lemma in a given sample. The original code for this level was inspired by \href{https://bl.ocks.org/mbostock/3213173}{Mike Bostock's brushable scatterplot matrix}, but it is not a scatterplot matrix itself, and its current implementation is somewhat different.

The dropdown menus on the sidebar (Figure \ref{fig:nepho2-basic}) read the columns in the data frame of variables, which can include any sort of information for each of the tokens, such as sense annotation, sources, number of context words in a model, concordance lines, etc. Categorical variables can be used for colour- and shape-coding, as shown in Figure \ref{fig:nepho2-colour}, where the senses of the chosen lemma are mapped to colours; numerical variables, such as the number of context words selected by a given lemma, can be mapped to size. Note that the mapping will be applied equally to all the selected models: the current code does not allow for variables --- other than the coordinates themselves --- to adapt to the specific model in each scatterplot. That is the purview of Level 3.

Before further examining the scatterplots, a small note should be made about the distance matrix mentioned above. The heatmap corresponding to the medoids of \emph{heffen} `to levy/to lift' is shown in Figure \ref{fig:nepho2-heatmap}.
The \textsc{nmds} representation in Level 1 tried to find patterns and keep the relative distances between the models as faithful to their original positions as possible, but such a transformation always loses information. Given a restricted selection of models, however, the actual distances can be examined and compared more easily. A heatmap maps the range of values to the intensity of the colours, making patterns of similar/different objects easier to identify. For example, Figure \ref{fig:nepho2-heatmap} shows that the sixth medoid is very different from all the other medoids except from the seventh, and that the second medoids is quite different from all the others except the first. Especially when the model selection followed a criterion based on strong parameter settings, e.g.~keeping \texttt{PPMI} constant to look at the interaction between window size and part-of-speech filters, such a heatmap could reveal patterns that are slightly distorted by the dimensionality reduction in Level 1 and even hard to pinpoint from visually comparing the scatterplots. But even with the medoid selection, which aims to find representatives that are maximally different from each other (or at least that are the core elements of maximally different \emph{groups}), the heatmap can show whether some medoids are drastically \emph{more} different, or conversely, similar to others.
As a reference, the heatmap is particularly useful to check hypotheses about the visual similarity of models. For example, unlike with \emph{heffen} `to levy/to lift' in Figure \ref{fig:nepho2-colour}, if we colour-code the medoids of \emph{haten} `to hate' with the manual annotation (Figure \ref{fig:nepho2-haten}), all the models look equally messy. As we will see below, we can brush over sections of the plot to see if, at least, the tokens that are close together in one medoid are also close together in another (spoiler alert: not the case). The heatmap of distances confirms that not all models are equally different from each other, but indeed, each of them are messy in their own particular way.



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/nephovis-level2-heatmap} \caption{Heatmap of distances between medoids of \emph{heffen} `to levy/to lift'.}\label{fig:nepho2-heatmap}
\end{figure}



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/nephovis-level2-haten} \caption{2D representation of medoids of \emph{haten} `to hate', colour-coded with senses, next to the heatmap of distances between models.}\label{fig:nepho2-haten}
\end{figure}

Next to the colour-coding, Figure \ref{fig:nepho2-colour} also illustrates how hovering over a token shows the corresponding identifier\footnote{The identifier of a token includes four main pieces of information separated by slashes. The first two, stem and part-of-speech (\emph{hef} and \emph{verb} in the example) indicate the target lemma. The third section points to the filename from which the token was extracted. The filenames from this corpus have at least three sections split by underscores: the name of the newspaper (\emph{De Volkskrant}), the date of publication in \textsc{yyyy-mm-dd} format (2001-06-21) and the number of the article, among those harvested for the corpus (36). The final part points to the index of the token in the article including punctuation: in this case, the word form \emph{hieven} (third person plural preteritum of \emph{heffen}, `(they) lifted') around which the concordance line is built is the 163rd token in its file.} and concordance line. Figure \ref{fig:nepho2-selection}, on the other hand, showcases the brush-and-link functionality. By brushing over a specific model, the tokens found in that area are highlighted and the rest are made more transparent. Such a functionality is missing from Level 1, but is also available in Level 3. Level 2 enhances the power of this feature by selecting the same tokens in the rest of the models, whatever area they occupy. Thus, we can see whether tokens that are close together in one model are still close together in a different model, which is specially handy in more uniform plots, like the one for \emph{haten} `to hate' in Figure \ref{fig:nepho2-haten}. Figure \ref{fig:nepho2-selection} reveals that the tokens selected in the second medoid are, indeed, quite well grouped in the other five medoids around it, with different degrees of compactness. It also highlights two glyphs on the right margin of the bottom right plot. In Level 2, this margin gathers all the tokens that were selected for modelling but were lost by the model in question due to lack of context words. In this case medoid 6, with a combination of \texttt{bound3lex} and \texttt{PPMIselection}, is extremely selective, and for a few tokens no context words could be captured.



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/nephovis-level2-colour-and-tooltip} \caption{Level 2 for the medoids of \emph{heffen} `to levy/to lift', colour-coded with categories from manual annotation. Hovering over a token shows its concordance line.}\label{fig:nepho2-colour}
\end{figure}



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/nephovis-level2-selection} \caption{Level 2 for the medoids of \emph{heffen}, colour coded with categories from manual annotation. Brushing over an area in a plot selects the tokens in that area and their positions in other models.}\label{fig:nepho2-selection}
\end{figure}

In any given model, we expect tokens to be close together because they share a context word, and/or because their context words are distributionally similar to each other: their type-level vectors are near neighbours. Therefore, when inspecting a model, we might want to know which context word(s) pull certain tokens together, or why tokens that we expect to be together are far apart instead. For individual models, this can be best achieved via the ShinyApp described in Section \ref{shiny}, but NephoVis also includes features to explore the effect of context words, such as frequency tables.
In Level 2, while comparing different models, the frequency table has one row per context word and one or two columns per selected model, e.g.~the medoids. Such a table is shown in Figure \ref{fig:nepho2-table}.
The columns in this table are all computed by NephoVis itself based on lists of context words per token per model. Next to the column with the name of the context word, the default table shows two columns called ``total'' and two per model, headed by the corresponding number and either a ``+'' or a ``-'' sign. The ``+'' columns indicate how many \emph{of the selected tokens} in that model co-occur with the word in the row; the ``-'' columns indicate the number of non selected tokens that co-occur with the word. The ``total'' columns indicate, respectively, the number of selected or non-selected tokens for which that context word was captured by at least one model.
Here it is crucial to understand that, when it comes to distributional modelling, a \textbf{context word} is not simply a word that can be found in the concordance line of the token, but an item captured by a given model. Therefore, a word can be a context word in a model, but be excluded by a different model with stricter filters. For example, the screenshot\footnote{The full picture is impractical to include in a printed text; it is recommended to explore the tool interactively instead.} in Figure \ref{fig:nepho2-table} gives us a glimpse of the frequency table corresponding to the tokens selected already in Figure \ref{fig:nepho2-selection}. The most frequent context word for the 31 selected tokens, i.e.~the first row of the table, is the noun \emph{glas} `glass', which is used in expressions such as \emph{een glas heffen op iemand} `to toast for someone, lit. to lift a glass on someone'. The columns for models 1 an 2 show that \emph{glas} `glass' was captured by those models for all 31 selected tokens. In column 3, however, the positive column reads 29, which indicates that the model missed the co-occurrence of \emph{glas} `glass' in two of the tokens. The names on top of the plots reveal that the first two models have a window size of 10, while the third restricts it to 5, meaning that in the two missed tokens \emph{glas} `glass' occurs 6 to 10 slots away from the target. These are most likely the orange tokens a bit far to the right of the main highlighted area in the third plot. Finally, in the fourth model, which is hidden behind the table, \emph{glas} `glass' is missed from one of the 31 tokens but captured in 2 tokens that were excluded from the selection. If we moved the window of the table we would see that this is a \texttt{PATHweight} model: the missed co-occurrence must be within the \textsc{bow} window span but too far in the dependency path, wile the two captured co-occurrences in the ``-'' column must be within three steps of the dependency path but beyond the \textsc{bow} window span of 10. This useful frequency information is available for all the context words that are captured by at least one model in any of the selected tokens. In addition, the \textbf{Select information} dropdown menu gives access to a range of transformations based on these frequencies, such as odds ratio, Fisher Exact and cue validity.



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/nephovis-level2-table} \caption{Level 2 for the medoids of \emph{heffen} `to levy/to lift', and frequency table of the the context words co-occurring with the selected tokens across models.}\label{fig:nepho2-table}
\end{figure}

The layout of Level 2, showing multiple plots at the same time and linking the tokens across models, is a fruitful source of information, but it has its limits. To exploit more model-specific information, we go to Level 3.

\hypertarget{nepho3}{%
\section{Level 3}\label{nepho3}}

Level 3 of the visualization tool shows a zoomable, interactive scatterplot in which each glyph, by default a steel blue circle, represents a token, i.e.~an attestation of the target lexical item. An optional second plot has been added to the right, in which each glyph, by default a steel blue star, represents a first-order context word, and the coordinates derive from applying the same dimensionality reduction technique on the type-level cosine distances between the context words.
The name of the model, coding the parameter settings, is indicated on the top, followed by information on the dimensionality reduction technique. Like in the other two levels, it is possible to map colours and shapes to categorical variables, e.g.~sense labels, and sizes to numerical variables, e.g.~number of available context words, and the legends are clickable, allowing the user to quickly select the items with a given value.

Figure \ref{fig:nepho3-base} shows what Level 3 looks like if we access it by clicking on the name of the second model in Figure \ref{fig:nepho2-selection}. Colour-coding and selection are transferred between the levels, so we can keep working on the same information if we wish to do so. Conversely, we could change the mappings and selections on Level 3, based on model-specific information, and then return to Level 2 (and refresh the page) to compare the result across models. For example, if the frequency table in Figure \ref{fig:nepho2-table} had shown us that \emph{glas} `glass' was also captured in tokens outside our selection, or if we had reason to believe that not all of the selected tokens co-occurred with \emph{glas} `glass' in this model, we could input \texttt{glas/noun} on the \texttt{Features\ in\ model} field in order to select all the tokens for which \emph{glas} `glass' was captured in the model, and only those. Or maybe we would like to find the tokens in which \emph{glasje} `small glass' occurs, but we are not sure how they are lemmatized, so we can input \texttt{glasje} in the \texttt{Context\ words} field to find the tokens that include this word form in the concordance line, regardless of whether its lemma was captured by the model\footnote{Admittedly, the names of the fields can be confusing and should probably be changed. Both fields work with partial regex matches, but \texttt{Features\ in\ model} look in the list of captured context words, which is a list of lemmas, while \texttt{Context\ words} performs the search on the concordance line, i.e.~word forms, regardless of whether the model captured them.}.

In sum, (groups of) tokens can be selected in different ways, either by searching words, inputting the id of the token, clicking on the glyphs or brushing over the plots.\footnote{The (beta) feature of the type-level plot on the right side also enables token selection by clicking on the co-occurring context words (and \emph{vice versa}) but this is still under development.} Given such a selection, clicking on \includegraphics[width=0.88em,height=1em]{phdThesis_files/figure-latex/fa-icon-b13d96907a20b3a2ff6b54307520ea5a.pdf} \textbf{Open frequency table} will call a pop-up table with one row per context word, a column indicating in how many of the selected tokens it occurs, and more columns with pre-computed information such as \textsc{pmi} (see Figure \ref{fig:nepho3-table}). These values can be interesting if we would like to strengthen or weaken filters for a smarter selection of context words.

Like Level 2, Level 3 also offers the concordance line of a token when hovering over it. But unlike Level 2, the concordance can be tailored to the specific model on focus, as shown in Figure \ref{fig:nepho3-base}. The visualization tool itself does not generate a tailored concordance line for each model, but finds a column on the data frame that starts with \texttt{\_ctxt} and matches the beginning of the name of the model to identify the relevant format. A similar system is used to find the appropriate list of context words captured by the model for each token. For these models, the selected context words are shown in boldface and, for \texttt{PPMIweight} models such as the one shown in Figure \ref{fig:nepho3-base}, their \textsc{ppmi} values with the target, e.g.~\emph{heffen}, are shown in superscript.



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/nephovis-level3-base} \caption{Level 3 for the second medoid of \emph{heffen} `to levy/to lift': bound10all-\textsc{ppmi}weight-\textsc{5000}all with some selected tokens. Hovering over a token shows tailored concordance line.}\label{fig:nepho3-base}
\end{figure}



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/nephovis-level3-table} \caption{Level 3 for the second medoid of \emph{heffen} `to levy/to lift': bound10all-\textsc{ppmi}weight-\textsc{5000}all. The frequency table gives additional information on the context words co-occurring with the selected tokens.}\label{fig:nepho3-table}
\end{figure}

As we have seen along this chapter, the modelling pipeline returns a wealth of information that requires a complex visualization tool to make sense of it and exploit it efficiently. The Javascript tool described up to now, NephoVis, was developed and used by the same people within the Nephological Semantics projects, but is meant to be deployed to a much broader audience that could benefit from its multiple features. It can still grow, and its \href{https://github.com/qlvl/NephoVis/}{open-source code} makes it possible for anyone to adapt it and develop it further. Nevertheless, for practicality reasons, an extension was developed in a different language: R. The dashboard described in the next section elaborates on some ideas originally thought for NephoVis and particularly tailored to explore the relationship between the t-\textsc{sne} solutions and the \textsc{hdbscan} clusters on individual medoids.

\hypertarget{shiny}{%
\section{ShinyApp}\label{shiny}}

The visualization tool discussed in this section was written in R with the \texttt{shiny} library \autocite{R-shiny}, which provides R functions that return \textsc{html}, \textsc{css} and Javascript for interactive web-based interfaces. The interactive plots have been rendered with \texttt{plotly} \autocite{R-plotly}. Unlike NephoVis, this tool requires an R server to run, so it is hosted on \texttt{shinyapps.io} instead of a static Github Page\footnote{This code is also freely available at \url{https://github.com/montesmariana/Level3}.}. It takes the form of a dashboard, shown in Figure \ref{fig:shiny-basic}, with a few tabs, multiple boxes and dropdown menus to explore different lemmas and their medoids. All the functionalities are described in the About page of the dashboard, so here only the most relevant features will be described and illustrated.

The sidebar of the dashboard offers a range of controls. Next to the choice between viewing the dashboard and reading the documentation, two dropdown menus offer the available lemmas and their medoids, by number. By selecting one, the full dashboard adapts to return the appropriate information, including the name of the model on the orange header on top. The bottom half of the sidebar gives us control over the definition of relevant context words in terms of minimum frequency, recall and precision, which will be explained below.



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/shinyapp-basic} \caption{Starting view of the \href{https://marianamontes.shinyapps.io/Level3/}{ShinyApp dashboard}, extension of Level 3.}\label{fig:shiny-basic}
\end{figure}

The main tab, \textbf{t-SNE}, contains four collapsable boxes: the blue ones focus on tokens while the green ones, on first-order context words. The top boxes (Figure \ref{fig:shiny-tooltips}) show t-\textsc{sne} representations (perplexity 30) of tokens and their context words respectively, like we would find on Level 3 of NephoVis. However, the differences with NephoVis are crucial.

First, the colours match pre-computed \textsc{hdbscan} clusters (\(minPts = 8\)) and cannot be changed; in addition, the transparency of the tokens reflects their \(\varepsilon\). The goal of this dashboard is, after all, to combine the \textsc{2d} visualization and the \textsc{hdbscan} clustering for a better understanding of the models. This functionality is not currently available in NephoVis because, unlike sense tags, it is a model-dependent categorical variable\footnote{The current code is not suited to adapt the automatic selection of categorical variables to model-dependent ones, and adding the clustering solution for each of the models would clutter the list of categorical variables.}.

Second, the type-level plot does not use stars but the lemmas of the context words themselves. More importantly, they are matched to the \textsc{hdbscan} clusters based on the measures of frequency, precision and recall. In short, only context words that can be deemed relevant for the definition or characterization of a cluster are clearly visible and assigned the colour of the cluster they represent best; the rest of the context words are faded in the background. A radio button on the sidebar offers the option to highlight context words that are ``relevant'' for the noise tokens as well.

Third, the tooltips offer different information from NephoVis: the list of captured context words in the case of tokens, and the relevance measures as well as the nearest neighbours of the context word in the type-level plot. For example, in the left side of Figure \ref{fig:shiny-tooltips} we see the same token-level model shown in Figure \ref{fig:nepho3-base}. Hovering over one of the tokens in the bottom left light blue cluster, we can see the list of context words that the model caputes for it: the same we could have seen in bold in the NephoVis rendering by hovering over the same token. Among them, \emph{glas/noun} `glass' is highlighted, because it is the only one that surpasses the relevance thresholds we have set. On the right side of the figure, i.e.~the type-level plot we can see the similarities between the context words that surpass these thresholds for any cluster, and hovering on one of them provides us with additional information. In the case of \emph{glas/noun} `glass', the first line reports that it represents 31 tokens in the light blue \textsc{hdbscan} clusters, with a recall of 0.94, i.e.~it co-occurs with 94\% of the tokens in the cluster, and a precision of 1, i.e.~it only co-occurs with tokens in that cluster. Below we see a list of the nearest neighbours, that is, the context words most similar to it at type-level and their cosine similarity. The fact that the similarity with its nearest neighbour is 0.77 (in a range from 0 to 1) is worrisome.



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/shinyapp-tooltips} \caption{Top boxes of the \textbf{t-SNE} tab of the \href{https://marianamontes.shinyapps.io/Level3/}{ShinyApp dashboard}, with active tooltips.}\label{fig:shiny-tooltips}
\end{figure}

The two bottom boxes of the tab show, respectively, the concordance lines with highlighted context words and information on cluster and sense, and a scatterplot mapping each context word to its precision, recall and frequency in each cluster. The darker lines inside the plot are a guide towards the threshold: in this case, relevant context words need to have minimum precision or recall of 0.5, but if they were modified the lines would move accordingly. The colours indicate the cluster the context word represents, and the size its frequency in it, also reported in the tooltip. Unlike in the type-level plot above, here we can see whether context words co-occur with tokens from different clusters. Figure \ref{fig:shiny-bottom} shows the right-side box next to the top token-level box. When one of its dots is clicked, the context words co-occurring with that context word --- regardless of their cluster --- will be highlighted in the token-level plot, and the table of concordance lines will be filtered to the same selection of tokens.



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/shinyapp-selection} \caption{Token-level plot and bottom plot of context words in the \textbf{t-SNE} tab of the \href{https://marianamontes.shinyapps.io/Level3/}{ShinyApp dashboard}, with one context word selected.}\label{fig:shiny-bottom}
\end{figure}

The first tab of this dashboard is an extremely useful tool to explore the \textsc{hdbscan} clusters, their (mis)match with the t-\textsc{sne} representation and the role of the context words. In addition, the \textbf{HDBSCAN structure} tab provides information on the proportion of noise per medoid and the relationship between \(\varepsilon\) and sense distribution in each cluster. Finally, the \textbf{Heatmap} tab illustrates the type-level distances between the relevant context words, ordered and coloured by cluster, as shown in Figure \ref{fig:shiny-heatmap}. In some cases, it confirms the patterns found in the type-level plot; in others, like this model, it shows that most of the context words are extremely different from each other, forming no clear patterns. This is a typical result in \texttt{5000all} models like the one shown here and tends to lead to bad token-level models as well.



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/shinyapp-heatmap} \caption{Heatmap of type-level distances between relevant context words in the \href{https://marianamontes.shinyapps.io/Level3/}{ShinyApp dashboard}.}\label{fig:shiny-heatmap}
\end{figure}

\hypertarget{nepho-summary}{%
\section{Summary}\label{nepho-summary}}

In this chapter two visualization tools for the exploration of token-level distributional models have been described. Both are open-source, web-based and interactive. They were developed within the Nephological Semantics projects at KU Leuven and constitute the backbone of the research described in this dissertation.

Data visualization can be beautiful and contribute to successful communication, but its main goal is to provide insight \autocite{card.etal_1999}. Indeed, these tools have provided a valuable interface to an otherwise inscrutable mass of data.
NephoVis offers an informative path from the organization of models to the organization of tokens, representing abstract differences generated by complicated algorithms as intuitive distances between points on a screen. Selecting different kinds of models and moving back and forth between different levels of granularity is just a click away and incorporates various sources of information simultaneously: find all models with window size of 5, look at them side by side, zoom in on the prettiest one, read a token, read the token next to it, find out its sense annotation, go back to the selection of models\ldots{} Abstract corpus-based similarities between instances of a word, and between \emph{ways} of representing these similarities (i.e.~the models) become tangible, colourful clouds on a screen.
Most of the points discussed in the second part of this dissertation would have been simply impossible if it were not for these tools. Hopefully, they will prove at least half as valuable in future research projects.

\hypertarget{dataset}{%
\chapter{Case studies}\label{dataset}}

Every empirical study needs a dataset. The methodological orientation of this project means that it does not aim for a linguistic description of some phenomenon in itself, but for the development of a tool that could aid such a description. Therefore, in order to test the workflow described in Chapter \ref{workflow} and the visualization tools described in Chapter \ref{nephovis}, the methodology was applied to a dataset. For that purpose, 32 Dutch nouns, adjectives and verbs exemplifying a range of semasiological phenomena were selected. The phenomena include: homonymy in the case of nouns, interaction between semantic variation and argument structure in the case of verbs and, for all parts of speech, metaphor, metonymy and generalization/specialization. The goal was to explore which phenomena were revealed by distributional models and whether they were related to certain parameter settings.

\textbf{Homonymy} occurs when the same lemma has two or more (sets of) senses that are not semantically or etymologically related. The rest of the relationships between senses can be broadly classified as generalization/specialization, metaphor, or metonymy. \textbf{Specialization} and \textbf{generalization} are two sides of the same coin: one of the senses involved is applied to a particular context or situation, and the other has a much broader application. Crucially, this process involves some additional semantic feature. For example, \emph{herstructureren} `to restructure' can be applied to a range of situations, but when it applies to companies or parts of companies in particular it does not only mean `to change the structure of something' but also `to reduce the personnel', which is missing in the general application. The direction of the relationship, i.e.~whether the first sense is a generalization of the second or the other way around, is not relevant for the purposes of this study. The relevance is instead linked to the expectation that specialized senses would be more easily identified than general ones.
Within Cognitive Linguistics, \textbf{metaphor} and \textbf{metonymy} are understood as cognitive principles that influence semantic structure, rather than mere expressive tools. They are found to interact and, at the same time, the distinction between them is not always unambiguous
\autocite{lakoff.johnson_2003,barcelona_2015,lemmens_2015,geeraerts_2003}.
While metaphor is described in terms of comparison, similarity and mapping between different domains, metonymy is described in terms of reference, contiguity and mappings within a domain
\autocite{lemmens_2015}.
For example, when \emph{grijs} `gray' is applied to a weather-related term, e.g.~\emph{grijze avond} `gray evening', the colour of the overcast sky stands for the weather in a metonymical mapping; when it is applied to an abstract entity like a \emph{buurt} `neighbourhood' a metaphorical sense `boring, sad' is activated instead. However, the definition of what counts as a domain is not without problems, leaving the boundaries between metaphor and metonymy challenging to define as well \autocite{croft_2003}. For the purposes of these case studies, the distinction is relevant to the extent that metonymical senses are more likely than metaphorical senses to occur in the same contexts as their literal counterparts.

In practice, the situation is even more complicated. In the case of structural metaphors
\autocite{lakoff.johnson_2003},
metaphorical extensions might be elaborated by means of longer expressions. For example, in \emph{we richten de spots op de zoektocht naar kandidaten} `we aim the spotlights towards the search for candidates', \emph{richten} `to direct' and \emph{op} `on' can co-occur with either the literal or metaphorical senses of \emph{spots} `spotlight', and \emph{zoektocht} `search' is the cue that makes the literal sense less appropriate. This leads us to a situation already discussed by
\textcite{geeraerts_2003}
regarding the interaction of metaphor and metonymy in idiomatic and composite expressions. In a case like \emph{hete aardappel} `hot potato', which in the sample always refers to delicate situations that nobody wants to deal with, is the adjective `hot' literal or metaphorical? Following Geeraerts' prismatic model of composite expressions,
it could be explained as a combination of literal \emph{heet} `hot to the touch' with literal \emph{aardappel} `potato' that together is metaphorically understood as a delicate situation; a reinterpretation could then complete the mapping between the potato and the situation, and between the property of being hot to the touch and that of being delicate and to be avoided. The degree to which these reinterpreted mappings match systematic metaphorical or metonymical mappings of the individual elements is a separate issue: it could be argued for \emph{heet}, which has a `conflictive' meaning in non idiomatic constructions, but not for \emph{aardappel} `potato'. As a rule, these cases have been annotated as literal, understanding that it is the situation as a whole that is metaphorical.

It should be noted that these criteria are argumentative and justify the selection of the lemmas, but cannot go further than that. It is unfortunate, but the intriguing question about mapping parameter settings to these phenomena has a negative answer. As the second part of the dissertation will show, other factors play a role in the formation of the clouds, relegating these traditional semantic categories to a secondary place, if not as extras on the show. Nevertheless, the phenomena are accounted for, the questions have been asked and, no matter how unsatisfactorily, they have been answered.

Hence, this chapter focuses on the selection, collection and annotation of the dataset on which the methodology was tested. First, Section \ref{selection} will introduce the 32 selected lemmas and their senses, making explicit which of the aforementioned phenomena they exhibit. I will not discuss each lemma in detail; instead, I will expand of those used for illustration in Part II as it becomes relevant. Section \ref{extraction} will focus on how the concordance lines were collected and the manual annotation procedure. Relevant information regarding the annotation itself will also be provided. Finally, Section \ref{ann-summary} rounds up the description and the technical part of this dissertation.

\hypertarget{selection}{%
\section{The lemmas}\label{selection}}

The selection of lemmas aimed to cover a wide range of phenomena: metaphor, metonymy, generalization/specialization, and more. The nouns were chosen because they exhibit both homonymy and polysemy: they have unrelated (groups of) meanings and at least one of them presents finer distinctions. The selection of adjectives also includes different kinds of semantic extension which are mostly related to the kind of noun that is modified by it. Finally, the verbs combine syntactic and semantic dimensions. The definitions provided to the annotators with their respective examples and their translations to English will be listed in tables, but no other examples will be shown in this chapter. Instead, relevant tokens and their contexts will be reproduced in the second part of the dissertation to illustrate the results from the analyses. Empty cells in the Dutch columns of the definitions indicate sense tags that were not present in the original selection of senses but instead were included \emph{after} the annotation procedure --- and assigned in a second stage --- based on the results of the annotation itself. The Dutch definitions themselves are adaptations made by Dirk Geeraerts and me based on consultation of dictionaries \autocites[e.g.][]{vandale_groot,vandale_klein} and pilot surveys of small concordances from the corpus.

The selection of phenomena was attached to certain expectations. We expected specific senses to be easier to identify than general senses, i.e.~to have a more identifiable context. With regard to nouns, homonyms were expected to be discriminated more easily that their internal distinctions. For verbs, instead, the expectation was to find more confusion between senses that either shared the semantic or the syntactic dimension than between senses that did not.
We also expected metonymical senses to be harder to disambiguate than synaesthetic or metaphorical senses, since they are more likely to have an overlapping context with the more concrete, literal senses.

\hypertarget{nouns}{%
\subsection{The nouns}\label{nouns}}

A set of 7 nouns was selected that exhibit both homonymy and polysemy in at least one of the homonyms\footnote{Originally we selected 8 nouns, but the very interesting \emph{spoor} was discarded because of the high disagreement between the annotators and their (and my) difficulty understanding the definitions. It has three homonyms, `trace', `railway' and `spurs', and some senses of `trace' can be confused with some of `railway'. In any case, the data is available for future analyses.}, as shown in Table \ref{tab:noundefs}. The purpose of this selection was to examine how models dealt with granularity, i.e.~hierarchies of senses: homonyms should be easier to disambiguate than their senses, since they will apply to very different contexts, but maybe it would be possible to tune the parameter settings for different levels of granularity, like adjusting the focus on a camera.

\renewcommand{\arraystretch}{1.4}



\begingroup\fontsize{7}{9}\selectfont

\begin{longtabu} to \linewidth {>{\raggedright\arraybackslash}p{19em}>{\raggedright\arraybackslash}p{1.5em}>{\raggedright\arraybackslash}p{19em}}
\caption{\label{tab:noundefs}Definitions and examples for the senses of each of the 7 analysed nouns. In each sense, the first number indicates the homonym and, if there is a second number, the sense within the homonym.}\\
\toprule
\multicolumn{1}{>{\centering\arraybackslash}p{19em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{Dutch}\endgroup} & \multicolumn{1}{>{\centering\arraybackslash}p{1.5em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{sense}\endgroup} & \multicolumn{1}{>{\centering\arraybackslash}p{19em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{English}\endgroup}\\
\midrule
\endfirsthead
\caption[]{\textit{(continued)}}\\
\toprule
\multicolumn{1}{>{\centering\arraybackslash}p{19em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{Dutch}\endgroup} & \multicolumn{1}{>{\centering\arraybackslash}p{1.5em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{sense}\endgroup} & \multicolumn{1}{>{\centering\arraybackslash}p{19em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{English}\endgroup}\\
\midrule
\endhead

\endfoot
\bottomrule
\endlastfoot
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{blik}}\\
oogopslag (\textit{een blik werpen op iets, een blik van verstandhouding}) & 1.1 & gaze (\textit{throw a look at something, a look of understanding})\\
gezichtsvermogen (\textit{een scherpe blik}) & 1.2 & sight (\textit{a sharp sight})\\
inzicht, in intellectuele zin (\textit{een brede blik}) & 1.3 & perspective, in intellectual sense (\textit{a wide view})\\
dun geplet metaal, i.h. bijz. vertind dun plaatstaal (\textit{dozen uit blik}) & 2.1 & thin flattened metal, in particular thin tin-plated steel (\textit{boxes of tin})\\
voorwerp (i.h.bijz. doos voor voedsel) vervaardigd uit zulk materiaal (\textit{stoffer en blik, een blik erwtjes, een maaltijd uit blik}) & 2.2 & object (in particular food container) made of tin (\textit{brush and dustpan, a can of peas, canned meal})\\
voedsel bewaard in een voorwerp als bedoeld in 2.2 (\textit{eet je niet teveel blik?}) & 2.3 & food contained in an object as described by 2.2 (\textit{don't you eat too much canned food?})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{hoop}}\\
ongeordende stapel (\textit{een hoop rommel, gooi maar op de hoop}) & 1.1 & unordered mass (\textit{a pile of junk, just drop it on the pile})\\
grote hoeveelheid (\textit{een hoop mensen, een hele hoop geld}) & 1.2 & great quantity (\textit{a bunch of people, a lot of money})\\
positieve verwachting, vertrouwen op iets positiefs (\textit{hoop koesteren, de hoop uitspreken dat...}) & 2 & positive expectation, trust in something positive (\textit{to nurture hope, express the hope that...})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{horde}}\\
bende, ordeloze groep personen (\textit{een woeste horde}) & 1 & band, unordered group of people (\textit{a ferocious horde})\\
 & 1.2 & unordered group of non-people (\textit{a horde of computers})\\
materiële hindernis, m.n. houten raamwerk gebruikt bij het hordelopen (\textit{de 400m horden bij de vrouwen}) & 2.1 & material obstacle, namely wooden frames used for hurdling (\textit{the 400m hurdles for women})\\
hindernis in figuurlijke zin (\textit{een horde nemen}) & 2.2 & obstacle in figurative sense (\textit{to take a hurdle})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{schaal}}\\
een geordende reeks cijfers, afstanden, hoeveelheden e.d. waarmee iets gemeten wordt (\textit{de schaal van Celsius, Richter, op een schaal van 1 tot 5}) & 1.1 & an ordered list of numbers, distances, quantities and such, with which something is measured (\textit{the scale of Celsius, Richter, on a scale from 1 to 5})\\
de verhouding tussen de grootte van iets en de weergave ervan in een kaart, model, grafiek etc. (\textit{een schaal van 1:20, een schaal van 10 km}) & 1.2 & the ratio between the size of something and its representation in a map, model, graph etc. (\textit{a scale of 1:20, a scale of 10km})\\
grootteorde, omvang (\textit{de schaal van een probleem, op grote/kleine schaal}) & 1.3 & magnitude, size (\textit{the scale of a problem, on a large/small scale})\\
harde buitenbekleding van zekere organische zaken (\textit{de schaal van een ei, de schalen van een mossel}) & 2.1 & hard exterior of certain organic things (\textit{the shell of an egg, the shell of a mussel})\\
ondiepe en wijde schotel (\textit{een schaal met vruchten}) & 2.2 & shallow and wide dish (\textit{a platter with fruits})\\
elk van de beide schotels die aan de armen van een balans hangen (\textit{gewicht in de schaal leggen}) & 2.3 & each of the dishes hanging from the arms of a scale (\textit{lay a weight on the (dish of a) scale})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{spot}}\\
 & 0 & (idiosyncratic usage in sports headlines) (\textit{Spot op 1ste})\\
oneerbiedige, ridiculiserende uitspraak of behandeling (\textit{de spot drijven met, bijtende spot}) & 1 & disrespectful, mocking expression or behaviour (\textit{mock someone, sarcasm})\\
reclameboodschap via radio, televisie, bioscoop (\textit{een spotje voor tandpasta}) & 2.1 & advertisement via radio, television, cinema (\textit{a spot for toothpaste})\\
schijnwerper (\textit{de spots richten op}) & 2.2 & spotlight (\textit{direct the spotlights on})\\
 & 2.3 & metaphorical spotlight (\textit{he likes to be in the spotlight})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{staal}}\\
zeer hard ijzer met laag koolstofgehalte (\textit{twaalf ton staal, ijzer en staal, een man van staal}) & 1.1 & very hard iron with low carbon content (\textit{twelve tons of steel, iron and steel, man of steel})\\
 & 1.3 & steel industry (\textit{steel is striking})\\
voorwerp of deel van een voorwerp uit zulk metaal (\textit{het staal van de velgen is verroest}) & 1.2 & object or part of an object made of such metal (\textit{the steel in the rims is rusted})\\
monster van een stof of materiaal, bij wijze van proef (\textit{een staal vragen, goederen op staal verkopen}) & 2.1 & sample of a substance or material, as evidence or proof (\textit{to ask for a sample, to buy a sample of goods})\\
proef, voorbeeld, bewijs (\textit{een staaltje van hun kunnen, een staaltje van bewaamheid}) & 2.2 & proof, example, evidence (\textit{a sample of their abilities, a proof of competence})\\
 & 2.3 & sample taken from a population for statistical analysis (\textit{a representative sample})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{stof}}\\
materie, substantie van een bepaald type (\textit{giftige stoffen, vaste stof, grijze stof}) & 1.1 & matter, substance of a certain kind (\textit{poisonous substances, solid substances, gray matter})\\
weefsel (\textit{wollen en katoenen stoffen}) & 1.2 & fabrics (\textit{woolen and cotton fabrics})\\
onderwerp waarover men spreekt, schrijft, nadenkt etc. (\textit{stof voor een roman, stof tot onenigheid}) & 1.3 & topic about which people talk, write, think, etc. (\textit{material for a novel, topic of disagreement})\\
massa zeer kleine droge deeltjes van verschillende oorsprong, door de lucht meegevoerd (\textit{een wolk stof, stof afnemen}) & 2.1 & mass of very small dry particles of various origin, floating in the air (\textit{a cloud of dust, to clean dust (=to dust)})\\
massa zeer kleine deeltjes als toestand van een specifieke substantie (\textit{iets tot stof vermalen, tot stof verpulveren}) & 2.2 & mass of very small particles as state of a specific substance (\textit{to bring something to dust})\\
 & 2.3 & idiomatic uses of 'dust' (\textit{lift up dust})\\*
\end{longtabu}
\endgroup{}

Three nouns have one frequent, monosemous homonym and a less frequent, polysemous one: \emph{hoop} `hope/heap', \emph{spot} `ridicule/show or spotlight' and \emph{horde} `horde/hurdle'. The polysemy phenomena are varied. First, \emph{horde} `hurdle' can refer to literal hurdles, e.g.~in races, while the other sense is metaphorical: abstract difficulties are talked about as obstacles to be surpassed. In addition, after the annotation a new sense tag derived from `horde' was included, for the cases in which the members of the horde were not human beings, but insects, cars or other entities.
Second, one of the \emph{hoop} `heap' senses refers to literal heaps of things that can form a pile, while the other one is a generalization to large quantities, e.g.~\emph{een hoop werk} `a lot of work'. Finally, the polysemous homonym of \emph{spot} has two main senses linked by metonymy, namely `short video', e.g.~and advertisement spot, or `spotlight'. The `spotlight' sense can also be used either literally or metaphorically (`to be in the spotlight'); this distinction was not included in the original definitions, but the annotators pointed it out and it was added afterwards.\footnote{Next to these more traditional tags, one category (sense 0 in Table \ref{tab:noundefs}) represents a selection of confusing lines with the format \emph{Spots op \{1ste, 2de, 3de\}.} There are 13 such tokens in the sample, all from the start of Regional Sports articles from \emph{Het Nieuwsblad}, published between 2003-09-10 and 2004-10-27. This category is not like any other sense, but it was included after the annotation just to see what the models did with it.}

The other four nouns have two polysemous homonyms: \emph{schaal} `scale/dish', \emph{blik} `gaze/tin', \emph{stof} `substance/dust\ldots{}', and \emph{staal} `steel/sample'.
First, the frequent homonym of \emph{blik} (`gaze') has a concrete sense with two metaphoric extensions: `intellectual look', which was not attested in the sample, and `perspective', which is quite infrequent. The infrequent homonym, `tin', can either refer to the material itself, to an object made of that material (`tin can') or its content (`canned food'); due to their low frequency and the difficulty on part of the annotators to distinguish between the senses, the two last senses were later combined into one.
Second, the frequent homonym of \emph{stof} has two concrete, referentially distinct senses (`substance' and `fabric') and an abstract one (`topic, material'). In contrast, for the less frequent homonym we distinguished two senses presenting a subtle, context-specific difference: between `dust (in the air)' and the `dust' in `reducing something to dust, to pulverize'. The last sense was so infrequent that it was excluded, but another distinction emerged from the annotation, namely between literal `dust' and `dust' in idiomatic expressions, such as \emph{stof doen opwaaien} `to be controversial, lit. to stir up dust'. The new sense was added because, even though within the idiomatic expression the meaning of \emph{stof} is still `dust', the annotators kept confusing it with the `topic, material' sense, which actually refers to expressions such as \emph{stof voor een roman} `material for a novel'.
Third, \emph{schaal} exhibits subtle perspective shifts in one homonym (`scale') and refers to different concrete objects with the second `shell/dish', of which the very distinctive `shell' sense was removed due to its low frequency.
Finally, \emph{staal} `steel' could refer, like \emph{blik} `tin', to either the material or the part of an object that is made from it --- the latter is very infrequent among our sample, but instead another sense could be identified, namely `steel industry'. The `sample' homonym, on the other hand, originally presented a metaphorical distinction between material samples and `evidence' of abstract characteristics, but was modified after annotation to a specialization distinction between general samples, e.g.~a urine sample, and (statistically) representative samples.

As we can see, the nouns present a variety of semantic phenomena at a finer granularity than homonymy: metaphor in the case of \emph{blik} `gaze', \emph{horde} `hurdle' and \emph{spot} `spotlight', metonymy in the case of \emph{horde} `horde', \emph{blik} `tin', \emph{staal} `steel' and \emph{spot} `videoclip/spotlight', generalization/specialization in the case of \emph{staal} `sample', \emph{schaal} `dish' and \emph{hoop} `heap', perspective shifts for \emph{schaal} `scale' and other relationships in the frequent \emph{stof} homonym.

\hypertarget{adjs}{%
\subsection{The adjectives}\label{adjs}}

The selection of adjectives includes 13 lemmas presenting different kinds of polysemy phenomena (Table \ref{tab:adjdefs}). The purpose of this selection was to examine how models dealt with their semantic relationships and whether they could extract them from the different nouns modified by the target adjective.

Three adjectives have a metonymic reading: \emph{hoopvol} `hopeful', \emph{geestig} `witty' and \emph{hachelijk} `dangerous/critical'.
For \emph{geestig} and \emph{hoopvol}, one of the senses is anthropocentric, i.e.~it's mainly or exclusively applied to people: witty people against the witty things they say or do, and people who express hope against things that inspire it.
In \emph{hachelijk}'s case, the difference is a matter of temporal or telic perspective: between things that might go wrong and situations that are already problematic.



\begingroup\fontsize{7}{9}\selectfont

\begin{longtabu} to \linewidth {>{\raggedright\arraybackslash}p{19em}>{\raggedright\arraybackslash}p{1.5em}>{\raggedright\arraybackslash}p{19em}}
\caption{\label{tab:adjdefs}Definitions and examples for the senses of each of the 13 analysed adjectives.}\\
\toprule
\multicolumn{1}{>{\centering\arraybackslash}p{19em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{Dutch}\endgroup} & \multicolumn{1}{>{\centering\arraybackslash}p{1.5em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{sense}\endgroup} & \multicolumn{1}{>{\centering\arraybackslash}p{19em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{English}\endgroup}\\
\midrule
\endfirsthead
\caption[]{\textit{(continued)}}\\
\toprule
\multicolumn{1}{>{\centering\arraybackslash}p{19em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{Dutch}\endgroup} & \multicolumn{1}{>{\centering\arraybackslash}p{1.5em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{sense}\endgroup} & \multicolumn{1}{>{\centering\arraybackslash}p{19em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{English}\endgroup}\\
\midrule
\endhead

\endfoot
\bottomrule
\endlastfoot
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{dof}}\\
(van kleuren en zichtbare dingen) mat, zonder glans, vaal (\textit{een doffe blik}) & 1 & (of colours and visible things) matte, without shine, pale (\textit{a dull gaze})\\
(van geluiden) niet luid of scherp, onderdrukt, gesmoord (\textit{een doffe kreet}) & 2 & (of sounds) not loud or sharp, suppressed, smothered (\textit{a dull cry})\\
(van personen, gevoelens e.d.) niet opgewekt, lusteloos, zonder energie (\textit{doffe onverschilligheid, doffe ellende}) & 3 & (of people, feelings, etc.) not cheerful, apathetic, without energy (\textit{dull apathy, dull misery})\\
(van denkbeelden e.d.) niet scherp voor de geest staand (\textit{een doffe herinnering}) & 4 & (of ideas and such) not sharp in the mind (\textit{a dull memory})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{geestig}}\\
scherpzinnig en humoristisch van aard (\textit{een geestige collega}) & 1 & of witty and humoristic nature (\textit{a witty colleague})\\
blijk gevend van, uitdrukking gevend aan, gekenmerkt door scherpzinnigheid en humor (\textit{een geestig boek, een geestige blik, een geestige opmerking}) & 2 & giving an impression of, expressing, characterized by wittiness and humor (\textit{a witty book, a witty look, a witty remark})\\
 & 3 & being perceived as witty (\textit{I find this funny})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{gekleurd}}\\
met kleur, in letterlijke zin (in het bijzonder, niet zwart, wit of grijs) (\textit{gekleurde wangen}) & 1 & with colour, in a literal sense (in particular, not black, white or gray) (\textit{colored cheeks})\\
(van personen e.a.) niet blank (\textit{de gekleurde medemens, van gekleurde afkomst zijn}) & 2 & (of people a.o.) not white (\textit{the fellow colored man, to be of colored origin})\\
(van uitspraken, opvattingen e.d.) niet neutraal, tendentieus (\textit{een gekleurde voorstelling van zaken}) & 3 & (of expressions, concepts) not neutral, tendentious (\textit{a colored representation of things})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{geldig}}\\
van kracht, van toepassing, van waarde zijnde volgens wettelijke of andere regels (\textit{een geldig vervoerbewijs, betaalmiddel, juridisch bewijs}) & 1 & valid, acceptable, with value according to legal or other rules (\textit{a valid driving license, currency, legal evidence})\\
van kracht, van toepassing, van waarde in ruimere zin (\textit{een geldige redenering}) & 2 & valid, acceptable, with value in general sense (\textit{a valid reasoning})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{gemeen}}\\
gemeenschappelijk in gebruik of bezit, gedeeld (\textit{gemene kosten, een gemene muur}) & 1 & common property or of common use, shared (\textit{common costs, a common wall})\\
openbaar, publiek (\textit{de gemene zaak}) & 2 & public (\textit{the public business})\\
alledaags, gewoon, tot de middelmaat behorend (\textit{het gemene volk, de gemene man}) & 3 & commonplace, normal, mediocre (\textit{the common people, the common man})\\
boosaardig, kwaadaardig, laaghartig, malicieus (\textit{een gemene streek}) & 4 & malicious, evil, mean (\textit{a mean trick})\\
ordinair, plat, onkies, vulgair (\textit{gemene praatjes}) & 5 & ordinary, flat, indecent, vulgar (\textit{mean conversations})\\
 & 6 & cool, awesome, badass\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{goedkoop}}\\
laag in prijs, betaalbaar, voordelig (\textit{goedkope wijn}) & 1 & of low price, affordable, advantageous (\textit{cheap wine})\\
geen hoge prijzen vragend (\textit{een goedkoop winkeltje, een goedkope loodgieter}) & 2 & not asking a high price (\textit{a cheap shop, a cheap plumber})\\
waar de prijzen laag zijn (\textit{een goedkope buurt}) & 3 & where the prices are low (\textit{a cheap neighborhood})\\
van weinig waarde, makkelijk verkregen, oppervlakkig, banaal (\textit{goedkope lof, goedkoop succes, goedkope argumenten}) & 4 & with little value, received easily, superficial, banal (\textit{cheap praise, cheap success, cheap arguments})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{grijs}}\\
met een kleur die ligt tussen wit en zwart; vaalwit, grauw (\textit{grijs van het stof, de grijze dolfijn}) & 1 & with a color between white and black, pale white (\textit{gray from the dust, the gray dolphin})\\
(van periodes e.d.) zonder veel zonneschijn, bewolkt, betrokken (\textit{een grijze dag}) & 2 & (of periods and such) without much sunlight, cloudy, covered (\textit{a gray day})\\
(van haar) zijn kleur verloren hebbend, m.n. door gevorderde leeftijd (\textit{een grijs baardje}) & 3 & (of hair) having lost its color, namely because of old age (\textit{a gray beard})\\
(van personen e.a.) grijsharig, en vandaar, betrekking hebbend op ouderen (\textit{de grijze golf}) & 4 & (of people and related) gray haired, and thus, related to old people (\textit{the gray wave})\\
saai, kleurloos, vervelend (\textit{een grijze buurt}) & 5 & boring, not colorful, tedious (\textit{a gray neighborhood})\\
niet helemaal volgens de wet of de regels, halflegaal (\textit{de grijze economie}) & 6 & not exactly following the law or rules, half legal (\textit{the gray economy})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{hachelijk}}\\
met kans op een ongunstige afloop, (potentieel) gevaarlijk (\textit{een hachelijke onderneming}) & 1 & with chances of unfavorable outcome, (potentially) dangerous (\textit{a dangerous enterprise})\\
(reëel) gevaarlijk, netelig, kritiek, benard (\textit{een hachelijke situatie}) & 2 & (actually) dangerous, trick, critical, dire (\textit{a dangerous situation})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{heet}}\\
(van dingen) zeer warm (\textit{een gloeiend hete kachel}) & 1 & (of things) very warm (\textit{a very hot stove})\\
(van het lichaam) warm aanvoelend, een hogere temperatuur dan normaal hebbend (\textit{hete wangen, het heet hebben}) & 2 & (of the body) feeling warm, having a higher temperature than normal (\textit{hot cheeks, to feel hot})\\
(van het weer) zeer warm (\textit{hete dagen, hete zomer}) & 3 & (of the weather) very warm (\textit{hot days, hot summer})\\
(van voedsel) pikant (\textit{hete sauzen}) & 4 & (of food) spicy (\textit{hot sauce})\\
(van personen) sexueel hartstochtelijk, geil (\textit{een hete bok}) & 5 & (of people) sexually attractive, horny (\textit{a hot buck})\\
(van gebeurtenissen, periodes e.d.) gekenmerkt door heftige strijd (\textit{het ging er heet aan toe, een hete herfst}) & 6 & (of events, periods, etc.) characterized by fierce conflict (\textit{it was getting hot, a hot autumn})\\
 & 7 & popular, interesting or new, recent\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{heilzaam}}\\
(letterlijk) bijdragend tot gezondheid en lichamelijk welzijn (\textit{een heilzaam dieet}) & 1 & (lit.) that brings health and physical wellbeing (\textit{a healthy diet})\\
(figuurlijk) nuttig, een gunstig effect hebbend (\textit{een heilzaam besluit}) & 2 & (fig.) necessary, having a beneficial effect (\textit{a beneficial decision})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{hemels}}\\
betrekking hebbend op de hemel (\textit{de hemelse Vader, de hemelse boodschap}) & 1 & related to heaven (\textit{de heavenly Father, the heavenly message})\\
verrukkelijk, heerlijk, zalig, goddelijk (\textit{een hemelse verschijning, een hemelse stem}) & 2 & delightful, lovely, blissful, divine (\textit{a heavenly appearance, a heavenly voice})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{hoekig}}\\
(van voorwerpen, figuren e.d.) met hoeken of scherpe kanten (\textit{een hoekige tekening, een hoekig gezicht}) & 1 & (of objects, figures, etc.) with angles or sharp edges (\textit{an angulous drawing, an angulous face})\\
(van bewegingen, ritmes e.d.) niet vloeiend (\textit{een hoekig melodietje}) & 2 & (of movements, rhythms, etc.) not fluent (\textit{a broken melody})\\
(van personen) houterig, stijf, onhandig in de omgang (\textit{een hoekig karakter}) & 3 & (of people) rigid, stiff, clumsy (\textit{a clumsy character})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{hoopvol}}\\
(van personen, uitingen, gedragingen etc.) blijk gevend van hoop, vol hoop, optimistisch (\textit{een hoopvolle stemming, dat stemt mij hoopvol}) & 1 & (of people, expressions, behaviors, etc.) giving an impression of hope, full of hope, optimistic (\textit{a hopeful mood, that brings me hope (makes me hopeful)})\\
reden tot hoop gevend, beloftevol (\textit{hoopvolle perspectieven}) & 2 & giving reason for hope, promising (\textit{hopeful perspectives})\\*
\end{longtabu}
\endgroup{}

Four adjectives have metaphoric readings: \emph{hoekig} `angular', \emph{dof} `dull', \emph{heilzaam} `healthy/beneficial' and \emph{gekleurd} `colourful/person of colour/tainted'.
\emph{Heilzaam} has two senses, distinguishing between things that are literally healing, or beneficial for the health, and things that are metaphorically healing, or beneficial in general.
\emph{Hoekig} and \emph{gekleurd} present three sense distinctions, one of which is particularly concrete and the most frequent, `of angular form' and `colourful' respectively, and another one explicitly anthropocentric: `clumsy' and `non white'. The third sense distinction has a different quality: synaesthetic for \emph{hoekig}, applied to rhythms, and metaphoric for \emph{gekleurd}, meaning `tainted, corrupted'.
Finally, \emph{dof} has a concrete sense applied to the visual domain, a synaesthetic extension applied to sounds, and an abstract meaning applied to feelings and emotions; the fourth meaning listed in the table was not attested.

Three adjectives present some other form of similarity between the readings: \emph{geldig} `valid', \emph{hemels} `heavenly' and \emph{gemeen} `shared/mean\ldots{}'.
\emph{Geldig} `valid' and \emph{hemels} `heavenly' offer two options: one restricted to a specific context (laws and reglaments for \emph{geldig} and Heaven for \emph{hemels}) and one much broader.
The case of \emph{gemeen} is quite complex, involving a number of rather subtle distinctions that often co-exist in the same attestation: i.e.~`common' and `shared', or `average' and `ordinary'.

Finally, the remaining three adjectives present a more complex picture: \emph{heet} `hot' and \emph{goedkoop} `cheap' have literal senses with different kinds of entities but has also metaphorical extensions, while \emph{grijs} `grey' has both metaphorical and metonymical extensions.
\emph{Heet} `hot' presents, first, three very concrete senses that differ in perspective: temperatures of objects, of weather and as it is felt in the body; the other three senses are metaphorical, i.e.~the objects to which \emph{heet} is applied cannot be physically hot. Crucially, there is no exclusive sense tag for idiomatic expressions in which the combination of \emph{heet} `hot' and its concrete object (e.g.~\emph{hang\_ijzer} `iron', \emph{aardappel} `potato') is used metaphorically. \emph{Goedkoop}, on the other hand, presents a modest set of 4 sense distinctions: a concrete, prototypical and frequent sense (i.e.~cheap products), two perspectival shifts (i.e.~cheap shops and cheap area) and a clear metaphor (i.e.~of little values).
Finally, \emph{grijs} presents a very frequent, concrete sense, three specific metonymic extensions --- to weather and to hair, and from there to old people or generations --- and two metaphorical ones --- `boring' and `half legal'. In practice, the `boring' reading can include `sad, not cheerful', and the `half legal' sense is more general, applying to `gray areas' between two poles.

In sum, the adjectives include more simple semasiological structures with only one kind of semantic extension involved as well as more complex interactions between the phenomena.

\hypertarget{verbs}{%
\subsection{The verbs}\label{verbs}}

The criterion to select the 12 verbs analysed here was to cover a range of combinations of syntactic and semantic variation, with the goal of exploring how different parameter settings dealt with their interaction or whether certain types of models would focus on one or the other aspect.\footnote{The original set of verbs also included \emph{herkennen}, but it was excluded because of the extreme subtlety of its sense distinctions, which made the annotation particularly challenging.} Their senses and translations are shown in Table \ref{tab:verbdefs}.

Four verbs are always transitive and their senses can be distinguished by the objects they can take: people or objects for \emph{haten} `to hate', people or opinions for \emph{huldigen} `to honour/to believe', concrete objects or taxes for \emph{heffen} `to levy/to lift', and statements or decisions for \emph{herroepen} `to recant/to void'.

Two of the verbs can be transitive, with a distinction based on the direct object, or intransitive: \emph{helpen} `to help' and \emph{herstructureren} `to restructure'. In both cases the intransitive sense is semantically similar to one of the transitive senses. For example, the intransitive sense and one of the transitive senses of \emph{herstructureren} only apply to companies, with the connotation that the personnel is being reduced, while the other transitive sense has a much more general application.

Three verbs can be transitive, with a distinction based on the direct object, or reflexive: \emph{diskwalificeren} `to disqualify', \emph{herhalen} `to repeat' and \emph{herinneren} `to remember/to remind'. In the case of \emph{diskwalificeren} `to disqualify' and, to a lesser degree, \emph{herhalen} `to repeat', this opposition can be interpreted as a specific situation where the object and the subject coincide.
In contrast, \emph{herinneren} means `to remember' in the reflexive construction and `to remind' in the transitive construction with the preposition \emph{aan}; the transitive construction without the preposition can also be attested (e.g.~\emph{ik word herinnered als}, `I am remembered as') but very infrequently.



\begingroup\fontsize{7}{9}\selectfont

\begin{longtabu} to \linewidth {>{\raggedright\arraybackslash}p{19em}>{\raggedright\arraybackslash}p{1.5em}>{\raggedright\arraybackslash}p{19em}}
\caption{\label{tab:verbdefs}Definitions and examples for the senses of each of the 12 analysed verbs.}\\
\toprule
\multicolumn{1}{>{\centering\arraybackslash}p{19em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{Dutch}\endgroup} & \multicolumn{1}{>{\centering\arraybackslash}p{1.5em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{sense}\endgroup} & \multicolumn{1}{>{\centering\arraybackslash}p{19em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{English}\endgroup}\\
\midrule
\endfirsthead
\caption[]{\textit{(continued)}}\\
\toprule
\multicolumn{1}{>{\centering\arraybackslash}p{19em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{Dutch}\endgroup} & \multicolumn{1}{>{\centering\arraybackslash}p{1.5em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{sense}\endgroup} & \multicolumn{1}{>{\centering\arraybackslash}p{19em}}{\begingroup\fontsize{9}{11}\selectfont \textbf{English}\endgroup}\\
\midrule
\endhead

\endfoot
\bottomrule
\endlastfoot
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{diskwalificeren}}\\
(trans.) ongeschikt verklaren en uitsluiten van een bepaalde functie of positie (\textit{een getuige diskwalificeren}) & 1 & (trans.) declare unsuitable and exclude from a certain function or position (\textit{disqualify a witness})\\
(trans.) wegens onregelmatigheden uitsluiten bij een wedstrijd (\textit{FC De Trappers werd gediskwalificeerd wegens wangedrag}) & 2 & (trans.) exclude from a competition because of irregularities (\textit{FC De Trappers was disqualified because of misbehaviour})\\
(reflex.) zichzelf buiten spel zetten, zich onmogelijk maken (\textit{met zulk gedrag diskwalificeer je jezelf}) & 3 & (reflex.) exclude oneself, make oneself impossible (\textit{with such a behaviour you disqualify yourself})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{haken}}\\
(trans.) met of als met een haak vastmaken (aan, in, achter iets) (\textit{een wagen aan een locomotief haken, een sleutel in een ring haken}) & 1 & (trans.) fix something with or as if with a hook (at, to, behind something) (\textit{hook a wagon to a locomotive, a key in a key ring})\\
(intrans.) met of als met een haak vastraken (\textit{de doornen haakten aan haar jas, haar paraplu bleef haken aan de deurknop}) & 2 & (intrans.) get stuck with or as if with a hook (\textit{the thorns got stuck in her coat, her umbrella got stuck in the doorknob})\\
(trans.) over een uitgestoken been doen struikelen (\textit{hij werd gehaakt in de elfmeter, iemand pootje haken}) & 3 & (trans.) make trip over a stuck out leg (\textit{he was made to trip in the penalty kick, make someone trip})\\
(intrans., met 'blijven') van gedachten, blikken e.d.: haperen, telkens terugkeren (aan of bij iets) (\textit{ik bleef haken bij de herinnering aan mijn broer}) & 4 & (intrans., with 'to keep') of thoughts, gazes and such: falter, come back (to something) (\textit{I kept going back to the memory of my brother})\\
(intrans./trans.) zeker handwerk maken door met een staafje met een weerhaak lussen samen te weven (\textit{haken tijdens het televisiekijken, hoe ontspannend!, een babymutsje haken}) & 5 & (intrans./trans.) make handcraft by weaving loops together with a hooked needle (\textit{crochetting while watching tv, so relaxing!, crochet a baby hat})\\
 & 6 & (with 'towards') desire, aim for\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{harden}}\\
(trans.) hard maken, in letterlijke zin (\textit{staal harden}) & 1 & (trans.) make hard, in literal sense (\textit{harden steel})\\
(intrans.) hard worden, in letterlijke zin (\textit{snel hardende verven}) & 2 & (intr.) become hard, in literal sense (\textit{quickly hardening paint})\\
(trans.) hard maken in figuurlijke zin; weerstand en veerkracht bijbrengen (\textit{een kind harden tegen het klimaat}) & 3 & (trans.) make hard in figurative sense; impart resistance and resilience (\textit{toughen a child against the weather})\\
(reflex.) bij zichzelf weerstand en veerkracht aankweken (\textit{zich harden tegen het lot}) & 4 & (reflex.) develop resistance and resilience by oneself (\textit{toughen oneself against fate})\\
(trans.) uithouden, verdragen (\textit{niet te harden}) & 5 & (trans.) endure, tolerate (\textit{unbearable ('not to bear')})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{haten}}\\
(trans.) iem. haat toedragen, een sterk gevoel van afkeer en vijandschap t.o.v. iem. hebben (\textit{waarom haat hij mij zo?}) & 1 & (trans.) feel hatred, have a strong feeling of aversion and enmity towards someone (\textit{why does he hate me so much?})\\
(trans.) iets onaangenaam, verfoeilijk, verwerpelijk vinden (\textit{hoe zou iemand de taalkunde kunnen haten?}) & 2 & (trans.) consider something unpleasant, detestable, reprehensible (\textit{how could someone hate linguistics?})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{heffen}}\\
(trans.) m.b.t. materiële zaken: in de hoogte brengen, optillen (\textit{met geheven hoofd; hij heft met gemak 80 kilo in de hoogte}) & 1 & (trans.) w.r.t. material objects: move to a higher position, lift (\textit{lifting their head; he easily lifted 80 kg})\\
(trans.) m.b.t. geld e.d.: invorderen, eisen, opleggen (\textit{belasting, rente, accijns heffen}) & 2 & (trans.) w.r.t. money and such: collect, demand, impose (\textit{collect tax, interest, excise})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{helpen}}\\
(trans.) ondersteunen in materiële of morele zin, bijstaan (\textit{met raad en daad helpen, een helpende hand, uit de nood helpen}) & 1 & (trans.) support in material or moral sense, assist (\textit{help in word and deed, a helping hand, help out})\\
(trans.) iem. assisteren door met hem samen te werken (\textit{helpen met het huiswerk; heb je dat alleen gedaan of heeft iemand je geholpen?}) & 2 & (trans.) assist someone by collaborating with them (\textit{help with homework, did you do that by yourself or did someone help you?})\\
(intrans.) voordeel opleveren, nuttig zijn (\textit{dat drankje heeft goed geholpen}) & 3 & (intrans.) yield advantage, be useful (\textit{that drink helped a lot})\\
 & 4 & (trans.) with inanimate entities, be helpful, useful\\
 & 5 & (with 'to/for') to provide\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{herhalen}}\\
(trans.) m.b.t. handelingen of activiteiten: opnieuw uitvoeren (\textit{een experiment, een les, een bezoek herhalen}) & 1 & (trans.) w.r.t. acts or activities: perform again (\textit{repeat an experiment, a lesson, a visit})\\
(trans.) m.b.t. zinnen, boodschappen e.d.: opnieuw uitspreken (\textit{kunt u dat even herhalen?}) & 2 & (trans.) w.r.t. utterances, messages and such: pronounce again (\textit{Could you please repeat that?})\\
(reflex.) zich opnieuw voordoen (\textit{de geschiedenis herhaalt zich}) & 3 & (reflex.) occur again (\textit{history repeats itself})\\
 & 4 & (trans.) of a show or an episode, broadcast again\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{herinneren}}\\
(met 'aan') weer te binnen brengen, in het geheugen terugroepen (\textit{iemand aan iets herinneren}) & 1 & (with 'of') bring back to the mind, to the memory (\textit{remind someone of something})\\
(reflex.) in het geheugen aanwezig hebben, niet vergeten (\textit{zich een gebeurtenis, een persoon herinneren}) & 2 & (reflex.) have present in the memory, not forget (\textit{remember an event, a person})\\
(trans.) met een plechtigheid, monument o.i.d. gedenken (\textit{we herinneren vandaag de Slag bij Ronceval}) & 3 & (trans.) remember with a celebration, monument and such (\textit{today we remember the Battle of Roncevaux Pass})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{herroepen}}\\
(trans.) m.b.t. wetten, besluiten e.d.: intrekken, niet langer geldig verklaren (\textit{een besluit, volmacht, decreet herroepen}) & 1 & (trans.) w.r.t. laws, decisions and such: withdraw, declare not valid anymore (\textit{annul a decision, power of attorney, decree})\\
(trans.) m.b.t. uitspraken, meningen e.d.: terugnemen en rechtzetten (\textit{Trump moest weer een van zijn dwaze tweets herroepen}) & 2 & (trans.) w.r.t. statements, opinions and such: retract and correct (\textit{Trump had to retract one of his crazy tweets again})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{herstellen}}\\
(trans.) repareren, de eraan ontstane schade wegwerken (\textit{het dak herstellen}) & 1 & (trans.) repair, get rid of the damage in something (\textit{repair the roof})\\
(trans.) tot de vorige toestand terugbrengen, doen terugkeren (\textit{de goede verstandhouding herstellen}) & 2 & (trans.) bring back, make return to the previous state (\textit{repair the understanding})\\
(trans.) goedmaken, weer doen vergeten (\textit{een fout herstellen}) & 3 & (trans.) make good, make forget (\textit{fix a mistake})\\
(reflex.) tot de oorspronkelijke toestand terugkeren (\textit{de rust herstelt zich}) & 4 & (reflex.) return to the original state (\textit{peace is restored})\\
(intrans.) genezen (\textit{van een ziekte herstellen}) & 5 & (intrans.) heal (\textit{heal from a disease})\\
 & 6 & (intrans.) of a financial/economic entity, recover\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{herstructureren}}\\
(trans.) reorganiseren, een nieuwe structuur geven (\textit{je kunt deze tekst maar beter herstructureren}) & 1 & (trans.) reorganize, give a new structure (\textit{you should restructure this text})\\
(trans.) m.b.t. bedrijven in problemen: activiteiten of personeel afstoten, downsizen (\textit{Bayer herstructureert zijn plasticdivisie}) & 2 & (trans.) w.r.t. businesses in difficulties: remove activities or personeel, downsize (\textit{Bayer restructures its plastic division})\\
(intrans.) van bedrijven in problemen: activiteiten of personeel afstoten, downsizen (\textit{de chemie moet zich herstructureren}) & 3 & (intrans.) of businesses in difficulties: remove activities or personeel, downsize (\textit{chemistry must restructure (itself)})\\
\addlinespace[0.3em]
\multicolumn{3}{c}{\textbf{huldigen}}\\
(trans.) iets of iem. eer bewijzen, vieren (\textit{we huldigen de uitvinder van de herbruikbare broodzak}) & 1 & (trans.) celebrate, pay homage to someone or something (\textit{we honor the inventor of the reusable bread bag})\\
(trans.) erkennen, aankleven, toegedaan zijn (\textit{een opvatting, mening, theorie huldigen}) & 2 & (trans.) acknowledge, follow, be commited to (\textit{hold a view, an opinion, a theory})\\*
\end{longtabu}
\endgroup{}

\renewcommand{\arraystretch}{1}

Two more verbs can be transitive, intransitive or reflexive, with semantic distinctions within the transitive structure: \emph{harden} `to make or become hard/ to tolerate' and \emph{herstellen} `to repair/ to heal\ldots{}'. The senses of \emph{harden} can be split in two main groups. One is more closely related to the property of `hardness', i.e.~to turn something or someone hard or to become hard, in literal or figurative sense, with different constructions: from the intransitive literal sense in \emph{om hun kaas te laten harden} `in order to make their cheese harden' to the transtive figurative one in \emph{Verdriet heeft haar gehard} `Grief has hardened her'. The second group, however, includes one transitive construction in a very specific pattern but is more frequent in the sample than all the others combined: \emph{(niet) te harden} (`to (not) tolerate', always negative).

Finally, \emph{haken} `to hook' presents semantic distinctions within both the transitive and the intransitive structures. It can refer literally or metaphorically to hooking something or remaining hooked, but there are also two very specific senses: one characteristic of the football context, meaning `to make someone trip (by placing a foot in front of them)', and `to crochet'.

In sum, the set of verbs includes cases where only the kind of direct object plays a role in the disambiguation and cases where it interacts with syntactic patterns. Moreover, the specific ways in which these kinds of direct objects are defined differ across verbs: from animacy or agency in the case of \emph{haten} to concreteness in the case of \emph{heffen}. The semantic distinctions can also rely on a broader context: \emph{diskwalificeren} will typically have people as direct object, but the sports-related context defines a specific sense, characterised by distinct motivations and consequences.

\hypertarget{extraction}{%
\section{The dataset}\label{extraction}}

For each of the 32 lemmas listed above, about 300 tokens were collected from the \emph{QLVLNewsCorpus} (described in Section \ref{corpus}). All attestations were manually annotated by at least three different people based on the definitions found in the Dutch column of Tables \ref{tab:noundefs}, \ref{tab:adjdefs} and \ref{tab:verbdefs}. Next to the sense assignment, which was later revised for uniformity --- and to include senses emerging from the annotation itself, as mentioned above --- the annotation included confidence assignment and selection of disambiguating context words.

The selection of the lemmas involved some introspection as well as consultation of lexical resources and corpus data: thinking of potential candidates, checking the senses reported in dictionaries \autocite{vandale_groot,vandale_klein} and estimating their relative frequencies in small concordances. We tried to avoid extremely skewed distributions approximating a monosemous structure or numerous infrequent senses that would be unlikely to stand out in a model.\footnote{In a number of cases, the corpus survey (reading a random concordance of 40-50 lines) invalidated options that intuitively or according to the dictionary definitions would have conformed to our requirements. When judging such a discrepancy, it is important to take into account the composition of the corpus. The topics addressed in newspapers and the terms used to talk about them are certainly not representative of everyday life or the entirety of language.} In the end, as we will see, sense frequency is not really an issue, because clouds don't model senses anyways.

The exploration of these samples of concordances also served for the calculation of the number of tokens to model and annotate. Regardless of the actual frequency of the items in the corpus, the minimum sample contained 240 tokens; it was raised to 280 if any of the senses had a relative frequency below 20\% in the sample, to 320 if it was below 10\%, and to 360 if there were many senses and therefore some had a low frequency (e.g.~\emph{heet}). The lower and upper bound were estimated from pilot studies of clouds as a large enough amount to warrant the use of this methodology and small enough to make sense of in the visualization tool. Table \ref{tab:lemmafreq} shows the absolute frequency (in the \textsc{520mw} \emph{QLVLNewsCorpus}) of each selected lemma, the size of the sample and the distribution of the senses: the more the boxplot in the rightmost column goes to the right, the more frequent one of the senses. For example, the long boxplots for \emph{blik} and \emph{hoop} indicate a very skewed distribution, i.e.~a sense with very high frequency and senses with very low frequencies, while the narrow, centred boxplots for \emph{hachelijk} and \emph{hemels} indicate that their senses are equally frequent.
The sample extraction was almost completely random, with the only restriction that no two instances of the same lemma would be extracted from the same file. There were, however, a few duplicates, due to repetition of the same fragment on different dates.



\begin{longtable}[t]{lrr>{}r}
\caption{\label{tab:lemmafreq}Absolute frequency of the lemmas in the corpus, number of batches and distribution of their senses. The number next to the boxplots indicate the number of different senses.}\\
\toprule
lemma & frequency & sample & senses\\
\midrule
\endfirsthead
\caption[]{\textit{(continued)}}\\
\toprule
lemma & frequency & sample & senses\\
\midrule
\endhead

\endfoot
\bottomrule
\endlastfoot
\addlinespace[0.3em]
\multicolumn{4}{l}{\textbf{nouns}}\\
\hspace{1em}spot & 3496 & 240 & 5\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_380842004643.pdf}\\
\hspace{1em}horde & 3224 & 280 & 4\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38084f1c6af5.pdf}\\
\hspace{1em}blik & 22175 & 280 & 4\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38086700401d.pdf}\\
\hspace{1em}staal & 5796 & 320 & 5\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_380838fa7ffd.pdf}\\
\hspace{1em}schaal & 14249 & 320 & 5\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_3808495b6a2a.pdf}\\
\hspace{1em}stof & 24502 & 320 & 5\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_380855865233.pdf}\\
\hspace{1em}hoop & 41946 & 320 & 3\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38083e46183.pdf}\\
\addlinespace[0.3em]
\multicolumn{4}{l}{\textbf{adjectives}}\\
\hspace{1em}hachelijk & 1307 & 240 & 2\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38086c657089.pdf}\\
\hspace{1em}hemels & 1417 & 240 & 2\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_3808637a1b16.pdf}\\
\hspace{1em}heilzaam & 1476 & 240 & 2\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_380877027406.pdf}\\
\hspace{1em}hoopvol & 3680 & 240 & 2\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_380855b23c22.pdf}\\
\hspace{1em}geldig & 5128 & 240 & 2\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38085f0c4045.pdf}\\
\hspace{1em}hoekig & 1242 & 280 & 3\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_3808773142be.pdf}\\
\hspace{1em}geestig & 3970 & 280 & 3\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38084cf613f6.pdf}\\
\hspace{1em}gekleurd & 4520 & 280 & 3\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_380846391e53.pdf}\\
\hspace{1em}dof & 1268 & 320 & 4\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_3808676695b.pdf}\\
\hspace{1em}gemeen & 2997 & 320 & 7\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38084395581d.pdf}\\
\hspace{1em}grijs & 13567 & 320 & 7\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38085d0626cc.pdf}\\
\hspace{1em}goedkoop & 40669 & 320 & 4\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_380869106bae.pdf}\\
\hspace{1em}heet & 10676 & 360 & 7\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38082c661f34.pdf}\\
\addlinespace[0.3em]
\multicolumn{4}{l}{\textbf{verbs}}\\
\hspace{1em}herroepen & 848 & 240 & 2\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38082ffc6f6b.pdf}\\
\hspace{1em}herstructureren & 936 & 240 & 3\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_380869186293.pdf}\\
\hspace{1em}diskwalificeren & 1084 & 240 & 3\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_380827acd0c.pdf}\\
\hspace{1em}huldigen & 4091 & 240 & 2\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38083ee35e7a.pdf}\\
\hspace{1em}heffen & 4799 & 240 & 2\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38081bfa4a21.pdf}\\
\hspace{1em}haten & 4828 & 240 & 3\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38083f514e91.pdf}\\
\hspace{1em}herstellen & 28814 & 240 & 6\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38084bc22088.pdf}\\
\hspace{1em}herinneren & 33432 & 240 & 3\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_380820317d14.pdf}\\
\hspace{1em}helpen & 87136 & 240 & 6\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38082f6466f8.pdf}\\
\hspace{1em}harden & 1050 & 320 & 5\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_3808a155351.pdf}\\
\hspace{1em}herhalen & 16856 & 320 & 4\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_38084f46979.pdf}\\
\hspace{1em}haken & 1403 & 360 & 6\includegraphics[width=0.67in, height=0.17in]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/phdThesis_files/figure-latex/boxplot_380876d53a2c.pdf}\\*
\end{longtable}

For each of the tokens a concordance line was extracted with 15 words to either side. Bachelor students of Linguistics at KU Leuven were recruited and hired to manually annotate the samples of the selected lemmas. Each of them was tasked with annotating 40 tokens of each of 12 types (at least three nouns, four adjectives and four verbs, plus one of either of the categories)\footnote{Recall that originally there were 8 nouns and 12 verbs.}: a total of 480 tokens\footnote{A few of them doubled their load and annotated two sets of 480 tokens.}, to annotate in 6 weeks. In total, each of the 9600 tokens was annotated by at least three annotators; 10\% of them were annotated by four. Each lemma was split in 6-9 batches of 40 tokens, each of them annotated by a different group of annotators. The annotators were offered an introductory meeting, a video tutorial and written guidelines, but the procedure itself was performed individually.

Both the lemmas and the batches were assigned randomly, while keeping in mind the part-of-speech distribution. It was the intention to shuffle the samples of each lemma before splitting them into batches, but something went wrong with the code and they were ordered by source; each batch would have mostly tokens of a different newspaper.
The annotation involved three tasks:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Assign a sense from a predefined set of definitions, namely the Dutch column in Tables \ref{tab:noundefs} through \ref{tab:verbdefs}. If none of the tags apply, select ``None of the above'' and explain why;
\item
  Express the confidence of the decision in a scale of 6 values;
\item
  Identify the words of the context that helped in the disambiguation.
\end{enumerate}

Since entering textual information in a spreadsheet can easily lead to typos and inconsistencies and, furthermore, annotating the helpful context words is particularly challenging in such a tool, a user-friendly visual interface was designed that received input from buttons and returned the output in \textsc{json} format.
The interface, which is not available in its original form any more, had a menu with the list of lemmas and two tabs: an overview of the concordance lines of the selected type and an annotation workspace (Figure \ref{fig:semann}). The annotation workspace focused on one concordance line\footnote{The web-based interface interpreted \textsc{html}, of course. As a consequence, the sentence separator \texttt{\textless{}sentence\textgreater{}\textless{}/sentence\textgreater{}} was simply ignored; it should have been replaced with \texttt{\textless{}p\textgreater{}\textless{}/p\textgreater{}} to properly render the division, especially after headlines, which lack final stops. Interestingly, this rendering also could have read strings such as \texttt{\&quot;} as \texttt{"}, but at some earlier stage of pre-processing of the corpus all the \texttt{\&} have been transformed into \texttt{and}, resulting in a number of confusing appearances of \texttt{andquot;} in the concordance lines.} (or token) at a time, offering
first the text, then a series of long radio buttons with the definitions and examples, a star rating option for the confidence evaluation, followed by a clickable reproduction of the text, and a text input field for comments. The long radio buttons meant that the annotators had the full definitions and examples at their disposal every time they had to assign a sense for a given lemma, while the final output transformed their decisions into more manageable codes, such as \texttt{sense\_1}, \texttt{sense\_2}, etc. The clickable concordance lines let them select the context words they deemed most useful to the annotation procedure by simply clicking on them; the program then translated this as an array of positions relative to the target, e.g.~\texttt{{[}"R1",\ "L2"{]}} if the first word to the right and the second to the left are selected.\footnote{For a few weeks into the annotation, the code had a bug that meant that if a word form was repeated in the concordance line and one of its instances was selected its first occurrence was recorded even if the chosen one was a later co-occurrence. The bug was fixed as soon as it was reported and the rest of the annotators were warned, but not all the resulting errors were corrected.} Finally, the text input field at the bottom was available to leave any sort of comment and was compulsory when ``None of the above'' was selected.



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/semann-annotation} \caption{Screenshot of the options in the annotation tool.}\label{fig:semann}
\end{figure}

The dataset obtained from this procedure is very rich and interesting for a variety of purposes. For each token we have sense assignment, confidence evaluation and selection of informative cues by at least three different independent annotators, as well as comments on at least the cases which did not receive a sense. Agreement between the annotators can be measured with coefficients such as Fleiss' \(\kappa\) \autocite{fleiss_1971}, illustrated in Figure \ref{fig:agreement}, but the resulting picture may be unnecessarily complex. First, disagreement is susceptible to granularity: annotators might disagree between senses of a noun but not between the homonyms, except for their confusion between idiomatic senses of \emph{stof} `dust' and its `topic, material' sense. Second, annotators were not very sensitive to grammatical distinctions (e.g.~between transitive and intransitive senses), which was a strong reason for disagreement in \emph{herstructureren}, \emph{helpen}, \emph{haken} and \emph{herstellen}. Third, disagreements were sometimes concentrated on one annotator, who showed a strong preference for a certain sense; as such, they were not an indicator of the ambiguity of the token but of misunderstandings on the part of the annotator. Some annotators exhibited an almost excessive attention to nuances, while others were much less thorough.

More importantly, for the great majority of the tokens
(83.8\%)
the majority of the annotators agreed on one tag that remained as the official sense for that token.
After gathering and exploring the data, the tokens were reread by me and a final decision was made for their sense tags. Figure \ref{fig:final-agreement} shows the number of tokens with full agreement, a majority agreement (i.e.~only one annotator disagreed) or no agreement and whether the same chosen sense was kept in the final annotation, another tag was applied or the token was removed (e.g.~tokens of \emph{heet} that corresponded to the verb \emph{heten}). The \texttt{Other} category includes new senses suggested by the annotators themselves as well as corrections from misunderstandings, such as the second original sense of \emph{blik}, which annotators interpreted in different ways and was actually not attested in the dataset. The very few cases of \texttt{Same} with no agreement were tokens annotated by four annotators where two of them selected the senses that remained, while the other two disagreed.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/agreement-1.pdf}
\caption{\label{fig:agreement}Agreement between annotators per batch per lemma, computed with \texttt{irr::kappam.fleiss()} \autocite{R-irr}.}
\end{figure}



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/final-agreement-1.pdf}
\caption{\label{fig:final-agreement}Number of tokens per lemma with full, partial (majority) or no agreement, split by whether the majority sense was kept or changed. Removed tokens are not included.}
\end{figure}

In addition, the final sense distribution is not significantly different from that in the much smaller pilot samples. Distribution across batches, instead, was affected by regional variation. For example, Belgian sources include more sports-related articles than the Netherlandic sources, leading to variation in the sense distribution of lemmas with such a sense (\emph{diskwalificeren} `to disqualify', \emph{haken} `to make someone trip' and \emph{horde} `hurdle') across regions. This discrepancy in distribution across batches could have been avoided if the tokens had been properly shuffled.

Around 4\% of all the assigned tags where ``None of the above'', with a clearly uneven distribution. The lemmas with the largest amount of were \emph{haken}, with 117 tokens in which three annotators chose ``None of the above'' and 72 in which two of them did. \emph{Heet} and \emph{harden} follow with 69 and 90 tokens with 3 such tags and 14 and 10 with two. Many of these were due to wrong lemmatization: the concordance of \emph{haken} had many instances of \emph{afhaken} `to stop' or \emph{met haken en ogen}, an idiomatic expression in which it is a noun; the concordances of \emph{heet} and \emph{harden} included instances of the verb \emph{heten} `to call, to be named' and the adjective \emph{hard} respectively. In a similar way, many of the tokens in the concordance of \emph{heffen} were instances of \emph{opheffen} `to lift/to cancel', but the annotators did not always catch these cases. The verbs \emph{afhaken} and \emph{opheffen} are separable verbs in Dutch: in some constructions, the prefix is separated from the root, so that a syntactic parser might confuse them with a different verb and a preposition. Next to these issues, annotators assigned ``None of the above'' in cases where the tokens did not match any of the suggested senses, especially in cases of idiomatic expressions such as \emph{hete aardappel} `hot potato'. All these annotations where classified in four categories: \texttt{wrong\_lemma}, for the cases of wrongly selected concordance lines, was assigned to 413; \texttt{not\_listed}, assigned 421 times, indicated that the lemma was correct but none of the suggestions applied; \texttt{unclear} (240 times) was used when the token could not be parsed by the annotator, and \texttt{between} (45 cases) referred to doubt between two or more of the given options. These different classes informed later decisions such as whether to add or remove senses or tokens.

Tokens were removed for different reasons. Next to the cases where the concordance line did not belong to begin with (including adverbial uses of the adjectives), there were some indecipherable tokens, extremely infrequent senses (e.g.~4, 5 tokens out of 250) and duplicated tokens. In total, 424 tokens were removed, 109 of which belonged to \emph{haken}.

Confidence values were explored but not used, because they tend to be similar across batches, lemmas and senses, with a tendency towards the highest values and variation across annotators instead: what is low confidence for some of them is high confidence for others. Figure \ref{fig:confidence} breaks this down in terms of the degree of agreement and whether the assigned tag matched one of the senses offered or not. Note that the top facet, ``None of the above'', has much lower counts than the lower facet. We would expect confidence ratings to be lower for annotations that do not agree with the other votes for the same token and, in relative terms, that is the case. Confidence assignment to a ``None of the above'' tag is ambiguous: some annotators tend to give them the minimum confidence because they are not confident about the meaning of the concordance line, while others assign a high value because they are confident that none of the other options applies.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/confidence-1.pdf}
\caption{\label{fig:confidence}Distribution of confidence values across annotations, by whether the annotators agreed with another in the same token and by whether they selected a sense or ``None of the above''.}
\end{figure}

The selection of cues was consulted when defining parameter settings (Section \ref{params}): if two annotators agreed on both the sense tag and a context word for a given token, that context word was considered an official \textbf{cue} for that sense. From the relative position representing the cue in the output of the annotation tool, other information available in the corpus could be extracted and counted, such as the lemma of the context word, its dependency relation (or distance) to the target and its \textsc{bow} distance to the target. For example, Tables \ref{tab:heilzaamdep} and \ref{tab:heilzaamcues} list the most frequent dependency paths, lemmas and window sizes across the official cues of \emph{heilzaam} `healthy/beneficial' for each of its senses. As we will see again in Section \ref{heilzaam}, this lemma is characterised by frequent nouns modified by the target, namely \emph{werking} `effect', \emph{effect} and \emph{invloed} `influence', which are ambiguous in terms of the senses of \emph{heilzaam}: in a sentence such as \emph{de heilzame werking van look} `the healing power of garlic', \emph{garlic} is a better cue in the `health/beneficial' distinction than \emph{werking} `effect, power'. Nonetheless, annotators did select these context words as cues for both senses, not realising that they were not distinctive of one or the other sense. The pattern fulfilled by \emph{garlic} in this example was indeed captured by some cues, as shown in the third line of Table \ref{tab:heilzaamdep}, but it is much less frequent.



\begin{table}

\caption{\label{tab:heilzaamdep}Four most frequent dependency paths among the cues of \emph{heilzaam}, with counts per sense. \texttt{NA} indicates that the cue is not in the sentence of the target. In the path, \texttt{CW} stands for the cue and \texttt{T} stands for the target: the head is at the left of \(\rightarrow\) and its dependents are to the right, preceded by the name of the dependency relation.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabu} to \linewidth {>{\raggedright\arraybackslash}p{11em}>{\raggedright\arraybackslash}p{11em}>{\raggedleft\arraybackslash}p{3em}>{\raggedleft\arraybackslash}p{3em}}
\toprule
path & examples & beneficial & healthy\\
\midrule
CW $\rightarrow$ mod:T & $\textbf{heilzame}$ $\textit{werking}$ 'healing $\textit{power}$' & 60 & 41\\
\addlinespace
NA & Different sentence & 13 & 32\\
\addlinespace
werking $\rightarrow$ [mod:T,mod:van $\rightarrow$ obj1:CW] & de $\textbf{heilzame}$ werking van $\textit{look}$ 'the healing power of $\textit{garlic}$' & 8 & 14\\
\addlinespace
ben $\rightarrow$ [predc:T,mod:voor $\rightarrow$ obj1:CW] & look is $\textbf{heilzaam}$ voor de $\textit{gezondheid}$ 'garlic is beneficial for the $\textit{health}$' & 7 & 1\\
\bottomrule
\end{tabu}}
\end{table}



\begin{table}

\caption{\label{tab:heilzaamcues}Six most frequent lemmas and window spans among the cues of \emph{heilzaam}, with counts per sense.}
\centering
\begin{tabular}[t]{lr>{}r|rrr}
\toprule
CW & healthy & beneficial & BOW & healthy & beneficial\\
\midrule
werking/noun & 20 & 12 & 1 & 74 & 48\\
effect/noun & 5 & 9 & 4 & 38 & 28\\
gezondheid/noun & 5 & 0 & 3 & 27 & 23\\
lichamelijk/adj & 4 & 0 & 2 & 18 & 22\\
medisch/adj & 4 & 0 & 5 & 21 & 20\\
\addlinespace
economie/noun & 0 & 4 & 6 & 21 & 14\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{ann-summary}{%
\section{Summary}\label{ann-summary}}

In this chapter we looked at the dataset used to test and explore the workflow and the visualization tools. The selection of lemmas was described along with the semantic phenomena they would allow us to test. Afterwards, the annotation procedure was delineated, from the extraction of concordances to the assignment of senses, confidence values and cues.

As was mentioned before, for each of the lemmas, 200-212 models were generated following the workflow described in Chapter \ref{workflow}. The cues selected by the annotators informed some of the decisions involved in the parameter settings. The sense annotation was applied to assess how well the models performed at disambiguation: initially, we did not try to match senses to clustering solutions, but looked for a spatial configuration that might hide more subtle relationships. As a few examples in Chapter \ref{nephovis} have shown, this is much more straightforward in some lemmas than in others.

The range of semantic phenomena was meant to provide different possible aspects of meaning that distributional models might be able to capture. From a lexicological point of view, ``similarity of distribution correlates with similarity of meaning'' is not enough. What is similarity of meaning?\footnote{Sahlgren restricts the notion of meaning, as it can be found in distributional models, to ``the meanings that are in the text'' \autocite*[49]{sahlgren_2008} and distinguishes between models that capture paradigmatic and syntagmatic relationships (without any further distinctions). Even if we \emph{could} be satisfied with such an answer, it only applies to type-level models.} Does this mean that more granular distinctions, such as senses within homonyms, will be more difficult to capture than coarser distinctions, i.e.~the homonyms themselves? Are metonymy, metaphor and specialization modelled by the same parameter settings? Can they be discriminated, can we fine-tune models to capture one or the other? And what is the role of constructions: does argument structure interfere in the modelling of senses?
These were the questions that the case studies presented here tried to address, and the following part of this dissertation will present the answers.

\hypertarget{part-the-cloudspotters-handbook}{%
\part{The cloudspotter's handbook}\label{part-the-cloudspotters-handbook}}

\hypertarget{shapes}{%
\chapter{A cloud atlas}\label{shapes}}

Clouds come in many shapes. Like the cotton-like masses of droplets we see in our skies, the clouds of word occurrences generated by token-level distributional models may take different forms, depending on their density, their size and their distinctiveness. ``Meaning is use'', ``Differences in usage correlate with differences in meaning'', ``You shall know a word by the company it keeps''\footnote{Attributed to Ludwig Wittgenstein, Zellig Harris and J. R. Firth respectively, as discussed previously.} and other such catchy slogans sound intuitively accurate, but they hide a wealth of complexity and variation. Like meaning, context is far from orderly, and a myriad of words with different characteristics interact to generate the variation we see in these clouds.

In this chapter, we will try to make sense of the nephological topology, i.e.~the variety of shapes that these clouds may take. For this purpose, we will classify \textsc{hdbscan} clusters mapped to t-\textsc{sne} representations in a way that can help us understand what we see when we see a cloud. The starting point is the shape that a researcher sees in the t-\textsc{sne} plot, which will be visually likened to types of meteorological clouds and further described in technical terms.

In Section \ref{theo2-rationale} we will discuss the rationale behind this particular classification and the tools used to operationalize these decisions. A more detailed description of each cloud type and their technical interpretations follows in Section \ref{cloud-types}, while Section \ref{cloud-patterns} zooms back out to compare the characteristics of the different types. Finally, we summarize the chapter in Section \ref{theo2-summary}.

\hypertarget{theo2-rationale}{%
\section{Rationale of the classification}\label{theo2-rationale}}

When we look at the t-\textsc{sne} plot of a token-level model, we might see different kinds of shapes. For example, Figure \ref{fig:grey6} shows the t-\textsc{sne} solution for the same parameter configuration in six different lemmas. Some of them have clear, neat islands that stand out against a large mass, while others look smooth and uniform. Even this uniformity might take rounder or more angular shapes, with bursts of density when three or four tokens get together. As we have mentioned before, a t-\textsc{sne} solution that looks very uniform typically means that the perplexity is too high, whereas too many small islands suggest that it is too low. However, the models never seem to look better in the other perplexity values we have explored\footnote{This can be checked in Level 2 of the visualization: \url{https://qlvl.github.io/NephoVis/}.}.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/grey6-1.pdf}
\caption{\label{fig:grey6}Uncoloured t-\textsc{sne} representations of the same parameter settings (bound5lex-\textsc{ppmi}selection-\textsc{foc}all) across six different lemmas.}
\end{figure}

Mapping an \textsc{hdbscan} clustering solution with \(minPts = 8\), like we do in Figure \ref{fig:coloured6} for the same models shown in Figure \ref{fig:grey6}, has proved to be a decent system for identifying the structure we see in these clouds. Clusters tend to match the tighter islands we see, and to highlight dense areas that might be too subtle for our eyes. In some cases, the clustering solution and the visualization do not agree, e.g.~clusters are spread around or overlap. This can be taken as a sign of uncertainty, as an indication that the group of tokens involved is much harder to describe and model that others in which both algorithms do agree.

At the stage of the distance matrix, we can establish, for each of our tokens, its similarity to any other token in the model. These similarities are independent from each other: until we do not transform them, they do not even need to respect the triangle inequality\footnote{The triangle inequality refers to a property of metric spaces, according to which the distance between point A and point B cannot be larger than the sum of the distances between A and C and between B and C.}. In contrast, both clustering and visualization add a layer of processing meant to find patterns of similar tokens that are different from the other tokens. The relationships between different pairs of tokens are not independent any more: nearest neighbours are the nearest because other tokens are farther away. Sometimes these patterns are easy to find, which leads to very nice, interpretable clouds, like the top plots in Figure \ref{fig:coloured6}; sometimes they are very hard to find, resulting in lots of noise and/or less defined clouds, like in the last two plots.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/coloured6-1.pdf}
\caption{\label{fig:coloured6}T-\textsc{sne} representations of the same parameter settings (bound5lex-\textsc{ppmi}selection-\textsc{foc}all) across six different lemmas, coloured coded with \textsc{hdbscan} clustering. Some of the \emph{heet} clusters are gray because there are more clusters than colours we can clearly distinguish.}
\end{figure}

In this chapter we will look at a classification of the possible shapes, what we know about their genesis and how we can interpret them. The term \emph{cloud} will refer to an \textsc{hdbscan} cluster or its noise: each of the coloured patches in the plots of Figure \ref{fig:coloured6}. The model itself, like a picture of the sky, might present multiple clouds of different types.

As we will see in Chapter \ref{semantic-interpretation} as well, the factors that interact to produce a group of similar tokens include the frequency of the context words, whether they co-occur within the sample and their type-level similarity. Clusters dominated by one context word may look similar to clusters dominated by a group of similar context words, and yet have different semantic interpretations. Along the way, we should keep in mind that the patterns observed here are tendencies, rather than rules: they are are a first map around an unknown land that still calls for more adventurous explorers.

The clouds have been classified into five main categories and an additional, orthogonal feature. The classification is based on a combination of t-\textsc{sne} visualization (perplexity 30) and \textsc{hdbscan} (\(minPts = 8\)) and it would probably be different if other visualization techniques or clustering algorithms are used.

The main categories, which will be described in more detailed in Section \ref{cloud-types}, are, in descending degree of clarity:

\begin{itemize}
\tightlist
\item
  Cumulus: the most defined clusters, revealing strong patterns that t-\textsc{sne} and \textsc{hdbscan} agree on;
\item
  Stratocumulus: a slightly looser definition of still decent clouds;
\item
  Cirrus: the weakest, smallest, less defined clouds, resulting from weaker patterns that might not be immediately evident without colour coding;
\item
  Cumulonimbus: massive clouds;
\item
  Cirrostratus: the \textsc{hdbscan} noise.
\end{itemize}

The inspiration for the names of the types of clouds is visual: the shapes that we would find when mapping the \textsc{hdbscan} clusters to the t-\textsc{sne} solution resemble the shapes of different types of meteorological clouds. Admittedly, for those who are familiar with meteorological types of clouds, this is not necessarily the most salient feature. Altitude, temperature and composition, instead, are more relevant in categorizing metereological clouds. As we will see in Section \ref{cloud-patterns}, it could be possible to map the \(\varepsilon\) (epsilon) values to the altitudes of the clouds, but that might already take the metaphor too far.

Technical criteria were defined in order to automatically categorize a large number of clusters. They are the result of both theoretical reasoning and trial and error, so that the final classification matches the intuitions derived from visual inspection. In other words: this classification should help us understand what we are looking at based on the shapes we identify, but technical, objective criteria were designed that approximate these intuitions for a larger scale analysis.
These criteria make use of (i) the noise category from \textsc{hdbscan}, (ii) the relative size of the cluster, (iii) separability indices, (iv) cosine distances between the tokens and (v) \(\varepsilon\) values.

Criteria (i) and (ii) are straightforward. Criterion (iii) refers to two measures developed within the \texttt{semvar} package \autocite{R-semvar,speelman.heylen_2017}, \texttt{kNN} and \texttt{SIL}: they assess how well the items are clustered based on a distance matrix. In this case, we are looking for the match between the \textsc{hdbscan} clusters, which take the role of classes, and the euclidean distances within the t-\textsc{sne} plot. Let's see how they work.

The first measure, \texttt{kNN}, is a separability index developed by \textcite{R-semvar} based on the proportion of ``same class items'' among the \(k\) nearest neighbours of an item. It answers the following question: looking at the \textsc{hdbscan} clusters mapped to the t-\textsc{sne} plot: how pure are the clusters? Do they form tight groups of the same colour, or do they overlap (maybe with noise tokens)? Recall that this has no bearing on the semantic composition of the cluster: instead, it refers to the visual homogeneity of the cluster as mapped to the plot.

For our purposes, it makes sense to set \(k\) to 8, the minimum number of tokens that a cluster should have based on the current \textsc{hdbscan} parameters. As a result, for each token \(x\) of a cluster \(C\), if the 8 tokens closest to \(x\) in the t-\textsc{sne} plot belong to the same \textsc{hdbscan} cluster \(C\), then \texttt{kNN} = 1, and if none of them do, then \texttt{kNN} = 0, regardless of what other class(es) the other items belong to. When the proportions are mixed, the ranking of the neighbours plays a role: if the tokens closest to \(x\) belong to \(C\), \texttt{kNN} will be higher; if instead they belong to another class, \texttt{kNN} will be lower. The \texttt{kNN} value of the cloud itself (\(C\)) is the mean of the \texttt{kNN} assigned to each of its members. A high \texttt{kNN} means that there are only a few instances of a different class mixed in among the tokens of the cloud: in other words, the cloud is quite compact and pure.
The problem with \texttt{kNN} is that it is biased in favour of large clouds. The larger the cloud is, the higher the proportion of tokens that is entirely surrounded by items of the same cluster. However, clusters with the same \texttt{kNN} and different sizes have different shapes. In order to counteract this bias, we include a \texttt{SIL} threshold.
\texttt{SIL}, or silhouette, is a popular measure of cluster quality that takes into account the distances between the members of a cluster and to the members outside that cluster \autocite{rousseeuw_1987}. When the tokens inside a cloud are much closer to each other than to tokens outside the cloud, \texttt{SIL} is highest, with an upper bound of 1. If the cloud is very spread out and/or other clouds are very close by, e.g.~because they overlap, \texttt{SIL} will go down. Thus, a combination of high \texttt{kNN} and high \texttt{SIL} results in more compact, homogeneous, isolated clouds.

Criteria (iv) and (v) are the distances between the tokens belonging to the same cluster and the \(\varepsilon\) values respectively. The former refer to the original cosine distances between the tokens of the same cluster: the lower they are, the more similar the tokens are to each other. These may be different from the euclidean distances based on the t-\textsc{sne} plot.
Finally, \(\varepsilon\) values are extracted from the \textsc{hdbscan} clustering and were explained in Chapter \ref{hdbscan}. The lower the \(\varepsilon\), the denser the area of the token, i.e.~the smaller the area covered by its nearest neighbours. Noise tokens have typically the highest \(\varepsilon\) values: they are very disperse, and therefore the radius required to find 8 near neighbours is larger. The members of a cluster might have a variety of \(\varepsilon\) values: the lower the \(\varepsilon\), the closer it is to the core, i.e.~the denser area of the cluster. To be clear, I am not making any claims about the technical or semantic interpretation of \(\varepsilon\) right now. A brief discussion on this is given in Chapter \ref{semantic-interpretation}. Instead, the utility of these values lies in their straightforward mapping to the visual effects of the plot. If the \(\varepsilon\) values of a clustered token are close to those of noise tokens, the cluster is, in a way, submerged in noise: \textsc{hdbscan} is finding patterns that t-\textsc{sne} does not. On the contrary, if the \(\varepsilon\) values are much lower than for noise tokens, the cloud stands out.

The five criteria are combined in the following algorithm to classify the different clusters.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The noise is categorised as a Cirrostratus cloud.
\item
  The clusters that cover at least 50\% of the modelled tokens (including noise) are Cumulonimbus clouds.
\item
  The clearest, roundest, densest clusters are Cumulus clouds. They must at least have a \texttt{kNN} \(\ge\) 0.75, \texttt{SIL} \(\ge\) 0.5 and mean cosine distance \(\le\) 0.5. In addition, less than 10\% of the tokens in the cluster may have a higher \(\varepsilon\) than the lowest noise \(\varepsilon\), or the noise in the model must cover less than 10\% of the tokens.
\item
  The smallest clusters, i.e covering less than 10\% of the modelled tokens, if 75\% of the model is noise or \texttt{kNN} \textless{} 0.7, are Cirrus clouds.
\item
  The most decent of the remaining clusters are Stratocumulus clouds. They must have \texttt{kNN} \(\ge\) 0.7, \texttt{SIL} \(\ge\) 0.5 or mean distance \(\le\) 0.2. In addition, either more than half of the tokens have lower \(\varepsilon\) than the noise tokens or no more than 10\% of the modelled tokens are noise.
\item
  The remaining clusters are Cirrus clouds.
\end{enumerate}

In addition, the category of Hail groups the clouds with at least 8 identical tokens; these can belong to any of the other classes.

Table \ref{tab:cloudFreqs} shows the number of clouds, either in medoid models or across all models, belonging to each of the categories. By definition, almost all models have a Cirrostratus cloud, i.e.~noise tokens, and no more than one Cumulonimbus cloud, i.e.~massive cloud. The rest of the clouds may occur more than once in the same model. The number of clouds that also belongs to the Hail category is given in parentheses.

\begin{table}

\caption{\label{tab:cloudFreqs}Number of clouds of each type per medoid or model in general; in parenthesis, the number of Hail clouds is specified.}
\centering
\begin{tabular}[t]{lll}
\toprule
Cloud type & Clouds in Medoids & All clouds\\
\midrule
Cumulus & 267 (25) & 6899 (459)\\
Stratocumulus & 412 (34) & 8777 (692)\\
Cirrus & 342 (2) & 9477 (32)\\
Cumulonimbus & 42 (15) & 1025 (221)\\
Cirrostratus & 254 (1) & 6453 (3)\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{cloud-types}{%
\section{Types of clouds}\label{cloud-types}}

In this section, the different cloud shapes will be described in some detail. Their general look on a plot will be compared to pictures of meteorological clouds and I will offer a technical interpretation for them.

Before going into the descriptions, an explanation of one of the measures that takes part in the technical interpretation is in order: the \(F\)-score.
Clouds can be represented by the set of context words co-occurring with the tokens that compose it. The relationship between each context word \(cw\) and the cluster may be described in terms of precision and recall, already mentioned in Section \ref{shiny}: \textbf{precision} indicates the proportion of tokens co-occurring with \(cw\) that also belong to the cluster, while \textbf{recall} indicates the proportion of tokens within the cluster that co-occur with \(cw\). For example, if all the tokens in a cluster co-occur with the definite determiner \emph{de}, \emph{de} has a recall of 1 for that cluster; but in all likelihood, these tokens only constitute around 40\% of the tokens co-occurring with \emph{de} across the sample, resulting in a precision of 0.4. Both values can be summarized in an \(F\)-score, which is defined as the (weighted) harmonic mean of precision and recall. In this case, the unweighted \(F\), that is, where precision and recall are deemed equally important, equals 0.57. The higher the \(F\), the better the representativeness of the context word in relation to the cluster: an \(F\) of 1 indicates that all the tokens co-occurring with that word belong to that cluster, and all the tokens in that cluster co-occur with that word, while an \(F\) of 0 indicates the absolute lack of overlap between the domain of the context word and the clouds.
When a context word has a high \(F\) in relation to a cluster, that cluster is \emph{dominated} by the context word. This is a handy term that will come up frequently as I describe types of clouds, and especially in Chapter \ref{semantic-interpretation}. In general, only context words that co-occur with at least two tokens within a cluster are considered, to avoid inflating the value of \emph{hapax legomena}.

\hypertarget{cumulus-clouds}{%
\subsection{Cumulus clouds}\label{cumulus-clouds}}

In meteorological terms, Cumulus clouds look puffy: they are our prototypical and ideal images of clouds. As token-level clouds, they also correspond to our ideal images of clusters: mostly roundish, visually salient because of their density and isolation. We would be able to find them even without colour-coding: both t-\textsc{sne} and \textsc{hdbscan} agree that those tokens belong together.
In Figure \ref{fig:cumulus}, the four rightmost clusters, in green, light blue, yellow and blue, are Cumulus; the rest are Stratocumulus clouds.



\begin{figure}
\includegraphics[width=0.5\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/cumulus} \includegraphics[width=0.5\linewidth]{phdThesis_files/figure-latex/cumulus-2} \caption{Example of Cumulus cloud: inspiration on the left, plot example on the right (nobound10lex-\textsc{ppmi}weight-\textsc{foc}all of \emph{dof}). Picture by Glg, edited by User:drini - photo taken by Glg, CC BY-SA 2.0 de, \url{https://commons.wikimedia.org/w/index.php?curid=3443830}.}\label{fig:cumulus}
\end{figure}

Cumulus clouds are defined by a number of different measures with strict values, after excluding Cirrostratus (noise) and Cumulonimbus (massive clouds).
First, the clusters need to have both \texttt{kNN} \(\ge\) 0.75 and \texttt{SIL} \(\ge\) 0.5, as well as a mean pairwise cosine distance between the tokens of 0.5 or lower. The combination of these three strict thresholds ensures quite pure, compact, isolated clusters: they don't visually overlap with other clusters or noise. The final requirement makes sure that the cloud stands out against the noise. One of the ways it can achieve this is by having an \(\varepsilon\) lower than the minimum noise \(\varepsilon\) in at least 90\% of the tokens: at least 9 out of 10 tokens stand out. However, in models without any noise or with very little, noise \(\varepsilon\) values might be particularly high, so this threshold is not applied in models with less than 10\% noise.

Most of these clouds are characterized by one context word with high precision and recall for the cluster. In fact, 75\% of these clouds have a context word with an \(F\) of
0.72 or higher, while in 75\% of the rest of the clouds the highest \(F\) is lower than that. These top context words also tend to have high \textsc{pmi}, but some may even have negative \textsc{pmi}.

The lemmas with the highest proportion of Cumulus clouds are \emph{heffen} `to levy/to lift', \emph{hachelijk} `dangerous/critical', \emph{schaal} `scale/dish', \emph{gemeen} `common/mean\ldots{}' and \emph{stof} `substance/dust\ldots{}'. They are all cases with strong collocational patterns of the kind discussed in Section \ref{collocation}. Lemmas that repel Cumulus clouds, on the other hand, such as \emph{haten} `to hate', \emph{geestig} `witty', \emph{gekleurd} `coloured' and \emph{hoekig} `angular', lack such collocational patterns and instead form more uniform, fuzzy pictures.

\hypertarget{stratocumulus-clouds}{%
\subsection{Stratocumulus clouds}\label{stratocumulus-clouds}}

In meteorological terms, Stratus clouds are flat or smooth clouds: Stratocumulus clouds are then a flatter, less compact version of the Cumulus clouds discussed above. In Figure \ref{fig:stratocumulus}, all three clouds are Stratocumulus: from the large, disperse light blue cloud, to the more stretched orange one and the more compact green cloud that lost three points in the bottom right.



\begin{figure}
\includegraphics[width=0.5\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/stratocumulus} \includegraphics[width=0.5\linewidth]{phdThesis_files/figure-latex/stratocumulus-2} \caption{Example of Stratocumulus cloud: inspiration on the left, plot example on the right (bound5all-\textsc{ppmi}no-\textsc{foc}all of \emph{heffen}). Picture by Joydeep - Own work, CC BY-SA 3.0, \url{https://commons.wikimedia.org/w/index.php?curid=20357040}.}\label{fig:stratocumulus}
\end{figure}

The definition of Stratocumulus clouds takes a number of different measures and applies less strict thresholds than for Cumulus clouds. First the Cirrostratus, Cumulonimbus and Cumulus must classified, and the smallest clouds, either in noisy models or without high \texttt{kNN}, must be reserved for Cirrus. On the remaining clouds we apply two filters. First, they must either have \texttt{kNN} \(\ge\) 0.7, \texttt{SIL} \(\ge\) 0.5 or mean pairwise cosine distance \(\le\) 0.2. Second, either more than half the tokens have an \(\varepsilon\) value below the minimum noise \(\varepsilon\) value or the percentage of noise tokens in the model is lower than 10\%.

Stratocumulus clouds are generally large: while 75\% of either Cumulus or Cirrus have
28 tokens or fewer, half the Stratocumulus have 26 or more.
However, in comparison to Cirrus they tend to have lower type-token ratio of context words\footnote{Either counting all context words in the cluster or just those that are enough to cover the tokens.} and higher \(F\) values of their representative context words. In addition, the mean cosine distance between the tokens tend to be comparable to that in Cirrus clouds, in spite of the difference in size: in other words, they are larger but more compact and more clearly defined.

While lemmas that prefer Cumulus clouds tend to avoid Cirrus clouds and vice versa, the relationship with Stratocumulus is not so straightforward. A preference for Cumulus tends to go hand in hand with a preference for Stratocumulus, as in the case of \emph{heffen} `to levy/to lift', but that is not necessarily the case. Both \emph{gemeen} `common/mean\ldots{}' and \emph{stof} `substance/dust\ldots{}' prefer Cumulus against either Cirrus or Stratocumulus, and \emph{haten} `to hate', which prefers Cirrus to Cumulus, does have a slight preference for Stratocumulus too. One lemma that prefers Stratocumulus over anything else is \emph{heilzaam} `healthy/beneficial', which is described in Section \ref{heilzaam}: even though its clusters tend to be dominated by clear collocates of the target, they are semantically heterogeneous.

\hypertarget{cirrus-clouds}{%
\subsection{Cirrus clouds}\label{cirrus-clouds}}

From a meteorological perspective, Cirrus clouds are high up and wispy. In these plots, the description translate to typically small, disperse clouds that we might not be able to isolate without the help of \textsc{hdbscan}. In Figure \ref{fig:cirrus}, both clouds belong to this category.



\begin{figure}
\includegraphics[width=0.5\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/cirrus} \includegraphics[width=0.5\linewidth]{phdThesis_files/figure-latex/cirrus-2} \caption{Example of Cirrus cloud: inspiration on the left, plot example on the right (bound5all-\textsc{ppmi}selection-\textsc{foc}all of \emph{herstructureren}). Picture by Dmitry Makeev - Own work, CC BY-SA 4.0, \url{https://commons.wikimedia.org/w/index.php?curid=85153684}.}\label{fig:cirrus}
\end{figure}

Cirrus clouds are defined as small clouds in noisy models or with a low \texttt{kNN}, i.e.~substantial overlap between the cloud and other clusters or noise tokens, as well as the remainder of the clouds after defining the other four categories.
They are generally small, like Cumulus clouds: in a few cases they cover more than 100 points, and they would be considered Stratocumulus if their \texttt{SIL} was higher and either their \texttt{kNN} or the percentage of tokens below noise was higher too.
In spite of their size, they have a high type-token ratio of context words and these context words have low \(F\), even compared to larger Stratocumulus clouds: in other words, they tend not to be represented by single powerful collocates, and instead their tokens co-occur with many different, infrequent words.

The weakness of their patterns should be seen as a tendency, rather than a law. They are more likely than Cumulus clouds to be semantically heterogeneous and hard to interpret, but it is not necessarily the case. In some lemmas with tendency to a more uniform internal structure, Cirrus clouds may group the few patterns that emerge at all.
Lemmas that prefer Cirrus clouds, such as \emph{geestig} `witty', \emph{gekleurd} `coloured', \emph{hoekig} `angular' and \emph{haten} `to hate', are precisely characterized by uniform-looking plots, low frequency collocates and weak patterns overall.

\hypertarget{cumulonimbus-clouds}{%
\subsection{Cumulonimbus clouds}\label{cumulonimbus-clouds}}

In the physical world, Cumulonimbus clouds are puffy (as indicated by the prefix \emph{Cumulo-}) and bring rain and storm (\emph{nimbus}). They are massive, towering clouds that may lie as low as Cumulus clouds and reach as high as Cirrus clouds. In our models, the Cumulonimbus category (the largest cluster in Figure \ref{fig:cumulonimbus}) is the least frequent, but when it does occur, it dominates the picture.

Cumulonimbus clouds are minimally defined as clouds that cover at least 50\% of the modelled tokens, including those discarded as noise. In practice, half of them cover at least 58.7\% of the model or more, reaching as much as 95.7\%.
Next to them, we typically have one more cluster (in 85.6\% of the cases);
occasionally we may have two (11.1\%) or even up to 5.
The smaller cluster next to the massive Cumulonimbus tends to be a Cumulus, but all combinations are attested.



\begin{figure}
\includegraphics[width=0.5\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/cumulonimbus} \includegraphics[width=0.5\linewidth]{phdThesis_files/figure-latex/cumulonimbus-2} \caption{Example of Cumulonimbus cloud: inspiration on the left, plot example on the right (bound10all-\textsc{ppmi}weight-\textsc{foc}all of \emph{stof}). Picture by fir0002flagstaffotos {[}at{]} gmail.comCanon 20D + Canon 17-40mm f/4 L, GFDL 1.2, \url{https://commons.wikimedia.org/w/index.php?curid=887553}.}\label{fig:cumulonimbus}
\end{figure}

The most typical situation in which we encounter a Cumulonimbus cloud is when a small group of tokens is very tight, but very different from everything else, and the rest of the tokens are not distinctive enough to form different clusters. Most of these tokens are then grouped in this large, normally disperse Cumulonimbus cloud, which may seem to have inner structure captured by t-\textsc{sne} but not by \textsc{hdbscan}. The small group of tokens may be brought together by a set of similar context words (see Section \ref{semantic-preference}), but most typically they represent an idiomatic expression.

In fact, the lemmas with a strong preference for this format, with Cumulonimbus in more than a third of their models, have a very clear idiomatic expression responsible for the small Cumulus clouds, so that the differences among the rest of the tokens are smoothed. These are \emph{gemeen} `common/mean\ldots{}', \emph{stof} `substance/dust\ldots{}' and \emph{schaal} `scale/dish'. In contrast, lemmas that barely have any Cumulonimbus clouds (in less than 5\% of the models), such as \emph{herroepen} `to recant/to void', \emph{hoekig} `angular', \emph{diskwalificeren} `to disqualify' and \emph{horde} `horde/hurdle', lack such a strong pattern and have groups with similar frequencies and mutual differences instead.

In the case of \emph{gemeen} `common/mean\ldots{}', the tight cloud represents the expression \emph{grootste gemene deler} `greatest common divisor': both \emph{groot} `big, great' and \emph{deler} `divisor' co-occur with a large number of tokens but are, at the type-level, different from each other and to everything else. As a result, the token-level vectors of the \emph{grootste gemene deler} `greatest common divisor' tokens will be very similar to other tokens instantiating the same expression, and very different from everything else. Similarly, the pattern most frequently tied to this phenomenon in the case of \emph{stof} `substance/dust\ldots{}' is \emph{stof doen opwaaien} `lit. to stir up dust', an idiomatic expression referring to controversial actions and situations. \emph{Schaal} `scale/dish', on the other hand, has two main idiomatic contexts that generate Cumulonimbus clouds, discussed in Section \ref{schaal}.

The rest of the tokens, i.e.~the Cumulonimbus cloud itself, is not defined by either a strong dominating context word or group of similar context words, but instead is defined against this stronger, small cloud. Cumulonimbus clouds are not huge clouds of similar tokens, but a mass of tokens that is not structured enough in opposition to the distinctive small cloud that is next to it. It may have dense areas inside of it, but they are not semantically linked to each other. The reason they are a cluster is not because the tokens are similar to each other, as much as because the tokens in the small partner are very coherent and different from everything else. The mean distance between tokens in a Cumulonimbus cloud is typically very large, sometimes as large as within Cirrostratus (noise), and significantly larger than within other kinds of clouds --- although the few examples of Cirrus and Stratocumulus co-occurring with Cumulonimbus also have relatively large mean distances.
For a discussion on the semantic interpretation of these clouds, see Section \ref{openchoice}.

\hypertarget{cirrostratus-clouds}{%
\subsection{Cirrostratus clouds}\label{cirrostratus-clouds}}

In meteorological terms, Cirrostratus clouds are high (\emph{Cirro-}), flat and smooth (\emph{-stratus}) clouds. For our purposes, they just indicate the noise tokens. They lie in the background of (almost) all our clouds and constitute 100\% of two of the medoids. Considering the entirety of the models, 146 (2.3\%) of them are fully Cirrostratus clouds (Figure \ref{fig:cirrostratus}).



\begin{figure}
\includegraphics[width=0.5\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/cirrostratus} \includegraphics[width=0.5\linewidth]{phdThesis_files/figure-latex/cirrostratus-2} \caption{Example of Cirrostratus cloud: inspiration on the left, model with 100\% noise on the right (nobound10lex-\textsc{ppmi}no-\textsc{foc}all of \emph{hoopvol}). CC BY-SA 3.0, \url{https://commons.wikimedia.org/w/index.php?curid=100381}.}\label{fig:cirrostratus}
\end{figure}

It might be interesting to cluster the subset of tokens that make up these clouds, at least for some lemmas, but that is not pursued in these studies. It would require a deeper investigation of how \textsc{hdbscan} works with these models, why tokens are sometimes not clustered and how it interacts with parameters like \(minPts\). I will not try to semantically interpret these clouds, but they are always present and affect how other clouds are defined.

\hypertarget{hail}{%
\subsection{Hail}\label{hail}}

The final, orthogonal category can apply to any cloud, and often describes a section of it rather than the full cloud. It responds to a special criterion, to highlight the occasional phenomenon of superdense clusters. In Figure \ref{fig:hail}, three of the clouds (light blue, yellow and red) are Cumulus, while the rest are Stratocumulus; all of them but the yellow and green clouds present Hail, that is, extremely tight, dense circles of identical tokens. These are clouds with at least 8 identical tokens, defined as having a cosine distance lower than \(\ensuremath{10^{-6}}\).

As we can see in the blue cloud, one cluster may have more than one piece of Hail, as is the case in some Cumulonimbus clouds. In fact, in relative numbers, the cloud type with a higher tendency to generate Hail is the Cumulonimbus
(in 21.56\% of the cases), which is very fitting for a cloud that brings storms. Overall,
5\% of the clouds, in 924 different models, have these characteristics.



\begin{figure}
\includegraphics[width=0.5\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/hail} \includegraphics[width=0.5\linewidth]{phdThesis_files/figure-latex/hail-2} \caption{Example of cloud with hail: inspiration on the left, plot example on the right (\textsc{rel}1-\textsc{ppmi}selection-\textsc{foc}all of \emph{heet}). Picture by Tiia Monto, CC BY-SA 3.0, \url{https://commons.wikimedia.org/w/index.php?curid=88743807}}\label{fig:hail}
\end{figure}

These conditions are prompted by a low number of context words per token and a low type-token ratio (\textsc{ttr}) of these context words (see Figure \ref{fig:cwFreq}).
TTR is a measure of complexity computed as the number of different context words, i.e.~types, divided by the total number of occurrences, i.e tokens. A \textsc{ttr} of 1 indicates that all words are only used once, while a lower \textsc{ttr} results from different words occurring multiple times. In this case, the higher the \textsc{ttr}, the richer the variety of context words captured by the model for the tokens in the cluster.
Hail only covers a minority of the clouds, but it is clear that both the \textsc{ttr} and the number of context words per token play a role, with lower values for the Hail clouds.
Hail tends to emerge in very restrictive models where many tokens can be grouped together because they have identical vectors: they shared the few words that survived the thresholds. They often reveal the strongest context words, i.e.~those that also dominate in other clouds. But as we will see in Section \ref{collocation}, the dominating context word is not always indicative of a sense. Moreover, a larger variation in the context can give us a richer, more nuanced picture of the distributional behaviour of the target word.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/cwFreq-1.pdf}
\caption{\label{fig:cwFreq}Mapping between the type-token ratio of the context words and the mean number of context words per token in a cluster of a medoid, by whether the cloud has Hail.}
\end{figure}

We might be tempted to consider these clouds idiomatic expressions: they match, visually, what we think a representation of idiomatic expressions would be like. Instead, they match groups of context words that occur very frequently in a very short distance (either in terms of bag-of-words or dependency relations) to the target. It tells us something about bigrams: about how often \emph{niet} `not' occurs close to \emph{harden} `to tolerate'; \emph{van} `of' to \emph{staal} `steel/sample', \emph{op} `on' to \emph{spot} `spotlight', or \emph{hang\_ijzer} `iron' to \emph{heet} `hot'. At the same time, all the \emph{harden} `to tolerate' tokens co-occurring with \emph{niet} `not' are brought together in one pattern that disregards any other possible co-occurrence, any possible internal variation.

\hypertarget{cloud-patterns}{%
\section{Patterns across types of clouds}\label{cloud-patterns}}

Beyond the features used as formal criteria to define the types of clouds, we can find patterns across other relevant features. Most of these features are technical properties that can be extracted automatically from our dataset: the representativeness of context words \(F\), their \textsc{pmi} with the target lemma, the type-token ratio of context words co-occurring with the tokens in a cluster (\textsc{ttr}), and their \(\varepsilon\) values. In addition, we will take advantage of the semantic annotation and look at the entropy of the clouds, i.e.~how homogeneous they are in terms of dictionary senses. The figures in this section represent clusters in the medoids, because including all the models results in a more cluttered version of the same patterns.

First, we will look at the properties of the most representative context word in each cluster, defined as the context word with a minimum frequency of 2 within the cluster and the highest \(F\)-score (explained in Section \ref{cloud-types}). Figure \ref{fig:fscorePmi} plots the context words' \(F\) on the horizontal axis and, on the vertical axis, their \textsc{pmi} with the corresponding target lemma, based on a symmetric window of 4 words to either side. The types of clouds are mapped to the colour of the points and the fill of the marginal boxplots. Therefore, a bright purple spot at \(x = 0.941\) and \(y = 9.89\) represents a Cumulus cloud whose most representative context word, e.g.~\emph{deler} `divisor', has an \(F\) of 0.941, i.e.~it is a very good cue, and a \textsc{pmi} with the lemma of its model, e.g.~\emph{gemeen}, equal to 9.8, which is very high.

We can see that Cirrostratus clouds (noise) tend to have low \(F\) context words, and that these tend to have very low \textsc{pmi} values with the targets. Cumulus clouds, on the other side, have the highest \(F\), i.e.~they tend to be dominated by one context word, and these context words tend to have high \textsc{pmi}. Cirrus and Cumulonimbus clouds have lower values than Cumulus clouds across both dimensions, while Stratocumulus spans in between. Moreover, the correlation between \(F\) and \textsc{pmi} is moderate to weak, with a higher value among Cumulus clouds (Spearman's \(\rho\) = 0.55, p-value \textless{} 0.001) and much lower and/or less significant for Cumulonimbus and Cirrostratus
(\(\rho\) = 0.05, p-value \(\approx\) 0.085 and \(\rho\) = -0.15, p-value \textless{} 0.001, respectively), with minimal changes for different \texttt{PPMI} settings.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/fscorePmi-1.pdf}
\caption{\label{fig:fscorePmi}Mapping between the highest \(F\) between the clouds of the medoids and a context word and that context word's \textsc{pmi} with the target, coloured by cloud type.}
\end{figure}

Second, we will look at the relationship between the highest \(F\)-score and the type-token ratio (\textsc{ttr}, described in Section \ref{hail}). They are mapped to the horizontal and vertical axes respectively in Figure \ref{fig:ttFscore}. As we can see, both Cirrus and Cirrostratus clouds tend to have a higher \textsc{ttr} than the rest; indeed, they also tend not to have Hail (see Table \ref{tab:cloudFreqs}). In general, the more different context words we find in the cluster --- the higher the \textsc{ttr} ---, the lower is the representativity of the strongest context word --- the lower the \(F\) ---, but there is a really wide range of variation, and each type of cloud has a different profile. Cirrostratus clouds have higher \textsc{ttr} and lower \(F\), while the opposite defines Cumulus clouds; Stratocumulus and Cumulonimbus clouds have similar \textsc{ttr} to Cumulus but lower or much lower \(F\), and the \textsc{ttr} in Cirrus clouds is comparable to Cirrostratus, with a much higher \(F\)-score.
In short, both the variety of context words co-occurring with the tokens of a cluster and the \(F\)-score of the most relevant of them play a role in the shape that the clouds take. This relationship notwithstanding, we should note that other factors also intervene, both in the constitution of the clusters and their semantic interpretation, such as the representativeness of other context words and the type-level distances between them.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/ttFscore-1.pdf}
\caption{\label{fig:ttFscore}Mapping between the highest \(F\) of a context word to a cluster and the type-token ratio (\textsc{ttr}) of context words in the cluster, coloured by cloud type.}
\end{figure}

Third, we will look at the \(\varepsilon\) values across different cloud types. They were part of their definition, insofar the proportion of tokens with a lower \(\varepsilon\) than the lower noise \(\varepsilon\) is a criterion for Cumulus, Stratocumulus and Cirrus clouds. Nevertheless, it could be useful to summarize the resulting patterns. In that spirit, Figure \ref{fig:epsplot} shows, for each of the clusters in the medoids, the minimum, mean and maximum \(\varepsilon\) within a cluster. Note that this gives us no insight on the relationship between the \(\varepsilon\) of the tokens in the cluster and the values in other tokens, either clustered or noise.
As we would expect, Cirrostratus clouds tend to have the highest \(\varepsilon\): their tokens are disperse, far away from other tokens. Cumulus, Stratocumulus and Cirrus tend to have relatively similar values, although some Cumulus clouds are quite low and Cirrus clouds are quite flat and never very low. The differences between them are more likely to be found in their relationship with the noise \(\varepsilon\). Cumulus clouds stand out as dense areas against a very disperse (i.e.~high \(\varepsilon\)) background, whereas Cirrus clouds are just slightly denser than the rest of the clouds in their surroundings. Think of the uniform plots of \emph{haten} and \emph{hoop} in Figure \ref{fig:grey6} and the \textsc{hdbscan} interpretation in Figure \ref{fig:coloured6}: all the tokens look, roughly, equally disperse. Finally, Cumulonimbus clouds exhibit the widest range of all: their tokens vary from very dense areas, i.e.~very low \(\varepsilon\), to very disperse ones, i.e.~high \(\varepsilon\).



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/epsplot-1.pdf}
\caption{\label{fig:epsplot}Range of \(\varepsilon\) values within clouds of different types. Lines join the points belonging to the same cluster.}
\end{figure}

These characteristics can be roughly mapped to the altitude of the clouds from a meteorological perspective (see Figure \ref{fig:cloudtypes}). Figure \ref{fig:epsplot} relies on a common everyday metaphor: high values above, low values below. But what counts as high and low here is rather arbitrary: low \(\varepsilon\) indicates a dense area in the plots, that is, that a token can find its 7 nearest neighbours in a very small radius, while a high \(\varepsilon\) indicates a sparse area, with large distances between a token and its nearest neighbours. At the same time, the metaphor of altitude is also coherent with the original goal of this mapping: the low values, or high densities, stand out to the viewer as if they were closer. Similarly, if we look at clouds on the sky from below, lower clouds are going to stand out: that is the case of Cumulus, Stratocumulus and, naturally, Cumulonimbus clouds.



\begin{figure}
\includegraphics[width=1\linewidth]{C:/Users/u0118974/OneDrive - KU Leuven/repos/montesmariana/phdThesis/assets/img/cloudtypes} \caption{Graphical representation of meteorological clouds at different altitudes. By Christopher M. Klaus at w:en:Argonne National Laboratory - Own work by en:User:Klaus, Public Domain, \url{https://commons.wikimedia.org/w/index.php?curid=2760873}}\label{fig:cloudtypes}
\end{figure}

Finally, Figure \ref{fig:cloudentropy} shows the entropy\footnote{Computed with \texttt{entropy::entropy()} \autocite{R-entropy}.} of clouds of different types in terms of the manually annotated senses, against the entropy across the whole model. Entropy is a measure of information, and in this case it works as follows: the higher the entropy, the more variation of senses and the more balanced their frequencies; the lower the entropy, the more one sense dominates. We would like the entropy of the cluster (the \(y\)-axis in Figure \ref{fig:cloudentropy}) to be as low as possible, that is, for the cluster to be as homogeneous as possible in terms of senses. At the same time, models with a higher initial entropy --- due to the sense distribution of the lemmas they model --- are more likely to have clusters with higher entropy.

On the one hand, the horizontal boxplots show that clouds of all types are equally likely to emerge in any model regardless of their sense distribution. This is consistent with the point I make in Chapter \ref{semantic-interpretation} that clouds do not model senses. On the other hand, the vertical boxplots show that the different cloud types do tend to exhibit different entropy values. Cumulus clouds are the most homogeneous, while the Cumulonimbus clouds tend to be as heterogeneous as Cirrostratus (noise) --- they might even have higher entropy than their models as a whole. Cumulus clouds in particular, but sometimes also Stratocumulus and maybe Cirrus, may be completely homogeneous regardless of the sense composition of the model itself, but they can also have higher entropy. Stratocumulus clouds tend to have slightly lower entropy than Cirrus clouds, i.e.~they tend to be more homogeneous, even though they also tend to be larger.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/cloudentropy-1.pdf}
\caption{\label{fig:cloudentropy}Mapping between the entropy in a medoid and in a cluster by cloud type.}
\end{figure}

\hypertarget{theo2-summary}{%
\section{Summary}\label{theo2-summary}}

Token-level distributional models process a wealth of complex, messy information and try to return clear, interpretable patterns. These patterns take different forms: sometimes we have very clear, isolated, dense groups of similar tokens, like our ideal image of clouds in a clear sky; other times, a pattern is harder to find, and we barely catch a few clear wisps against an overcast sky. The clouds of one model are not independent from each other, and depending on the power of their leading context words they might merge into larger masses or split into smaller groups; powerful small Cumulus clouds may force everything else into a huge Cumulonimbus clouds, and the tension between its semantic fields might even create Hail.

In this chapter we have seen the variety of shapes that emerges from these distributional models, in particular in the interaction between the t-\textsc{sne} visualization with perplexity 30 and the \textsc{hdbscan} clustering with \(minPts = 8\). We have linked the visual results to the variety of context words and their representativeness, and we have found patterns in their semantic homogeneity. We know that all lemmas exhibit all types of clouds, but in different proportions, related to their tendency towards strong collocational patterns. In the next chapter, we will delve into the linguistic interpretation of these clouds, that is, their collocational properties and their relationship to the manually annotated dictionary senses.

\hypertarget{semantic-interpretation}{%
\chapter{The language of clouds}\label{semantic-interpretation}}

In linguistic terms, clouds may provide us with different types of information, both at syntagmatic and paradigmatic level. At the syntagmatic level, they may illustrate cases of collocation, colligation, semantic preference or even tendencies towards the open-choice principle. The paradigmatic level, on the other hand, codes the relationship between the clusters and dictionary senses, from heterogeneous clusters to those that represent (proto)typical contexts of a sense.

Given a naive understanding of the correlation between context and meaning, we would mostly expect, from the paradigmatic perspective, clusters that equal senses: each cloud would cover all the occurrences of a dictionary sense and only the occurrences of that sense. However, even if we relax the requirements, expecting \emph{mostly} homogeneous clusters covering \emph{most} of the \emph{clustered} tokens, this does not arise often. Instead, even homogeneous clusters only group typical contexts within a sense, which, at the syntagmatic level, tend to correspond to collocations. In any case, as we will see in this chapter, the full picture is more complex, and we can obtain much richer information than just lexical collocations representing typical contexts within a sense.

In this chapter, we will look into the types of syntagmatic and paradigmatic information that the clouds offer. Section \ref{infotypes} starts with an overview of the different levels in each dimension and mentions a few examples of their interaction in a contingency table. We then elaborate with more detailed examples of each in situation in sections \ref{collocation} through \ref{openchoice}, and round up with an overall summary in Section \ref{theo1-summary}.

\hypertarget{infotypes}{%
\section{Types of information}\label{infotypes}}

The linguistic information obtainable from the clusters can be understood from the syntagmatic perspective as co-occurrence patterns of different kinds, and from the paradigmatic perspective in relation to dictionary senses. Both dimensions interlace, resulting in a number of specific phenomena that we may encounter. The relationship is summarized in Table \ref{tab:colsem}; the syntagmatic or collocational dimension is represented by the columns and discussed in Section \ref{collocationally}, and the paradigmatic or semantic dimension is represented by the rows and discussed in Section \ref{semantically}.

\hypertarget{collocationally}{%
\subsection{Collocational perspective}\label{collocationally}}

In order to interpret the different levels of information that a syntagmatic or collocational perspective may offer us, we can make use of some theoretical concepts from the foundations of Corpus Linguistics. Some of the terms were already coined by \textcite{firth_1957a}, but they were integrated in a framework for corpus analysis by \textcite[124-125]{sinclair_1998} and other publications. The framework includes, next to the node, i.e.~our targets, four key components: one obligatory --- semantic prosody, which will not be discussed here --- and three more that will help us make sense of the observed output of the clouds: collocation, colligation and semantic preference.

In their simplest form, \textbf{collocations} are defined as the co-occurrence of two words within a certain span \autocites[13]{firth_1957a}[170]{sinclair_1991}[15]{sinclair_1998}[124]{stubbs_2009}. They might be further filtered by the statistical significance of their co-occurrence frequency or by their strength of attraction; such as \textsc{pmi} \autocite[see][122-133 for a discussion]{mcenery.hardie_2012}. Even though a collocational relationship is asymmetric, that is, the co-occurrence with a more frequent word B may be more important for the less frequent word A than for B, the measures used to described it are most often symmetrical \autocite{gries_2013}.
When it comes to the interpretation of clouds, this category takes a different form and is definitely asymmetric. Considering models built around a target term or node, frequent, distinct context words are bound to make the tokens that co-occur with them similar to each other and different from the rest: they will generate clusters. Such context words do tend to have a high \textsc{pmi} with the target, but, crucially, they stand out because they are a salient feature among the occurrences of the target, independently from how salient the target would be when modelling the collocate.
Concretely, we are talking about clusters defined by one context word or a group of co-occurring context words with a high \(F\)-score in relation to the cluster: these context words can be interpreted as collocates of the target.
Unlike in most collocational studies, where you study a list of words that co-occur (significantly) frequently with your target node, vector space models allow you to see whether these context words exclude each other or also co-occur within the context of the target. In fact, we might even find more complex collocational patterns, including multiple context words.

Whereas collocation is understood as a relationship between words (and, traditionally, as a relationship between word forms), \textbf{colligation} is defined as a relationship between a word and grammatical categories or syntactic patterns \autocites[14]{firth_1957a}[15]{sinclair_1998}[124]{stubbs_2009}. In order to capture proper colligations as clusters, we would need models in which parts of speech or maybe dependency patterns are used as features, which is not the case in these studies. However, by rejecting a strict separation between syntax and lexis
(for everything is semantics in Cognitive Linguistics),
we can make a grammatically-oriented interpretation of collocations with function words, such as frequent prepositions or the passive auxiliary. Given this caveat, we will talk about lexically instantiated colligations when we encounter clusters dominated by items that indicate a specific grammatical function.

\textbf{Semantic preference} is defined as the relationship between a word and semantically similar words \autocites[16]{sinclair_1998}[125]{stubbs_2009}[138-140]{mcenery.hardie_2012}. Within traditional collocational studies, this implies grouping collocates, that is, already frequently co-occurring items, based on semantic similarity, much as colligation can be the result of grouping collocates based on their grammatical categories. Compared to collocation, its identification requires more interpretation on the part of the researcher.
In the interpretation of individual clusters, semantic preference appears in clusters that are not dominated by a single collocate or group of co-occurring collocates, but are instead defined by a group of infrequent context words with similar type-level vectors and for which we can give a semantic interpretation. (Cases of similar context words without a semantic interpretation are quite rare, and normally involve pronouns or adverbs.) This is a key contribution of token-level distributional models that may remain inaccessible in traditional collocational studies: next to powerful collocates that group virtually identical occurrences, we can identify patterns in which the context words are not the exact same but are similar enough to emulate a collocate.

The three notions described above assume identifiable patterns: occurrences that are similar enough to a substantial number of other occurrences, and different enough from other occurrences, to generate a cluster. Going back to \textcite{sinclair_1991}'s founding notions, we are assuming the domination of the idiom principle:

\begin{quote}
\ldots a language user has available to him or her a large number of semi-preconstructed phrases that constitute single choices, even though they might appear to be analysable into segments. \autocite[110]{sinclair_1991}
\end{quote}

The opposite situation would be given by the open-choice principle:

\begin{quote}
At each point where a unit is completed (a word or a phrase or a clause), a large range of choice opens up and the only restraint is grammaticalness. \autocite[109]{sinclair_1991}
\end{quote}

The idiom principle and the open-choice principle are supposed to organise the lexicon and the production of utterances. But if, instead, they are understood as poles in the continuum of collocational behaviour, they can help us interpret the variety of shapes that we encounter within and across lemmas. Lemmas in which we tend to find identifiable clusters, with strong collocations, lexically instantiated colligations or sets with semantic preference, can be said to respond to the idiom principle. In contrast, lemmas that exhibit large proportions of noise tokens, and small, diffuse clusters (Cirrus clouds, mostly), can be said to approximate the open-choice principle. They don't necessarily lack structure, but whatever structure they have is less clear than for other lemmas, and harder to capture with these models.
With this reasoning, next to the three categories described above, we include \textbf{near-open choice} as a fourth category, meant to include the clouds that do not conform to either of the clearer formats.

\hypertarget{semantically}{%
\subsection{Semantic perspective}\label{semantically}}

In terms of the relationship between the \textsc{hdbscan} clusters and the manually annotated dictionary senses, we can initially distinguish between heterogeneous clusters, i.e.~those that do not exhibit a clear preference for one sense, and homogeneous clusters. Secondly, the homogeneous clusters may cover all the (clustered) tokens of a given sense, or only part of it, i.e.~a (proto)typical context of the sense. Additionally, said (proto)typical context may highlight a certain aspect or dimension of the meaning of the target, different from that highlighted by a different context.

As a result, the semantic dimension covers four different types of situations. The first one, i.e.~heterogeneous clusters or clusters with multiple senses, would normally be interpreted as bad modelling, if we consider the senses a gold standard and the target of our models. It is also the most frequent interpretation of the near-open choice clouds. Nonetheless, they can also occur in other kinds of clouds, and as such illustrate the mismatch between contextual and semantic structure: clear contextual patterns do not imply dictionary senses.
The second type of situation, i.e.~clusters that perfectly match senses, is the ideal situation and what we would initially expect from distributional models. Instead, it is quite rare and often indicative of fixed expressions or very particular meanings.
Rather than full senses, contextual patterns tend to represent (proto)typical contexts of a sense.

As it was already described in Section \ref{prototypicality}, the notion of prototypicality in Cognitive Semantics is related to the principle that categories need not be discrete and uniform and to its application to the semasiological structure of lemmas and their meanings \autocite{geeraerts_1988,geeraerts_1997}. At the extensional level, which in this case covers the domains or contexts of application of our target item, categories may be defined by a varied set of overlapping features (i.e.~context words) and have fuzzy boundaries and/or degrees of membership. The central or more prototypical members of this category exhibit more of these overlapping features; the fewer features co-occur with an item, the weaker its connection to the category.
As they appear in the clouds, a sense may exhibit one typical context that is much more frequent and clear that the rest, or multiple typical contexts with similar frequencies. Unfortunately, neither t-\textsc{sne} nor \textsc{hdbscan} provide a reliable mapping between quantitative properties and relative centrality \emph{of} the clusters. In contrast, we can identify central cases within an \textsc{hdbscan} cluster based on their membership probability, which, as briefly mentioned before, is the normalized core distance within a cluster. Items with a higher membership probability lie in a denser area of an \textsc{hdbscan} cluster, and therefore have more items similar to it than the items in sparser areas. They do not necessarily occur in the euclidean centre in the t-\textsc{sne} plot, but might form one or more dense cores closer towards an edge instead. In addition, we can distinguish between rather uniform clusters, in which all members have a similar weight, from more diverse clusters with dense cores and sparse peripheries.

Extensional prototypicality works at multiple levels. We could identify (proto)typical instances/contexts of a lemma, of a particular sense, or of a dimension of a sense. In this last case, we run into an interaction with intensional prototypicality. On the one hand, we find multiple extensionally prototypical patterns, i.e.~two or more groups of attestations that instantiate different patterns. On the other, each of these patterns correlates with a different semantic dimension or aspect, wich means that that meaning dimension is salient (intensional prototypicality) to that pattern.

\hypertarget{interaction-between-dimensions}{%
\subsection{Interaction between dimensions}\label{interaction-between-dimensions}}

As we can see in Table \ref{tab:colsem}, the interaction between the four levels of each dimension result in a 4x4 table with all but two cells filled with at least one example. Naturally, not all the combinations are equally frequent or interesting; the most salient one is certainly the collocation that indicates the prototypical context of a sense. But this does not mean that the rest of the phenomena should be ignored: we can still find interesting and useful information with other shapes of clouds, other contextual patterns, other semantic structure.

In the following sections, we will look in detail at examples of each attested combination. Each section will focus on one level of the collocational dimension, and will be further subdivided by the levels of the semantic dimension.
The examples will be illustrated with scatterplots in which the colours represent \textsc{hdbscan} clusters, the shapes indicate manually annotated dictionary senses, and the transparency, the \(\varepsilon\) value from \textsc{hdbscan}. The senses are not specified in the legends, but the clusters will be named with the context word that represents it best (see Section \ref{cloud-types}). Textual reproductions of some tokens will also be offered; in all cases the target will be in bold face and the context words captured by the relevant model, in italics. The name of the newspaper, the date of publication and the number of the article will follow the original text, and the following paragraph will reproduce the English translation between simple inverted commas.

\begin{landscape}\begin{table}

\caption{\label{tab:colsem}Contingency table between the collocational and semantic perspectives, with a few examples.}
\centering
\fontsize{8}{10}\selectfont
\begin{tabu} to \linewidth {>{\raggedright\arraybackslash}p{6em}>{\raggedright}X>{\raggedright}X>{\raggedright}X>{\raggedright\arraybackslash}p{6em}}
\toprule
Semantic interpretation & Single collocation & Lexically instantiated colligation & Semantic preference & Near-open choice\\
\midrule
Heterogeneous clusters & \textit{heilzaam} `healthy/beneficial' + \textit{werking} `effect' (and relatives) & \textit{herstructureren} `to restructure' + passive aux. \textit{word} (part of the two transitive senses); \textit{helpen} `to help' + \textit{om} \& \textit{te} `in order to' & \textit{geestig} `witty' + \textit{wijze}/\textit{manier} `manner'/various adverbs; \textit{grijs} `grey' + colours and clothes; \textit{herroepen} `to recant/to void' + \textit{uitspraak} `statement/verdict' \& juridical field & \textit{blik} `gaze/tin' - \textit{werpen} `to throw', \textit{richten} `to aim'\\
\addlinespace
Dictionary clusters & \textit{staal} `sample' + \textit{representatief} `representative'; \textit{schaal} `dish of a scale' + \textit{gewicht} `weight'; \textit{schaal} `scale' + \textit{Richter} & \textit{herhalen} `to repeat' + \textit{zich} `itself'; \textit{hoop} `hope/heap', in the one model that gets the senses right & \textit{haken} `to make trip/to crochet' + sports terms or hobby terms; \textit{schaal} `scale' + earthquake-topic or kitchen-topic & \textit{huldigen} `to honour'\\
\addlinespace
(Proto)typical context & \textit{heffen} `to levy/to lift' and all its collocates (except for \textit{hand}/\textit{arm}); \textit{hachelijk} `dangerous/critical' and its collocates & \textit{diskwalificeren} `to disqualify' + passive aux. \textit{word}; \textit{helpen} `to help' + different pronouns/prepositions (\textit{bij}, \textit{aan}) as only remaining context words; \textit{herinneren} `to remember/to remind' + \textit{(er)aan} `of (it)', \textit{ik} `I' \& reflexive pron. \textit{me}, \textit{zich} & \textit{grijs} `grey' + cars; \textit{heet} `hot' + food; \textit{hemels} `heavenly' + music; \textit{dof} `dull' + sounds & -Not relevant-\\
\addlinespace
(Proto)typical context with profiling & \textit{stof} `substance' and its adjectives; \textit{horde} `horde' & \textit{horde} `horde' + \textit{journalist} \& \textit{door} `by' & \textit{geldig} `valid' + tickets \& dates / identity documents \& \textit{voorleggen} `submit' /\textit{bezitten} `possess'; \textit{staal} `steel' + \textit{ton} \& \textit{milioen} `million' / materials & -Not relevant-\\
\bottomrule
\end{tabu}
\end{table}
\end{landscape}

\hypertarget{collocation}{%
\section{Collocation}\label{collocation}}

The first level of the collocational or syntagmatic dimension is that of the collocation: clusters dominated by one context word or a group of co-occurring context words. They are most likely to be found as Cumulus clouds, but also as Stratocumulus clouds or, very rarely, Cirrus clouds.

\hypertarget{heilzaam}{%
\subsection{Heterogeneous clouds}\label{heilzaam}}

Albeit infrequently, collocations might transcend senses, that is, they might be frequent and even distinctive of a lemma without showing a preference for a specific sense.
The most clear example is found in \emph{heilzaam} `healthy/beneficial', which can mean that something is literally beneficial for the health or be applied, metaphorically, to other domains as well. Its clusters tend to be dominated by one context word that is not indicative of any one sense: mostly \emph{werking} `effect' and \emph{effect}, adding in some models the less frequent \emph{invloed} `influence'. Some examples of are shown in (5) and (6) for the `healthy' sense and (7) and (8) for the `beneficial' sense.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{4}
\item
  Het lypoceen, een \emph{bestanddeel} dat bijdraagt aan \emph{de} rode \emph{kleur}, \emph{zou} \emph{een} \textbf{heilzame} \emph{werking} \emph{hebben} \emph{op} \emph{de} prostaat. (\emph{De Volkskrant}, 2003-11-08, Art. 14)

  `Lypocene, a \emph{component} that contributes to \emph{the} red \emph{colour}, \emph{would} \emph{have} \emph{a} \textbf{healing} \emph{power} \emph{on} \emph{the} prostate.'
\item
  Pierik \emph{beschrijft} \emph{de} \textbf{heilzame} \emph{effecten} \emph{van} \emph{alcoholgebruik} \emph{op} \emph{de} bloedvaten en \emph{de} bloeddruk, op mogelijke beroerten, galstenen, lichaamsgewicht, vruchtbaarheid, zwangerschap, botontkalking, kanker, verkoudheid, suikerziekte en seniele dementie. (\emph{NRC Handelsblad}, 1999-11-27, Art. 148)

  `Pierik \emph{describes} \emph{the} \textbf{healing} \emph{powers} \emph{of} \emph{alcohol consumption} \emph{on} {[}\emph{the}{]} blood vessels and {[}\emph{the}{]} blood pressure, on potential strokes, gallstones, body weight, fertility, pregnancy, osteoporosis, cancer, the cold, diabetes and senile dementia.'
\item
  Voor politici met dadendrang een gruwel, maar als men de casus van de Betuwelijn nog \emph{voor} \emph{de} \emph{geest} haalt dan \emph{zou} \emph{het} advocatensysteem zijn \textbf{heilzame} \emph{werking} \emph{hebben} \emph{kunnen} \emph{bewijzen}. (\emph{De Volkskrant}, 2002-03-29, Art. 79)

  `For politicians with thirst for action it is an abomination, but when one recalls (lit. `brings \emph{to the spirit}') the case of the Betuwe line then \emph{the} lawyer system \emph{would} have been \emph{able} to \emph{prove} its \textbf{beneficial} \emph{effect}.'
\item
  \emph{De} \emph{kwestie} \emph{heeft} \emph{alvast} één \textbf{heilzaam} \emph{effect}: \emph{het} \emph{profiel} \emph{van} commerciële boekenprijzen staat opnieuw ter discussie. (\emph{De Standaard}, 1999-03-27, Art. 133)

  `\emph{The} \emph{matter} \emph{certainly} \emph{has} a \textbf{beneficial} \emph{effect}: \emph{the} \emph{profile} \emph{of} commercial book prizes is again under discussion.'
\end{enumerate}

The model is shown in Figure \ref{fig:heilzaam}: the clusters dominated by \emph{werking} `effect', \emph{effect} and \emph{invloed} `influence' are shown in yellow, light blue and green, respectively, and the manually annotated senses are mapped to the shapes: the literal `healthy' sense is coded in circles, and the general sense, in triangles. All but the \emph{invloed} `invloed' cluster, a Cumulus, are Stratocumulus clouds.

Within the \emph{werking} `effect' cluster, the literal tokens (as in (5)) are the majority and tend towards the left side of the cloud, whereas the general ones (like (7)) tend towards the right side. While there is a preference for the literal sense, especially considering that across the full sample the general sense is more frequent, it is far from homogeneous. The balance is even more striking within the \emph{effect} cluster.
Such a picture is pervasive across multiple models of \emph{heilzaam} `healthy/beneficial'. The vague organization within the \emph{werking} `effect' cluster suggests that it is not necessarily the case that the models do not capture words representative of `physical health', but they have to compete with the most salient context words, which are not precisely discriminative of these two senses.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/heilzaam-1.pdf}
\caption{\label{fig:heilzaam}Cloud of \emph{heilzaam}: bound10all-\textsc{ppmi}weight-\textsc{foc}all. Circles are `healthy, healing', triangles are `beneficial' in general.}
\end{figure}

This is an issue if we come to the distributional semantics expecting lexical collocates, such as \emph{werking} `werking', \emph{effect}, and \emph{invloed} `influence', to unequivocally represent different dictionary senses. On the other hand, \emph{ben} `to be' and \emph{werk} `to work, to have an effect' (of which \emph{werking} is a nominalization), co-occur with the tokens in the orange cluster, dominated by the general sense, and less so outside this cluster; see examples (9) and (10).
In other words, the most frequent nouns modified by \emph{heilzaam} `beneficial' tend to occur in attributive constructions (particularly \emph{een heilzame werking hebben} `to have a beneficial/healing effect/power' and \emph{de heilzame werking van} `the beneficial/healing effect/power of') and for either sense, whereas the predicative constructions present a wider variety of nouns and a stronger tendency towards the general sense.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{8}
\item
  Versterking \emph{van} \emph{de} politieke controle \emph{op} \emph{de} \emph{Commissie} \emph{kan} \textbf{heilzaam} \emph{zijn} \emph{maar} \emph{de} \emph{huidige} ongenuanceerde \emph{discussie} \emph{is} \emph{gevaarlijk} \emph{voor} Europees beleid en besluitvorming. (\emph{De Morgen}, 1999-03-18, Art. 45)

  `Reinforcement \emph{of} \emph{the} politicial control \emph{at} \emph{the} \emph{Commission} \emph{can} \emph{be} \textbf{beneficial}, \emph{but} \emph{the} \emph{current} unnuanced \emph{discussion} \emph{is} \emph{dangerous} \emph{for} European policy and decision-making.'
\item
  Ten slotte nog één fundamentele bedenking: ook \emph{de} permanente actualiteit \emph{van} \emph{de} thematiek in \emph{de} \emph{media} \emph{werkt} \textbf{heilzaam} \emph{op} \emph{de} \emph{weggebruikers}. (\emph{De Morgen}, 2001-02-28, Art. 107)

  `To conclude, one final fundamental thought: \emph{the} permanent presence \emph{of the} topic in \emph{the media} has a beneficial effect (lit. `\emph{works} \textbf{beneficially}') \emph{on road users}.'
\end{enumerate}

The models of \emph{heilzaam} `healthy/beneficial' show that that we cannot take for granted that collocations will be representative of senses. What is more, they illustrate how neither a high \textsc{pmi} nor their selection as cues by human annotators guarantee that a context word distinguishes predefined senses, given that these words have both a high \textsc{pmi} with \emph{heilzaam} `healthy/beneficial' and were often selected as cues by the annotators (recall Tables \ref{tab:heilzaamdep} and \ref{tab:heilzaamcues} in Chapter \ref{dataset}) .
When it comes to \textsc{pmi}, it is understandable: the measure is meant to indicate how distinctive a context word is of the type as a whole, in comparison to other types. It does not take into account how distinctive it is of a group of occurrences against another group of occurrences of the same type.
When it comes to cueness annotation, however, we could have expected a more reliable selection, but apparently the salience of these context words is too high for the annotators to notice that it is not distinctive of the different senses.

\hypertarget{schaal}{%
\subsection{Dictionary clouds}\label{schaal}}

In a few cases we can see clusters characterized by one dominant context word that perfectly match a sense, or at least its clustered tokens. These are normally fixed expressions, at least to a degree: the definition of the sense itself may specify a required expression, such as \emph{representatieve staal} `representative sample'.

An interesting example is shown in Figure \ref{fig:schaal}, a model of the noun \emph{schaal} `scale/dish'. In the plot, the `scale' homonym is represented by circles (`a range of values, e.g.~the scale of Richter, a scale from 1 to 5'), squares (`magnitude, e.g.~on a large scale') and a few triangles (`ratio, e.g.~a scale of 1:20'), whereas the `dish' homonym is represented by crosses (`shallow wide dish') and crossed squares (`dish of a scale').
Both the `range' and the `dish of scale' senses, exemplified in (11) and (12), have a perfect match (or almost) with an \textsc{hdbscan} cluster, represented by a context word with perfect \(F\)-score. All the \emph{schaal} tokens co-occurring with \emph{Richter} are grouped in the red Cumulus cloud, and cover almost the full range of attestations of the `range' sense, and all the tokens co-occurring with \emph{gewicht} `weight' are grouped in the light blue Cumulus cloud and cover all the attestations of the `dish of a scale' sense. The blue cloud of crosses is also an homogeneous Cumulus dedicated to the `shallow wide dish' sense, but not dominated by a collocate, and the rest are variably homogeneous Stratocumulus clouds representing parts of the `magnitude' sense.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{10}
\item
  Wenen, Beneden-Oostenrijk en Burgenland zijn dinsdagochtend opgeschrikt door een \emph{aardschok} \emph{van} \emph{4,8} \emph{op} \emph{de} \textbf{schaal} \emph{van} \emph{Richter}. (\emph{Het Nieuwsblad}, 2000-07-12, Art. 4)

  `Vienna, Lower Austria and Burgenland have been scared up on Tuesday morning by an \emph{earthquake} \emph{of} \emph{4.8} \emph{on} \emph{the} \emph{Richter} \textbf{scale}.'
\item
  Daarom is het van belang dat Nederland zich deze week achter de VS heeft geschaard, ook al legt ons land natuurlijk minder \emph{gewicht} \emph{in} \emph{de} \textbf{schaal} dan \emph{Duitsland} \emph{in} het \emph{Europese} debat over de al dan niet noodzakelijke toestemming van de Veiligheidsraad voor militaire actie tegen Irak. (\emph{NRC Handelsblad}, 2002-09-07, Art. 160)

  `Therefore it is important that the Netherlands has united behind the US this week, even though our country has of course less influence (lit. `places less \emph{weight on the} \textbf{dish of the scale}') than \emph{Germany in} the \emph{European} debate on the potentially necessary permission of the Security Council for military action against Iraq.'
\end{enumerate}

In a way, the phenomenon indicates a fixed, idiomatic expression: a combination of two or more words that fully represents a sense. However, the picture is more nuanced.
First, technically, the `range' sense can potentially occur with more context words than \emph{Richter}. In fact, one of the examples given to the annotators is \emph{schaal van Celsius} `Celsius scale', as well a pattern like the one found in (13), one of the orange circles at the top of Figure \ref{fig:schaal}. However, in the corpus used for these studies, \emph{Celsius} does not co-occur with \emph{schaal} in a symmetric window of 4; moreover, of the 32 tokens of this sense attested in this model, 22 co-occur with \emph{Richter}, 3 follow the pattern from (13), and the rest exhibit less fixed patterns or the infrequent \emph{glijdende schaal} `slippery slope' construction. The few matching (13) are more readily clustered with other tokens co-occurring with the preposition \emph{op} `on', such as (14). In other words, in the register of newspapers, the `range' sense of \emph{schaal} is almost completely exhausted in the \emph{schaal van Richter} `Richter scale' expression.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{12}
\item
  "Misschien deelt de computer mij op grond \emph{van} \emph{statistische} analyses \emph{op} \emph{een} \textbf{schaal} \emph{van} \emph{1} \emph{tot} \emph{12} \emph{in} categorie 3", zegt woordvoerder B. Crouwers van de registratiekamer. (\emph{NRC Handelsblad}, 1999-01-09, Art. 10)

  `"Maybe the computer on the basis \emph{of} \emph{statistical} analyses \emph{on} \emph{a} \textbf{scale} \emph{of} \emph{1} \emph{to} \emph{12} puts me \emph{in} category 3", says spokesperson B. Crouwers of the registration chamber.'
\item
  Die stad vormde de opmaat tot de latere \emph{collectieve} \emph{regelingen} \emph{op} \emph{nationale} \textbf{schaal}, stellen \emph{de} auteurs, in navolging van socioloog prof. dr. Abram de Swaan. (\emph{De Volkskrant}, 2003-05-03, Art. 253)

  `That city was the prelude to the later \emph{collective} \emph{arrangements} \emph{at} \emph{national} \textbf{level} (lit. `\emph{on} a \emph{national} \textbf{scale}'), state \emph{the} authors, in accordance with sociologist Prof.~Dr.~Abram de Swaan.'
\end{enumerate}

Second, the `dish of a scale' sense need not be used in the metaphorical expression illustrated in (12), but that is indeed the case in our data. Next to \emph{gewicht} `weight', these tokens also mostly co-occur with \emph{leg} `to lie, to place' or, in lesser degree, with \emph{werp} `to throw'. Even in other models, this cluster tends to be built around the co-occurrence with \emph{gewicht} `weight', normally excluding tokens that only co-occur with \emph{leg} `to lie, to place', which do not belong to the same sense any more.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/schaal-1.pdf}
\caption{\label{fig:schaal}Cloud of \emph{schaal}: nobound5all-\textsc{ppmi}weight-\textsc{foc}all. Within the `scale' homonym, circles are `range'; triangles, `ratio', and squares, `magnitude'; for the `dish' homonym, crosses represent `dish' and crossed squares, `dish of a scale'.}
\end{figure}

These examples don't disprove the possibility of clouds dominated by a collocate perfectly covering a sense, as long as we keep in mind the characteristics and limitations of the corpus we are studying and the difference between describing ``how a sense is used'' and ``how a sense is used \emph{in this particular corpus}''.

\hypertarget{prototypical-clouds}{%
\subsection{(Proto)typical contexts}\label{prototypical-clouds}}

The most frequent phenomenon among Cumulus and Stratocumulus clouds is a cluster dominated by one context word or group of co-occurring context words that represents a (proto)typical context of a sense. It may be \emph{the} prototypical context, if the rest of the sense is discarded as noise or spread around less clear clusters, but we might also find multiple clusters representing different typical contexts of the same sense. Neither t-\textsc{sne} nor \textsc{hdbscan} can tell whether one of these contexts is more central than the other, at least not in the same sense we would expect from prototype theory. Denser areas of tokens, as perceived by \textsc{hdbscan}, are those where many tokens are very similar to each other. The more tokens are similar, and the more similar they are, the denser the area. As we will see in this example, this is not a good proxy for prototypicality.

One of the most clear examples of this phenomenon is found in \emph{heffen} `to levy/to lift', whose typical objects are also characteristic of its two main senses (see Figure \ref{fig:heffen}). On the one hand, the `to levy' sense occurs mostly with \emph{belasting} `tax', \emph{tol} `toll'\footnote{Typical of the Netherlandic sources, since tolls are not levied in Flanders.}, and \emph{accijns} `excise', as shown in (15) through (17). Their frequencies are large enough to form three distinct clusters, which tend to merge in the following levels of the \textsc{hdbscan} hierarchy, that is, they are closer to each other than to the clusters of the other sense. On the other hand, the `to lift' sense occurs with \emph{glas} `glass', where the final expression \emph{een glas(je) heffen op} takes the metonymical meaning `to give a toast to' (see (18)), and with the body-parts \emph{hand}, \emph{arm} and \emph{vinger} `finger', in which they might take other metonymical meanings. The latter group does not really belong to this ``collocation'' category but to ``semantic preference'' (see Section \ref{semantic-preference}).

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{14}
\item
  Op het inkomen boven \emph{die} drie miljoen \emph{gulden} \emph{wil} De \emph{Waal} \emph{honderd} \emph{procent} \emph{belasting} \textbf{heffen}. (\emph{Het Parool}, 2001-05-02, Art. 99)

  `De \emph{Waal} \emph{wants} to \textbf{levy} a \emph{one hundred percent tax} on all incomes above \emph{that} three million \emph{guilders}.'
\item
  Mobiliteitsproblemen, rekeningrijden, op een andere manier het \emph{gebruik} van de \emph{weg} \emph{belasten}, kilometers \emph{tellen}, \emph{tol} \textbf{heffen} --- de \emph{mogelijkheden} \emph{om} de ingebouwde chip \emph{te} benutten zijn vrijwel onbeperkt. (\emph{NRC Handelsblad}, 1999-10-02, Art. 31)

  `Mobility problems, road pricing, \emph{taxing} the \emph{use} of \emph{roads} in a different way, \emph{counting} kilometres, \textbf{levying} \emph{taxes} --- the \emph{possibilities} \emph{to} utilize the built-in chip are almost unlimited.'
\item
  \ldots in landen als Groot-Brittannië (waar de accijnzen op 742 euro per 1.000 liter liggen), Italië \emph{en} \emph{Duitsland} (\emph{die} \emph{beide} \emph{accijnzen} \emph{boven} de \emph{400} \emph{euro} \textbf{heffen}) komt de \emph{harmonisering} ten goede van de transportsector. (\emph{De Morgen}, 2002-07-25, Art. 104)

  `\ldots in countries like Great Britain (where excise duties are at 742 euros per 1,000 liters), Italy \emph{and} \emph{Germany} (\emph{both of which} \textbf{levy} \emph{excise duties} \emph{above} \emph{400} \emph{euros}) the transport sector benefits from the \emph{harmonization}.'
\item
  Nog \emph{twaalf} andere deelnemers \emph{konden} \emph{maandagavond} \emph{het} \emph{glas} \textbf{heffen} \emph{op} de \emph{hoogste} \emph{winst}. (\emph{De Standaard}, 2004-10-20, Art. 150)

  `\emph{On Monday night} another \emph{twelve} participants \emph{could} \textbf{raise} \emph{their glasses} \emph{to} the \emph{highest} \emph{profit}.'
\end{enumerate}

As we can see in Figure \ref{fig:heffen}, the model is very successful at separating the two senses and the clusters are semantically homogeneous: the most relevant collocates of \emph{heffen} `to levy/to lift' are distinctive of one or the other of its senses. Crucially, no single cluster is even close to covering a full sense; instead, each of them represents a prototypical pattern that stands out due to its frequency, internal coherence and distinctiveness.
It seems reasonable to map the clusters to prototypical patterns because of their frequency and distinctiveness, but we should be careful about how we apply the results of the modelling to this kind of semantic analysis. From the perspective of prototype theory, a feature of a category is more central if it is more frequent, i.e.~it is shared by more members, while a member is more central if it exhibits more of the defining features of the categories. As such, within the `to levy' sense, the \emph{belasting heffen} `to levy taxes' pattern is the most central, and tokens instantiating such a pattern will be more central. In contrast, \textsc{hdbscan} prioritizes dense areas, that is, groups of tokens that are very similar to each other. Thus, membership probabilities, which we might be tempted to use as proxy for centrality, indicate internal consistency, lack of variation. From such a perspective, given that \emph{belasting heffen} `to levy taxes' is more frequent and applies to a wider variety of contexts than the other two patterns of `to levy', its area is less dense, and its tokens have lower membership probabilities within a compound of `to levy' clusters.
In other words, the models can offer us typical patterns of a lemma and of its senses and tell us how distinctive they are from each other and how much internal variation they present. Beyond this information, they don't map in a straightforward manner to our understanding of prototypicality.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/heffen-1.pdf}
\caption{\label{fig:heffen}Cloud of \emph{heffen}: bound10all-\textsc{ppmi}weight-\textsc{foc}nav. Circles are `to lift', triangles are `to levy'.}
\end{figure}

It must be noted that clusters defined by collocations may not be just characterized by one single context word, but by multiple partially co-occurring context words. A clear example is \emph{hachelijk} `dangerous/critical', where both senses are characterized by prototypical contexts, exemplified in (19) through (24): \emph{onderneming} `undertaking', \emph{zaak} `business' and \emph{avontuur} `adventure' for the `dangerous, risky' sense, \emph{moment}, \emph{situatie} `situation', and \emph{positie} `position' for the `critical, hazardous' sense. A model is shown in Figure \ref{fig:hachelijk}, where only the yellow, orange and green clusters are Cumulus clouds, and the rest, Stratocumulus.
These six frequent context words are paradigmatic alternatives of each other, all taking the slot of the modified noun, i.e.~the entity characterized as dangerous or critical. However, unlike its very near type-level neighbour \emph{situatie} `situation', \emph{positie} `position' may also co-occur with \emph{bevrijd} `to free' (and \emph{uit} `from') and, additionally, with \emph{brandweer} `firefighter', typically in Belgian contexts. The frequency of these co-occurrences in the sample, next to the type-level dissimilarity between these three lexical items, splits the co-occurrences with \emph{positie} `position' in three clusters (in light blue, green and red in Figure \ref{fig:hachelijk}), based on these combinations.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{18}
\item
  Het is geen gewaagde stelling dat de deelname van de LPF aan de \emph{regering} \emph{een} \textbf{hachelijke} \emph{onderneming} \emph{blijft}. (\emph{De Volkskrant}, 2002-08-05, Art. 46)

  `It is not a bold statement that the participation of the LPF in the \emph{government} \emph{remains} \emph{a} \textbf{risky} \emph{undertaking}.'
\item
  Daar baseerden de media zich op slechts één bron, en elke journalist weet dat \emph{dat} \emph{een} \textbf{hachelijke} \emph{zaak} \emph{is}. (\emph{De Volkskrant}, 2004-05-05, Art. 42)

  `The media relied on only one source, and every journalist knows that \emph{that} \emph{is} \emph{a} \textbf{dangerous} \emph{thing to do}.'
\item
  \ldots met storm opzij is het \emph{inhalen} van \emph{een} \emph{vrachtwagen} \emph{een} \textbf{hachelijk} \emph{avontuur}\ldots{} (\emph{Het Parool}, 2000-03-17, Art. 34)

  `\ldots under sidewind conditions \emph{overtaking a truck} is \emph{a} \textbf{risky} \emph{adventure}\ldots{}'
\item
  \emph{Kortrijk} \emph{beleefde} \emph{enkele} \textbf{hachelijke} \emph{momenten} tegen \emph{Brussels}, dat in zijn ondiep bad bewees zijn vierde plaats in de play-offs waard te zijn. (\emph{Het Laatste Nieuws}, 2001-05-14, Art. 375)

  `\emph{Kortrijk experienced some} \textbf{critical} \emph{moments} against \emph{Brussels}, who in their shallow pool proved to be worthy of their fourth place in the play-offs.'
\item
  Kort maar krachtig staat er: ``De \textbf{hachelijke} \emph{situatie} van \emph{Palestina} \emph{is} vooral een interne aangelegenheid, hoewel de bezetting en de confrontatie met Israël er de context voor schept." (\emph{De Standaard}, 2004-10-02, Art. 162)

  `Short but powerful, it reads: ``The \textbf{critical} \emph{situation} in \emph{Palestine is} mostly an internal matter, even though the occupation and the confrontation with Israel create the context for it."'
\item
  Zij toont knappe filmpjes, \emph{opgenomen} \emph{vanuit} de \textbf{hachelijke} \emph{positie} van \emph{een} deltavlieger\ldots{} (\emph{De Morgen}, 1999-06-07, Art. 126)

  `She shows outstanding videos, \emph{taken from} the \textbf{hazardous} \emph{position} of \emph{a} hang glider\ldots{}'
\end{enumerate}

The model does not give us information about the relative centrality of the three \emph{positie} clusters. They result from the combination of three features, and each cluster exhibits a different degree of membership based on how many of these overlapping features it co-occurs with. At the same time, they have a distinctive regional distribution. Based on this data, we might said that a prototypical context of \emph{hachelijke posities} `dangerous/critical positions' in Flanders is a situation in which firefighters free someone/something from them, while this core is not present, or at least not nearly as relevant, in the Netherlandic data. We might also say that the same situation is not typical of \emph{hachelijke situaties} `dangerous/critical situations', and this therefore presents a (local) distributional difference between two types that otherwise, at corpus level, are near neighbours.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/hachelijk-1.pdf}
\caption{\label{fig:hachelijk}Cloud of \emph{hachelijk}: bound5all-\textsc{ppmi}weight-\textsc{foc}all. Circles are `dangerous, risky'; triangles are `critical, hazardous'.}
\end{figure}

\hypertarget{stof}{%
\subsection{Profiling}\label{stof}}

Clusters dominated by a context word may not only represent a typical context within a sense, but also one that highlights a different dimension of such sense than other clusters. This is not extremely frequent and requires an extra layer of interpretation, but it is an additional explanation to some of the clustering solutions.

One example is given by the `substance' meaning of \emph{stof}, represented as circles in Figure \ref{fig:stof}.
Within this sense, we tend to find clusters dominated by \emph{gevaarlijk} `dangerous', \emph{schadelijk} `harmful' (which also attracts \emph{kankerwekkend} `carcinogenic') and \emph{giftig} `poisonous' (which often attracts \emph{chemisch} `chemical'). These dominant context words are nearest neighbours at type-level, and the clusters they govern belong to the same branch in the \textsc{hdbscan} hierarchy.

However, we can find additional information, among the context words that co-occur with them, which suggests that frequency is not the only responsible for their separated clusters. Concretely, the tokens in the cluster dominated by \emph{schadelijk} `harmful' tend to focus on the environment and composition of substances, as indicated by the co-occurrence with \emph{uitstoot} `emissions', \emph{lucht} `air', \emph{stank} `stench' and \emph{bevat} `to contain'; meanwhile, those in the cluster dominated by \emph{giftig} `poisonous' focus on the context of drugs or profile the liberation of substances, with context words such as \emph{vorm} `to form', \emph{kom\_vrij} `to be released' and \emph{drugs\_gebruik} `drug use'. The clusters are not distinguished by their meaning as it would be coded in a dictionary entry, but by semantic dimensions that are highlighted in some contexts and hidden in others, but always latent.
This effect of the less frequent context words is one of the consequences of less restrictive models: at some levels of analysis, one word (\emph{gevaarlijk} `dangerous', \emph{schadelijk} `harmful'\ldots) might be enough to disambiguate the target, but this extra information enriches our understanding of how the words are actually used. It is also contextualized information: not just about how \emph{stof} `substance' is used, but how it is used when in combination with certain frequent collocates.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/stof-1.pdf}
\caption{\label{fig:stof}Cloud of \emph{stof}: bound5lex-\textsc{ppmi}selection-\textsc{foc}all. Within the first homonym, circles are `substance'; triangles, `fabric'; filled squares, `topic, material'. For the second, crosses are literal `dust' and crossed square, idiomatic expressions.}
\end{figure}

\hypertarget{colligation}{%
\section{Lexically instantiated colligation}\label{colligation}}

Even without relying on part-of-speech tags or dependency relationships as features for our models, we can obtain grammatical information from lexical collocates. For example, the passive auxiliary \emph{word} indicates passive constructions, as well as the somewhat less frequent preposition \emph{door}, which indicates an explicit agent, much like \emph{by} in English. Other constructions might also be indicated by key function words, such as \emph{om te} `in order to', \emph{dat} `that' for relative clauses, \emph{dan} `than' for comparatives, and prepositions. The patterns that emerge from clusters with lexically instantiated colligation may cross the boundaries of dictionary senses --- resulting in heterogeneous clusters --- match senses, or indicate a prototypical configuration within a sense. The following subsections explore examples of these different phenomena.

\hypertarget{heterogeneous-clusters}{%
\subsection{Heterogeneous clusters}\label{heterogeneous-clusters}}

The verb \emph{herstructureren} `to restructure' was annotated with three sense tags emerging from a combination of specialization, i.e.~whether it's specifically applied to companies, and argument structure, distinguishing between transitive and intransitive \emph{herstructureren}. The intransitive sense is always specific --- companies restructure, undergo a process of restructure.

Models are typically not very successful at disentangling these three senses, or any one of them, for that matter. Instead, the clusters that emerge tend to highlight either the semantic or the syntactic dimension, disregarding the other one.
The lexical items that most frequently dominate clusters of \emph{herstructureren} `to restructure' are the passive auxiliary \emph{word}, \emph{bedrijf} `company', \emph{grondig} `thorough(ly)', and the pair of prepositions \emph{om te} `in order to', as illustrated in (25) through (27).

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{24}
\item
  OK-score deelt bedrijven op in tien klassen; klasse 1 blaakt van gezondheid, klasse 10 is op sterven na dood, ofwel, staat op de rand van faillissement en \emph{moet} \emph{grondig} \emph{worden} \textbf{geherstructureerd}. (\emph{Het Parool}, 2003-04-16, Art. 69)

  `The OK-score divides companies into ten classes: class 1 is brimming with health, class 10 is as good as dead, or rather, stands on the edge of bankruptcy and \emph{must be thoroughly} \textbf{restructured}.'
\item
  \emph{Ze} \textbf{herstructureerden} \emph{het} \emph{bedrijf} \emph{en} loodsten het de internationale groep Taylor Nelson Sofres (TNS) binnen. (\emph{De Standaard}, 2004-01-06, Art. 59)

  `\emph{They} \textbf{restructured} \emph{the company and} steered it towards the Taylor Nelson Sofres (TNS) international group.'
\item
  Uiteindelijk is dat de regering, want toen de crisis uitbrak nam de overheid een belang in de banken \emph{om} \emph{ze} \emph{te} \textbf{herstructureren} \emph{en} \emph{uiteindelijk} \emph{weer} te verkopen. (\emph{NRC Handelsblad}, 2000-11-07, Art. 11)

  `In the end that is the government, because when the crisis hit the authorities took an interest in the banks \emph{in order to} \textbf{restructure} \emph{them and eventually} sell them \emph{again}.'
\end{enumerate}

The two nouns never co-occur, and only occasionally co-occur with \emph{word} or \emph{om te}, which themselves co-occur a few times. Both \emph{grondig} `thorough(ly)' and \emph{bedrijf} `company' are good cues for the company-specific senses, but may occur with either transitive or intransitive constructions. In contrast, \emph{word} is a good cue for transitive (specifically, passive) constructions, but may occur with either the company-specific or the general sense. Finally, \emph{om te} may be attested in either of the three senses. The stark separation of the clusters in Figure \ref{fig:herstructureren} would seem to suggest opposite poles, but that is not the case at the semantic level. In fact, unlike Figures \ref{fig:heffen} or \ref{fig:hachelijk}, dominated by Cumulus and Stratocumulus clouds, the clusters are merely slightly denser areas in a rather uniform, noisy mass of tokens --- the green cloud is a Stratocumulus and the other two are Cirrus clouds --- and would be much harder for the naked human eye to capture without \textsc{hdbscan} input. Instead, each cluster indicates a pole of contextual behaviour which itself may code a semantic dimension, in the case of the \emph{bedrijf} `company' cluster, or a syntactic one, as in the lexically instantiated colligation clusters.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/herstructureren-1.pdf}
\caption{\label{fig:herstructureren}Cloud of \emph{herstructureren}: bound3all-\textsc{ppmi}selection-\textsc{foc}all. Circles indicate the transitive, general sense; triangles, the transitive companies-specific sense, and squares, the intransitive (companies-specific) sense.}
\end{figure}

\hypertarget{dictionary-clouds}{%
\subsection{Dictionary clouds}\label{dictionary-clouds}}

While a rare thing, we might be able to find a cluster dominated by a grammatical pattern that matches a dictionary sense. One clear case is the reflexive sense of \emph{herhalen} `to repeat', characterized by its co-occurrence with \emph{zich} `itself' in \texttt{BOW} models without part-of-speech filters (\texttt{all}) and in \texttt{REL} models, especially if \texttt{PPMIweight} is applied too.\footnote{\texttt{PATH} models also capture \emph{zich} `itself', but somehow don't build clusters around it.}
In the model shown in Figure \ref{fig:herhalen}, it is the clearest cluster, the red Stratocumulus of squares at the bottom. Looking closely, we can see that it is made of two halves: a small one on the left, in which the tokens also co-occur with \emph{geschiedenis} `history', and a bigger one on the right, where they do not. This particular model is very restrictive: it normally captures only one or two context words per token, which is all that we need to capture this particular sense.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/herhalen-1.pdf}
\caption{\label{fig:herhalen}Cloud of \emph{herhalen}: \textsc{rel}1-\textsc{ppmi}selection-\textsc{foc}all. Circles are `to do again'; triangles, `to say again'; squares, `(reflexive) to happen again', and crosses, `to broadcast again'.}
\end{figure}

We expected this kind of output in other lemmas with purely reflexive senses as well, but it is not easy to achieve. In the case of \emph{diskwalificeren} `to disqualify', the very infrequent reflexive sense is typically (but not always) absorbed within the transitive sense that matches it semantically, i.e.~the non sports-related sense.
Alternatively, a lexically instantiated colligation may prefer a certain sense without exhausting its attestations: in that case, it represents a prototypical context, as shown in the following section.

\hypertarget{prototypical-contexts}{%
\subsection{(Proto)typical contexts}\label{prototypical-contexts}}

The verb \emph{herinneren} has two main senses defined by well defined constructions: either an intransitive construction co-occurring with the preposition \emph{aan}, meaning `to remind', or a reflexive construction meaning `to remember'; a third, transitive sense is also attested but very infrequently.
This lemma is sometimes rendered as three equally sized Stratocumulus clouds, as shown in Figure \ref{fig:herinneren}: the orange cluster is characterized by the preposition \emph{aan} (see (28)), the green one by the subject and reflexive first person pronouns \emph{ik} and \emph{me} (see (29)), and the yellow one by the third person reflexive pronoun \emph{zich} (see (30)). A smaller group of tokens co-occurring with \emph{eraan}, a compound of the particle \emph{er} and \emph{aan} (see example (31), where it works as a placeholder to connects the preposition to a subordinate clause), may form its own Cumulus cloud, like the light blue one in Figure \ref{fig:herinneren}, or be absorbed by one of the larger ones.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{27}
\item
  Vinocur \textbf{herinnert} \emph{aan} een tekening van Plantu in L'Express. (\emph{Het Parool}, 2002-05-18, Art. 101)

  `Vinocur \textbf{reminds} {[}the spectator{]} \emph{of} a drawing by Plantu in L'Express.'
\item
  \emph{Ik} \textbf{herinner} \emph{me} een \emph{concert} \emph{waarop} \emph{hij} hevig gesticulerend applaus in ontvangst kwam nemen. (\emph{Het Parool}, 2003-11-14, Art. 79)

  `\emph{I} \textbf{remember} a \emph{concert in which he} received a round of overwhelming applause.'
\item
  "Het was \emph{die} \emph{dag} \emph{bloedheet}", \textbf{herinnert} de \emph{atlete} \emph{uit} \emph{Sint-Andries} \emph{zich} \emph{nog} \emph{levendig}. (\emph{Het Nieuwsblad}, 2001-08-08, Art. 192)

  `"It was \emph{scorching hot that day}", \textbf{remembers} the \emph{athlete from Sint-Andries vividly}.'
\item
  In \emph{zijn} \emph{voorwoord} \textbf{herinnert} Manara \emph{eraan} \emph{dat} deze \emph{meisjes} in hun \emph{tijd} \emph{vaak} met toegeknepen oogjes werden aanschouwd. (\emph{De Morgen}, 2001-11-10, Art. 40)

  `In \emph{his preface} Manara \textbf{reminds} {[}the reader{]} \emph{that} back in their \emph{time} these \emph{girls} were \emph{often} looked at with squinted eyes.'
\end{enumerate}

As the shape coding in the plot indicates, the clusters are semantically homogeneous\footnote{With the exception of three tokens in the first-person cluster also co-occurring with \emph{aan}, and one instantiating \emph{ik zal herinnerd worden als} `I will be remembered as'.}, because these function words are perfect cues for the senses. The rest of the co-occurring context words do not make a difference: they are not strong enough, in the face of these pronouns and prepositions, to originate further salient structure. Nonetheless, both the \emph{aan} and \emph{eraan} clusters on one side, and the pronoun-based clusters on the other, belong to the same sense. Thus, what these lexically instantiated colligation clusters represent is a typical or salient pattern within each sense.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/herinneren-1.pdf}
\caption{\label{fig:herinneren}Cloud of \emph{herinneren}: bound10all-\textsc{ppmi}weight-\textsc{5000}nav. Circles indicate `to remind' (with \emph{aan}); triangles, `(reflexive) to remember', and (the very few) squares, `(trans.) to remember'.}
\end{figure}

\hypertarget{profiling}{%
\subsection{Profiling}\label{profiling}}

Like clusters defined by collocations, clusters defined by lexically instantiated colligations can also represent a typical context that highlights a specific dimension of the sense of the target. One such case is found in the `horde' sense of \emph{horde}, whose most salient collocates in this corpus are \emph{toerist} `tourist' and \emph{journalist}. The two collocates are quite similar to each other at type-level, but the rest of the context words in their clusters point towards a different dimension of the `horde' sense: hordes of journalists, photographers and fans (other nouns present in the same cluster) will surround and follow celebrities, as suggested by the co-occurrence of \emph{omring} `to surround', \emph{wacht\_op} `to wait' and \emph{achtervolg} `to chase', among others. In contrast, hordes of tourists will instead flood and move around in the city, with words such as \emph{stroom\_toe} `to flood' and \emph{stad} `city'.
As it stands, the situation is equivalent to the case of \emph{stof} `substance' described above. However, in the models that capture function words
like the one shown in Figure \ref{fig:horde},
the profiling in these clusters is strengthened by lexically instantiated colligations. The \emph{journalist} cluster is dominated by the preposition \emph{door}, which signals explicit agents in passive constructions;
the passive auxiliary \emph{word} also occurs, albeit less frequently. Meanwhile, the \emph{toerist} `tourist' cluster includes tokens co-occurring with \emph{naar} `towards'. The prepositions are coherent with the dimensions of `horde' highlighted by each of the clusters, i.e.~aggressivity and flow respectively. Interestingly, they don't co-occur with all the tokens that also co-occur with \emph{journalist} and \emph{toerist} `tourist' respectively, but the nouns and prepositions complement each other instead.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/horde-1.pdf}
\caption{\label{fig:horde}Cloud of \emph{horde}: bound5all-\textsc{ppmi}selection-\textsc{foc}all. Within the `horde' homonym, circles indicate human members and triangles, nonhuman members; within the `hurdle' homonym, squares show the literal sense and crosses, the metaphorical one.}
\end{figure}

\hypertarget{semantic-preference}{%
\section{Semantic preference}\label{semantic-preference}}

Clusters that are not clearly dominated by one context word or group of co-occurring context words, be they lexical collocations or lexically instantiated colligations, may still be the result of coherent distributional and semantic patterns. Representing first-order context words with their type-level vectors allows infrequent near neighbours to join forces and approximate the effect of one context word with their cumulative frequency. These context words may occur one to four times in the sample, that is, in about one every hundred occurrences of the target, but together with other similar context words, they form a visible pattern.

\hypertarget{uitspraak}{%
\subsection{Heterogeneous clusters}\label{uitspraak}}

Just like we can have clusters dominated by one context word that is not characteristic of one sense, we can have clusters dominated by multiple similar context words that are not characteristic of any sense. This is the case of names of colours and clothing terms\footnote{A similar group of context words is responsible for joining the `fabric' and `lit. dust' senses of \emph{stof}, even across homonyms.} co-occurring with \emph{grijs} `gray', which in a model like the one shown in Figure \ref{fig:grijs} also includes \emph{haar} `hair'.
As a result, \emph{grijs} `gray' tokens referring to concrete grey objects in general and, specifically, to grey/white hair, form the light blue Stratocumulus cloud on the top right of the figure. Note that, visually, the two senses occupy opposite halves of this cluster: the \emph{haar} `hair' tokens (squares) occupy their own space, but the type-level similarity of the context word to the names of colours and clothing terms makes them indistinguishable to \textsc{hdbscan}.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/grijs-1.pdf}
\caption{\label{fig:grijs}Cloud of \emph{grijs}: bound5all-\textsc{ppmi}no-\textsc{foc}all. Circles represent the literal sense; triangles, `overcast'; squares and crosses, to applications to hair and white-haired people respectively; crossed squares, `boring', and asterisks, `half legal'.}
\end{figure}

A second example is the set of juridical terms in \emph{herroepen}, which means `to recant' when the object is a statement or opinion, and `to annul, to void' when it is a law or decision. In the \emph{QLVLNewsCorpus}, it is often used in a broad legal or juridical context. However, one of the most frequent collocates of \emph{herroepen} within this field is \emph{uitspraak}, which can either mean `verdict', therefore invoking the `to void' sense like in (32), or `statement', to which `to recant' applies, like in (33). Unfortunately, the broader context is not clear enough for the models to disambiguate the appropriate meaning of \emph{uitspraak herroepen} in each instance. At the type-level, \emph{uitspraak} is very close to a number of context words of the juridical field, namely \emph{rechtbank} `court', \emph{vonnis} `sentence', \emph{veroordeling} `conviction', etc. Together, they constitute the semantic preference of the light blue Stratocumulus cloud in Figure \ref{fig:herroepen}, which, similar to the \emph{grijs haar} `gray/white hair' situation above, is visually split between the tokens co-occurring with \emph{uitspraak} and those co-occurring with the rest of the juridical terms.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{31}
\item
  \emph{Het} beroepscomité \textbf{herriep} \emph{gisteren} \emph{de} \emph{uitspraak} van de licentiecommissie en besliste om KV Mechelen toch zijn licentie te geven. (\emph{De Standaard}, 2002-05-04, Art. 95)

  `\emph{Yesterday the} court of appeal \textbf{voided} \emph{the verdict} from the licencing committee and instead decided to grant KV Mechelen a licence.'
\item
  Onder druk van Commissievoorzitter Prodi heeft Nielson verklaard dat hij verkeerd is geïnterpreteerd, maar hij heeft \emph{zijn} \emph{uitspraak} \emph{niet} \textbf{herroepen}. (\emph{NRC Handelsblad}, 2001-10-04, Art. 79)

  `Under pressure from committee chairman Prodi, Nielson declared that he had been misinterpreted, but he did \emph{not} \textbf{recant} \emph{his statement}.'
\end{enumerate}

The result is understandable and interpretable: the context words co-occurring with the tokens in the light blue cluster belong to a semantically coherent set and are distributional near neighbours. The problem is that, in the sample, the sense of \emph{uitspraak} that occurs the most is not the juridical one like in (32) but `statement' like in (33), therefore representing a different sense of \emph{herroepen} than its juridical siblings. In some models, the two groups are split as different clusters, but in those like the one shown in Figure \ref{fig:herroepen}, they form a heterogeneous cluster generated by semantic preference.

Interestingly, \emph{verklaring} `statement' and \emph{bekentenis} `confession' could be considered part of the same semantic field as well, in broad terms. However, they belong to a different frame within the same field of legal action --- a different stage of the process --- and, correspondingly, their type-level vectors are different and they tend to represent distinct, homogeneous clusters (the green Cumulus in the figure).



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/herroepen-1.pdf}
\caption{\label{fig:herroepen}Cloud of \emph{herroepen}: bound3all-\textsc{ppmi}selection-\textsc{foc}all. Circles represent `to void'; triangles, `to recant'.}
\end{figure}

\hypertarget{dictionary-clusters}{%
\subsection{Dictionary clusters}\label{dictionary-clusters}}

A few senses can be completely clustered by groups of similar context words.
One of these cases was already discussed in the context of \emph{schaal} `scale' tokens: in models that exclude \emph{Richter} because of its part-of-speech tag \emph{name}, the tokens co-occurring with it can alternatively be grouped by \emph{kracht} `power', \emph{aardbeving} `earthquake' and related context words. As in the case of \emph{Richter} as dominating collocate, the semantic field of earthquakes is not part of the definition of the `range' sense of \emph{schaal}, but the dominating semantic pattern within the corpus under study.

Another example is found in \emph{haken}, where the `to make someone trip' sense is characterized by a variety of football-related terms (\emph{strafschop} `penalty kick', \emph{penalty}, \emph{scheidsrechter} `referee', etc.), and the very infrequent `crochet' sense, by \emph{brei} `to knit', \emph{naai} `to sew', \emph{hobby} and similar words. They are represented as a Stratocumulus of dark blue squares and a Cirrus of light blue crossed squares in Figure \ref{fig:haken} respectively. As indicated by the name of the dark blue cluster, the passive auxiliary \emph{word} is also characteristic of the `to make someone trip' cluster and very rarely occurs outside of it: here, lexically instantiated colligation is working together with the clear semantic preference of the cloud.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/haken-1.pdf}
\caption{\label{fig:haken}Cloud of \emph{haken}: bound3all-\textsc{ppmi}selection-\textsc{foc}all. Circles and triangles represent the transitive and intransitive literal `to hook'; crosses represent the figurative (intransitive) sense; filled squares represent `to make someone trip'; crossed squares, `to corchet', and asterisks, `to strive for' (with \emph{naar}).}
\end{figure}

\hypertarget{prototypical-contexts-1}{%
\subsection{(Proto)typical contexts}\label{prototypical-contexts-1}}

There are several examples of clusters defined by semantically similar infrequent context words representing typical contexts of a sense. In Figure \ref{fig:grijs}, for example, the dark blue Stratocumulus is represented by cars, mostly indicated by \emph{Mercedes} and \emph{Opel}, next to other brands. In the case of lemmas like \emph{dof} `dull', some models might dedicate different clusters to specific collocates, such as \emph{klink} `to sound', \emph{knal} `bang', \emph{klap} `clap' and \emph{dreun} `pounding', while others group them together in one large cluster defined by a semantic preference indicative of a sense, e.g.~sounds.

A typical semantic group attested in different lemmas is culinary: found with \emph{schaal} `dish' --- the blue Cumulus of crosses in Figure \ref{fig:grijs} --- and with \emph{heet} `hot', the red Stratocumulus of mostly circles in Figure \ref{fig:heet}. In the case of \emph{heet} `hot', almost all the tokens co-occurring in this cluster refer to literally hot foods and drinks, although the full expression might be idiomatic, like in (34), and only a few of them belong to the much less frequent sense `spicy'. In other models, the tokens co-occurring with \emph{soep} `soup' and/or those co-occurring with \emph{water} tokens might form separate clusters.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{33}
\item
  Hoogstwaarschijnlijk zal Poetin Ruslands afgeknapte westerse partners discreet laten weten dat zodra hij eenmaal in het Kremlin \emph{zit}, \emph{de} \emph{soep} \emph{minder} \textbf{heet} \emph{gegeten} \emph{zal} \emph{worden}. (\emph{De Volkskrant}, 1999-12-21, Art. 22)

  `Most probably Putin will discretely let Russia's former western allies know that as soon as he \emph{is} in the Kremlin, things will look up (lit. `\emph{the soep will be eaten less} \textbf{hot}').'
\end{enumerate}

In addition, \emph{aardappel} `potato' is at type-level a near neighbour of the context words in this semantic group, but it still tends to form its own cluster, like the orange Cumulus in the figure. This is due both to its frequency and the distinctiveness of its larger cotext, e.g.~the co-occurrence with \emph{schuif\_door} `to pass on'. Like other expressions annotated with the `hot to the touch' sense (circles in the figure), including \emph{hete hangijzer} `hot irons' in yellow and \emph{hete adem (in de nek)} `hot breath (on the neck)' in light blue, \emph{hete aardappel} `hot potato' is used metaphorically. In the strict combination of adjective and noun, the meaning of \emph{heet} proper is still `hot to the touch': it is the combination itself that is then metaphorized \autocite[for a discussion see][]{geeraerts_2003}.
The context words themselves are frequent and distinctive enough to generate clusters of their own with the tokens that co-occur with them, but \emph{aardappel} `potato' tends to stick close to the culinary cluster or even merge with it.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/heet-1.pdf}
\caption{\label{fig:heet}Cloud of \emph{heet}: bound5all-\textsc{ppmi}no-\textsc{foc}all. Among the literal senses, cricles, filled triangles and filled diamonds represent tactile, weather and body senses; empty squares and triangles represent `spicy' and `attractive' respectively; crosses represent `conflictive', and asterisks, `popular or new'.}
\end{figure}

\hypertarget{profiling-1}{%
\subsection{Profiling}\label{profiling-1}}

The adjective \emph{geldig} `valid' can relate to a legal or regulated acceptability, which is its most frequent sense in the sample, or may have a broader application, to entities like \emph{redenering} `reasoning'. By definition, and like for most of the lemmas studied here, each sense matches some form of semantic preference. In addition, models of this lemma reveal semantic preference patterns within the frequent, specific sense, each of which, in turns, highlights a different dimension of this sense. These patterns may be only identified as areas in the t-\textsc{sne} plots or, in models like the one shown in Figure \ref{fig:geldig}, as clouds.

The green Stratocumulus is characterized by context words such as \emph{rijbewijs} `driving license', \emph{paspoort} `passport' and other forms of identification, as well as verbs like \emph{leg\_voor} `to present', \emph{heb} `to have' and \emph{bezit} `to possess'. In other words, it represents contexts in which someone has to demonstrate possession of a valid identification document, as shown in (35). The light blue Cirrus and the yellow Cumulus, on the other hand, co-occur with other kinds of documents (\emph{ticket}, \emph{abonnement} `subscription'), \emph{euro}, the preposition \emph{tot} `until', and times (\emph{maand} `month', \emph{jaar} `year', numbers, etc.). In this case, the price of the documents and the duration of their validity are more salient, as illustrated in (36).

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{34}
\item
  Aan de incheckbalie \emph{kon} de \emph{Somaliër} \emph{echter} geen \textbf{geldige} \emph{papieren} \emph{voorleggen}. (\emph{Het Laatste Nieuws}, 2001-08-24, Art. 64)

  `\emph{But} the \emph{Somali could} not \emph{show} any \emph{valid papers} at the check-in desk.'
\item
  Klanten van Kunst In Huis zijn bovendien zeker van variatie: wie lid is, kan elke maand een ander werk uitkiezen, het \emph{abonnement} \emph{blijft} een leven \emph{lang} \textbf{geldig} en de \emph{maandelijkse} \emph{huurprijs} van 250 \emph{frank} \emph{is} \emph{ook} \emph{niet} bepaald hoog te noemen. (\emph{De Standaard}, 1999-05-29, Art. 41)

  `Moreover, customers of Kunst In Huis (lit. `Art At Home') are guaranteed variation: members can choose a different work each month; the \emph{subscription remains} \textbf{valid} for a life\emph{time} and the \emph{monthly fee} of 250 \emph{franks is not} particularly high \emph{either}.'
\end{enumerate}



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/geldig-1.pdf}
\caption{\label{fig:geldig}Cloud of \emph{geldig}: bound10lex-\textsc{ppmi}selection-\textsc{foc}all. Circles represent the specific sense and triangles, the general one.}
\end{figure}

\hypertarget{openchoice}{%
\section{Near-open choice}\label{openchoice}}

The clouds described up to now in this chapter can be easily interpreted in terms of dominating context words or semantic domains. We would expect this always to be the case: if \textsc{hdbscan} identifies a cluster, there must be structure; if there is structure, there must be an underlying pattern; if there is an underlying pattern, it can be meaningfully interpreted. Unfortunately, this is not always the case. \textsc{hdbscan} clusters can also be formed in opposition: as we saw before in the case of the Cumulonimbus clouds, i.e.~the massive clusters covering at least half the sampled tokens, the grouping criterion might be a negative definition. There is a strong pattern, and everything else that does not conform to it is dumped together. In other situations, whatever structure the \textsc{hdbscan} picks up on is very faint, compared to the Cumulus skies we may find in \emph{heffen} and \emph{hachelijk} (see Section \ref{prototypical-clouds}). At present, we do not understand the relationship between \textsc{hdbscan} and token-level distributional models well enough to make sense of why these less interpretable clusters emerge and how meaningful they really are.

One of the possible interpretations of these kinds of clusters, from the linguistic point of view, is that some patterns are closer to the ``open choice'' side of the spectrum, while the cases discussed in Section \ref{collocation} are closer to the ``idiom'' side. The open-choice and idiom principle were not really presented as poles of a continuum, but they do help as interpretative tool to make sense of the variation in cloud shapes within a lemma and across lemmas. We cannot split the data studied here between models that follow the idiom principle and those that don't, because the degree to which the distributional behaviour of each lemma can be explained by the idiom principle is different.
When we generate a list of collocations for an item, we see the most relevant patterns; when we read sorted concordances, we focus on the similarities that stand out; with token-level distributional models, instead, we can see how strong or weak these patterns are.

In this section we will look at examples of clusters that cannot be interpreted in terms of dominating context words or semantic domains. Most of these result in heterogeneous clusters, especially Cumulonimbus clouds, but they can also, occasionally, bring together all the tokens of senses with certain characteristics. What I have not found is cases of near-open choice clusters that represent semantically homogeneous prototypical contexts.

\hypertarget{blik}{%
\subsection{Heterogeneous clusters}\label{blik}}

The most common situation in clusters that are not explained by a dominant context word or semantic preference, especially when they are Cumulonimbus clouds, is that they are semantically heterogeneous. These massive clouds occur in models where a small number of tokens that are very similar to each other --- typically idiomatic expressions, but not necessarily --- stand out as a cluster, and everything else either belongs to the same massive cluster or is noise. In many cases there is barely any noise left, while in others \textsc{hdbscan} does seem to find a difference between the many, varied tokens in the Cumulonimbus clouds and those that are left as noise.

One such example is the Cumulonimbus cloud of \emph{blik} in Figure \ref{fig:blik}, shown in orange. The small Cumulus clouds to either side are represented by the co-occurrence of \emph{werp} `to throw' and \emph{richt} `to aim', which indicate prototypical instances of \emph{blik} `gaze' (see (37) and (38)). Very few tokens are excluded as noise --- the patterns they form seem to be too different from the clustered tokens to merge with them, but too infrequent to qualify as a cluster on their own.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{36}
\item
  Op zaterdag 27 april zwaait de lokale politie van de zone Kortrijk-Kuurne-Lendelede de deuren wijd \emph{open} voor \emph{al} \emph{wie} \emph{een} \textbf{blik} wil \emph{werpen} \emph{achter} \emph{de} \emph{schermen} van het politiewerk. (\emph{Het Laatste Nieuws}, 2002-04-23, Art. 54)

  `On Saturday 27 April the local police of the Kortrijk-Kuurne-Lendelede zone \emph{opens} their doors wide for \emph{all those who} want to \emph{have a} \textbf{look} \emph{behind the scenes} of police work.'
\item
  Maar wat is goed genoeg, zo lijkt Staelens zich \emph{af} te vragen, \emph{haar} \textbf{blik} \emph{strak} \emph{naar} \emph{beneden} \emph{gericht}. (\emph{De Volkskrant}, 2003-09-27, Art. 170)

  `But what is good enough, Staelens seems to wonder, \emph{her} \textbf{gaze} \emph{looking straight down}.'
\end{enumerate}

The orange cluster may seem homogeneous because of the predominance of the circles, but that is simply an effect of the large frequency of the `gaze' sense, which can also occur in contexts like (39). The other sense of the `gaze' homonym, `perspective', as shown in (40), and of the `tin' homonym (see (41)), are also part of this massive heterogeneous cluster. If anything brings these tokens together, other than the fact that they normally do not match the patterns in (37) and (38), is that they typically co-occur with \emph{een} `a, an', \emph{de} `the', \emph{met} `with', \emph{op} `on', and other frequent prepositions, or more than one at the same time. These frequent, partially overlapping, and not so meaningful patterns bring all those tokens together and, to a degree, set them apart.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{38}
\item
  Totdat \emph{Walsh} \emph{met} \emph{een} \emph{droevige} \textbf{blik} \emph{in} \emph{zijn} \emph{ogen} vertelt dat hij het moeilijk heeft. (\emph{Het Parool}, 2004-03-02, Art. 121)

  `Until \emph{Walsh}, \emph{with} \emph{a} \emph{sad} \textbf{look} \emph{in} \emph{his} \emph{eyes}, says that he's having a hard time.'
\item
  IMF en Wereldbank liggen al jaren onder vuur wegens \emph{hun} vermeend \emph{eenzijdige} \textbf{blik} \emph{op} \emph{de} ontwikkelingsproblemen \emph{van} \emph{Afrika}. (\emph{Algemeen Dagblad}, 2001-02-20, Art. 129)

  `The IMF and the World Bank have been under attack for years because of \emph{their} alledgedly \emph{unilateral} \textbf{view} \emph{on} \emph{the} delevopment issues \emph{in Africa}.'
\item
  Zijn vader had \emph{een} fabriek waar \emph{voedsel} \emph{in} \textbf{blik} werd gemaakt. (\emph{NRC Handelsblad}, 2003-12-05, Art. 120)

  `His father had \emph{a} factory where canned food (lit. `\emph{food} \emph{in} \textbf{tin cans}') was made.'
\end{enumerate}



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/blik-1.pdf}
\caption{\label{fig:blik}Cloud of \emph{blik}: bound5all-\textsc{ppmi}weight-\textsc{5000}nav. For the first homonym, circles represent `gaze' and triangles, `view, perspective'; for the second, squares represent `tin' and crosses, `made of tin' or `canned food'.}
\end{figure}

\hypertarget{huldigen}{%
\subsection{Dictionary clusters}\label{huldigen}}

It might seem pointless to look for meaning in clusters that do not respond to either dominating context words or semantically similar context words, but for some lemmas, it might make sense. Such is the case of the model of \emph{huldigen} shown in Figure \ref{fig:huldigen}.

Like with other transitive verbs, the senses of this lemma are characterized by the kind of direct objects they can take. When the direct object of \emph{huldigen} is an idea or opinion, it means `to hold, to believe': in our sample, typical cases include \emph{principe} `principle', \emph{standpunt} `point of view' and \emph{opvatting} `opinion' (see examples (42) through (44)). The three of them are near neighbours at type level, but frequent enough to lead their own Cumulus or Stratocumulus clouds in most models, like in Figure \ref{fig:huldigen}.
In other contexts, \emph{huldigen} means `to honour, to pay homage', and the role of patient is normally filled by human beings (see examples (45) and (46)). In practice, the variety of nouns that can take this place is much larger than for `to believe', and as a result, the clusters that cover `to honour' are less compact and defined than the clusters representing the other sense. And yet, the Cumulonimbus shown in yellow in Figure \ref{fig:huldigen} almost perfectly represents the `to honour' sense. How is that possible?

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{41}
\item
  Jacques: ``Voor het \emph{eerst} \textbf{huldigen} we het \emph{principe} dat de vervuiler betaalt." (\emph{De Morgen}, 1999-03-10, Art. 12)

  `Jacques: ``For the \emph{first} time we \textbf{uphold} the \emph{principle} that polluters must pay."'
\item
  De regering in Washington \textbf{huldigt} het \emph{standpunt} dat volgens Amerikaans recht de vader beslist over het domicilie van zijn minderjarige zoon. (\emph{NRC Handelsblad}, 2000-04-03, Art. 97)

  `The government in Washington \textbf{holds} the \emph{view} that according to American law fathers decide on the primary residence of their underage sons.'
\item
  \ldots de objectieve stand van zaken in de buitenwereld zou kunnen \emph{weerspiegelen}. Rorty \textbf{huldigde} \emph{voortaan} de \emph{opvatting} dat waarheid synoniem is voor wat goed is voor ons. (\emph{De Standaard}, 2003-01-09, Art. 93)

  `\ldots would \emph{reflect} the objective state of affairs in the outside world. \emph{Ever since} Rorty \textbf{has held} the \emph{opinion} that the truth is a synonym for what is good for us.'
\item
  "Elk \emph{jaar} \textbf{huldigen} wij onze \emph{kampioenen} en sinds enkele jaren richten we een jeugdkampioenschap in", zegt voorzitter Eddy Vermoortele. (\emph{Het Laatste Nieuws}, 2003-04-15, Art. 121)

  `"Every \emph{year} we \textbf{honour} our \emph{champions} and for a few years we've been organizing a youth championship", says chairman Eddy Vermoortele.'
\item
  Langs de versierde straten zijn we naar de kerk gereden en na de plechtigheid hebben we Karel nog \textbf{gehuldigd} in \emph{feestzaal} Santro. Hij is nog een heel kranige man. (\emph{Het Laatste Nieuws}, 2003-07-18, Art. 256)

  `We drove through the ornate streets towards the church and after the ceremony we \textbf{honoured} Karel at the \emph{party hall} Santro. He is still a spry man.'
\end{enumerate}



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/huldigen-1.pdf}
\caption{\label{fig:huldigen}Cloud of \emph{huldigen}: nobound3lex-\textsc{ppmi}selection-\textsc{foc}all. Circles represent `to believe, to hold (an opinion)'; triangles, `to honour'.}
\end{figure}

One of the factors playing a role in the layout of this model is that the co-occurrences with \emph{principe} `principle', \emph{standpunt} `point of view' and \emph{opvatting} `opinion' exhaust about half the attestation of the `to believe' sense. The rest of the tokens are too varied and typically fall into noise. The variety within the `to honour' sense cannot compete against the stark differences between these clusters and everything else. Nonetheless, there is some form of structure within the sense that differentiates it from the equally varied remaining tokens of `to believe', and that is a family resemblance structure.

No single semantic field is enough to cover the variety of contexts in which \emph{huldigen} `to honour' occurs in our sample: instead, we find different aspects and variations of the prototypical situation of ceremonies organized by sports- and city organizations in public places, in honour of successful athletes.
In order to get a better picture of the syntagmatic relationships between the context words within the cluster, we can represent them in a network, show in Figure \ref{fig:huldigennet}. Each node represents one of the 150 most frequent context words co-occurring with tokens from the yellow cloud in Figure \ref{fig:huldigen}, and it is connected to each of the context words with which it co-occurs in a token of that cluster. The thickness of the edges represents the frequency with which the context words co-occur within the sample; the size of the nodes summarizes that frequency, and the size of the label roughly represents the frequency of the context word among the tokens in the cluster.

The most frequent context word is the passive auxiliary \emph{word}: it is the only context word captured in the tokens of the dense core on the upper right corner of the cloud, and co-occurs with about half the tokens of this cluster. A number of different, less frequent context words partially co-occur with it, such as \emph{kampioen} `champion', \emph{stadhuis} `city hall' and \emph{sport\_raad} `sports council'. They subsequently generate their own productive branches in the family resemblance network. Crucially, this shows how we might have a token that co-occurs with \emph{verdienstelijk} `deserving' and \emph{sport\_raad} `sports council' and one that co-occurs with \emph{gemeente\_bestuur} `municipal administration' and \emph{officieel} `official', both as part of the same cluster.

Semantically and distributionally, the context words plotted in this network belong to different, loosely related fields, such as sports (\emph{kampioen} `champion', \emph{winnaar} `winner', \emph{sport\_raad} `sports council'), town administration (\emph{stad\_bestuur}, \emph{gemeente\_bestuur} `city administration') and temporal expressions (\emph{jaar} `year', \emph{weekend}). The predominance of the passive auxiliary \emph{word} --- lexically instantiated colligation --- the presence of unified semantic fields --- multiple semantic preferences --- and the family resemblance among tokens, resulting from an intricate network of co-occurrences, work together to model the subtle, complex semantic structure of \emph{huldigen} `to honour'.



\begin{figure}
\includegraphics[width=1\linewidth]{phdThesis_files/figure-latex/huldigennet-1} \caption{Network of context words of the \emph{huldigen} `to honour' cluster.}\label{fig:huldigennet}
\end{figure}

\hypertarget{theo1-summary}{%
\section{Summary}\label{theo1-summary}}

Different types of clouds offer us different kinds of information. The ideal result of clusters that equal dictionary senses is only rarely found, and instead we typically find collocations that represent (proto)typical contexts within a sense. Next to this typical result, we encounter a variety of phenomena combining syntagmatic and paradigmatic aspects. Along with collocations, we find colligation and semantic preference as motors behind most of the clusters, but also a number of cases where no clear distributional pattern can be found. These phenomena correlate decently with the types of clouds discussed in Chapter \ref{shapes}: collocations with Cumulus clouds, lexically instantiated colligation with Stratocumulus clouds, semantic preference with all but Cumulonimbus, and near-open choice with Cumulonimbus. These are, of course, not deterministic mappings, but general tendencies.
At the paradigmatic or semantic level, next to clusters that represent typical contexts, we find heterogeneous clusters and some that match senses completely. In addition, typical contexts may include richer information regarding different semantic dimensions of a sense that are highlighted in certain contexts, i.e.~that are prototypical of that contextual pattern.

In this chapter we have seen the different combinations of these syntagmatic and paradigmatic phenomena, and the shapes they can take in the models of different lemmas. Clouds do not necessarily match senses, but may offer us other types of information, depending on the distributional properties of the lemma and the dimensions that are most relevant in its semasiological structure. In the following chapter we will look at the (lack of) relationship between the information we obtain and parameter settings.

\hypertarget{no-optimal}{%
\chapter{No sky is the best sky}\label{no-optimal}}

There is no magic trick to extract neat, semantically homogeneous clouds from the wild sea of corpus attestations. As we have seen in Chapter \ref{shapes}, the clouds can take a number of different shapes, depending on the variability of the context words that co-occur with the target, their frequency and their diversity. Chapter \ref{semantic-interpretation} further shows that these clusters may have various interpretations, both from a syntagmatic perspective and from a paradigmatic perspective, resulting in a diverse net of phenomena. It also explores the role of the similarity and co-occurrence between the context words. In this chapter, we will look at the relationship between these results and the parameter settings that produce them.

In consonance to the previous analyses, there is no golden law to be drawn from here. There is no set of parameter settings that reliably returns the best output: not for specific parts of speech, nor for specific semantic phenomena.
This variability will be illustrated in two sections: in Section \ref{hoopstof} I will compare the medoids of \emph{hoop} `hope/heap' and \emph{stof} `substance/dust\ldots{}' that best model homonymy in each lemma, while Section \ref{paramranking} will look at the shape that the same parameter configuration takes in many different models.

\hypertarget{hoopstof}{%
\section{A pile of dust}\label{hoopstof}}

As mentioned in Chapter \ref{dataset}, we have modelled 7 homonymous and polysemous nouns, with the intention of studying the relationship between parameter settings and granularity of meaning. We expected certain parameters to be better at modelling differences between homonyms and others to be able to capture, at least in some cases, the more subtle differences between senses of a homonym. However, even though homonymy should be relatively easy to model\footnote{See for example in \textcite{schutze_1998}; \textcite{yarowsky_1995}.}, the results are not so straightforward. As an example, let's look at the medoids of \emph{hoop} `hope, heap' and \emph{stof} `substance, dust\ldots{}' that most successfully model the manual annotation.

Figure \ref{fig:besthomonym} shows the best medoid of each of the lemmas, in terms of semantic homogeneity of the clusters. By mapping the sense tags to colours, we can see that each of them has a rather well defined, homogeneous area in the t-\textsc{sne} plot. It should be noted, however, that the areas are relatively uniform, and we would be hard pressed to find such a clear structure without any colour-coding. In fact, \textsc{hdbscan} only highlights the most salient areas, covering, for example, only the center of the light blue island in the left plot.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/besthomonym-1.pdf}
\caption{\label{fig:besthomonym}Best medoids of \emph{hoop} (\textsc{path}weight-\textsc{ppmi}no-\textsc{foc}all) and \emph{stof} (bound5lex-\textsc{ppmi}selection-\textsc{foc}all).}
\end{figure}

The senses plotted to the colours are coded with numbers to avoid cluttering. The senses of \emph{hoop} are, for the first homonym, {[}1{]} literal `heap, pile' and {[}2{]} general `heap, bunch', and for the second homonym, {[}3{]} `hope'. The first homonym of \emph{stof} includes {[}1{]} `substance', {[}2{]} `fabric' and {[}3{]} `topic, material', while the second covers {[}4{]} literal `dust' and {[}6{]} idiomatic `dust'. There is no sense {[}5{]}, originally `(reduced to) dust', because it was not attested.
Some relevant examples will be given below.

The parameters that result in these models are in fact very different, although their second-order configuration is equivalent: the union of all the context words captured by the model are also used as second-order dimensions. As a result, the dimensionality of the token-level vectors is quite low: 833 for \emph{hoop} and 483 for \emph{stof}.

The model that works best for \emph{hoop} is the only medoid that manages to group the tokens of the `heap' homonym away from the larger mass of `hoop' tokens (in green), with even a neat moat in between. If we sacrifice the infrequent literal `heap' sense (in orange), the split is indeed outstanding. This is achieved by a \texttt{PATHweight} model: it uses syntactic information, selects the context words connected up to three steps away from the target, and weights the contribution of each item on that distance, regardless of the precise nature of the syntactic relationship, part-of-speech information or \textsc{pmi}. The syntactic distances, i.e.~the number of steps to the target in the dependency path, are illustrated with the superscripts in examples (47) and (48).

In (47), the indefinite determiner \emph{een} and the modified noun \emph{onzin} `nonsense' are directly linked to the target \emph{hoop} as dependent and head respectively, so they are taken by the model and receive the highest weight. The first occurrence of the verb \emph{is} is the head of its subject \emph{onzin} `nonsense', hence two steps away of the target: it is included and receives a slightly lower weight. The particle \emph{er}, which is tagged as a modifier of \emph{is}, and the second instance of \emph{is}, as head of the subordinate clause, are three steps away from the target, and therefore obtain a low weight. The rest of the context is ignored by this model.

Example (48) offers a much more complex picture, particularly because the link between the target \emph{hoop} `hope' and the verb \emph{spreek\_uit} `to express' (split in \emph{sprak} and its particle \emph{uit}), is short. As the core of the dependency tree, the main verb opens the path to many other elements in the sentence.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{46}
\item
  Er\textsuperscript{3} is\textsuperscript{2} een\textsuperscript{1} \textbf{hoop} onzin\textsuperscript{1}, talent is\textsuperscript{3} niet iedereen gegeven. (\emph{Algemeen Dagblad}, 2001-01-27, Art. 78)

  `There is a \textbf{lot of} nonsense; talent is not given to everyone.'
\item
  De\textsuperscript{3} trainer\textsuperscript{2} van\textsuperscript{3} FC Utrecht sprak\textsuperscript{1} verder\textsuperscript{2} de\textsuperscript{1} \textbf{hoop} uit\textsuperscript{2} dat\textsuperscript{1} hij\textsuperscript{3} binnenkort weer eens mag\textsuperscript{2} investeren\textsuperscript{3} van de clubleiding. (\emph{NRC Handelsblad}, 2004-05-24, Art. 93)

  `The manager of FC Utrecht also expressed the \textbf{hope} that the club management would allow him to invest once again soon.'
\end{enumerate}

A key point for this lemma is that \emph{hoop} `hope', represented by (48), is a mass noun, and therefore tends to occur with the definite determiner \emph{de} (40\% of the cases). In contrast, \emph{hoop} `heap', represented by (47), tends to occur with \emph{een} `a(n)' (64 out of 76 occurrences). This correlation is hard to extract with a bag-of-words model, which would either filter out function words such as the determiners, or include all determiners, related to the target or not, thus drowning this pattern in noise.

In contrast, the parameter settings that work best for \emph{stof} are \texttt{bound5lex} and \texttt{PPMIselection}, i.e.~they capture the nouns, verbs, adjectives and adverbs within 5 slots to each side of the target, as long as they are within the limits of the sentence and their \textsc{pmi} with the target lemma is positive. In the case of (49), for example, the model selects \emph{discussie} `discussion' and \emph{lever\_op} `to bring about, to return', in italics in the transcription. Words that might follow after the period would be excluded by this model, as are those before \emph{film} `movie'. Within the window span of 5 words to each side, \emph{die} `that', \emph{na} `after', \emph{veel} `much' and \emph{tot} `to' are excluded because of the part-of-speech filter. Finally, the nouns \emph{film} `movie' and \emph{afloop} `end, conclusion', which survive the window size and part-of-speech filters, are excluded by the association strength filter, since their \textsc{pmi} value in relation to \emph{stof} is lower than 0.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{48}
\item
  Dit is een perfect voorbeeld van een film die na afloop veel \textbf{stof} tot \emph{discussie} \emph{oplevert}. (\emph{Algemeen Dagblad}, 2003-12-11, Art. 58)

  `This is a perfect example of a film that afterwards \emph{provides} a lot of food for thought (lit. `\textbf{stuff} for \emph{discussion}').'
\end{enumerate}

Being generous, we can find a good representation of granularity of meaning for \emph{hoop} in Figure \ref{fig:besthomonym}. In the case of \emph{stof}, however, the senses are quite well distinguished but the homonyms are not.
First, most of the idiomatic `dust' tokens group quite nicely in some sort of appendix to the main cloud. These tokens, which are by definition idiomatic uses of \emph{stof}, tend to be very tightly grouped in most models. An example can be seen in (50). Notably, they also include a few literal tokens that also co-occur with one of the defining context words, i.e.~\emph{doe} `to make' and \emph{waai\_op} `to lift'.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{49}
\item
  Het huwelijk tussen de hervormde Maurits en de katholieke Marylene \emph{deed} de \emph{nodige} \textbf{stof} \emph{opwaaien}. (\emph{Algemeen Dagblad}, 1999-12-08, Art. 3)

  `The wedding between Maurit, a Reformed Christian, and Marylene, a Catholic, inspired a much needed debate (lit. `\emph{stirred up} the \emph{necessary} \textbf{dust}').'
\end{enumerate}

The rest of the tokens seem to be organized by sense with subtle borders in between. The most frequent sense, `substance', even includes a few independent islands on top, already discussed in Section \ref{stof}.

Most interestingly, `fabric' and `dust', in light blue and yellow respectively, like to go together, even though they belong to different homonyms. In fact, \textsc{hdbscan} merges them together in one cluster, as we will see in Figure \ref{fig:popular1}. This is not entirely surprising, given that both senses tend to co-occur with quite concrete context words, such as names for materials and colours (see for example (51) and (52)), while the `substance' sense is more chemically-oriented and the `topic, material' sense, illustrated in (49), co-occurs with the semantic domain of communication instead.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{50}
\item
  Dankzij de nieuwe vlekwerende ``stay clean"-behandelingen dringen zelfs vloeistoffen zoals olie, vruchtensap of \emph{water} niet in de \textbf{stof}. (\emph{De Standaard}, 2001-01-19, Art. 6)

  `Thanks to the new stain-resistant ``stay clean" treatments even liquids such as oil, fruit juice or \emph{water} do not penetrate the \textbf{fabric}.'
\item
  Na het \textbf{stof} de \emph{douche}. De tocht door de Hel zit er op. (\emph{De Morgen}, 2003-04-15, Art. 65)

  `After the \textbf{dust} the \emph{shower}. The trip through Hell {[}a cobblestone cycling road{]} is over.'
\end{enumerate}

This description should suffice to understand how very different parameter configurations are necessary to model such different lemmas. The fact that both of them are homonyms is not enough: other aspects of their structure, such as the kind of contextual features that characterize each sense or homonym, play a role.

What I have not shown is that other models are not as good. What would come out from applying the parameter settings that work best for one lemma onto the other? This we see in Figure \ref{fig:switchbest}.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/switchbest-1.pdf}
\caption{\label{fig:switchbest}Model of \emph{hoop} with the parameters that work best for \emph{stof} and viceversa: bound5lex-\textsc{ppmi}selection-\textsc{foc}all for \emph{hoop} and \textsc{path}weight-\textsc{ppmi}no-\textsc{foc}allfor \emph{stof}}
\end{figure}

Indeed, swapping the configurations returns unsatisfying results. In the case of \emph{hoop}, we see a similar picture to many other models: a plot overrun by `hope', with maybe an area with more `literal heap' tokens, while the `general heap' tokens, that were so nicely separated in Figure \ref{fig:besthomonym}, are mixed and distributed across one hemisphere. In the case of \emph{stof}, we keep having a large `substance' area in orange, an isolated blue section for the idiomatic `dust' and a shy green peninsula of `topic, material' tokens, but the concrete senses, `fabric' and `dust', are disperse and mixed.

Even for a fairly straightforward task as discriminating homonyms, parameters that succeed in one lemma fail in the other. This is unrelated to the number or frequency of the senses. Instead, it is inextricably linked to the particular distributional behaviour of each lemma. While \emph{stof} can find collocations or semantic preferences that, to various degrees, represent (parts of) senses, the lexical contexts of \emph{hoop} are too varied to generate clear clusters. On the other hand, a syntactically informed model can identify determiners as a relevant feature of \emph{hoop}, while the same information seems less interesting in regard to \emph{stof}.

\begin{landscape}\begin{table}

\caption{\label{tab:level1}Salient parameter settings per lemma.}
\centering
\begin{threeparttable}
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{3em}>{\raggedright\arraybackslash}p{7em}>{\raggedright\arraybackslash}p{7em}>{\raggedright\arraybackslash}p{7em}>{\raggedright\arraybackslash}p{7em}>{\raggedright\arraybackslash}p{7em}>{\raggedright\arraybackslash}p{7em}}
\toprule
\multicolumn{1}{c}{} & \multicolumn{2}{c}{Only lex} & \multicolumn{2}{c}{lex or PPMIweight} & \multicolumn{2}{c}{No lex effect} \\
\cmidrule(l{3pt}r{3pt}){2-3} \cmidrule(l{3pt}r{3pt}){4-5} \cmidrule(l{3pt}r{3pt}){6-7}
SOC effect & radial window & no window & radial window & no window & radial window & no window\\
\midrule
5000-all & horde, gekleurd, hoopvol, haten, helpen & staal, blik, hemels, gemeen, grijs & stof, dof, geestig, heet &  &  & hoekig, geldig, goedkoop\\
\addlinespace
5000 around & hachelijk & haken & spot, schaal & heilzaam & heffen$^1$ & \\
\addlinespace
None & hoop, herinneren, herstellen$^1$, harden$^1$ & herhalen, diskwalificeren, herstructureren &  & huldigen$^2$ &  & herroepen\\
\bottomrule
\end{tabular}
\begin{tablenotes}
\item[1] Models with window size of 3 are separated, no radial structure.
\item[2] Dependency-based models are closer to those with larger window instead of those with smaller window.
\end{tablenotes}
\end{threeparttable}
\end{table}
\end{landscape}

\hypertarget{paramranking}{%
\section{Weather forecast gone crazy}\label{paramranking}}

Parameter settings do not have an equal effect across all models. Even at Level 1, where we compare models of a lemma with each other, we encounter a variety of patterns.
Table \ref{tab:level1} groups all the lemmas based on the three criteria that make the greatest difference in the organization of the Level 1 plots. The main columns refer to effects of the first-order part-of-speech filter and the \textsc{ppmi} weighting: in the first group of lemmas, \texttt{lex} models occupy a specific area of the Level 1 plot; in the second they are isolated next to the \texttt{PPMIweight} models (and sometimes \texttt{REL} as well), and in the third, no effect of the part-of-speech setting is found. The next level of columns distinguishes the effect of window size among the \texttt{BOW} models. A radial window configuration means that models with a window of 5 lie between those with a window of 3 and those with a window of 10. Typically, the models with smaller windows are closer to the dependency-based models, with \emph{huldigen} being an exception. Three of these lemmas do not really exhibit a radial structure, but the models with the smallest window tend to be isolated instead. Finally, the rows indicate an effect of the second-order vectors: the first row gathers the lemmas with a separate section for the \texttt{5000all} second-order configuration; the second, lemmas where models with \texttt{5000} vectors simply have a tendency to wrap around the rest of the models (like the wings of a beetle), and the third row is used for the lemmas where second-order parameters have no special effect on the organization of their models. Models with \texttt{5000all} second-order configuration are consistently messy, and tend to make the type-level distances between all pairs of context words huge.

As we can see in the table, these patterns are not related to the part-of-speech of the target or the semantic phenomena we expect in it. This variability and the different ranges of distances between the models are the reason why selecting medoids is the most reasonable way of exploring the diversity of models.

Qualitatively, the same set of parameter settings can generate multiple different solutions, depending on the distributional properties of the lemma being modelled. We already saw this in the comparison between Figures \ref{fig:besthomonym} and \ref{fig:switchbest}: what works best for one lemma will not necessary give a decent result in another. In this section, we briefly look at the models previously plotted in Figures \ref{fig:grey6} and \ref{fig:coloured6}. In all cases, the parameter settings are the same of the best model of \emph{stof}:
bound5lex-\textsc{ppmi}selection-\textsc{foc}all. The colour-coding matches the \textsc{hdbscan} clusters, and the shapes, the annotated senses.

In Figure \ref{fig:popular1}, we see the same model for \emph{heet} `hot' and \emph{stof} `substance, dust\ldots{}'. The model of \emph{heet} `hot' has 12 clusters, with roughly equal proportion of Cumulus, Stratocumulus and Cirrus clouds. Most of them are collocation clusters representing typical patterns within a sense, but we also find cases of semantic preference and a few heterogeneous near-open choice clusters. The \emph{stof} `substance, dust\ldots{}' model looks roughly similar, with 7 relatively homogeneous clusters: the three Stratocumulus on the upper left are the collocation clusters discussed in Section \ref{stof} and, next to the red Cirrus defined by semantic preference, they represent typical uses of the `substance' sense. The rest of the clusters, as discussed above, are more heterogeneous. A further difference between the two lemmas is that, while the homogeneous clouds of \emph{stof} `substance' represent typical uses that profile different dimensions of the sense, the typical patterns within \emph{heet} `hot' constitute idiomatic expressions.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/popular1-1.pdf}
\caption{\label{fig:popular1}Models of \emph{heet} and \emph{stof} with bound5lex-\textsc{ppmi}selection-\textsc{foc}all.}
\end{figure}

The lemmas shown in Figure \ref{fig:popular2}, \emph{dof} `dull' and \emph{huldigen} `to believe/to honour', look rather similar to each other but very different from the ones in Figure \ref{fig:popular1}. Even though \emph{dof} `dull', not unlike \emph{heet}, tends to have multiple clusters characterized by collocations with different types of sounds, it takes a different shape in this model. The metaphorical sense represented by the collocation with \emph{ellende} `misery' forms a neat orange Cumulus on one side; the semantic preference for sounds gives rise to the homogeneous light blue Stratocumulus below, and the rest of the tokens, both those related to the visual sense and the rest of the metaphorical ones, gather in the heterogeneous green Stratocumulus. As we have seen before, \emph{huldigen} also has some strong collocates, but in this model, the tokens of `to believe', led by \emph{principe} `principle', \emph{opvatting} `opinion' and \emph{standpunt} `point of view', take part of an extremely homogeneous orange Stratocumulus, while most of the `to pay homage' sense covers the light blue Cumulonimbus, like in the case described in Section \ref{huldigen}.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/popular2-1.pdf}
\caption{\label{fig:popular2}Models of \emph{dof} and \emph{huldigen} with bound5lex-\textsc{ppmi}selection-\textsc{foc}all.}
\end{figure}

The lemmas in Figure \ref{fig:popular3}, \emph{haten} `to hate' and \emph{hoop} `hope/heap', show yet another configuration generated by the same parameter settings. Except for the green Stratocumulus in \emph{haten}, roughly dominated by \emph{mens} `human, people', the rest of the clouds are Cirrus clouds: small, heterogeneous, characterized by many different words.



\begin{figure}
\centering
\includegraphics{phdThesis_files/figure-latex/popular3-1.pdf}
\caption{\label{fig:popular3}Models of \emph{haten} and \emph{hoop} with bound5lex-\textsc{ppmi}selection-\textsc{foc}all.}
\end{figure}

\hypertarget{theo3-summary}{%
\section{Summary}\label{theo3-summary}}

The output of a model is not directly predictable from its parameter settings. Clouds can take many shapes, lemmas exhibit different distributional patterns, and these patterns can have different semantic interpretations. The parameter settings that model one phenomenon best, in a certain model, will not necessarily model the same phenomenon in another lemma, or anything else of interest for that matter.
The same parameter settings can result in drastically different shapes across lemmas, or even if the shapes are similar and they are the result of comparable distributional behaviours, they might have different semantic interpretations.

With these cheerful thoughts, the analytical part of this dissertation comes to an end. In the next chapter I will conclude with a brief summary of the findings in the form of guidelines --- tips and tricks for the interested cloudspotter --- thoughts for further research.

\hypertarget{part-the-cloudspotters-cheatsheet}{%
\part{The cloudspotter's cheatsheet}\label{part-the-cloudspotters-cheatsheet}}

\hypertarget{conclusions-and-guidelines}{%
\chapter{Conclusions and guidelines}\label{conclusions-and-guidelines}}

The focus of this dissertation is methodological: rather than describing a specific phenomenon in language, e.g.~metaphorical extensions of temperature terms in Italian, it develops and tests a workflow that could be used in concrete case studies. It combines computational techniques with a Cognitive Semantics framework with the aim of implementing \textsc{nlp} tools to lexicological and lexicographical research. From this position, the main research questions revolve around the possible mappings between parameter settings, i.e.~sets of decisions that generate different models, and semantic phenomena of lexicographic interest:

\begin{itemize}
\tightlist
\item
  Which parameter settings model senses the best?
\item
  How can we tailor the parameter settings to capture homonymy, metaphor, specialization, argument structure\ldots?
\end{itemize}

In addition, since manually annotated senses are not taken as a unique truth and, beyond accuracy, we are interested in what makes models (fail to) approximate human-based categories, the study incorporates \emph{ad hoc} visual analytics for a fluid, quantitatively-rich qualitative analysis.

After an initial presentation of the foundations of the study in the \protect\hyperlink{intro}{Introduction}, Part I, \emph{The Cloudspotter's toolkit}, laid out the methodological background. Chapter \ref{workflow} described the computational techniques and the methodological choices, Chapter \ref{nephovis} showcased the visualization tools and Chapter \ref{dataset} introduced the selected lemmas and the annotation procedure.

Part II, \emph{The Cloudspotter's handbook}, discussed the results of the analyses. Even though the answer to the original research questions is negative, it is indeed possible to learn something from the models, and these three chapters elaborate on these possibilities.
Chapter \ref{shapes} offered a typology of the nephological shapes, for not all the clouds in the sky are white and fluffy. These shapes result from identifiable properties of the contexts and can be interpreted in different ways.
Chapter \ref{semantic-interpretation} followed with a systematization of these possible interpretations from a linguistic perspective. A net of phenomena is woven from a combination of paradigmatic relations --- from heterogeneous clusters to clouds that reveal semantic profiling of patterns --- and syntagmatic relations --- from collocations through semantic preference to open-choice tendencies. They are not the same phenomena we set out to investigate initially; although we may find metaphor, metonymy, specialization and argument structure, it greatly depends on each lemma and on how it matches these semasiological categories to its distributional behaviour. It is not enough for a lemma to \emph{have} metaphorical extensions, they also have to correlate with salient contextual patterns. Nevertheless, we do find linguistic properties --- and particularly the kind of properties that corpus-methods can capture while other empirical approaches might not.
Finally, Chapter \ref{no-optimal} illustrated the negative answer to the main question: there is no set of parameter settings that works best across the board. Each lemma has a different semasiological structure in terms of distributional behaviour, thus applying the same tool will return different results. If a parameter configuration is a cookie cutter, the various lemmas are kinds of mixtures: lemon-flavoured cookie dough, dough with chips, dough flattened by an embossed rolling pin\ldots{} or even sourdough or cake batter.

In the remainder of this chapter I will summarize some points that emerge from the dissertation as a whole. First, Section \ref{naive} offers a possible explanation for the discrepancy between the expectations that we may come to distributional models with and the actual results. However, this shall not stop us: Section \ref{tips} lists a few technical guidelines for model building, based on the set of models explored here, and Section \ref{further} is dedicated to general suggestions for further research based on what was not done for this project. Finally, Section \ref{contributions} summarizes the contributions of this dissertation to distributional approaches to semantics.

\hypertarget{naive}{%
\section{Types, tokens and clouds}\label{naive}}

Distributional models rely on the Distributional Hypothesis: words that occur in similar contexts tend to be semantically similar. That seems to work for types, and projecting the intuition onto the token-level sounds straightforward: attestations occurring in similar contexts will be semantically similar, and those occurring in different contexts will be semantically different. Semantic distinctions between attestations of a word, i.e.~their semasiological variation, are normally grouped as senses. So it stands to reason that we can use token-level distributional models to find senses \autocite{schutze_1998,yarowsky_1995}. However, this line of reasoning has two issues.

On the one hand, there is the issue of patterns.
At the type-level, vector representations aggregate over all the occurrences, building profiles that take into account patterns of attraction and avoidance across hundreds, thousands or even millions of events. Similar words share the same tendencies; different words prefer different things.
The intuition behind distributional models is often illustrated with examples like the following \autocite[613]{pantel.lin_2002}:

\begin{quote}
A bottle of \emph{tezgüno} is on the table.

Everyone likes \emph{tezgüno}.

\emph{Tezgüno} makes you drunk.

We make \emph{tezgüno} out of corn.
\end{quote}

The authors make the point that the words in the context of \emph{tezgüno} suggest that it may be a kind of alcoholic beverage, because other alcoholic beverages tend to occur in similar contexts \autocite[613]{pantel.lin_2002}. And indeed, at \emph{type-level}, such patterns are likely to generate a distributional profile for \emph{tezgüno} that is similar to that of \emph{beer}, for example.
And even though actual contexts are rarely as self-explanatory as these examples, type-level distributional models --- to some degree at least --- \emph{work}.

Type-level models will be most similar between words with similar overall \emph{patterns}: tendencies towards or against certain contexts. Each individual context is not enough. The examples above highlight different properties of \emph{tezgüno}, namely that it is a liquid stored in bottles, that people have (positive) opinions about it, that it is alcoholic and that it is made out of corn. The range of items that could occur ``in the same context'' of \emph{tezgüno} will depend on which of the contexts we take into account. Take, for example, the following replacements:

\begin{quote}
A bottle of \emph{water} is on the table.

Everyone likes \emph{you}.

\emph{Whiskey} makes you drunk.

We make \emph{cornflakes} out of corn.
\end{quote}

Each context is not enough: at most, they set up situations in which some meaning or meaning dimension fits, while the other dimensions, whatever they are, are backgrounded and irrelevant. Type-level models work because they look at all the contexts together. At the same time, we cannot really know if the \emph{tezgüno} that makes you drunk and the one made of corn are the same \emph{tezgüno}; type-level models build on the assumption that they do, and for that reason they conflate semasiological structure.

In the same way, token-level models look for patterns, i.e.~tendencies towards or against certain contexts or context words, but with a much more restricted pool of variables. First, the context of a token contains fewer variables than the aggregated context of a type to draw a pattern from, which results in more polarization and less nuance. Frequently co-occurring words will dominate and define what counts as a pattern, while weaker words will lack the necessary distinctiveness to impose their patterns. And because authentic concordances are not neat, propositional, explanatory descriptions of the targets, these patterns do not necessarily match \emph{senses}.

That is, in fact, the second issue. The possibility of determining what counts as different senses is debatable \autocite{geeraerts_1993,glynn_2014c}, so why should we look for senses in the first place? Indeed, Geeraerts suggests a procedural rather than reified conception of meaning: ``words are searchlights that highlight, upon each application, a particular subfield of their domain of application'', and adds that ``the distinction between what can and what cannot be lit up at the same time is not stable'' \autocite[137]{geeraerts_2006e}. In terms of clouds, context words compete for the opportunity to signal the subfield highlighted by the target at the moment. The result is imprecise for several reasons.
First, the context words are represented as type-level vectors that generalize over their most salient patterns, which are not necessarily the relevant dimension in this context, as in the case of \emph{uitspraak herroepen} `to recant a statement/to void a verdict' discussed in Section \ref{uitspraak}.
Second, the dimension the context words highlight are not necessarily the ones we are interested in; there is structure in models of \emph{heilzaam} `healthy/beneficial' discussed in Section \ref{heilzaam}, but it does not correspond to the distinction between literally healthy or healing and metaphorically healthy, i.e.~beneficial.
Third, and in relation to the issue of patterns, the context words might be too infrequent and not distinctive enough for their voice to reach us.

On the bright side, there is so much variation across these patterns that their shapes alone are already interesting information. All words can be described with lists of collocations, but token-level models reveal how strong (or weak), how distinctive, how widespread the collocations are within the scope of the target. And beyond the clouds themselves, visualizing the models can let us see spatial organization that might be missed by clustering solutions, such as the fact that the occurrences of \emph{uitspraak herroepen} `to recant a statement/to void a verdict' come together while staying close to other instances of \emph{herroepen} `to void' in a juridical context, or the fact that health-specific and general attestations of \emph{heilzame werking} `beneficial effect' occupy opposite poles of the same cluster. Distributional models might not replicate our intuitions about the semantic distinctions within a lemma, but will offer us a different, complementary perspective that only they, by scanning and organizing hundreds of empirical observations, may capture.

\hypertarget{tips}{%
\section{Practical tips}\label{tips}}

Even if there is no infallible parameter settings configuration and it is hard to predict their output, some guidelines are possible. In this section I would like to offer some suggestions for a future case study that would use distributional semantics and, of course, the visualization tools presented here, to investigate the semasiological structure of a given lemma. The initial research questions would go along the lines of ``How strong are the collocational patterns of this lemma?'', for example. Given the variety of results from the 32 lemmas analysed for this dissertation, all these guidelines can offer is a starting point to explore the distributional behaviour of a lemma; further steps to refine the questions and fine-tune the models would depend on the results from such initial exploration. In broad terms, the outline of such a case study would be as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Choose your lemma(s)\footnote{They could be separate words, as different case studies, or related words that might overlap in the application. In that case, it would be possible to combine a semasiological perspective, i.e.~looking at the distribution of each lemma, with an onomasiological perspective, i.e.~exploring the overlap and differences between the lemmas.}. In the Nephological Semantics project we look for ways of scaling up this procedure, but these are suggestions for small-scale studies, where a detailed examination of the clouds is viable.
\item
  Set up a range of parameter settings that are not too restrictive:

  \begin{itemize}
  \tightlist
  \item
    keep window sizes above 3;
  \item
    forget about sentence boundaries;
  \item
    avoid long, unfiltered type-level vectors;
  \item
    don't bother with \texttt{REL} templates;
  \end{itemize}
\item
  Generate hundreds of models on a manageable sample of tokens based on those parameters;
\item
  Explore the plot of models in Level 1 of NephoVis (Section \ref{nepho1}) to get an idea of how the parameter settings interact;
\item
  Compute up to 9 medoids with \textsc{pam} and explore them in Level 2 of NephoVis;

  \begin{itemize}
  \tightlist
  \item
    I chose 8 because it was the minimum that kept enough variation across lemmas, but on a lemma-by-lemma basis it could very well be reduced. More than 9 medoids are difficult to visualize simultaneously.
  \end{itemize}
\item
  Cluster the models with \textsc{hdbscan} and explore them with the ShinyApp, finding types of clouds, collocational patterns, etc. The classifications in Chapters \ref{shapes} and \ref{semantic-interpretation} will be useful, for example:

  \begin{itemize}
  \tightlist
  \item
    Cumulus clouds (very tight and salient) tend to be dominated by strong collocates and represent typical usages of a sense.
  \item
    Cumulonimbus clouds (the huge ones) are normally as good as noise tokens.
  \item
    When Cirrus clouds (the small, wispy ones) are the most salient clusters, they are capturing the little structure there is. The model is probably characterized by weak collocational patterns.
  \end{itemize}
\item
  Interpret the clusters.

  \begin{itemize}
  \tightlist
  \item
    What are the models saying? Are there collocates, lexically instantiated colligates, semantic preference, or neither? Are the clusters heterogeneous or homogeneous? Could they be considered different senses?
  \item
    Which medoids exhibit a more interpretable structure? What parameters do they represent?\footnote{For example, via a conditional tree with the clustering solution as response and the parameter settings as predictors.}
  \item
    How much more data is left to annotate?
  \end{itemize}
\item
  If necessary, readjust the parameters and/or incorporate manual annotation and start again.
\end{enumerate}

Among the interpretative questions, one of the most crucial ones is: ``Could they be considered different senses?''. I already mentioned in the introduction that the prototypicality of categories leads us to be sceptical about the existence of discrete senses. Accordingly, the clouds offer an alternative view on the semasiological structure of a lemma: a classification that neither matches dictionary senses nor replaces them, but could inform semantic research nonetheless. In the rest of this section I will elaborate on some of the recommendations made above.

First, I would discourage very restrictive models. We might be tempted to remove as much noise as possible and only leave context words that are very informative, which sounds reasonable in theory. But even assuming you can figure out which words are going to be informative --- e.g.~via annotation of cues --- the result might not be what you expect. Restrictive models tend to generate clouds with Hail: dense areas with identical tokens, which override more subtle relationships. The less ``relevant'' context words might be harmful, but they might also make no impact whatsoever, or even add information we did not expect, like the semantic profiling of specific patterns. That said, some lemmas may require very strict settings because the context words that would then be captured are already varied enough.

Concretely, window sizes smaller than 5 tend to be too restrictive, while the window size of 10 is already bordering into too noisy. Within the dependency-based models, \texttt{RELgroup1} models are often too restrictive and rarely informative enough. A wider variety of \texttt{REL} templates is more useful, but in any case, designing the templates to fit increasingly complex patterns --- especially when chains of verbs come into play --- is time consuming and never good enough. \texttt{REL} models could be discarded altogether, unless the researcher has a good idea of which templates are useful for the specific lemma under study. For example, \emph{haten} `to hate' tends to occur in active constructions without chains of modals (e.g.~\emph{ik haat het} `I hate it'), while \emph{herroepen} `to recant, to void' often co-occurs with the passive auxiliary, modals or even both (e.g.~\emph{het nachtverbod moest worden herroepen} `the night ban had to be voided'). As a result, a simple \texttt{REL} template capturing the direct object of the verb could be enough for \emph{haten} `to hate'\footnote{We might want to do this because in the current models the strongest context word is \emph{ik} `I', which does not contribute to the disambiguation. However, a brief test modelling the direct objects revealed that they were grouped thematically instead of by animacy, and thus could not model the distinction between `to hate' and `to dislike' either. Maybe other second-order settings could return a more adequate model.} but would miss many of the \emph{herroepen} `to recant, to void' tokens.

In a similar vein, \texttt{PPMI} can be too restrictive for some lemmas and should be used with care, especially \texttt{PPMIweight}, which might enhance the influence of already powerful context words and, for example, cause Cumulonimbus clouds. Since the filtering power of \texttt{PPMIselection} depends on the range of association strength values between the target and its context words, it is not straightforward to find a threshold that is just as restrictive as we want it to and not more for every lemma. Instead, it could be fruitful to test out different thresholds --- and even combine other measures --- on a lemma-by-lemma basis.

One parameter setting that should be certainly avoided is \texttt{5000all}, which often makes a great impact in the difference between models but never for the better. Either applying a part-of-speech filter or reducing the dimensionality, e.g.~by using the first-order context words as second order dimensions (\texttt{FOC}), already gives better results. This is most likely due to sparsity and/or low informativeness of the dimensions selected by \texttt{5000all}, so applying \textsc{svd} afterwards might also help.

Finally, ignoring sentence boundaries does not seem to make a difference. In most cases, Level 1 plots place models that are only different on this parameter right next to each other; the few times that it makes a difference, two or three other parameters are already more important.

These tips should help in the selection of parameter settings for future models, but it is still a good idea to generate multiple models and look at their medoids. Chapter \ref{no-optimal} showed that there is no unique recipe to tailor a model to disambiguate in a certain way. Models find patterns based on the distributional behaviour of the lemma --- how frequent its context words are, how similar they are to each other, how often they co-occur, etc. The degree to which these patterns match senses in general or any sort of semasiological structure --- homonymy relations, metaphor, idioms, argument structure\ldots{} --- is an empirical question, and that is what this procedure addresses. Fine-tuning can only be implemented after the first set of medoids have traced an outline of the lemma's structure.

What is more, the medoids can also provide an estimation of how much manual annotation is actually needed. Given a model like \emph{heffen} `to levy/to lift' or \emph{herinneren} `to remember/to remind', the patterns are so clear and homogeneous that checking the main context words of the different clusters and a few of their concordance lines is enough; at most, you would need to examine some noise tokens more closely. At the same time, in a case like \emph{heilzaam} `healthy/beneficial' you would immediately see that the collocation-based clouds are semantically heterogeneous, while a case like \emph{haten} `to hate' might make you want to rethink your life choices. In any case, you don't need to annotate all the tokens at the beginning unless there is an \emph{a priori} classification you are intent in finding. Even then, it's best to keep it under 6 categories, or it becomes really hard to distinguish their colour-coding visually.

These suggestions should avoid a lot of trial and error in case-studies along these lines. Interpreting clouds when we have not seen any before and, especially, if we expect them all to be clearly-defined islands, is quite challenging already. Besides, as \textcite[73]{geeraerts_2010} argues, ``empirical research involves an empirical cycle in which several rounds of data gathering, testing of hypotheses, and interpretation of the results follow each other'', and cloudspotting is no exception.

\hypertarget{further}{%
\section{To the sky and beyond}\label{further}}

The choices described in the \protect\hyperlink{intro}{Introduction} and Chapter \ref{workflow} implied leaving out the alternatives, which could very well be explored in future research projects.

At the level of parameter settings, other selections of part-of-speech filters, for example expanding \texttt{lex} with proper names and prepositions, could offer a middle point between the two options that were examined, since \texttt{lex} was sometimes too restrictive, while \texttt{all} could be too noisy. When it comes to dependency-based models, the natural extension is to incorporate the dependency path into the feature, e.g.~with ``is object of \emph{to eat}'' as a feature. This is technically more challenging and likely to result in sparser vectors, but would make the connection between the target and the second-order dimensions more clear. In the current implementation, the relationship between the target token \emph{study\(_1\)} and its second-order dimension \emph{language/n} in Table \ref{tab:tokens} is given by the association strength between said second-order dimension and the first-order context word \emph{lexicography/n}: \emph{lexicography/n} occurs in the immediate context of \emph{study\(_1\)} and has a \textsc{ppmi} of 4.37 with \emph{language/n}, so the coordinate of \emph{study\(_1\)} in the \emph{language/n} dimension is 4.37. If dependency relations are built into the feature, e.g.~``its object is \emph{lexicography/n}'', the dimensions highlighted by that feature would be other verbs that take \emph{lexicography/n} as object.

In relation to this issue, the precise effect of the second-order parameters has not been thoroughly explored, but techniques should be devised to better understand the effect of the second-order dimensions. Moreover, instead of comparing \texttt{FOC} second-order vectors with longer ones based on frequency, they could be compared with \texttt{FOC} vectors based on different samples: \texttt{FOC} models transfer the context words that survived the first-order filters as second-order dimensions, so the same set of parameter-settings on different samples --- particularly on samples of different sizes --- may result in different selections of context words. Additionally, they could be compared to implicit type-level vectors \autocite{lenci_2018}, i.e.~where the dimensionality was reduced by \textsc{svd} or nonnegative matrix factorization, or even prediction-based vectors. The original reason not to implement this was to keep the transparency of the vectors to a maximum \autocite{heylen.etal_2015}, but the transition to second-order vectors already obscures the meaning of the dimensions to a great extent.

Following this reasoning, the motivation to exclude prediction-based models disappears. On the one hand, type-level word embeddings could be incorporated as representations of the first-order context words. On the other, given the possibilities offered by the family of \textsc{bert} models, \textsc{bert}je \autocite{devries.etal_2019} could be applied to the tokens themselves. For a proper comparison between the methods, new models would have to be created with word forms as units, re-tokenizing the corpus with \textsc{bert}je's tokenizer. The first goal would then be to check how well the classifications presented in Chapters \ref{shapes} and \ref{semantic-interpretation} can be mapped to models based on word forms and to what degree they also apply to \textsc{bert}je models. Nonetheless, concerns about the tokenization should be addressed: the output might be useful for certain \textsc{nlp} tasks, but if words cannot be captured because the tokenization breaks them (as is the case of \emph{heilzaam}, which is split between \emph{heil} and \emph{\#\#zaam}), the utility of \textsc{bert}je for lexicographical purposes decreases. A solution might be the implementation of larger units as targets and features in modelling procedure, such as bigrams. That in itself is another interesting avenue for further research, since words do not work in isolation, but technically more challenging.

Not only the model-building process, but also the model-analysis process could use a deeper exploration. First, the possibility of implementing \textsc{umap} should be explored. Based on initial comparisons, the clarity of the clusters does not seem to be very different from the t-\textsc{sne} output, but the shapes are different and their relative distances are supposed to be interpretable. In addition, \textsc{hdbscan} clustering with \(minPts = 8\) replicates the visually identified patterns quite well, but it is not always clear when tokens are excluded as noise or how distinctive the clusters have to be to split. That said, switching to \textsc{umap}, other perplexity values for t-\textsc{sne} and/or other \(minPts\) values for \textsc{hdbscan} \emph{may} void the warranty on the classifications and descriptions offered in this dissertation.

\hypertarget{contributions}{%
\section{Summing up}\label{contributions}}

Distributional semantics addresses an issue for descriptive linguists who would like to use corpus methods
for semantic analysis. Such a linguist would be eager to exploit the increasingly large available corpora but tired of manually annotating hundreds of concordances with sense tags that might not even be that appropriate\footnote{Or of finding ways for other people to do so.}. Distributional models, on the other hand, present themselves as a scalable, automatic approach that can process large amounts of textual data and extract patterns with semantic correlates. They constitute an irresistible asset for empirical approaches aiming to maximize the automation of the most laborious, quantitative tasks and give the researcher more energy and time for the creative and hermeneutic aspects of research.
This dissertation was written for such a linguist, and it has good news and bad news.

The bad news is that, although distributional models can indeed reveal patterns and
offer information that we might not obtain by other means, these are not necessarily \emph{the} patterns and
information we would have expected. The results from this study suggest that, if we are to use distributional
semantics for descriptive analyses, we should not do so blindly.
Unlike what high accuracy scores on benchmarks would suggest, there is no parameter setting that works optimally across the board, because what is relevant in the description of one lexical item might not be for another. For the same reason, different configurations of parameter settings will have different effects on each lemma, highlighting specific aspects that may be more or less interesting from a linguistic perspective. They may be senses, or they may be something else.

The good news is that a user-friendly, comprehensive visualization tool is available for the exploration of such models. Interfaces like the ones described here turn the apparent chaos of distributional models into concrete visual representations for us to examine and interrogate. Rather than despairing in the face of multiple diverse models, we can create a composite picture based on a few representative models: we embrace the complexity and thus achieve a richer, more nuanced description. These tools offer both a fluid interaction with the output of the models and a look into their backstage operations.

In sum, this dissertation illustrates why, as descriptive linguists, we shouldn't trust distributional models blindly, but also how we can exploit them nonetheless. On the one hand, it illustrates a workflow for investigating distributional modelling itself: the same steps followed in this study can be applied to alternative implementations for a better understanding of distributional approaches. On the other hand, with both warnings and suggestions, it offers a framework and tools for future studies implementing token-level distributional models to linguistic research or, as we like to call it, linguistic cloudspotting.

\printbibliography[heading=bibintoc]

\includepdf{assets/covers/back-cover.pdf}

\end{document}
