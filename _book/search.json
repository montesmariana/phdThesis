[{"path":"index.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"’m starting first draft ever PhD dissertation.\r\nreports scattered place, try write things already\r\nthinking Final Product. need layout (briefly discussed end February) \r\nslowly start building final text.original title (case, title project) \r\nMethodological triangulation corpus-based distributional semantics,\r\ntriangulation part lost somewhere along way.really develop visualization,\r\nbased Thomas Wielfaert’s original code,\r\nanalyze parameter settings multiple ways,\r\nchecking different combinations exploring different avenues,\r\nlead, check, study compare manual annotation 32 lemmas.’m going write .","code":""},{"path":"acknowledgments.html","id":"acknowledgments","chapter":"Acknowledgments","heading":"Acknowledgments","text":"words pages, thoughts try convey, result \r\nyears thinking, discussing, studying, learning. voice weaves together,\r\ndraws many sources encouraged growth, stood ,\r\nfed curiosity, passion enthusiasm everything makes text.support ideas, want thank supervisors Dirk Geeraerts,\r\nDirk Speelman Benedikt Szmrecsanyi. gave piece, building\r\nconfidence, encouraging keep exploring learning. main supervisor,\r\nDirk Geeraerts, deserves special acknowledgment hours deep\r\ndiscussion complex issue meaning, \r\n. appreciate patience engagement. Every time talked left\r\nfeeling excited passionate topic, confident happy.\r\nHartelijk bedankt.must also thank colleagues Linguistics Department KU Leuven,\r\ndifferent stages years lovely company \r\nsupport system. particular, like thank members \r\nNephological Semantics project, shared much excitement \r\nfrustrations common project.\r\njoined project, already brought history connection\r\n(cognitive) linguistics, corpora, statistics programming. honestly wouldn’t\r\ntoday weren’t parents, Miguel Patricia. \r\nalways supported fostered study interests, given tools \r\ngrow, face new challenges. know can, believe .","code":""},{"path":"an-interface-to-the-world-of-clouds.html","id":"an-interface-to-the-world-of-clouds","chapter":"1 An interface to the world of clouds","heading":"1 An interface to the world of clouds","text":"part (knows many chapters) mean describe\r\nvisualization tool. originally created Thomas Wielfart,\r\naround July 2019 started play around code learn Javascript\r\nD3, culminating present version (Montes QLVL 2021).section include technical description workflow, pertains\r\ntool processing work made (Python module, \r\nPython R functions), sort manual ’s used. less\r\nredundant paper wrote Kris December (Montes Heylen, n.d.),\r\nless like vignettes documentation (now, still documented).high level automatization vector space models makes possible analyze semantic patterns huge amounts corpus data. advantage making semantic analyses data-driven, also implies lower level control linguist, confronted advanced statistical output straightforwardly interpretable terms linguistic phenomena investigation. case vector space models, especially approach combines multiple parameter settings generate multitude models, output array distance matrices “somehow” models different aspects probabilistic semantic structure. interpret understand statistical modelling linguistic perspective, turn visual analytics.Visual analytics aims integrate statistical data analysis techniques information visualization human analysts can recognize, interpret reason statistical patterns data analysis reveals (Card, Mackinlay, Shneiderman 1999). Importantly, visual analytics approach offers manipulable, interactive visualization , unlike static diagrams, enables exploration space parameter values modelling outputs.Lexical semantic research vector space models benefit tool aids\r\n) visualization distance matrices based high-dimensional data,\r\nii) comparison multiple models \r\niii) detailed examination input models.","code":""},{"path":"parameter-settings.html","id":"parameter-settings","chapter":"2 Parameter settings","heading":"2 Parameter settings","text":"chapter describe various parameter settings explored:\r\npossible decisions, ones set looked ,\r\n. preceded explanation workflow .","code":""},{"path":"parameter-settings.html","id":"first-steps","chapter":"2 Parameter settings","heading":"2.1 First steps","text":"targets first second order features lemma/part--speech pairs,\r\nhaak/verb (verb haken ‘hook/crochet’),\r\nbeslissing/noun (noun beslissing ‘decision’), /prep\r\n(preposition ‘’).\r\nfeatures (context words) can part speech except punctuation\r\nminimum relative frequency frequency 1 2 million (absolute frequency 227)\r\ndiscarding punctuation token count full\r\nQLVLNews corpus. 60533 lemmas corpus.(threshold less arbitrary, ’re assuming words lower frequency\r\nwon’t rich enough vectorial representation.)steps defining corpus types obtaining token-level vectors,\r\ntwo main kinds parameters explore.\r\nFirst-order parameters influence context features selected\r\nimmediate environment target tokens,\r\nsecond-order parameters influence shape vectors\r\nrepresent first-order features.order visualize tokens, performed dimensionality reduction, .e.\r\nprocess try represent relative distances items low-dimensional space\r\npreserving distances high-dimensional space much possible.\r\nprocedure described [appropriate section].","code":""},{"path":"parameter-settings.html","id":"first-order-selection-parameters","chapter":"2 Parameter settings","heading":"2.2 First-order selection parameters","text":"call immediate context token first order context: therefore,\r\nfirst-order parameters influence elements immediate environment\r\ntoken included modeling said token. made two stages:\r\none dependent whether syntactic information use, one independent .goes without saying parameter space virtually unlimited, decisions\r\nmade regarding particular settings explored. tried \r\nkeep parameter settings different enough variation.\r\ndecisions based mix literature (Kiela Clark 2014),\r\nlinguistic intuition generalizations annotation targets.\r\n\r\npart annotation task, annotators select items \r\nimmediate context helped select appropriate tag. order remove\r\nnoise misunderstandings idiosyncrasy, looked pairs (trios) \r\nannotators agreed final annotation ranked\r\ncontext words agreed. distance dependency information\r\ncontext words used inform decisions .first stage, main distinction made BASE: bag--words (BOW) based\r\ndependency-based models (LEMMAPATH LEMMAREL).\r\nformer split window size (FOC-WIN), part--speech filters (FOC-POS)\r\nwhether sentence boundaries respected (BOUND).FOC-WIN (first order window)symmetric window 3, 5 10 tokens side target used.\r\ncourse, virtually value possible [add references!]. Windows \r\n5 10 typical literature [sources?], 3 enough capture \r\ncontext words tagged informative annotators.\r\nFOC-POS (first order part--speech)restriction placed select (common) nouns, adjectives, verbs adverbs (lex)\r\nsurroundings token. restriction placed, value parameter .\r\ncourse, selections possible. [add reference] distinguish \r\nnav, includes common nouns, adjectives, verbs, nav-nap, \r\nexpand selection proper nouns, adverbs prepositions.\r\ndetailed research different combinations material \r\nresearch. see, lex filter often redundant one based \r\nassociation strength.\r\nBOUNDARIESGiven information limits sentences (e.g. corpora annotated \r\nsyntactic dependencies), can exclude context words beyond sentence target (bound)\r\ninclude (nobound).\r\nparameter seems virtually irrelevant. thought way \r\nleveling comparison dependency-based models, definition don’t\r\ninclude context words beyond sentence, don’t seem make difference.\r\ndistinction BOW- dependency-based model doesn’t rely much \r\ncontext words selected tailored selection specific\r\ntokens. example, closed-class element like preposition may distinctive\r\nparticular usage patterns term might occur. However, frequent,\r\nmultifunctional word easily occur immediate raw context target\r\nwithout actually related . Unfortunately, just narrowing window span\r\ndoesn’t solve problem, since also drastically reduce number \r\ncontext words available token token model.\r\ncontrast, also context words directly linked target\r\nseparated many words , enlarging window include\r\nimply much noise token token model.dependency-based model, instead, include context words certain\r\nsyntactic relationship target, regardless number words .\r\nactual selection process takes two forms case: path length \r\nrelationship. former, call LEMMAPATH, similar window size\r\ncounts steps dependency path instead slots bag--words window.\r\nlatter, LEMMAREL, matches dependency paths specific templates inspired\r\ncontext words tagged informative annotators.exemplify, let’s look (1) take herhalen ‘repeat’ target.De geschiedenis rond Remmelink herhaalt zich. ‘history around Remmelink repeats .’LEMMAPATHThis set dependency-based models selects features enter syntactic\r\nrelation target maximum number steps.\r\npossible values included selection2 selection3, filter\r\ncontext words two three steps away, respectively, weight, \r\ngives larger weight context words closer dependency path.\r\none-step dependency path either head target direct dependent.\r\nfeatures included selection2 selection3 receive weight 1 weight.\r\n(1) includes subject, geschiedenis ‘history,’ reflexive pronoun zich,\r\ndepend directly . target geschiedenis ‘history,’ herhalen ‘repeat,’\r\nhead, selected.\r\ntwo-step dependency path either head head target, dependent dependent,\r\nsibling. features included selection2 selection3 receive weight 2/3 weight.\r\n(1) includes determiner de modifier rond ‘around’ directly depending \r\ngeschiedenis ‘history.’\r\nthree-step dependency path either head head head target,\r\nsibiling head head, dependent dependent dependent,\r\ndependent sibling. typical case last path subject passive construction modal,\r\ntarget verb participium (belastingen ‘taxes’ de belastingen moeten geheven worden ‘taxes must levied’).\r\nfeatures included selection3 excluded selection2 receive weight 1/3 weight.\r\n(1) corresponds Remmelink, object rond ‘around.’\r\nFeatures 3 steps away target always excluded.\r\nfeatures four steps away can interesting, passive subjects verb two modals, frequent may worth noise included accepting features many steps target. catch relationships, LEMMAREL efficient method.\r\ncontext words three steps away target (1).\r\nLEMMARELThis set dependency-based models selects features enter certain\r\nsyntactic relation target. tailored part--speech target,\r\ngroup expands selection group . specific selections\r\nlisted Table 2.1.\r\n\r\nTable 2.1: Dependency paths selected different LEMMAREL values.\r\ngroupsnounsverbsadjectives1modifiers determiners target, items target modifier determiner, verbs target object subjectdirect objects, active passive subjects (two modals active one), reflexive complement prepositions depending directly targetnouns modified target direct modifiers (except prepositions), subject direct objects verbs target direct modifier predicate complement, one modal auxiliary between2conjuncts target (without conjunction), objects modifier target, items whose modifier target objectconjuncts target, complementizers, nouns depending preposition verbal complements elements target verbal complementobject preposition modifying target, conjunct target (without conjunction), prepositional object verb modified target (modifier prepositional complement)3objects modifiers items target subject modifier, subjects modifiers items target subject modifier, modifiers modifiers target, items whose modifier target modifier","code":""},{"path":"parameter-settings.html","id":"ppmi-weighting","chapter":"2 Parameter settings","heading":"2.2.1 PPMI weighting","text":"PPMI parameter taken outside set first-order parameters can filter first-order features reshape vector representations. truth, choice positive pointwise mutual information (PPMI) weighting mechanisms, well setting threshold , already parameter setting, circumstances set PPMI threshold 0. cases, PPMI calculated based 4-4 window (also variable parameter).parameter can take three values. selection weight mean first-order features PPMI > 0 target type selected, rest discarded, apply filter. difference selection weight former uses value filter context features, latter also weighs vectors value.","code":""},{"path":"parameter-settings.html","id":"second-order-selection","chapter":"2 Parameter settings","heading":"2.2.2 Second-order selection","text":"selection second-order features influences shape vectors: selected first-order features represented. frequency transformation window values computed varied, set fixed values, namely PPMI 4-4 respectively. parameters varied across, although don’t expect drastic differences models, vector length part--speech.SOC-POS (second order part--speech)parameter can take two values: nav . former case, selection 13771 lect-neutral nouns, adjectives verbs made Stefano taken set possible second-order features. latter, lemmas frequency 227 part--speech considered.\r\nLENGTHVector length number second-order features therefore dimensionality matrices distance matrices based, although amount changes. applied filtering part--speech.\r\nselected two values: 5000 FOC. former includes 5000 frequent elements possible features, latter takes intersection possible second-order-features first-order-features, regardless frequency. SOC-POS:, FOC include first-order features model, SOC-POS:nav, included Stefano’s selection.\r\nactual number dimensions resulting FOC depends strictness first order filter. information can found plots , staal, show many first order context words left combination first order filters.\r\n","code":""},{"path":"parameter-settings.html","id":"foc-as-soc","chapter":"2 Parameter settings","heading":"2.2.2.1 FOC as SOC","text":"mean use first-order context words second-order context words?First, depending number target tokens strictness filter, different number context words, ranging hundreds low thousands.Second, context words compared based co-occurrence . behaviour context word outside context target largely ignored: course, association strength two items co-occurrence across whole corpus, well non-co-occurrence, included second order vector first item second also among first order context words.","code":""},{"path":"parameter-settings.html","id":"medoids","chapter":"2 Parameter settings","heading":"2.3 Medoids","text":"multiple parameters return huge number models, purely quantitative methods might\r\nable process compare , feasible human look hundreds clouds\r\nstay sane enough make anything . efficient –easier human mind–\r\nway approach , instead, look representative models.method requires us choose number medoids beforehand, easy\r\ntask. wanted medoids represent best clustering solution, run\r\nalgorithm different values \\(k\\) compare results measures \r\nsilhouette width, suggested Levshina (2015). However, \r\nnecessarily goal. want able see much variation possible, keeping\r\nnumber different models manageable (.e. 9). particularly problematic\r\nmodels redundant, long can ensure phenomena \r\ninterested represented .example, given lemma multiple senses, might case models\r\ngroup tokens one sense, others group tokens another: like see\r\nrepresentatives kinds.\r\nguarantee method best silhouette returns variation \r\ninterested –goal , rather, limit number different models need \r\nexamine total number, say 200, manageable amount, like 8.\r\nterms, also guarantee identify something interesting\r\nmedoid, .e. island particular usage pattern, models cluster \r\nmedoid, models, share characteristic. order check ,\r\ncan look random samples (, 8 9 models) clusters \r\nvisually compare medoids. doesn’t need thorough examination \r\nmedoids : suffices check random sample different\r\nseems share characteristic interest. [add example]general terms, characteristics identified case studies make \r\ninvestigation, can quite confident medoids representative models \r\nclusters. However, depending concreteness phenomena, variation across\r\nmodels, clarity visualization wishful thinking might lurk \r\nresearchers’ minds, might case something found assessed medoid \r\nshared models cluster. comparison needed random sample \r\nfast honest strongly recommended: medoids representative, can see \r\ninstant; , just takes bit longer admit . actually studying comparing 64 different models.","code":""},{"path":"from-corpora-to-clouds.html","id":"from-corpora-to-clouds","chapter":"3 From corpora to clouds","heading":"3 From corpora to clouds","text":"main goal distributional models discussed text explore semasiological structure\r\ntextual data. starting point corpus, one tangible outputs visual representation\r\ncloud.chapter describe path needed take generate clouds raw,\r\nseemingly indomitable ocean corpus.First, describe token-level vector space models created.\r\nSection 3.1 explain count-based models, means viable path.\r\ntechniques, BERT (Devlin et al. 2019), can generate vectors individual instances word,\r\ncan used first stage workflow.\r\ntoken-level vectors, need process . visualization purposes,\r\nneed reduce numerous dimensions vectors manageable number, 2.\r\nSection 3.2 explore compare alternatives.output put dimensionality reduction visualization can also\r\nsubmitted forms analysis clustering algorithms, whose results may\r\neven combined visualization. look HDBSCAN \r\n","code":""},{"path":"from-corpora-to-clouds.html","id":"vector-creation","chapter":"3 From corpora to clouds","heading":"3.1 A cloud machine","text":"core vector space models, aka distributional models, find Distributional Hypothesis, often linked Harris’s observation “difference meaning correlates difference distribution” (1954, 156). words, items occur similar contexts given corpus semantically similar, occur different contexts semantically different. Crucially, imply can describe individual item distributional properties, comparing distribution two items can tell us something semantic relationship (Sahlgren 2006, 19).Distributional models operationalize idea representing words vectors (.e. arrays numbers) coding frequency information. Typically, raw frequency transformed association strength measure, pointwise mutual information (PMI, see Church Hanks 1989), compares frequency two words occur close expected frequency words independent. example, Table 3.1 shows small vectors representing English nouns linguistic, lexicography, research chocolate, well adjective computational, series association strengths set lemmas. Empty cells indicate word row word column never co-occur corpus (given certain window span).\r\nTable 3.1: Example type-level vectors.\r\ntargetlanguage/nword/nflemish/jenglish/jspeak/vlinguistics/n4.370.993.160.41lexicography/n3.512.182.192.09computational/j1.600.08-1.00-1.80research/n0.20-0.840.04-0.50-0.38chocolate/n-1.72-0.531.28-0.73-1.13PMI values based symmetric window 10; frequency data GloWbE.row vector coding distributional information lemma represents. can see example, words similar vectors (e.g. linguistics lexicography) semantically similar, words different vectors (e.g. linguistics chocolate) semantically different.vectors Table 3.1 type-level vectors: aggregates instances given word, e.g. linguistics, build overall profile. result, collapses internal variation lemma, .e. semasiological structure. order uncover information, need build vectors individual instances tokens, relying principle: items occurring similar contexts semantically similar. instance, might want model three (artificial) occurrences study (2) (4), target item italics.like study lexicography?study computational linguistics well.eat chocolate study.Given , aggregate level, word can co-occur thousands different words, type-level vectors can include thousands values. contrast, token-level vectors can many values individual window size comprises, drastically reduces chances overlap vectors. fact, three examples don’t share item target. solution, inspired Schütze (1998), replace context words around token respective type-level vectors (Heylen et al. 2015; De Pascale 2019).example, represent example (2) vector context word lexicography, , second row Table 3.1; example (3) sum vectors linguistics (row 1) computational (row 3); example (4) vector chocolate (row 5). solves sparsity issue, ensuring overlap vectors, also allows us find similarity (2) (3) based similarity vectors lexicography linguistics.applying method obtain numerical representations occurrences word. can compare calculating pairwise distances, base clustering analyses visualization techniques based dimensionality reduction. However, order obtain result need make number decisions involved, mostly, defining context used represent item (Cf. Bolognesi 2020, 23:83).","code":""},{"path":"from-corpora-to-clouds.html","id":"dim-reduction","chapter":"3 From corpora to clouds","heading":"3.2 Dimensionality reduction","text":"Dimensionality reduction refers algorithms try locate different items low-dimensional space (e.g. 2D) preserving distances high-dimensional space (e.g. 5000D) well possible.\r\nliterature today tends go either multidimensional scaling (MDS) t-stochastic neighbor embeddings (t-SNE),\r\nmay run R function metaMDS() {vegan} package (Oksanen et al. 2020)\r\nRtsne() homonymous package (Krijthe 2018), respectively.MDS ordination technique, like principal components analysis (PCA). tries different low-dimensional configurations tries maximize correlation pairwise distances high-dimensional space low-dimensional space: items close together one space stay close together , items far apart one space stay far apart .\r\ncan evaluated via stress level, complement correlation coefficient: correlation pairwise distances 0.85, stress level 0.15.\r\nUnlike PCA, however, dimensions meaningful per se; two different runs MDS may result plots mirror representing thing. Nonethelesss, R implementation rotates plot horizontal axis represents maximum variation.\r\ncognitive linguistics literature metric (Hilpert Correia Saavedra 2017; Hilpert Flach 2020; Koptjevskaja-Tamm Sahlgren 2014)\r\nnonmetric MDS (Heylen et al. 2015; Heylen, Speelman, Geeraerts 2012; De Pascale 2019; Perek 2016) used.second technique, t-SNE (van der Maaten Hinton 2008; van der Maaten 2014), also incorporated cognitive distributional semantics (De Pascale 2019; Perek 2018).\r\nalgorithm quite different MDS, purposes crucial point prioritizes preserving local similarity structure instead global structure: items close together high-dimensional space stay close together low-dimensional space, far apart high-dimensional space may even farther apart low-dimensional space. leads nice, tight clusters distance less interpretable MDS plot.\r\nT-SNE state---art visualization technique word vectors computational linguistics (Smilkov et al. 2016) now generally replaced UMAP.cases need state desired number dimensions running algorithm –visualization purposes, useful choice 2. Three dimensions difficult interpret projected 2D space, screen (Card, Mackinlay, Shneiderman 1999, 18; Wielfaert et al. 2019, 222). addition, t-SNE requires setting parameter called perplexity, basically sets many neighbors preserved local structure cover.","code":""},{"path":"nephovis.html","id":"nephovis","chapter":"4 NephoVis","heading":"4 NephoVis","text":"chapter learn use visualization tool explore\r\ncompare token-level vector space models.moment, tool can found \r\nGithub Page, ,\r\nGithub repository can rendered\r\nstatic website (Montes QLVL 2021).\r\nobtains data submodule;\r\ninterested user clone repository just modify path data.code visualization written Javascript, making heavy use \r\nD3.js library, designed beautiful web-based\r\ndata-driven visualization. known steep learning curve,\r\ncan useful think terms R’s vectorized approach: links\r\nDOM elements arrays manipulates based items’ properties.main rationale framework visualization tool developed \r\nThomas Wielfaert (Wielfaert et al. 2019); code can found\r\n.current implementation exist without foundational setup. However,\r\nnumber available features added later.description tool immediately follow expected workflow user.\r\nInstead, start lowest level, Level 3,\r\nrepresents individual token-level clouds,\r\nzoom Level 2, shows multiple token-level clouds simultaneously,\r\nmake abstract level, Level 1, clear.\r\nAfterwards (Section 4.4) briefly simulate path user take Level 1 Level 3.\r\nperspective also taken Montes Heylen (n.d.).\r\nFinally, Section 4.5 goes Beta features\r\nrequire better development testing, well ideas might want \r\nimplement future. case, must noted July 2019 \r\n2021-05-01 user developer person, occasional,\r\nvaluable input members Nephological Semantics project. \r\nproject certainly benefit wider input suggestions.","code":""},{"path":"nephovis.html","id":"level_3","chapter":"4 NephoVis","heading":"4.1 Level 3","text":"Level 3 visualization tool shows zoomable scatterplot glyph represents token, .e. instance target lexical item. name model, coding parameter settings described \r\n\r\n, indicated top. possible map colors shapes categorical variables (sense labels) sizes numerical variables (number available context words) select tokens given value clicking corresponding legend key.","code":""},{"path":"nephovis.html","id":"level_2","chapter":"4 NephoVis","heading":"4.2 Level 2","text":"Level 2 visualization scatterplot matrix, although looks like one code inspired Mike Bostock’s example. Instead, just array small plots next wrap easier readability.represents different model basic features Level 3 available: color, shape size coding, selection clicking brushing, finding context hovering tokens.model-dependent, highlighted context searching tokens context word meaningless level, multiple models shown simultaneously. key contribution level, next superficial visual comparison shape plot, ability select one tokens plot highlighting rest plots well. Thanks functionality, user can compare relative position group tokens model different model.","code":""},{"path":"nephovis.html","id":"level_1","chapter":"4 NephoVis","heading":"4.3 Level 1","text":"Level 1 shows one zoomable scatterplot, similar Level 3, glyph representing one model, instead one token. reminder difference, default shape Level 1 wye (“Y”), levels circle. data represented scatterplot distance tokens anymore, models, described beginning Section 3. scatterplot aims represent similarity models allows user select models inspect according different criteria. Categorical variables (e.g. whether sentence boundaries used) can mapped colors shapes, shown Figure 5, numerical variables (e.g. number tokens model) can mapped size. selection buttons left panel, well legends color shape, can used filter models certain parameter setting. Otherwise, models can selected clicking glyphs represent .","code":""},{"path":"nephovis.html","id":"workflow","chapter":"4 NephoVis","heading":"4.4 The full story","text":"increasing granularity Level 1 Level 3 manner access different functionalities respect mantra “Overview first, zoom filter, details--demand” (Shneiderman 1996, 97).\r\nindividual plots Levels 1 3 literally zoomable; cases possible select items (either models, Level 1, tokens, two), detailed inspection. Finally, number features show details demand, names models Level 1 context tokens two levels.practice, user start Level 1, scatterplot models, can look structure distribution parameters plot. example, color coding may reveal models nouns, adjectives, verbs adverbs first-order context words different without strong filters part--speech, use sentence boundaries makes little difference. Depending whether user wants compare models similar different , parameters like keep fixed, use individual selection buttons choose models Level 2. case, click “Select medoids,” selects 8 models returned partitioning algorithm, offers wide range variation manageable number plots.Level 2 user can already compare shapes models take respective plots, distribution categories like sense labels, number lost tokens. addition, “distance matrix” button offers heatmap pairwise distances selected models. case heffen, restrictive collocational patterns presents lead crisp clusters visualization consistent organization across models. However, models less clearly defined structure may prove harder understand. cases, brushing linking functionality highlights whether tokens grouped one model also grouped different model. , user might switch back forth Level 2 Level 3 detailed inspection models.","code":""},{"path":"nephovis.html","id":"examining-context-words","chapter":"4 NephoVis","heading":"4.4.1 Examining context words","text":"possible look individual context token hovering , loses track larger patterns want understand. purpose frequency tables levels 2 3.given model, tokens might close together share context word, /context words (based second-order modelling) similar . First-order parameters , definition, directly responsible selection context words used model token. Therefore, inspecting model, might want know context word(s) pull certain tokens together, tokens expect together far apart instead. words, model offers different perspective distributional behavior token, want understand informs said perspective.Level 3, individual tokens groups may selected different ways. Given selection, clicking “Frequency table” open table one row per context word, column indicating many selected tokens occurs, columns pre-computed information (e.g. PMI values).following five columns include pre-computed frequency information, raw co-occurrence frequency PMI value context word target based windows 10 4, raw frequency corpus.\r\nvalues can interesting like strengthen weaken filters smarter selection context words. particular model uses dependency-based information well PMI threshold 0 select context words.Level 2, comparing different models, frequency table takes different form. still one context word per row, number tokens co-occurs depend model.\r\ncolumns table computed visualization based lists context words per token per model. Next column name context word, default table shows one column called “total” one per model, headed corresponding number. columns model match second column Level 3 frequency table: indicate many selected tokens context word co-occurs. “total” column, contrast, reveals union selection: many selected tokens context word co-occurs least one model.default table counts many selected tokens co-occur context words, use information tokens outside selection, .e. cue validity association strength context words selected group. purpose, dropdown button top left corner frequency table offers small range transformations, odds ratio, Fisher Exact, cue validity, etc. One option shows absolute frequencies within outside selection, green columns count number selected tokens co-occur context word, white columns count number tokens outside selection co-occurring context words.","code":""},{"path":"nephovis.html","id":"wishlist","chapter":"4 NephoVis","heading":"4.5 Wishlist","text":"","code":""},{"path":"hdbscan.html","id":"hdbscan","chapter":"5 HDBSCAN","heading":"5 HDBSCAN","text":"visual exploration extremely useful thorough, qualitative description\r\nvector space models. However, application can also become obstacle\r\ntruly systematic, scientific description. avoid talking objectivity:\r\nneither us, individually, can truly objective, instead strive \r\nhumble admission partiality fruitful combination partialities.describing cloud —particular clouds refuse show clear images,\r\nperfect sense disambiguation, distinct clusters—, can ensure \r\nsee found researchers? can make observations, \r\ninherently valid, least reproducible?\r\n, , goal strive embark quantitative methods.One tool can help us systematize observations, tightness least\r\nexistEnce distinct islands plot, \r\nHierarchical Density-Based Spatial Clustering Applications (HDBSCAN) (Campello, Moulavi, Sander 2013).\r\nalgorithm basically tries distinguish dense areas separated less dense areas1\r\nallows noisy data. words, unlike traditional hierarchical clustering,\r\ntry cluster points dataset, instead may discard \r\nfar everything else. Moreover, comparison non hierarchical counterpart,\r\nDBSCAN,\r\n\r\nrequires one parameter set priori, namely \\(minPts\\).\\(minPts\\) parameter indicates minimum size dense group points considered\r\ncluster. isolated dense group points \\(n < minPts\\) considered noise.\r\ncase studies described fixed \\(minPts\\) 8, seems reasonable\r\nsize smallest clusters, interested look systematically \r\neffect lowering threshold. Rising threshold, hand, \r\nincrease proportion points considered noise, already high.Like clustering algorithms dimensionality reduction techniques,\r\nHDBSCAN can take token-context matrix input distance matrix. used\r\ntransformed distance matrix, , input fed t-SNE algorithm,\r\nhdbscan() function {dbscan} R package (Hahsler Piekenbrock 2021). output includes,\r\namong things, cluster assignment, noise points assigned cluster 0,\r\nepsilon values, can used estimate density.HDBSCAN estimates density [area find] point \\(\\) calculating \r\ncore distance \\(core_{k}()\\), distance \\(k\\) nearest neighbor, \\(k\\) \\(minPts - 1\\).\r\nrecalculates distance matrix defining new distance measure, called\r\nmutual reachability, defined maximum distance \r\nitems \\(d(, b)\\) core distances.\\[d_{mreach-k}(,b) = max(core_{k}(), core_{k}(b), d(,b))\\]algorithm obtains distances, uses single linkage method create\r\nhierarchical clusters, using \\(minPts\\) calculations merge \r\nfinal selection. eps (epsilon) values returned hdbscan() indicate\r\nheight, single linkeage tree, point joined cluster,\r\ncan thus used proxy “density.”intuitively clear map clustering solution colors \r\neps value transparency t-SNE plot perplexity 30. part,\r\nresults converge, two main upsides. first place, independent\r\nconfirmation structure found t-SNE, different algorithm processing\r\ninput returns compatible output. Second, insofar HDBSCAN output matches\r\nvisual assessment, can systematize render reproducible.wonders notwithstanding, compatibility HDBSCAN output visual examination guaranteed. might find interesting tokens discarded noise, structure within\r\nsingle HDBSCAN cluster. However, must noted match (lack thereof)\r\nassessed dbscan::hdbscan() \\(minPts = 8\\) \r\nRtsne::Rtsne() \\(perplexity = 30\\). interesting avenue research experiment combinations, course UMAP output.","code":""},{"path":"annotation-schema.html","id":"annotation-schema","chapter":"6 Annotation schema","heading":"6 Annotation schema","text":"case studies, selected 34 Dutch lemmas annotate model token level vector spaces, two (herkennen spoor) discarded.\r\nselection process presented Section 6.1, description selected items expect annotation look like (eventually, expect clouds look like well). short description corpus (QLVLNewsCorpus, De Pascale 2019) follow. annotation procedure focus 6.5.\r\nStudents (later called annotators) recruited hired manually annotate samples selected lemmas, administrative procedure great interest project, number practical issues discussed: distribution tokens, assignment tasks (particular, graphic interface provided) processing/analysis data.","code":""},{"path":"annotation-schema.html","id":"selection","chapter":"6 Annotation schema","heading":"6.1 Selection of items","text":"case study 34 Dutch lexical items selected. aimed cover variety polysemy phenomena, addressed specific sections part speech: section 6.1.1 nouns, section 6.1.2 adjectives, section 6.1.3 verbs.\r\nmodelling different parts speech different kinds polysemy, expect develop robust generalizations regarding parameter settings best model specific phenomena.selection procedure mixed introspection (thinking words interesting), looking lexical resources (going tentative list dictionary entries figure kind polysemy expect) corpus data (surveying sample concordances evidence expected polysemy). dictionaries essential resource sketch sense labels annotators choose , also adjusted manageable granularity. concordances also crucial estimate sense distribution adjust granularity definitions. didn’t want overwhelmingly frequent sense affect annotators judgement, infrequent senses might hard model least visualise 2D representations. Still, allow complexity subtlety cases.number cases, corpus survey (reading concordance 40-50 randomly selected instances) invalidated options intuitively according dictionary definitions conformed requirements. judging discrepancy, important take account composition corpus. topics addressed newspapers terms used talk representative everyday life entirety language. long keep limitations mind, can draw valid conclusions data.also cases adjectives used adverbial form weren’t always properly tagged part--speech, discard . made difference cases hoopvol ‘hopeful,’ often occurs predicative contexts verb copula (e.g. ik ben hoopvol gestemd ‘makes hopeful,’ hij kijkt hoopvol omhoog ‘looks hopeful(ly)’) still predicates entity, cases gemiddeld ‘average,’ either predicate entity, gemiddelde student ‘average student,’ predicate, zij eet gemiddeld 3 koekjes elke dag ‘eats average 3 cookies per day.’ Sometimes incorrectly tagged cases (adverbs tagged adjectives) infrequent enough dismissed, cases many discard lemma candidate. direct consequence certain potentially interesting lemma couldn’t investigated, also taken account relying part--speech tagger steps workflow.next subsection describes selected nouns, adjectives verbs, QLVLNewsCorpus sampling method. selected item give approximate equivalent English definitions examples provided annotators. hypothesis annotations items look like also provided.","code":""},{"path":"annotation-schema.html","id":"nouns","chapter":"6 Annotation schema","heading":"6.1.1 The nouns","text":"8 nouns exhibit homonymy polysemy least one homonyms.Three nouns one polysemous homonym one non polysemous (hoop ‘hope/bunch,’ spot ‘ridicule/show spotlight’ horde ‘horde/hurdle’);Three nouns one polysemous homonym one non polysemous (hoop ‘hope/bunch,’ spot ‘ridicule/show spotlight’ horde ‘horde/hurdle’);four nouns two polysemous homonyms (schaal ‘scale/dish shell,’ blik ‘look/tin,’ stof ‘substance fabric topic/dust,’ staal ‘steal/sample’);four nouns two polysemous homonyms (schaal ‘scale/dish shell,’ blik ‘look/tin,’ stof ‘substance fabric topic/dust,’ staal ‘steal/sample’);one noun three homonyms, two polysemous: spoor ‘footprint trace/train(line, rail, company)/spur.’ noun later discarded proved complicated, data available reanalysis.one noun three homonyms, two polysemous: spoor ‘footprint trace/train(line, rail, company)/spur.’ noun later discarded proved complicated, data available reanalysis.group, definitions, examples expected relative frequency shown.","code":""},{"path":"annotation-schema.html","id":"one-polysemous-homonym","chapter":"6 Annotation schema","heading":"6.1.1.1 One polysemous homonym","text":"nouns Table 6.1 one frequent homonym another one equally less frequent polysemic (sense distribution probably skewed). polysemy phenomena represented polysemic homonym different: metaphor horde, metaphor/generalization hoop metonymy spot, one senses (‘spotlight’) can used literally metaphorically (annotators might either merge assign geen figurative uses).\r\nTable 6.1: caption.\r\nlemmatexthoopComing soonspotComing soonhordeComing soon","code":""},{"path":"annotation-schema.html","id":"two-polysemous-homonyms","chapter":"6 Annotation schema","heading":"6.1.1.2 Two polysemous homonyms","text":"homonyms Table 6.2 also present variety polysemy phenomena. blik, frequent homonym (‘look’) concrete sense metonymic metaphoric extension, infrequent one can refer material (‘tin’), object made material content: distinction quite clear might depend specificity context infrequent. Similarly, stof presents one frequent homonym two concrete, referentially distinct senses abstract one, another subtle, context-specificity dependent difference. schaal exhibits subtle perspective shifts one homonym (‘scale’) refers different concrete objects second (‘shell,’ ‘dish,’ ‘scale dish’). Finally, staal ‘steal’ refer, like blik, either material object made , ‘sample’ homonym sensitive construal (focus use evidence, ’s case): ’s likely present high confusion /skewed distribution homonyms separately.\r\nTable 6.2: caption.\r\nlemmatextschaalComing soonblikComing soonstaalComing soonstofComing soon","code":""},{"path":"annotation-schema.html","id":"adjs","chapter":"6 Annotation schema","heading":"6.1.2 The adjectives","text":"selection adjectives includes 13 lemmas presenting different kinds polysemy phenomena:three metonymic reading (hoopvol ‘hopeful,’ geestig ‘witty’ hachelijk ‘dangerous/critical’);three metonymic reading (hoopvol ‘hopeful,’ geestig ‘witty’ hachelijk ‘dangerous/critical’);four metaphoric readings (hoekig ‘angulous/clumsy,’ dof ‘dull,’ heilzaam ‘healthy/beneficial’ gekleurd ‘colorful, POC, tainted’);four metaphoric readings (hoekig ‘angulous/clumsy,’ dof ‘dull,’ heilzaam ‘healthy/beneficial’ gekleurd ‘colorful, POC, tainted’);three present form similarity readings (geldig ‘valid,’ hemels ‘heavenly’ gemeen ‘shared/public/mean/serious’);three present form similarity readings (geldig ‘valid,’ hemels ‘heavenly’ gemeen ‘shared/public/mean/serious’);three complex (heet ‘hot’ different entities metaphorically, grijs ‘gray,’ metaphorical metonymical extensions goedkoop ‘cheap,’ different entities metaphorically).three complex (heet ‘hot’ different entities metaphorically, grijs ‘gray,’ metaphorical metonymical extensions goedkoop ‘cheap,’ different entities metaphorically).group, definitions examples provided annotators shown estimated relative frequency considerations made regarding expect annotators.","code":""},{"path":"annotation-schema.html","id":"metonymic-cases","chapter":"6 Annotation schema","heading":"6.1.2.1 Metonymic cases","text":"illustrated Table 6.3, three adjectives two senses offered options. geestig hoopvol, one senses anthropocentric (’s mainly exclusively applied people), although distinction made explicit definitions geestig (suggested example). expected frequency anthropomorphic sense cases much higher one. hachelijk’s case, difference matter temporal telic perspective, probably harder distinguish, ’s probably likely annotators suggest second sense alternative first one (assigning ‘critical’ interpretation something potentially dangerous) way around.\r\nTable 6.3: caption.\r\nlemmatexthoopvolComing soongeestigComing soonhachelijkComing soon","code":""},{"path":"annotation-schema.html","id":"metaphoric-cases","chapter":"6 Annotation schema","heading":"6.1.2.2 Metaphoric cases","text":"adjectives metaphoric extensions, presented Table 6.4, different numbers senses. heilzaam two distinctions, metaphoric specialization: one refers something specifically/literally healthy, one broader less concrete. hoekig gekleurd present three sense distinctions, one particularly concrete frequent another one explicitly anthropocentric. third sense distinction different quality: rather synesthetic hoekig abstract, much metaphoric gekleurd. Finally, dof four kinds senses: concrete, synesthetic, anthropocentric abstract.\r\nTable 6.4: caption.\r\nlemmatextheilzaamComing soongekleurdComing soonhoekigComing soondofComing soon","code":""},{"path":"annotation-schema.html","id":"similarity","chapter":"6 Annotation schema","heading":"6.1.2.3 Similarity","text":"group adjectives Table 6.5 present sense distinctions roughly summarized title ‘similarity,’ generalization shift focus. geldig hemels offer two options, one restricted specific context one much broader. relation relative frequencies senses inverted (specific sense geldig less frequent general one, hemels ’s way around). expect specific sense offered alternative general sense much way around.case gemeen quite complex, involving number rather subtle distinctions. limits first second one third fifth hard establish; fourth sense seems clear context isn’t specific enough easily confused fifth. addition, senses always mutually exclusive, certain instance well conflate ambiguous two senses.\r\nTable 6.5: caption.\r\nlemmatextgeldigComing soonhemelsComing soongemeenComing soon","code":""},{"path":"annotation-schema.html","id":"complex-cases","chapter":"6 Annotation schema","heading":"6.1.2.4 Complex cases","text":"last group adjectives, listed Tables 6.6, 6.7 6.8, large number possible senses one polysemy phenomenon, treated separately.heet presents three concrete senses differ perspective (temperatures different kinds things). second half metaphorical, one synesthetic, one anthropocentric specific, one abstract also quite specific. Furthermore, exclusive sense tag idiomatic expressions, quite frequent; expected tagged concrete senses (maybe comment figurative interpretation), annotators might also use geen tag cases.\r\nTable 6.6: caption.\r\nlemmatextheetComing soongrijs presents frequent, concrete sense, two specific metonymic extensions, one anthropocentric sense, one rather abstract another specific metaphor.\r\nTable 6.7: caption.\r\nlemmatextgrijsComing soongoedkoop, hand, presents “” 4 sense distinctions: concrete, prototypical frequent sense, two perspectival shifts clear metaphor.\r\nTable 6.8: caption.\r\nlemmatextgoedkoopComing soon","code":""},{"path":"annotation-schema.html","id":"verbs","chapter":"6 Annotation schema","heading":"6.1.3 The verbs","text":"verbs, selected range combinations syntactic semantic variation:Transitive verbs sense distinction related objects can take (haten ‘hate,’ huldigen ‘honor/hold (attitudes, opinions, stances),’ heffen ‘raise,’ herroepen ‘annul (law)/retract (statement)’);Transitive verbs sense distinction related objects can take (haten ‘hate,’ huldigen ‘honor/hold (attitudes, opinions, stances),’ heffen ‘raise,’ herroepen ‘annul (law)/retract (statement)’);Verbs transitive, distinction based object, intranstive (helpen ‘help,’ herstructureren ‘restructure’);Verbs transitive, distinction based object, intranstive (helpen ‘help,’ herstructureren ‘restructure’);Verbs transitive, distinction based object, reflexive (diskwalificeren ‘disqualify,’ herhalen ‘repeat,’ herinneren ‘remember/remind,’ herkennen ‘recognize’);Verbs transitive, distinction based object, reflexive (diskwalificeren ‘disqualify,’ herhalen ‘repeat,’ herinneren ‘remember/remind,’ herkennen ‘recognize’);Verbs transitive, intransitive reflexive, semantic distinctions within transtive structure (harden ‘make/become hard, tolerate,’ herstellen ‘heal/repair’);Verbs transitive, intransitive reflexive, semantic distinctions within transtive structure (harden ‘make/become hard, tolerate,’ herstellen ‘heal/repair’);verb semantic distinctions within transitive intransitive structures (also problems): haken ‘hook’ (literally metaphorically), ‘crochet,’ ‘make someone trip’ (object person pootje ‘leg’), ‘get stuck’ intransitive form blijven haken (literally metaphorically).verb semantic distinctions within transitive intransitive structures (also problems): haken ‘hook’ (literally metaphorically), ‘crochet,’ ‘make someone trip’ (object person pootje ‘leg’), ‘get stuck’ intransitive form blijven haken (literally metaphorically).groups, definitions, examples relative frequencies senses summarized tables.","code":""},{"path":"annotation-schema.html","id":"only-transitive","chapter":"6 Annotation schema","heading":"6.1.3.1 Only transitive","text":"verbs first group (Table 6.9) always transitive different senses correlate possible direct objects take. haten heffen probably easy distinguish, former anthropocentric distinction (basically, hating people disliking things, possible gray areas , depending object construed) latter presenting rather clear common metaphor, physical objects abstract entities taxes raised. huldigen herroepen instead slightly subtle differences, former (honoring someone/something holding opinion) probably stronger easier distinguish latter, retracting statement annuling decree (interpreted differently depending entity construed, prototypical ).\r\nTable 6.9: caption.\r\nlemmatexthatenComing soonhuldigenComing soonheffenComing soonherroepenComing soon","code":""},{"path":"annotation-schema.html","id":"transitive-and-intransitive","chapter":"6 Annotation schema","heading":"6.1.3.2 Transitive and intransitive","text":"verbs alternate transitive intransitive constructions (Table 6.10) quite subtle might present lot confusion, particularly intransitive cases similar one transitive cases, might seem object just ellided. herstructureren, one transitive sense intransitive one (exemplified reflexive…) specific, regarding companies connotation personnel reduced, transitive sense broader might selected contexts less specificity. might also depend world knowledge (whether annotators know can guess certain object -subject intransitive construction- company) prominent implication personnel reduction . helpen, distinction transitive uses rather subtle (“collaboration” sense exclusive animate subjects, ’s explicit definitions), might disagreement annotation, intransitive sense confused transitive ones, first one.\r\nTable 6.10: caption.\r\nlemmatexthelpenComing soonherstructurerenComing soon","code":""},{"path":"annotation-schema.html","id":"transitive-and-reflexive","chapter":"6 Annotation schema","heading":"6.1.3.3 Transitive and reflexive","text":"argued distinction argument structures previous group (transitive versus intransitive) clear group (transitive reflexive), since reflexive pronoun contexts interpreted direct object. However, intransitive senses previous group also understood transitive cases object outside context (true?), reflexive argument structure (Table 6.11) strongly distinguishable transitive one. might tricky diskwalificeren, reflexive argument structure pretty much replicates transitive senses, particular case someone disqualifies . possibility distinguish transitive cases, differ specificity, relies instead clarity context. herkennen, sense distinction three transitive uses quite subtle, much sharper transitive reflexive; herhalen, object transitive senses (probably wouldn’t) subject reflexive, distinction clear, transitive uses differ kind objects take, certain prototypical nouns (possibility clauses second sense) maybe borderline cases. Finally, herinneren shows clear distinction reflexive transitive uses argument structure distinction transitive uses, either without aan complement (might absent restricted context).\r\nTable 6.11: caption.\r\nlemmatextdiskwalificerenComing soonherhalenComing soonherinnerenComing soonherkennenComing soon","code":""},{"path":"annotation-schema.html","id":"transitive-intransitive-and-reflexive","chapter":"6 Annotation schema","heading":"6.1.3.4 Transitive, intransitive and reflexive","text":"verbs Table 6.12 can occur three argument structures: transitive (three different senses), intransitive reflexive. case harden, transitive can concrete, figurative, concrete different sense specific construction, namely (niet) te harden; intransitive structure similar concrete transitive, taking object subject, reflexive similar second transitive. senses different argument structures confused, intransitive first reflexive second. (niet) te harden uses easy isolate, strong agreement annotators high confidence. herstellen, transitive structure presents three possible senses: one concrete, one figurative presented , one abstract subtly different second one. reflexive close figurative sense intransitive specific concrete healing (rather repairing) confused others.\r\nTable 6.12: caption.\r\nlemmatexthardenComing soonherstellenComing soon","code":""},{"path":"annotation-schema.html","id":"haken","chapter":"6 Annotation schema","heading":"6.1.3.5 Haken","text":"haken presented two transitive senses, two intransitive one transitive/intransitive. transitive senses concrete literal differ specificity: one sense refers particularly making somebody trip. Intransitive uses differ literality , might occur blijven, figurative definition mentions (apparently restricting ). figurative options mentioned transitive senses, occur annotators might either tag transitive concrete, intransitive figurative, geen. Finally, one sense can occur transitive intransitve (ellided object) ‘crochet’; ’s specific shouldn’t confused others probably high confidence.\r\nTable 6.13: caption.\r\nlemmatexthakenComing soon","code":""},{"path":"annotation-schema.html","id":"expectations-for-the-annotation","chapter":"6 Annotation schema","heading":"6.2 Expectations for the annotation","text":"first set expectations annotations types summarized six points, discussion revision needed. formulated predictions followed suggestions confirm . ‘technical’ terms :majority sense, meaning sense tag annotators assigned given token.alternative sense/annotation, meaning sense tag assigned given token, different majority sense.() confuse(d), meaning disagreement annotation.\r\nNOTE: also useful find literature kind annotations. ’m identifying anthropocentrism sense distinctions particularly foregrounded, considerations metaphor literature don’t really theoretical backup. hand, ’ve seen ‘geen’ annotations far partially supports intuition: annotators refuse assign horde 1 tag cases horde + KTM’s/vrachtwagens/danceprojecten/insecten.","code":""},{"path":"annotation-schema.html","id":"for-all-types","chapter":"6 Annotation schema","heading":"6.2.1 For all types","text":"specific senses confused general senses.\r\nmajority sense specific one, alternative annotation geen.\r\nConcretely:haken 5 haken 3 confused senses.heet 4 confused senses.Metaphor easier identify metonymy/specialization\r\nmetaphoric sense option distinct concrete/literal one, won’t often confused literal counterpart; annotators agree ’s figurative. metonymy specialisation, disagreement less confidence.\r\nConcretely:spoor 1.1 spoor 1.2 confused spoor 1.3 also spoor 1.4blik 1.1 confused 1.2 1.3.grijs 1 confused 2 3 6.goedkoop 1 confused 2 3 4adjectives metaphoric distinctions (hoekig, dof, gekleurd, heilzaam) present less confusion metonymic distinctions (hachelijk, hoopvol, geestig)Anthropocentric senses easily distinguishable.\r\ndefinition explicitly restricts application people, won’t alternative annotation , non anthropo-exclusive senses. Borderline cases, due probably unspecified context, low confidence.\r\nConcretely:low confusion haten, least low confidence borderline casesheet 5 confused othersgrijs 4 confused senses (except maybe 3, derived )gekleurd 2 confused othershoekig 3 confused othersdof 3 confused othershoopvol present less confusion geestig present less confusion hachelijk","code":""},{"path":"annotation-schema.html","id":"only-for-nouns","chapter":"6 Annotation schema","heading":"6.2.2 Only for nouns","text":"Homonyms confused .\r\nmajority sense one homonym, alternative annotations homonym geen.","code":""},{"path":"annotation-schema.html","id":"only-for-verbs","chapter":"6 Annotation schema","heading":"6.3 Only for verbs","text":"next two predictions overlap, explain different verb groupings (sometimes, different argument structure implies subject distinction, prominent?).Argument structure easier identify semantic differences.\r\nSenses differ argument structure confused (won’t ’s alternatives) much senses argument structure different kinds objects. distinction probably easier make reflexive intransitive cases.\r\nConcretely: general, transitive senses confused senses different argument structure (unless sense semantically similar transitive sense). Cases might generate confusion different argument structures :gral. trans. haken fig. intrans. haken cases fig. trans. hakenfig. trans. harden refl. hardenfig./abs. trans. herstellen refl. herstellenspec. trans. herstructrureren intrans. herstructurerenhelpen 1 intrans. helpenSenses require different subjects easier identify senses require different objects prepositional arguments\r\nSenses different subject restrictions won’t alternatives. ’m thinking subject restrictions often linked animacy, object restriction might subtle cases.\r\nConcretely: general, senses argument structure confused one takes (mostly) animate subjects one (mostly) inanimate subjects.","code":""},{"path":"annotation-schema.html","id":"corpus","chapter":"6 Annotation schema","heading":"6.4 The corpus and samples","text":"exploration samples concordances also served calculation number tokens annotate. Regardless actual frequency items corpus, extracted minimum 240 tokens type (thinking 6 batches 40 tokens), raised amount 280 senses relative frequency 20% sample, 320 10%, 360 many senses therefore low frequency.\r\nsample tokens selected almost absolutely randomly. First instances type extracted corpus; , type many files tokens wanted extract selected, file randomly selected one token. Therefore, qre two instances lemma file samples.corpus selection LeNC TwNC corpora, include newspapers articles Flanders Netherlands. selection, performed Stefano De Pascale eye lectally balanced corpus, containes 4,614,267 types 519,996,217 tokens (roughly 520M, 260 Flanders 260 Netherlands). articles subcorpus published 1999 2004 quality popular newspapers countries.","code":""},{"path":"annotation-schema.html","id":"annotation","chapter":"6 Annotation schema","heading":"6.5 Annotation procedure","text":"","code":""},{"path":"annotation-schema.html","id":"assigning-batches-to-annotators","chapter":"6 Annotation schema","heading":"6.5.1 Assigning batches to annotators","text":"","code":""},{"path":"annotation-schema.html","id":"some-issues-because-we-are-humans","chapter":"6 Annotation schema","heading":"6.5.1.1 Some issues, because we are humans","text":"","code":""},{"path":"annotation-schema.html","id":"annotation-toolinterface","chapter":"6 Annotation schema","heading":"6.5.2 Annotation tool/interface","text":"beginning October 48 students General Linguistics course 2nd year Bachelor Linguistics KU Leuven recruited work annotators tokens. tasked annotating 40 tokens 12 types (least three nouns, four adjectives four verbs, plus one either categories), total 480 tokens, expect work average 10 hours, spread 6 weeks. Students option subscribing double number tokens (hours, pay). types sets tokens assigned randomly, keeping mind part--speech distribution (idea shuffle tokens issue code , different batches tokens different sources… noticed late).annotation includes three compulsory pieces information one normally optional. tokens, :assign sense set definitions/examples provide. none senses satisfactory, may choose “None ” options.express confidence decision Likert scale 6 (illustrated star rating).identify words context (15 tokens left right target, disregarding sentence boundaries respecting article) helped assign sense.couldn’t assign sense, explain . assign one, still option adding extra information thoughts annotation process, ’s compulsory.Since entering textual information spreadsheet can easily lead typos inconsistencies , furthermore, annotating relevant context words (cues) challenging system (either one row per contextword decide value cases, select reliable system listing context words, couldn’t lemma wordform , better, position), designed user-friendly visual interface transforms button-output json file information required.interface menu types , selected type, two tabs: overview concordance lines annotation workspace. annotation workspace, read line individually, click button corresponding sense want assign, rate confidence star rating, click words found useful enter comments. overview section didn’t let see whole set tokens analyze, target items change color annotated links Annotation tab concordance lines.Since site static webpage (github page) public, doesn’t gather information. indeed interface, users download files data entered, JSON format. can also upload/open files previous work, don’t need everything one go. Eventually, send JSON file us.goals interface twofold:reduces typos inconsistances values straightforward present little variation (much faster design interface check typos 480 tokens times 40 annotators), andit makes annotation experience simpler even pleasant, letting annotators focus energies lexicographical task rather technicalities.particularly evident task selecting relevant context words. spreadsheet, either necessary separate rows per context words annotate (make sure forgetting ) make list items cell row relevant concordance. list need something truly identifying context word, therefore form lemma position (since item occur context always relevance), counting reliably time consuming prone errors. Clicking words program lists position relevant words, also making visible words selected, solves easiness reliability issues.","code":""},{"path":"annotation-schema.html","id":"known-issues","chapter":"6 Annotation schema","heading":"6.5.2.1 Known issues","text":"interface issues, consequences affect output.One technical issue bug code annotation, context words selected annotator might replaced context words wordform, previous position. bug found, annotators warned, necessarily checked previous annotation thoroughly. case, affects wordforms occur concordance (often) cleaned reasoning.Another issue format corpus, dealt better. one hand, different sentences concordance indiciated <sentence><\/sentence> impact rendering concordance, just replaced empty spaces. ’ve replaced <p><\/p> tags. hand, point corpus processing (access ), someone must replaced & , HTML entities like &quot;, ’ve translated \", rendered andquot;, extremely confusing annotators, especially already complicated concordances full . issue identified late (case, corpus already reads andquot; instead \", confusion ).","code":""},{"path":"annotation-schema.html","id":"output","chapter":"6 Annotation schema","heading":"6.5.2.2 Output","text":"student, received file json format username annotations recorded. checking tokens annotated required variables (‘geen’ cases comments), results turned tables merged. number attempts, two main tables:First, register tokens, row token (id: token_id) variables :\r\n- type: type token belongs ;\r\n- batch: batch (set 40 tokens) token belongs , named type plus number;\r\n- majority_sense: majority sense, tag annotators agreed ;\r\n- tag ‘geen’ (“none ”), classified comments kinds justification became alternative senses: (doubt given alternatives), not_listed (suggestion different alternative given), unclear (insufficient confusing context, unknown words) wrong_lemma (issues lemmatization, part--speech tagging even spelling, concordance really correspond wanted target);\r\n- agreement two annotators (three case four annotations), majority sense becomes no_agreement;\r\n- majority_agree: proportion (0-1) annotators voted majority sense;\r\n- majority_conf: mean confidence (standardized username-type combination) agreeing annotations;\r\n- mean_conf: mean confidence (standardized username-type combination) annotations token.Second, register annotations, row token-annotation combination (row-id, token_id identifies tokens annotator identifies annotations ann_1, ann_2, ann_3 ann_4). row, following variables registered:\r\n- type: type token belongs ;\r\n- batch: batch (set 40 tokens) token belongs , named type plus number;\r\n- username: name annotator (easier keep track , nothing publish);\r\n- code: codename annotator, combining number ‘student’ (set batches 12 different types) number annotator (matching annotator variable);\r\n- annotators: number annotators tagged given token (normally 3). important variable;\r\n- original_sense: sense tag applied annotator; either sense represented name type number, geen “none ”;\r\n- confidence: confidence assigned annotator, minimum 0 (1 star) maximum 5 (6 stars);\r\n- conf_std: standardized confidence values, grouping username type2;\r\n- comments: comments given annnotators, normally empty, unless sense geen (annotators also commented tokens assigned actual sense tag);\r\n- geen_reason: classification comments given annotators, grouping categories described (, other_sense, unclear wrong_lemma);\r\n- sense: modified sense annotation, replacing geen annotations original_sense categories geen_reason;\r\n- annotations: number different values sense given token (1 equals total agreement);\r\n- agree_nr: proportion (0-1) annotators assigned sense given row token_id row;\r\n- agree_fct: categorical version agree_nr, full represents full agreement annotators, none agreement, half two four agreed, minority current row disgreeing annotation token majority annotation agrees majority token.\r\n- column cues, stored somewhere can retrieve want start working .","code":""},{"path":"nonsense-or-no-senses.html","id":"nonsense-or-no-senses","chapter":"7 Nonsense or no senses?","heading":"7 Nonsense or no senses?","text":"part, knows many chapters, delve \r\ntheroetico-methodological insights –theoretical impact, – \r\nanalyses.describe annotation procedure (probably) , importantly,\r\ndiscuss main theoretical observations derived studies.main points, now, :cloud interpretation, see necessarily senses, rather\r\n“common/shared/similar” contexts usage.cloud interpretation, see necessarily senses, rather\r\n“common/shared/similar” contexts usage.single optimal solution every item.single optimal solution every item.second point, different parameter settings ,\r\nspecific items? (kind info pick ?)\r\nalso material first part project’s monograph\r\nsecond point, different parameter settings ,\r\nspecific items? (kind info pick ?)also material first part project’s monographCurrently (still much research ) think \r\ndifferent parameters offer different perspectives, picking different aspects\r\ncontext.\r\nperspectives won’t relevant lemmas –prepositions, dependency-informed,\r\nrelevant hoop nouns. Even relevance gradual.\r\nmight able generalize, classifying items depending parameter settings\r\nrelevant , depending look like certain kinds\r\nparameters.Say, horde heffen look quite good just setting, haten looks awful always.\r\nStill, based current way computing vectors,\r\nadds type-level vectors tokens instead averaging \r\n(thought ).\r\nstill look adjectives revise nouns verbs using medoids based \r\neuclidean distances.analyses change current conclusions? Chan chan chaaaannn…case, try look last two weeks February \r\ndiscuss DG content part 😄.","code":""},{"path":"the-nature-of-clouds.html","id":"the-nature-of-clouds","chapter":"8 The nature of clouds","heading":"8 The nature of clouds","text":"talk language, often talk linguistic sign. term \r\noften linked Saussure\r\n\r\nstructuralism, far form-meaning pairing cognitive linguistics.\r\ndifferent branches theoretical frameworks linguistic differ \r\ndefine elements pair. example, referring “meaning” signifié\r\naspect: linguistic internal? include reference? include social meaning?\r\nMoreover: relationship studied relation organized system,\r\ndiscovered turbulent chaos language use?Cognitive linguistics, theoretical framework guided studies, accepts\r\nbroadly encompassing notion meaning —certainly make easy \r\ndefine — values study language use. wonderfully compatible \r\nDistributional Hypothesis, methodological framework inspires research,\r\ncan lead disappointing misunderstandings.Distributional Hypothesis basically states correlation difference \r\ndistributional behavior (difference forms used) semantic difference.popular interpretation Hypothesis involves using distributional patterns,\r\nword vectors, operationalizations meaning. word space becomes \r\nsemantic space, type-level model Latent Semantic Analysis (LSA)\r\n“constructs single vector word meaning” (Bolognesi 2020, 23:82). core\r\nargument models, selling point distributional models word embeddings.However, analysis research project can make clear, usage meaning.\r\n\r\nForm can simplified, usage meaning extremely complex phenomena,\r\nsimplification abstraction may make one necessarily correlate\r\nsimplification abstraction prefer . Usage correlates \r\nmeaning, doesn’t mean specific distributional model correspond\r\ndictionary senses case , unfortunately, doesn’t.Even Sahlgren (2006) makes point treating semantic similarity vague terms,\r\ndistinguishing paradigmatic syntagmatic relationships.useful idea might think triad form, meaning, usage. \r\nnecessarily complexify picture, since usage, variety, \r\nconcrete operationalizable. Even equate usage patterns meaning,\r\nrelationship form usage patterns can still inform understanding \r\nmeaning. certainly render distributional methods useless. just \r\ncareful conflate correlated different phenomena, just like \r\nconflate form meaning.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
