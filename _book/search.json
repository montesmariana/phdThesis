[{"path":"index.html","id":"abstract","chapter":"Abstract","heading":"Abstract","text":"present study part Nephological Semantics research project QLVL,\naims develop tools large-scale corpus-based semantic analyses.\ncore aspect project involves representing semantic structure vector space models (VSMs),\ncomputational tool currently requires deeper understanding inner workings\nresults relate cognitive theories meaning.Count-based VSMs represent words1 vectors co-occurrence frequencies multidimensional space\n(Turney & Pantel 2010; Lenci 2018). Basically, word represented \nassociation strength words.\ncan generated type- token-level (Heylen, Speelman & Geeraerts 2012; Heylen et al. 2015; De Pascale 2019).\ntype level, two words represented similar attracted \ncontextual features (e.g. words) repelled contextual features. \nallow us identify semantic fields relationships words, collapses full\nrange contexts word one representation.\ntoken level, instead, look individual occurrences, define similar \nwords contexts attracted repelled contextual features.\nway able map internal variation behavior individual words,\n.e. semasiological structure.Within larger Nephological Semantics project, work package dedicated\nunderstanding token-level vector space models tool\nstudy polysemy. Concretely, explore number parameter settings models,\n.e. ways defining context used represent tokens, impact \nresulting representation, means visual analytics.\nused manual annotation sense tags heuristic, without\nconsidering golden standard. Instead, aim map parameter settings various\nsemantic phenomena coded annotations, \nmeaning granularity (e.g. distinguishing homonyms senses within homonyms).\nvector space models, take form large matrices,\ncan reduced two dimensions via different methods,\nt-SNE (van der Maaten & Hinton 2008; van der Maaten 2014).\ncoordinates can mapped onto scatterplot, resulting variety \nshapes, call clouds.workflow applied set 32 Dutch nouns, verbs adjectives exhibiting\nrange semantic phenomena. , 240-320 concordance lines extracted,\nannotated modeled. combination parameter settings, included syntactic\ninformation, resulted 200-212 different models. models clustered Partition\nAround Medoids (Kaufman & Rousseeuw 1990; Maechler et al. 2021) manageable, representative set explored\ndepth, particular visualizing t-SNE representations.Preliminary results suggest shape clouds depends \ndistinctiveness collocational patterns, may may match sense\nannotations. Noisier models can smooth sharp distinctions, refined\nmodels emphasize . importantly, set parameters works\nacross board.","code":""},{"path":"acknowledgments.html","id":"acknowledgments","chapter":"Acknowledgments","heading":"Acknowledgments","text":"words pages, thoughts try convey, result \nyears thinking, discussing, studying, learning. voice weaves together,\ndraws many sources encouraged growth, stood ,\nfed curiosity, passion enthusiasm everything makes text.support ideas, want thank supervisors Dirk Geeraerts,\nDirk Speelman Benedikt Szmrecsanyi. gave piece, building\nconfidence, encouraging keep exploring learning. main supervisor,\nDirk Geeraerts, deserves special acknowledgment hours deep\ndiscussion complex issue meaning, \n. appreciate patience engagement. Every time talked left\nfeeling excited passionate topic, confident happy.\nHartelijk bedankt.must also thank colleagues Linguistics Department KU Leuven,\ndifferent stages years lovely company \nsupport system. particular, like thank members \nNephological Semantics project, shared much excitement \nfrustrations common project.\njoined project, already brought history connection\n(cognitive) linguistics, corpora, statistics programming. honestly wouldn’t\ntoday weren’t parents, Miguel Patricia. \nalways supported fostered study interests, given tools \ngrow, face new challenges. know can, believe .","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"dissertation concerns application distributional methods,\ndeveloped within field Computational Linguistics (Section 1.1),\nlexicological research, particular theoretical framework Cognitive Semantics (Section 1.2).\naddition, study makes heavy use visual analytics (Section 1.3).part larger project, Nephological Semantics, even longer research programme within QLVL (Section 1.4).","code":""},{"path":"introduction.html","id":"comp","chapter":"1 Introduction","heading":"1.1 Distributional semantics and Computational Linguistics","text":"Distributional semantics popular technique Computational Linguistics, originated.\n[Brief mention references, elaborate ’s first technical chapter.]\nrelies Distributional Hypothesis, states correlation distributional properties\nwords meaning (rather, differences distribution differences meaning).differences use technique Computational Linguistics ’ll show\nthesis.First, Computational Linguistics typically task-oriented, tests models comparing \nresults benchmarks, gold standards [reference ]. contrast, \ntake manual annotation guideline, ground truth, interested \nlearning models can tell us behaviour words models differ \naccuracy. [Admittedly, part best model.]Second, distributional models mostly work type-level word forms units,\nwhereas look token-level models lemmas units.\ncourse, work token-level computational linguistics (describe first chapter)\npopular type level. recent exception BERT family.Third, since advent prediction-based models [Mikolov et al 2013…], word embeddings become\nincreasingly popular; number papers compared performance count-based models,\ndifferent results, practice, neural networks norm NLP. studies, \nlooked count-based model transparent method, .e. one can trace similarities\ntokens words co-occur type-level similarity.\nrest dissertation show, models necessarily transparent thought ,\nintuition still reasoning behind preference count-based models.[Can equate Computational Linguistics NLP?]","code":""},{"path":"introduction.html","id":"cog","chapter":"1 Introduction","heading":"1.2 Distributional semantics and Cognitive Semantics","text":"[computational audience?]Cognitive Linguistics theoretical framework characterized (among principles) emphasis meaning\n(everything can meaningful), notion fuzzy prototypical categories usage-based approach.\n[Bunch references!]three cornerstones inform study distributional models dissertation.First, given Distributional Hypothesis underlies methodology suggests correlation \ndistributional differences semantic differences, kind semantic differences play?\nCan model different semantic dimensions different distributional properties?\nkind semantic phenomena (specialization, generalization, metaphor, metonymy… even animacy, concreteness) can modelled?\n[semasiological point view; refer onomasiological lectometric studies :) ]Second, notion fuzzy prototypical categories underlies sceptical perspective towards existence senses\ndiscrete categories [references] encourages us pursue mechanism can represent semasiological structure\nnon concrete way. certain degree, need discrete entities talk , need classify things,\nsense annotation use clustering algorithms respond needs. don’t take norm; instead,\nembrace presence noise, degrees membership, partial overlap solutions general tendencies.\nfull dissertation read light.Third, usage-based approach easily mapped bottom-, empirical, quantitative methodology,\nwithin already established trend Cognitive Linguistics [references!]. exceptions (’ll see),\nexamples (randomly?2) extracted samples taken case studies. arguments exposed \ndissertation backed data used (available Cloud) specific analyses performed,\nalso means generalization power limited data analyses.\nGiven results don’t look like specific corpus (terms concrete descriptions lemmas,\nmethodological theoretical generalizations), likely apply forms well, course,\n’s empirical question :)","code":""},{"path":"introduction.html","id":"viz","chapter":"1 Introduction","heading":"1.3 Visual analytics","text":"Brief introduction motivation rationale visualization tools (get chapter.)","code":""},{"path":"introduction.html","id":"nephosem","chapter":"1 Introduction","heading":"1.4 Nephological Semantics","text":"Brief history description project, brings three points together,\nPhD shares previous PhD’s/publications within project holes fills.\nstill reread project description, Stefano’s subsection PhD Chapter 1 (suggestions?).","code":""},{"path":"introduction.html","id":"str","chapter":"1 Introduction","heading":"1.5 Structure of the dissertation","text":"rest dissertation consist three main parts.\nfirst part focus methodological procedure choices taken study:\nworkflow create vector space models (including introduction distributional semantics),\nvisualization tool clustering algorithms, selection dataset, annotation, parameter settings, etc. (necessarily order.)\nsecond part focus important findings study [.e. three main points].\nthird (less substantial?) part round dissertation general practical guide (tips, tricks warnings),\nsuggestions research conclusion. [Whether amounts one two chapters, ’ll still see.]\n","code":""},{"path":"an-interface-to-the-world-of-clouds.html","id":"an-interface-to-the-world-of-clouds","chapter":"2 An interface to the world of clouds","heading":"2 An interface to the world of clouds","text":"following chapters, go steps needed obtain “clouds” corpora explore visualization tool developed within Nephological Semantics project. originally created Thomas Wielfart,\nusing D3, popular Javascript library data-driven visualization, developed , culminating present version (Montes & QLVL 2021).section include technical description workflow, pertains\ntool processing work made (Python module, \nPython R functions), sort manual ’s used.Visual analytics aims integrate statistical data analysis techniques information visualization human analysts can recognize, interpret reason statistical patterns data analysis reveals (Card, Mackinlay & Shneiderman 1999). Importantly, visual analytics approach offers manipulable, interactive visualization , unlike static diagrams, enables exploration space parameter values modeling outputs.following chapters interlace technical explanations methodology \ndescription actual steps taken research. Chapter 3 offers introduction\ndistributional models everything researcher needs know go corpus\nmaterial needed visualization. abstract description followed \nexplanation specific parameters explored case studies Chapter 4.\ninformation enough understand usefulness visualization,\nthoroughly described 5, builds Montes & Heylen.\nChapter 6 expands analytical possibilities combining output workflow\nHDBSCAN visualizing Shiny App.\nFinally, Chapter 7 gives overview annotation procedure. step \ntaken modeling performed, necessary visual evaluation\nrelevant theoretical insights second part thesis.","code":""},{"path":"workflow.html","id":"workflow","chapter":"3 From corpora to clouds","heading":"3 From corpora to clouds","text":"main goal distributional models discussed text explore semasiological structure textual data.\nstarting point corpus, one tangible outputs visual representation cloud.\nchapter describe generate clouds raw, seemingly indomitable ocean corpora.First, describe token-level vector space models created.\nSection 3.1 explain count-based models, means viable path.\ntechniques, BERT (Devlin et al. 2019)3, can generate vectors individual instances word,\ncan used first stage workflow.\nvector representations individual instances lexical item, need process .\nvisualization purposes, need reduce numerous dimensions vectors manageable number, 2.\nSection 3.2 explore compare alternatives.output put dimensionality reduction visualization can also\nsubmitted forms analysis clustering algorithms, whose results may\neven combined visualization. look HDBSCAN particular Chapter 6.","code":""},{"path":"workflow.html","id":"vector-creation","chapter":"3 From corpora to clouds","heading":"3.1 A cloud machine","text":"core vector space models, aka distributional models, find Distributional Hypothesis, often linked Harris’s observation “difference meaning correlates difference distribution” (1954: 156), also Firth (1957) Wittgenstein.\n\nwords, items occur similar contexts given corpus semantically similar, occur different contexts semantically different (Jurafsky & Martin 2020, Ch. 6; Lenci 2018). Crucially, imply can describe individual item distributional properties, comparing distribution two items can tell us something semantic relatedness (Sahlgren 2006: 19).Firth (1957) inspired whole tradition corpus linguistics started look collocations part semantic description lemma. Cobuild dictionary first integrate collocational information entries. Birmingham school, pioneered John Sinclair, used co-occurrence frequency information describe lexical item (often word forms, English; see Sinclair (1991: 29) ; Stubbs (1995: 23–24)) set context words attracted . Researchers normally transform raw frequencies association measures mutual information\n(Church & Hanks 1989; Stubbs 1995: 33; McEnery, Xiao & Tono 2010; Gablasova, Brezina & McEnery 2017)\nt-score\n\namong others (see Gablasova, Brezina & McEnery (2017) overview),\nset threshold (around 3 mutual information)\n\nrank context words survive threshold.Count-based vectors basically compare two items contrasting list collocates, instead implementing binary distinction based arbitrary threshold,\n\nmagnitude association strengths play role. Rather measuring overlap traditional collocational profiles, depend actual values .Distributional models operationalize4 idea representing words vectors (.e. arrays numbers) coding frequency information. Typically, raw frequency transformed association strength measure, pointwise mutual information (PMI, see Church & Hanks 1989), compares frequency two words occur close expected frequency words independent. example, Table 3.1 shows small vectors representing English nouns linguistic, lexicography, research chocolate, well adjective computational, series association strengths set lemmas. Empty cells indicate word row word column never co-occur corpus (given certain window span).\nTable 3.1: Example type-level vectors.\ntargetlanguage/nword/nflemish/jenglish/jeat/vspeak/vlinguistics/n4.370.99-3.16-0.41lexicography/n3.512.18-2.19-2.09computational/j1.60.08--1--1.8research/n0.2-0.840.04-0.5-0.68-0.38chocolate/n-1.72-0.531.28-0.733.08-1.13PMI values based symmetric window 10; frequency data GloWbE.row vector coding distributional information lemma represents. lemma refer combination stem part speech, e.g. chocolate/n covers chocolate, chocolates, Chocolate… define unit decision must make build model (see Chapter 4); computational linguistic research, unit often word form, difference using word forms lemmas varies drastically depending language corpus. importantly, must remember vectors represent distributional profile lemma, automatically extracted corpus, meaning (Cf. Bolognesi 2020: 82).Table 3.1 offers brief example semantically similar lemmas (e.g. linguistics lexicography) similar vectors, semantically different lemmas (e.g. linguistics chocolate) different vectors.type-level vectors: aggregates instances given lemma, e.g. linguistics, build overall profile. result, collapses internal variation lemma, .e. semasiological structure. order uncover information, need build vectors individual instances tokens, relying principle: items occurring similar contexts semantically similar. instance, might want model three (artificial) occurrences study (1) (3), target item italics.like study lexicography?study computational linguistics well.eat chocolate study.Given , aggregate level, word can co-occur thousands different words, type-level vectors can include thousands values. contrast, token-level vectors can many values individual window size comprises, drastically reduces chances overlap vectors. fact, three examples don’t share item target. solution, inspired Schütze (1998), replace context words around token respective type-level vectors (Heylen et al. 2015; De Pascale 2019).example, represent example (1) vector context word lexicography, , second row Table 3.1; example (2) sum vectors linguistics (row 1) computational (row 3); example (3) vector chocolate (row 5). solves sparsity issue, ensuring overlap vectors, also allows us find similarity (1) (2) based similarity vectors lexicography linguistics.applying method obtain numerical representations occurrences word. can compare calculating pairwise distances, base clustering analyses (HDBSCAN, see Chapter 6) visualization techniques based dimensionality reduction (section 3.2).However, order obtain result need make number decisions related, among things, define word context (Cf. Bolognesi 2020: 83). decisions discussed Chapter 4.","code":""},{"path":"workflow.html","id":"dim-reduction","chapter":"3 From corpora to clouds","heading":"3.2 Dimensionality reduction","text":"Dimensionality reduction algorithms try reduce number dimensions high-dimensional entity retaining much information possible. Latent Semantic Analysys (LSA)\n\nused reduce type-level spaces thousands dimensions hundred, resulting reduced dimensions found correspond semantic fields.\nVan De Cruys (2008) tried SVD non-negative matrix factorization type-level BOW-based models whole paragraphs windows bring improvement.also used token-level spaces, comparisons discussed De Pascale (2019: 246) indicate don’t necessarily perform better non reduced spaces. Besides, see Chapter 4, can also generate spaces already hundred dimensions selecting first order context words second order features, underperform studies. Skipping SVD step also implies transparent vectors, facilitating understanding going hood, , many paths taken, application SVD remains parameter explore future.\ndimensionality reduction techniques neural networks suggested ways condensing long, sparse vectors (Jurafsky & Martin 2020; Bolognesi 2020),\nFOC-based selection second order dimensions suffices, really needed. Indeed, might want compare SVD versions embeddings vectors, purposes understanding going obtaining meaningful information corpora, still cool!algorithms discuss section, instead, try locate different items low-dimensional space (e.g. 2D) preserving distances high-dimensional space (e.g. 5000D) well possible.\nliterature today tends go either multidimensional scaling (MDS) t-stochastic neighbor embeddings (t-SNE);\nrecently, interesting alternative called UMAP introduced, ’ll discuss shortly.MDS ordination technique, like principal components analysis (PCA). tries different low-dimensional configurations aiming maximize correlation pairwise distances high-dimensional space low-dimensional space: items close together one space stay close together , items far apart one space stay far apart .\ncan evaluated via stress level, complement correlation coefficient: correlation pairwise distances 0.85, stress level 0.15.\nUnlike PCA, however, dimensions meaningful per se; two different runs MDS may result plots mirror representing thing. Nonetheless, R implementation (particular, metaMDS() {vegan} package, see Oksanen et al. (2020)) rotates plot horizontal axis represents maximum variation.\ncognitive linguistics literature metric (Hilpert & Correia Saavedra 2017; Hilpert & Flach 2020; Koptjevskaja-Tamm & Sahlgren 2014)\nnonmetric MDS (Heylen et al. 2015; Heylen, Speelman & Geeraerts 2012; De Pascale 2019; Perek 2016) used.second technique, t-SNE (van der Maaten & Hinton 2008; van der Maaten 2014), also incorporated cognitive distributional semantics (De Pascale 2019; Perek 2018).\nalso popular computational linguistics (Smilkov et al. 2016; Jurafsky & Martin 2020: 118); R, can implemented Rtsne function homonymous package (Krijthe 2018).\nalgorithm quite different MDS. purposes crucial point prioritizes preserving local similarity structure instead global structure: items close together high-dimensional space stay close together low-dimensional space, far apart high-dimensional space may even farther apart low-dimensional space.leads nice, tight clusters distance less interpretable MDS plot (, case, tight clusters rare occurrence studies). words, can interpret tight groups tokens similar , extract meaningful information distance groups. addition, seem points far away multidimensional space might show close together low dimensional space (Oskolkov 2021). Uniform Manifold Approximation Projection (McInnes, Healy & Melville 2020), instead, penalizes sort discrepancies. interesting avenue research, brief test current data reveal great differences t-SNE UMAP warrant replacement technique within duration project. apparent advantages speed observed small samples consideration (fact, UMAP —least R implementation {umap} package (Konopka 2020)— even slower).cases need state desired number dimensions running algorithm —visualization purposes, useful choice 2. Three dimensions difficult interpret projected 2D space, screen (Card, Mackinlay & Shneiderman 1999: 18; Wielfaert et al. 2019: 222). addition, t-SNE requires setting parameter called perplexity, basically sets many neighbors preserved local structure cover.","code":""},{"path":"params.html","id":"params","chapter":"4 Parameter settings","heading":"4 Parameter settings","text":"chapter describe various parameter settings explored:\npossible decisions, ones set looked ,\n. preceded explanation workflow .","code":""},{"path":"params.html","id":"fixed-decisions","chapter":"4 Parameter settings","heading":"4.1 Fixed decisions","text":"number parameters set fixed studies project, means possibility. cases rely previous work set fixed solution, cases rather matter practicality: time resources limited.Corpus: QLVLNews corpus —language: Dutch, register: newspapers, mode: written, period: 1999-2004Corpus: QLVLNews corpus —language: Dutch, register: newspapers, mode: written, period: 1999-2004Unit definition: stem + part speech (wordform, just stem, wordform part speech, even include dependency information) See Kiela & Clark (2014: 25) results English, favoring stemming requiring pos tags.Unit definition: stem + part speech (wordform, just stem, wordform part speech, even include dependency information) See Kiela & Clark (2014: 25) results English, favoring stemming requiring pos tags.Cosine distances vectors See Jurafsky & Martin (2020) 105, Kiela & Clark (2014) suggest correlation instead; euclidean distances models; log transformation ranks…Cosine distances vectors See Jurafsky & Martin (2020) 105, Kiela & Clark (2014) suggest correlation instead; euclidean distances models; log transformation ranks…PPMI values (Kiela & Clark 2014; De Pascale 2019) — Van De Cruys (2008) distinguishes local global PPMI; use global PPMIPPMI values (Kiela & Clark 2014; De Pascale 2019) — Van De Cruys (2008) distinguishes local global PPMI; use global PPMIWindow size second order: 4 (used depascale think,\nshow different results win 10)Window size second order: 4 (used depascale think,\nshow different results win 10)","code":""},{"path":"params.html","id":"first-steps","chapter":"4 Parameter settings","heading":"4.2 First steps","text":"targets first second order features lemma/part--speech pairs,\nhaak/verb (verb haken ‘hook/crochet’),\nbeslissing/noun (noun beslissing ‘decision’), /prep\n(preposition ‘’).\nfeatures (context words) can part speech except punctuation\nminimum relative frequency frequency 1 2 million (absolute frequency 227)\ndiscarding punctuation token count full\nQLVLNews corpus. 60533 lemmas corpus.(threshold less arbitrary, ’re assuming words lower frequency\nwon’t rich enough vectorial representation.)steps defining corpus types obtaining token-level vectors,\ntwo main kinds parameters explore.\nFirst-order parameters influence context features selected\nimmediate environment target tokens,\nsecond-order parameters influence shape vectors\nrepresent first-order features.order visualize tokens, performed dimensionality reduction, .e.\nprocess try represent relative distances items low-dimensional space\npreserving distances high-dimensional space much possible.\nprocedure described Section 3.2.","code":""},{"path":"params.html","id":"first-order-selection-parameters","chapter":"4 Parameter settings","heading":"4.3 First-order selection parameters","text":"call immediate context token first order context: therefore,\nfirst-order parameters influence elements immediate environment\ntoken included modeling said token. made two stages:\none dependent whether syntactic information use, one independent .goes without saying parameter space virtually unlimited, decisions\nmade regarding particular settings explored. tried \nkeep parameter settings different enough variation.\ndecisions based mix literature (Kiela & Clark 2014),\nlinguistic intuition generalizations annotation targets.\n\npart annotation task, annotators select items \nimmediate context helped select appropriate tag. order remove\nnoise misunderstandings idiosyncrasy, looked pairs (trios) \nannotators agreed final annotation ranked\ncontext words agreed. distance dependency information\ncontext words used inform decisions .first stage, main distinction made BASE: bag--words (BOW) based\ndependency-based models (LEMMAPATH LEMMAREL).\nformer split window size (FOC-WIN), part--speech filters (FOC-POS)\nwhether sentence boundaries respected (BOUND).FOC-WIN (first order window)symmetric window 3, 5 10 tokens side target used.\ncourse, virtually value possible [add references!]. Windows \n5 10 typical literature [sources?], 3 enough capture \ncontext words tagged informative annotators.\nFOC-POS (first order part--speech)restriction placed select (common) nouns, adjectives, verbs adverbs (lex)\nsurroundings token. restriction placed, value parameter .\ncourse, selections possible. [add reference] distinguish \nnav, includes common nouns, adjectives, verbs, nav-nap, \nexpand selection proper nouns, adverbs prepositions.\ndetailed research different combinations material \nresearch. see, lex filter often redundant one based \nassociation strength.\nBOUNDARIESGiven information limits sentences (e.g. corpora annotated \nsyntactic dependencies), can exclude context words beyond sentence target (bound)\ninclude (nobound).\nparameter seems virtually irrelevant. thought way \nleveling comparison dependency-based models, definition don’t\ninclude context words beyond sentence, don’t seem make difference.\ndistinction BOW- dependency-based model doesn’t rely much \ncontext words selected tailored selection specific\ntokens. example, closed-class element like preposition may distinctive\nparticular usage patterns term might occur. However, frequent,\nmultifunctional word easily occur immediate raw context target\nwithout actually related . Unfortunately, just narrowing window span\ndoesn’t solve problem, since also drastically reduce number \ncontext words available token token model.\ncontrast, also context words directly linked target\nseparated many words , enlarging window include\nimply much noise token token model.dependency-based model, instead, include context words certain\nsyntactic relationship target, regardless number words .\nactual selection process takes two forms case: path length \nrelationship. former, call LEMMAPATH, similar window size\ncounts steps dependency path instead slots bag--words window.\nlatter, LEMMAREL, matches dependency paths specific templates inspired\ncontext words tagged informative annotators.exemplify, let’s look (4) take herhalen ‘repeat’ target.De geschiedenis rond Remmelink herhaalt zich. ‘history around Remmelink repeats .’different say Van De Cruys (2008) combination dependency relation item make feature (think). requires (carefully planned) type-level matrix dependency features, didn’t get generate, might interesting future research, indeed better distinguishing nouns different degrees concreteness (although apparently also achieved BOW model global PPMI, use…).LEMMAPATHThis set dependency-based models selects features enter syntactic\nrelation target maximum number steps.\npossible values included selection2 selection3, filter\ncontext words two three steps away, respectively, weight, \ngives larger weight context words closer dependency path.\none-step dependency path either head target direct dependent.\nfeatures included selection2 selection3 receive weight 1 weight.\n(4) includes subject, geschiedenis ‘history,’ reflexive pronoun zich,\ndepend directly . target geschiedenis ‘history,’ herhalen ‘repeat,’\nhead, selected.\ntwo-step dependency path either head head target, dependent dependent,\nsibling. features included selection2 selection3 receive weight 2/3 weight.\n(4) includes determiner de modifier rond ‘around’ directly depending \ngeschiedenis ‘history.’\nthree-step dependency path either head head head target,\nsibiling head head, dependent dependent dependent,\ndependent sibling. typical case last path subject passive construction modal,\ntarget verb participium (belastingen ‘taxes’ de belastingen moeten geheven worden ‘taxes must levied’).\nfeatures included selection3 excluded selection2 receive weight 1/3 weight.\n(4) corresponds Remmelink, object rond ‘around.’\nFeatures 3 steps away target always excluded.\nfeatures four steps away can interesting, passive subjects verb two modals, frequent may worth noise included accepting features many steps target. catch relationships, LEMMAREL efficient method.\ncontext words three steps away target (4).\nSee Kiela & Clark (2014) 24-25 discussion type-level results similar approach compared small BOW window. don’t think ’s really comparable though.LEMMARELThis set dependency-based models selects features enter certain\nsyntactic relation target. tailored part--speech target,\ngroup expands selection group . specific selections\nlisted Table 4.1.\n\nTable 4.1: Dependency paths selected different LEMMAREL values.\ngroupsnounsverbsadjectives1modifiers determiners target, items target modifier determiner, verbs target object subjectdirect objects, active passive subjects (two modals active one), reflexive complement prepositions depending directly targetnouns modified target direct modifiers (except prepositions), subject direct objects verbs target direct modifier predicate complement, one modal auxiliary between2conjuncts target (without conjunction), objects modifier target, items whose modifier target objectconjuncts target, complementizers, nouns depending preposition verbal complements elements target verbal complementobject preposition modifying target, conjunct target (without conjunction), prepositional object verb modified target (modifier prepositional complement)3objects modifiers items target subject modifier, subjects modifiers items target subject modifier, modifiers modifiers target, items whose modifier target modifier","code":""},{"path":"params.html","id":"ppmi-weighting","chapter":"4 Parameter settings","heading":"4.3.1 PPMI weighting","text":"PPMI parameter taken outside set first-order parameters can filter first-order features reshape vector representations. truth, choice positive pointwise mutual information (PPMI) weighting mechanisms, well setting threshold , already parameter setting, circumstances set PPMI threshold 0. cases, PPMI calculated based 4-4 window (also variable parameter).parameter can take three values. selection weight mean first-order features PPMI > 0 target type selected, rest discarded, apply filter. difference selection weight former uses value filter context features, latter also weighs vectors value.","code":""},{"path":"params.html","id":"second-order-selection","chapter":"4 Parameter settings","heading":"4.3.2 Second-order selection","text":"selection second-order features influences shape vectors: selected first-order features represented. frequency transformation window values computed varied, set fixed values, namely PPMI 4-4 respectively. parameters varied across, although don’t expect drastic differences models, vector length part--speech.SOC-POS (second order part--speech)parameter can take two values: nav . former case, selection 13771 lect-neutral nouns, adjectives verbs made Stefano taken set possible second-order features. latter, lemmas frequency 227 part--speech considered.\nLENGTHVector length number second-order features therefore dimensionality matrices distance matrices based, although amount changes. applied filtering part--speech.\nselected two values: 5000 FOC. former includes 5000 frequent elements possible features, latter takes intersection possible second-order-features first-order-features, regardless frequency. SOC-POS:, FOC include first-order features model, SOC-POS:nav, included Stefano’s selection.\nactual number dimensions resulting FOC depends strictness first order filter. information can found plots , staal, show many first order context words left combination first order filters.\nKiela & Clark (2014) 24 say worth make longer 50k; jurafsky.martin_2020 mention something kind \nstefano say anything?","code":""},{"path":"params.html","id":"foc-as-soc","chapter":"4 Parameter settings","heading":"4.3.2.1 FOC as SOC","text":"mean use first-order context words second-order context words?First, depending number target tokens strictness filter, different number context words, ranging hundreds low thousands.Second, context words compared based co-occurrence . behaviour context word outside context target largely ignored: course, association strength two items co-occurrence across whole corpus, well non-co-occurrence, included second order vector first item second also among first order context words.","code":""},{"path":"params.html","id":"medoids","chapter":"4 Parameter settings","heading":"4.4 Medoids","text":"multiple parameters return huge number models, purely quantitative methods might\nable process compare , feasible human look hundreds clouds\nstay sane enough make anything . efficient –easier human mind–\nway approach , instead, look representative models.method requires us choose number medoids beforehand, easy\ntask. wanted medoids represent best clustering solution, run\nalgorithm different values \\(k\\) compare results measures \nsilhouette width, suggested Levshina (2015). However, \nnecessarily goal. want able see much variation possible, keeping\nnumber different models manageable (.e. 9). particularly problematic\nmodels redundant, long can ensure phenomena \ninterested represented .example, given lemma multiple senses, might case models\ngroup tokens one sense, others group tokens another: like see\nrepresentatives kinds.\nguarantee method best silhouette returns variation \ninterested –goal , rather, limit number different models need \nexamine total number, say 200, manageable amount, like 8.\nterms, also guarantee identify something interesting\nmedoid, .e. island particular usage pattern, models cluster \nmedoid, models, share characteristic. order check ,\ncan look random samples (, 8 9 models) clusters \nvisually compare medoids. doesn’t need thorough examination \nmedoids : suffices check random sample different\nseems share characteristic interest. [add example]general terms, characteristics identified case studies make \ninvestigation, can quite confident medoids representative models \nclusters. However, depending concreteness phenomena, variation across\nmodels, clarity visualization wishful thinking might lurk \nresearchers’ minds, might case something found assessed medoid \nshared models cluster. comparison needed random sample \nfast honest strongly recommended: medoids representative, can see \ninstant; , just takes bit longer admit . actually studying comparing 64 different models.","code":""},{"path":"nephovis.html","id":"nephovis","chapter":"5 NephoVis","heading":"5 NephoVis","text":"chapter learn use visualization tool explore\ncompare token-level vector space models.moment, tool can found \nGithub Page, ,\nGithub repository can rendered\nstatic website (Montes & QLVL 2021).\nobtains data submodule;\ninterested user clone repository just modify path data.code visualization written Javascript, making heavy use \nD3.js library, designed beautiful web-based\ndata-driven visualization. known steep learning curve,\ncan useful think terms R’s vectorized approach: links\nDOM elements arrays manipulates based items’ properties.main rationale framework visualization tool developed \nThomas Wielfaert (Wielfaert et al. 2019); code can found\n.current implementation exist without foundational setup. However,\nnumber available features added later.description tool immediately follow expected workflow user.\nInstead, start lowest level, Level 3,\nrepresents individual token-level clouds,\nzoom Level 2, shows multiple token-level clouds simultaneously,\nmake abstract level, Level 1, clear.\nAfterwards (Section 5.4) briefly simulate path user take Level 1 Level 3.\nperspective also taken Montes & Heylen.\nFinally, Section 5.5 goes Beta features\nrequire better development testing, well ideas might want \nimplement future. case, must noted July 2019 \n2021-07-07 user developer person, occasional,\nvaluable input members Nephological Semantics project. \nproject certainly benefit wider input suggestions.","code":""},{"path":"nephovis.html","id":"level_3","chapter":"5 NephoVis","heading":"5.1 Level 3","text":"Level 3 visualization tool shows zoomable scatterplot glyph represents token, .e. instance target lexical item. name model, coding parameter settings described \n\n, indicated top. possible map colors shapes categorical variables (sense labels) sizes numerical variables (number available context words) select tokens given value clicking corresponding legend key.","code":""},{"path":"nephovis.html","id":"level_2","chapter":"5 NephoVis","heading":"5.2 Level 2","text":"Level 2 visualization scatterplot matrix, although looks like one code inspired Mike Bostock’s example. Instead, just array small plots next wrap easier readability.represents different model basic features Level 3 available: color, shape size coding, selection clicking brushing, finding context hovering tokens.model-dependent, highlighted context searching tokens context word meaningless level, multiple models shown simultaneously. key contribution level, next superficial visual comparison shape plot, ability select one tokens plot highlighting rest plots well. Thanks functionality, user can compare relative position group tokens model different model.","code":""},{"path":"nephovis.html","id":"level_1","chapter":"5 NephoVis","heading":"5.3 Level 1","text":"Level 1 shows one zoomable scatterplot, similar Level 3, glyph representing one model, instead one token. reminder difference, default shape Level 1 wye (“Y”), levels circle. data represented scatterplot distance tokens anymore, models, described beginning Section 3. scatterplot aims represent similarity models allows user select models inspect according different criteria. Categorical variables (e.g. whether sentence boundaries used) can mapped colors shapes, shown Figure 5, numerical variables (e.g. number tokens model) can mapped size. selection buttons left panel, well legends color shape, can used filter models certain parameter setting. Otherwise, models can selected clicking glyphs represent .","code":""},{"path":"nephovis.html","id":"nephowf","chapter":"5 NephoVis","heading":"5.4 The full story","text":"increasing granularity Level 1 Level 3 manner access different functionalities respect mantra “Overview first, zoom filter, details--demand” (Shneiderman 1996: 97).\nindividual plots Levels 1 3 literally zoomable; cases possible select items (either models, Level 1, tokens, two), detailed inspection. Finally, number features show details demand, names models Level 1 context tokens two levels.practice, user start Level 1, scatterplot models, can look structure distribution parameters plot. example, color coding may reveal models nouns, adjectives, verbs adverbs first-order context words different without strong filters part--speech, use sentence boundaries makes little difference. Depending whether user wants compare models similar different , parameters like keep fixed, use individual selection buttons choose models Level 2. case, click “Select medoids,” selects 8 models returned partitioning algorithm, offers wide range variation manageable number plots.Level 2 user can already compare shapes models take respective plots, distribution categories like sense labels, number lost tokens. addition, “distance matrix” button offers heatmap pairwise distances selected models. case heffen, restrictive collocational patterns presents lead crisp clusters visualization consistent organization across models. However, models less clearly defined structure may prove harder understand. cases, brushing linking functionality highlights whether tokens grouped one model also grouped different model. , user might switch back forth Level 2 Level 3 detailed inspection models.","code":""},{"path":"nephovis.html","id":"examining-context-words","chapter":"5 NephoVis","heading":"5.4.1 Examining context words","text":"possible look individual context token hovering , loses track larger patterns want understand. purpose frequency tables levels 2 3.given model, tokens might close together share context word, /context words (based second-order modelling) similar . First-order parameters , definition, directly responsible selection context words used model token. Therefore, inspecting model, might want know context word(s) pull certain tokens together, tokens expect together far apart instead. words, model offers different perspective distributional behavior token, want understand informs said perspective.Level 3, individual tokens groups may selected different ways. Given selection, clicking “Frequency table” open table one row per context word, column indicating many selected tokens occurs, columns pre-computed information (e.g. PMI values).following five columns include pre-computed frequency information, raw co-occurrence frequency PMI value context word target based windows 10 4, raw frequency corpus.\nvalues can interesting like strengthen weaken filters smarter selection context words. particular model uses dependency-based information well PMI threshold 0 select context words.Level 2, comparing different models, frequency table takes different form. still one context word per row, number tokens co-occurs depend model.\ncolumns table computed visualization based lists context words per token per model. Next column name context word, default table shows one column called “total” one per model, headed corresponding number. columns model match second column Level 3 frequency table: indicate many selected tokens context word co-occurs. “total” column, contrast, reveals union selection: many selected tokens context word co-occurs least one model.default table counts many selected tokens co-occur context words, use information tokens outside selection, .e. cue validity association strength context words selected group. purpose, dropdown button top left corner frequency table offers small range transformations, odds ratio, Fisher Exact, cue validity, etc. One option shows absolute frequencies within outside selection, green columns count number selected tokens co-occur context word, white columns count number tokens outside selection co-occurring context words.","code":""},{"path":"nephovis.html","id":"wishlist","chapter":"5 NephoVis","heading":"5.5 Wishlist","text":"","code":""},{"path":"hdbscan.html","id":"hdbscan","chapter":"6 HDBSCAN","heading":"6 HDBSCAN","text":"visual exploration extremely useful thorough, qualitative description\nvector space models. However, application can also become obstacle\ntruly systematic, scientific description. avoid talking objectivity:\nneither us, individually, can truly objective, instead strive \nhumble admission partiality fruitful combination partialities.describing cloud —particular clouds refuse show clear images,\nperfect sense disambiguation, distinct clusters—, can ensure \nsee found researchers? can make observations, \ninherently valid, least reproducible?\n, , goal strive embark quantitative methods.One tool can help us systematize observations, tightness least\nexistEnce distinct islands plot, \nHierarchical Density-Based Spatial Clustering Applications (HDBSCAN) (Campello, Moulavi & Sander 2013).\nalgorithm basically tries distinguish dense areas separated less dense areas5\nallows noisy data. words, unlike traditional hierarchical clustering,\ntry cluster points dataset, instead may discard \nfar everything else. Moreover, comparison non hierarchical counterpart,\nDBSCAN,\n\nrequires one parameter set priori, namely \\(minPts\\).\\(minPts\\) parameter indicates minimum size dense group points considered\ncluster. isolated dense group points \\(n < minPts\\) considered noise.\ncase studies described fixed \\(minPts\\) 8, seems reasonable\nsize smallest clusters, interested look systematically \neffect lowering threshold. Rising threshold, hand, \nincrease proportion points considered noise, already high.Like clustering algorithms dimensionality reduction techniques,\nHDBSCAN can take token-context matrix input distance matrix. used\ntransformed distance matrix, , input fed t-SNE algorithm,\nhdbscan() function {dbscan} R package (Hahsler & Piekenbrock 2021). output includes,\namong things, cluster assignment, noise points assigned cluster 0,\nepsilon values, can used estimate density.HDBSCAN estimates density [area find] point \\(\\) calculating \ncore distance \\(core_{k}()\\), distance \\(k\\) nearest neighbor, \\(k\\) \\(minPts - 1\\).\nrecalculates distance matrix defining new distance measure, called\nmutual reachability, defined maximum distance \nitems \\(d(, b)\\) core distances.\\[d_{mreach-k}(,b) = max(core_{k}(), core_{k}(b), d(,b))\\]algorithm obtains distances, uses single linkage method create\nhierarchical clusters, using \\(minPts\\) calculations merge \nfinal selection. eps (epsilon) values returned hdbscan() indicate\nheight, single linkeage tree, point joined cluster,\ncan thus used proxy “density.”intuitively clear map clustering solution colors \neps value transparency t-SNE plot perplexity 30. part,\nresults converge, two main upsides. first place, independent\nconfirmation structure found t-SNE, different algorithm processing\ninput returns compatible output. Second, insofar HDBSCAN output matches\nvisual assessment, can systematize render reproducible.wonders notwithstanding, compatibility HDBSCAN output visual examination guaranteed. might find interesting tokens discarded noise, structure within\nsingle HDBSCAN cluster. However, must noted match (lack thereof)\nassessed dbscan::hdbscan() \\(minPts = 8\\) \nRtsne::Rtsne() \\(perplexity = 30\\). interesting avenue research experiment combinations, course UMAP output.","code":""},{"path":"ann.html","id":"ann","chapter":"7 Annotation schema","heading":"7 Annotation schema","text":"case studies, selected 34 Dutch lemmas annotate model token level vector spaces, two (herkennen spoor) discarded.\nselection process presented Section 7.1, description selected items expected annotation clouds look like. short description corpus (QLVLNewsCorpus, De Pascale 2019) follow. annotation procedure focus Section 7.5.\nBachelor students Linguistics KU Leuven (later called annotators) recruited hired manually annotate samples selected lemmas, administrative procedure great interest project, number practical issues discussed: distribution tokens, assignment tasks (particular, graphic interface provided) processing/analysis data.","code":""},{"path":"ann.html","id":"selection","chapter":"7 Annotation schema","heading":"7.1 Selection of items","text":"case study 34 Dutch lexical items selected. aimed cover variety polysemy phenomena, addressed specific sections part speech: section 7.1.1 nouns, section 7.1.2 adjectives, section 7.1.3 verbs.\nmodeling different parts speech different kinds polysemy, expected develop robust generalizations regarding parameter settings best model specific phenomena.selection procedure mixed introspection (thinking words interesting), looking lexical resources (going tentative list dictionary entries figure kind polysemy expect) corpus data (surveying sample concordances evidence expected polysemy). dictionaries essential resource sketch sense labels annotators choose , also adjusted manageable granularity. concordances also crucial estimate sense distribution adjust granularity definitions. didn’t want overwhelmingly frequent sense affect annotators judgement, infrequent senses might hard model least visualise 2D representations. Still, allow complexity subtlety cases.number cases, corpus survey (reading concordance 40-50 randomly selected instances) invalidated options intuitively according dictionary definitions conformed requirements. judging discrepancy, important take account composition corpus. topics addressed newspapers terms used talk certainly representative everyday life entirety language.also cases adjectives used adverbial form always properly tagged part--speech, discard . made difference cases hoopvol ‘hopeful,’ often occurs predicative contexts verb copula (e.g. ik ben hoopvol gestemd ‘makes hopeful,’ hij kijkt hoopvol omhoog ‘looks hopeful(ly)’) still predicates entity, cases gemiddeld ‘average,’ either predicate entity, gemiddelde student ‘average student,’ predicate, zij eet gemiddeld 3 koekjes elke dag ‘eats average 3 cookies per day.’ Sometimes incorrectly tagged cases (adverbs tagged adjectives) infrequent enough dismissed, cases many discard lemma candidate. direct consequence certain potentially interesting lemma couldn’t investigated, also taken account relying part--speech tagger steps workflow.next subsections describe selected nouns, adjectives verbs, QLVLNewsCorpus sampling method. includes general description polysemy phenomena hypotheses, specific definitions, examples translations can found Appendix XX.\n","code":""},{"path":"ann.html","id":"nouns","chapter":"7 Annotation schema","heading":"7.1.1 The nouns","text":"8 nouns exhibit homonymy polysemy least one homonyms.Three nouns one frequent, monosemous homonym less frequent, polysemous one: hoop ‘hope/bunch,’ spot ‘ridicule/show spotlight’ horde ‘horde/hurdle.’ polysemy phenomena varied: metaphor horde ‘hurdle,’ metaphor/generalization hoop ‘heap’ metonymy spot (‘short video/spotlight’). latter case, ‘spotlight’ sense can used literally metaphorically, distinction included among definitions given annotators.\nFour nouns two polysemous homonyms: schaal ‘scale/dish shell,’ blik ‘look/tin,’ stof ‘substance fabric topic/dust,’ staal ‘steal/sample.’\nblik, frequent homonym (‘look’) concrete sense metonymic metaphoric extension, infrequent one can refer material (‘tin’), object made material content: distinction quite clear might depend specificity context infrequent.\n\nSimilarly, stof presents one frequent homonym two concrete, referentially distinct senses (‘substance’ ‘fabric’) andd abstract one (‘topic’), another subtle, context-specificity dependent difference (‘dust (air)’ ‘reducing something dust, pulverize’). Schaal exhibits subtle perspective shifts one homonym (‘scale,’ e.g. “scale Celsius” opposed “large scale”) refers different concrete objects second (‘shell,’ ‘dish,’ ‘scale dish’).\nFinally, staal ‘steal’ refer, like blik ‘tin,’ either material object made , ‘sample’ homonym sensitive construal (sample evidence, general): ’s likely present high confusion /skewed distribution homonyms separately.Finally, spoor three homonyms, two polysemous: ‘footprint trace/train(line, rail, company)/spur.’ noun later discarded proved complicated, data available reanalysis.","code":""},{"path":"ann.html","id":"adjs","chapter":"7 Annotation schema","heading":"7.1.2 The adjectives","text":"selection adjectives includes 13 lemmas presenting different kinds polysemy phenomena.Three adjectives metonymic reading: hoopvol ‘hopeful,’ geestig ‘witty’ hachelijk ‘dangerous/critical.’\ngeestig hoopvol, one senses anthropocentric, .e. ’s mainly exclusively applied people, although distinction made explicit definitions geestig suggested example. expected frequency anthropocentric sense cases much higher one.\nhachelijk’s case, difference matter temporal telic perspective, probably harder distinguish, ’s probably likely annotators suggest second sense alternative first one (assigning ‘critical’ interpretation something potentially dangerous) way around.Four adjectives metaphoric readings: hoekig ‘angulous/clumsy,’ dof ‘dull,’ heilzaam ‘healthy/beneficial’ gekleurd ‘colorful, person color, tainted.’\nHeilzaam two distinctions, somewhere metaphoric specialization: one refers something specifically/literally healthy, one broader less concrete.\nHoekig gekleurd present three sense distinctions, one particularly concrete frequent another one explicitly anthropocentric. third sense distinction different quality: synaesthetic hoekig much metaphoric gekleurd.\nFinally, dof four kinds senses: concrete, synaesthetic, anthropocentric abstract.Three adjectives present form similarity readings: geldig ‘valid,’ hemels ‘heavenly’ gemeen ‘shared/public/mean/serious.’\nGeldig ‘valid’ hemels ‘heavenly’ offer two options, one restricted specific context one much broader. relation relative frequencies senses inverted: specific sense geldig less frequent general one, hemels ’s way around.\nexpect specific sense offered alternative general sense much way around.\ncase gemeen quite complex, involving number rather subtle distinctions. limits first second one third fifth hard establish; fourth sense seems clear context isn’t specific enough easily confused fifth. addition, senses always mutually exclusive, certain instance well conflate ambiguous two senses.Finally, three complex adjectives: heet ‘hot’ different entities metaphorically, grijs ‘gray,’ metaphorical metonymical extensions goedkoop ‘cheap,’ different entities metaphorically.Heet ‘hot’ presents, first, three concrete senses differ perspective: temperatures different kinds things.\n\nsecond half metaphorical, one synaesthetic, one anthropocentric specific, one abstract also quite specific. Crucially, exclusive sense tag idiomatic expressions, quite frequent; expected tagged concrete senses (maybe comment figurative interpretation), annotators might also use geen tag cases.Grijs presents frequent, concrete sense, two specific metonymic extensions, one anthropocentric sense, one rather abstract another specific metaphor.Goedkoop, hand, presents modest set 4 sense distinctions: concrete, prototypical frequent sense, two perspectival shifts clear metaphor.","code":""},{"path":"ann.html","id":"verbs","chapter":"7 Annotation schema","heading":"7.1.3 The verbs","text":"verbs, selected range combinations syntactic semantic variation:Four verbs always trasitive, sense distinction related objects can take: haten ‘hate,’ huldigen ‘honor/hold (attitudes, opinions, stances),’ heffen ‘raise,’ herroepen ‘annul (law)/retract (statement)’)\nHaten heffen probably easy distinguish, former anthropocentric distinction (basically, hating people disliking things, possible gray areas , depending object construed) latter presenting rather clear common metaphor, physical objects abstract entities taxes levied.\nHuldigen herroepen instead slightly subtle differences, former (honoring someone/something holding opinion) probably stronger easier distinguish latter, retracting statement annuling decree (interpreted differently depending entity construed, prototypical ).Two verbs can transitive, distinction based object, intransitive: helpen ‘help,’ herstructureren ‘restructure.’\nverbs quite subtle might present lot confusion, particularly intransitive uses semantically similar one transitive cases.\nherstructureren, one transitive sense intransitive one (exemplified reflexive…) specific, regarding companies connotation personnel reduced, transitive sense broader might selected contexts less specificity. might also depend world knowledge (whether annotators know can guess certain object -subject intransitive construction- company) prominent implication personnel reduction .\nhelpen, distinction transitive uses rather subtle (“collaboration” sense exclusive animate subjects, ’s explicit definitions), might disagreement annotation, intransitive sense confused transitive ones, first one.Three verbs can transitive, distinction based object, reflexive: diskwalificeren ‘disqualify,’ herhalen ‘repeat,’ herinneren ‘remember/remind.’ category initially included herkennen ‘recognize’ discarded.\nverbs opposition can interpreted specific situation object subject coincide.\nparticularly case diskwalificeren, reflexive argument structure pretty much replicates transitive senses, particular case someone disqualifies . possibility distinguish transitive cases, differ specificity (sport context general, mostly political context), relies instead clarity context.\n\nherhalen, object transitive senses (probably wouldn’t) subject reflexive, distinction clear, transitive uses differ kind objects take, certain prototypical nouns (possibility clauses second sense) maybe borderline cases.\nFinally, herinneren shows clear distinction reflexive transitive uses argument structure distinction transitive uses, either without aan complement (might absent restricted context).Two verbs can transitive, intransitive reflexive, semantic distinctions within transitive structure: harden ‘make/become hard, tolerate,’ herstellen ‘heal/repair.’\ncase harden, transitive can concrete, figurative, concrete different sense specific construction, namely (niet) te harden; intransitive structure similar concrete transitive, taking object subject, reflexive similar second transitive. senses different argument structures confused, intransitive first reflexive second. (niet) te harden uses easy isolate, strong agreement annotators high confidence.\nherstellen, transitive structure presents three possible senses: one concrete, one figurative presented , one abstract subtly different second one. reflexive close figurative sense intransitive specific concrete healing (rather repairing) confused others.Finally, included verb semantic distinctions within transitive intransitive structures: haken.\npresented two transitive senses, two intransitive one transitive/intransitive. transitive senses can concrete literal differ specificity: one sense refers particularly making somebody trip. Intransitive uses differ literality , might occur blijven, figurative definition mentions (apparently restricting ). figurative options mentioned transitive senses, occur annotators might either tag transitive concrete, intransitive figurative, geen. Finally, one sense can occur transitive intransitve (ellided object) ‘crochet’; ’s specific shouldn’t confused others probably high confidence.","code":""},{"path":"ann.html","id":"expectations-for-the-annotation","chapter":"7 Annotation schema","heading":"7.2 Expectations for the annotation","text":"first set expectations annotations types summarized six points, discussion revision needed. formulated predictions followed suggestions confirm . ‘technical’ terms :majority sense, meaning sense tag annotators assigned given token.alternative sense/annotation, meaning sense tag assigned given token, different majority sense.() confuse(d), meaning disagreement annotation.\n","code":""},{"path":"ann.html","id":"for-all-types","chapter":"7 Annotation schema","heading":"7.2.1 For all types","text":"specific senses confused general senses.\nmajority sense specific one, alternative annotation geen.\nConcretely:haken 5 haken 3 confused senses.heet 4 confused senses.Metaphor easier identify metonymy/specialization\nmetaphoric sense option distinct concrete/literal one, won’t often confused literal counterpart; annotators agree ’s figurative. metonymy specialisation, disagreement less confidence.\nConcretely:blik 1.1 confused 1.2 1.3.grijs 1 confused 2 3 6.goedkoop 1 confused 2 3 4adjectives metaphoric distinctions (hoekig, dof, gekleurd, heilzaam) present less confusion metonymic distinctions (hachelijk, hoopvol, geestig)Anthropocentric senses easily distinguishable.\ndefinition explicitly restricts application people, won’t alternative annotation , non anthropo-exclusive senses. Borderline cases, due probably unspecified context, low confidence.\nConcretely:low confusion haten, least low confidence borderline casesheet 5 confused othersgrijs 4 confused senses (except maybe 3, derived )gekleurd 2 confused othershoekig 3 confused othersdof 3 confused othershoopvol present less confusion geestig present less confusion hachelijk","code":""},{"path":"ann.html","id":"only-for-nouns","chapter":"7 Annotation schema","heading":"7.2.2 Only for nouns","text":"Homonyms confused .\nmajority sense one homonym, alternative annotations homonym geen.","code":""},{"path":"ann.html","id":"only-for-verbs","chapter":"7 Annotation schema","heading":"7.3 Only for verbs","text":"next two predictions overlap, explain different verb groupings (sometimes, different argument structure implies subject distinction, prominent?).Argument structure easier identify semantic differences.\nSenses differ argument structure confused (won’t ’s alternatives) much senses argument structure different kinds objects. distinction probably easier make reflexive intransitive cases.\nConcretely: general, transitive senses confused senses different argument structure (unless sense semantically similar transitive sense). Cases might generate confusion different argument structures :gral. trans. haken fig. intrans. haken cases fig. trans. hakenfig. trans. harden refl. hardenfig./abs. trans. herstellen refl. herstellenspec. trans. herstructrureren intrans. herstructurerenhelpen 1 intrans. helpenSenses require different subjects easier identify senses require different objects prepositional arguments\nSenses different subject restrictions won’t alternatives. ’m thinking subject restrictions often linked animacy, object restriction might subtle cases.\nConcretely: general, senses argument structure confused one takes (mostly) animate subjects one (mostly) inanimate subjects.","code":""},{"path":"ann.html","id":"corpus","chapter":"7 Annotation schema","heading":"7.4 The corpus and samples","text":"exploration samples concordances also served calculation number tokens annotate. Regardless actual frequency items corpus, extracted minimum 240 tokens type (thinking 6 batches 40 tokens), raised amount 280 senses relative frequency 20% sample, 320 10%, 360 many senses therefore low frequency.\nsample tokens selected almost absolutely randomly. First instances type extracted corpus; , type many files tokens wanted extract selected, file randomly selected one token. Therefore, two instances lemma file samples. , however, duplicates, due repetition fragment different dates.corpus selection LeNC TwNC corpora, include newspapers articles Flanders Netherlands. selection, performed De Pascale (2019) eye lectally balanced corpus, contains 4,614,267 types 519,996,217 tokens (roughly 520M, 260 Flanders 260 Netherlands). articles subcorpus published 1999 2004 quality popular newspapers countries.","code":""},{"path":"ann.html","id":"annotation","chapter":"7 Annotation schema","heading":"7.5 Annotation procedure","text":"","code":""},{"path":"ann.html","id":"assigning-batches-to-annotators","chapter":"7 Annotation schema","heading":"7.5.1 Assigning batches to annotators","text":"October 2019, 48 students General Linguistics course 2nd year Bachelor Linguistics KU Leuven recruited work annotators. tasked annotating 40 tokens 12 types (least three nouns, four adjectives four verbs, plus one either categories), total 480 tokens, expected work average 10 hours, spread 6 weeks. Students option subscribing double number tokens (hours, pay). types sets tokens assigned randomly, keeping mind part--speech distribution. intention shuffle samples lemma splitting batches, something went wrong code ordered source.annotation involved three compulsory tasks one normally optional. tokens, annotators :assign sense predefined set definitions, shown Appendix XX. none senses satisfactory, may choose “None ” option;express confidence decision Likert scale 6 values;identify words context helped assign sense, comprising 15 tokens left right target, disregarding sentence boundaries respecting article;couldn’t assign sense, explain . assign one, still option adding extra information thoughts annotation process, compulsory.","code":""},{"path":"ann.html","id":"annotation-toolinterface","chapter":"7 Annotation schema","heading":"7.5.2 Annotation tool/interface","text":"Since entering textual information spreadsheet can easily lead typos inconsistencies , furthermore, annotating relevant context words (cues) challenging tool, user-friendly visual interface designed transforms button-output json file information required.interface menu types , selected type, two tabs: overview concordance lines annotation workspace. annotation workspace, read line individually, click button corresponding sense wanted assign, rate confidence star rating, click words found useful enter comments. overview section didn’t let see whole set tokens analyze, target items changed color annotated links Annotation tab concordance lines.interface rendered webpage via Github Pages, processed information: annotators download (necessary upload) progress JSON file eventually send mail.goals interface twofold. First, reduce typos inconsistencies values straightforward present little variation: much faster design interface check typos 480 tokens times 40 annotators. Second, make annotation experience simpler even pleasant, letting annotators focus energies lexicographical task rather technicalities.particularly evident task selecting relevant context words. spreadsheet, either necessary separate rows per context words annotate (make sure forgetting ) make list items cell row relevant concordance. list need something truly identifying context word, therefore form lemma position (since item occur context always relevance), counting reliably time consuming prone errors. Clicking words program lists position relevant words, also making visible words selected, solves easiness reliability issues.","code":""},{"path":"ann.html","id":"known-issues","chapter":"7 Annotation schema","heading":"7.5.2.1 Known issues","text":"interface issues, consequences affect output.One technical issue bug code annotation, context words selected annotator might replaced context words wordform, previous position. bug found, annotators warned, necessarily checked previous annotation thoroughly. case, affects wordforms occur concordance (often) cleaned reasoning.Another issue format corpus, dealt better. one hand, different sentences concordance indiciated <sentence><\/sentence> impact rendering concordance, just replaced empty spaces. ’ve replaced <p><\/p> tags. hand, point corpus processing (access ), someone must replaced & , HTML entities like &quot;, ’ve translated quotation mark \", rendered andquot;, extremely confusing annotators, especially already complicated concordances full . issue identified late (case, corpus already reads andquot; instead \", confusion ).–>","code":""},{"path":"the-nature-of-clouds.html","id":"the-nature-of-clouds","chapter":"8 The nature of clouds","heading":"8 The nature of clouds","text":"talk language, often talk linguistic sign. term \noften linked Saussure\n\nstructuralism, far form-meaning pairing cognitive linguistics.\ndifferent branches theoretical frameworks linguistic differ \ndefine elements pair. example, referring “meaning” signifié\naspect: linguistic internal? include reference? include social meaning?\nMoreover: relationship studied relation organized system,\ndiscovered turbulent chaos language use?Cognitive linguistics, theoretical framework guided studies, accepts\nbroadly encompassing notion meaning —certainly make easy \ndefine — values study language use. wonderfully compatible \nDistributional Hypothesis, methodological framework inspires research,\ncan lead disappointing misunderstandings.Distributional Hypothesis basically states correlation difference \ndistributional behavior (difference forms used) semantic difference.popular interpretation Hypothesis involves using distributional patterns,\nword vectors, operationalizations meaning. word space becomes \nsemantic space, type-level model Latent Semantic Analysis (LSA)\n“constructs single vector word meaning” (Bolognesi 2020: 82). core\nargument models, selling point distributional models word embeddings.However, analysis research project can make clear, usage meaning.\n\nForm can simplified, usage meaning extremely complex phenomena,\nsimplification abstraction may make one necessarily correlate\nsimplification abstraction prefer . Usage correlates \nmeaning, doesn’t mean specific distributional model correspond\ndictionary senses case , unfortunately, doesn’t.Even Sahlgren (2006) makes point treating semantic similarity vague terms,\ndistinguishing paradigmatic syntagmatic relationships.useful idea might think triad form, meaning, usage. \nnecessarily complexify picture, since usage, variety, \nconcrete operationalizable. Even equate usage patterns meaning,\nrelationship form usage patterns can still inform understanding \nmeaning. certainly render distributional methods useless. just \ncareful conflate correlated different phenomena, just like \nconflate form meaning.","code":""},{"path":"nonsense-or-no-senses.html","id":"nonsense-or-no-senses","chapter":"9 Nonsense or no senses?","heading":"9 Nonsense or no senses?","text":"","code":""},{"path":"nonsense-or-no-senses.html","id":"introduction-1","chapter":"9 Nonsense or no senses?","heading":"9.1 Introduction","text":"linguistic terms, clouds may provide us different types information, syntagmatic paradigmatic level. syntagmatic level, may illustrate cases collocation, colligation, semantic preference even tendencies towards open-choice principle. paradigmatic level, hand, codes relationship clusters dictionary senses, heterogeneous clusters represent prototypical contexts sense.Given naive understanding correlation context meaning, mostly expect, paradigmatic perspective, clusters equal senses: cluster cover occurrences dictionary sense occurrences sense. However, even relax requirements, expecting clusters mostly occurrences one sense covering instances discarded noise, arise often. Instead, even homogeneous clusters group typical contexts within sense, , syntagmatic level, tend correspond collocations. case, see chapter, full picture much complex, may obtain much richer information just lexical collocations representing typical contexts within sense.chapter, look types syntagmatic paradigmatic information clouds offer. Section 9.2 starts overview different levels dimension mentions examples interaction contingency table. elaborate detailed examples situation sections 9.3 9.6, round overall summary Section 9.7.","code":""},{"path":"nonsense-or-no-senses.html","id":"infotypes","chapter":"9 Nonsense or no senses?","heading":"9.2 Types of information","text":"linguistic information obtainable clusters can understood syntagmatic perspective co-occurrence patterns different kinds, paradigmatic perspective relation dictionary senses. dimensions interlace, resulting number specific phenomena may encounter. relationship summarized Table 9.1; syntagmatic collocational dimension represented columns discussed Section 9.2.1, paradigmatic semantic dimension represented rows discussed Section 9.2.2.\nTable 9.1: Contingency table collocational semantic perspectives, examples.\n","code":""},{"path":"nonsense-or-no-senses.html","id":"collocationally","chapter":"9 Nonsense or no senses?","heading":"9.2.1 Collocational perspective","text":"order interpret different levels information syntagmatic collocational perspective may offer us, can make use theoretical concepts foundations Corpus Linguistics. terms already coined Firth (1957), integrated framework corpus analysis Sinclair (1998: 124–125) publications. framework includes, next node, .e. targets, four key components: one obligatory, semantic prosody, discussed , three help us make sense observed output clouds: collocation, colligation semantic preference.simplest form, collocations defined co-occurrence two words within certain span (Firth 1957: 13; Sinclair 1991: 170; Sinclair 1998: 15; Stubbs 2009: 124). might filtered statistical significance co-occurrence frequency strength attraction (e.g. ; see McEnery & Hardie (2012: 122–133) discussion). Even though collocational relationship asymmetric, , co-occurrence frequent word B may important less frequent word B, measures used described often symmetrical (Gries 2013).\ncomes interpretation clouds, category takes different form definitely asymmetric. Considering models built around target term node, frequent, distinct context words bound make tokens co-occur similar different rest: generate clusters. context words tend high  target, , crucially, stand salient feature among occurrences target, independently salient target modelling collocate.\nConcretely, talking clusters defined one context word group co-occurring context words high F-score relation cluster. words, tokens cluster co-occur word(s), tokens co-occurring words cluster. context words can interpreted collocates target.Unlike collocational studies, study list words co-occur (significantly) frequently target node, vector space models allow find whether context words exclude also co-occur within context target. fact, might even find complex collocational patterns, made multiple context words.Whereas collocation understood relationship words (, traditionally, relationship word forms), colligation defined relationship word grammatical categories syntactic patterns (Firth 1957: 14; Sinclair 1998: 15; Stubbs 2009: 124). order capture proper colligations clusters, need models parts speech maybe dependency patterns used features, case studies. However, rejecting strict separation syntax lexis\n(everything semantics Cognitive Linguistics),\ncan make grammatically-oriented interpretation collocations function words, frequent prepositions, om te combination, passive auxiliary. Given caveat, talk lexically instantiated colligations encounter clusters dominated items indicate specific grammatical function.Semantic preference defined relationship word semantically similar words (Sinclair 1998: 16; Stubbs 2009: 125; McEnery & Hardie 2012: 138–140). Within traditional collocational studies, implies grouping collocates, , already frequently co-occurring items, based semantic similarity, much colligation can result grouping collocates based grammatical categories. Compared collocation, identification requires interpretation part researcher.\ninterpretation individual clusters, semantic preference appears clusters dominated single collocate group co-occurring collocates, instead defined group infrequent context words similar type-level vectors can give semantic interpretation. (Cases similar context words without semantic interpretation quite rare, normally involve pronouns adverbs.) key contribution token-level distributional models may remain inaccessible traditional collocational studies: next powerful collocates group virtually identical occurrences, can identify patterns context words exact similar enough emulate collocate.three notions described assume identifiable patterns: occurrences similar enough substantial number occurrences, different enough occurrences, generate cluster. Going back Sinclair (1991)’s founding notions, assuming domination idiom principle:…language user available large number semi-preconstructed phrases constitute single choices, even though might appear analysable segments. (Sinclair 1991: 110)opposite situation given open-choice principle:point unit completed (word phrase clause), large range choice opens restraint grammaticalness. (Sinclair 1991: 109)idiom principle open-choice principle supposed organise lexicon production utterances. , instead, understood poles continuum collocational behaviour, can help us interpret variety shapes encounter within across lemmas. Lemmas tend find identifiable clusters, strong collocations, lexically instantiated colligations sets semantic preference, can said respond idiom principle. contrast, lemmas exhibit large proportions noise tokens, small, diffuse clusters (Cirrus clouds, mostly), can said tend towards open-choice principle. don’t necessarily lack structure, whatever structure less clear lemmas, harder capture models.reasoning, next three categories described , include near-open choice fourth category, meant include clouds conform either clearer formats.","code":""},{"path":"nonsense-or-no-senses.html","id":"semantically","chapter":"9 Nonsense or no senses?","heading":"9.2.2 Semantic perspective","text":"terms relationship HDBSCAN clusters manually annotated dictionary senses, can initially distinguish heterogeneous clusters, .e. exhibit clear preference one sense, homogeneous clusters. Secondly, homogeneous clusters may cover (clustered) tokens given sense, part , .e. (proto)typical context sense. Additionally, said (proto)typical context may highlight certain aspect dimension meaning target, different highlighted different context.result, semantic dimension covers four different types situations. first one, .e. heterogeneous clusters clusters multiple senses, normally interpreted bad modelling, consider senses gold standard target models. also frequent interpretation clouds , syntagmatically, tend towards open-choice principle. Nonetheless, can also occur kinds clouds, illustrate mismatch contextual semantic structure: clear contextual patterns imply dictionary senses.\nsecond type situation, .e. clusters perfectly match senses, normal expectation naive point view truly equate patterns dictionary cases. quite rare often indicative fixed expressions particular meanings.Rather full senses, contextual patterns tend represent typical contexts sense.\nnotion prototypicality Cognitive Semantics related perspective categories need discrete uniform application semasiological structure lemmas meanings (Geeraerts 1988). extensional level, case covers domains contexts application target item, categories may defined varied set overlapping features (.e. context words) fuzzy boundaries /degrees membership. central prototypical members category exhibit overlapping features; fewer features co-occur item, weaker connection category.\nappear clouds, sense may exhibit one typical context much frequent clear rest, multiple typical contexts various frequencies. Unfortunately, neither t-SNE HDBSCAN provide reliable mapping quantitative properties relative centrality clusters. contrast, can identify central cases within HDBSCAN cluster based membership probability, , saw , normalized core distance within cluster. Items higher membership probability lie denser area HDBSCAN cluster, therefore items similar items sparser areas. necessarily occur euclidean centre t-SNE plot, might form one dense cores closer towards edge instead. addition, can distinguish rather uniform clusters, members similar weight, diverse clusters dense cores sparse peripheries.Extensional prototypicality works multiple levels. identify (proto)typical instances/contexts lemma, sense, dimension sense.\nsake illustration, let’s take frequency proxy saliency prototypicality, look one medoid horde ‘horde/hurdle.’ five frequent context words (ones co-occurring 10 tokens) , descending order: nemen ‘take,’ journalist, toerist ‘tourist,’ meter worden (passive auxiliary). point view, nemen ‘take,’ represents rather fixed expression een horde nemen ‘take obstacle,’ single typical context lemma horde, particular figurative ‘hurdle’ sense. represent frequent sense, however, journalist toerist ‘tourist represent ’horde’ sense, combined frequencies slightly larger nemen ‘take.’ Next, within sense, nemen ‘take’ meter represent typical contexts respective senses, .e. metaphorical literal ‘hurdle,’ whereas journalist toerist ‘tourist’ instantiate sense ‘horde.’ Neither can said semantically central ‘horde’ meaning, given rather similar frequencies. just two typical contexts sense. case can also go deeper, distinguishing different aspects ‘horde’ sense. rest context words co-occurring tokens clusters represented journalist toerist ‘tourist’ point towards different dimensions aspects ‘horde,’ een horde journalisten ‘horde journalists’ typical context ‘intimidating, dangerous violent mass people’ dimension, een horde toeristen ‘horde tourists’ typical context ‘massive flow people’ dimension.","code":""},{"path":"nonsense-or-no-senses.html","id":"interaction-between-dimensions","chapter":"9 Nonsense or no senses?","heading":"9.2.3 Interaction between dimensions","text":"can see Table 9.1, interaction four levels dimension result 4x4 table one cell filled least one example. Naturally, combinations equally frequent interesting; salient one certainly collocation indicates prototypical context sense. mean rest phenomena ignored: can still find interesting useful information shapes clouds, contextual patterns, semantic structure.following sections, look detail examples attested combination. section focus one level collocational dimension, subdivided levels semantic dimension.\nexamples illustrated scatterplots colours represent HDBSCAN clusters, shapes indicate manually annotated dictionary senses, transparency, eps value HDBSCAN. senses specified legends, clusters named context word represents best. Concretely, cluster calculate precision recall context words co-occur tokens, .e. proportion tokens cluster co-occur word, well proportion tokens co-occurring word included cluster. values, F-score calculated: higher , better cue context word cluster. highest value, 1, indicates tokens co-occurring word, tokens co-occurring word, within cluster. context word highest F-score, F-score, used name clusters plots.","code":""},{"path":"nonsense-or-no-senses.html","id":"collocation","chapter":"9 Nonsense or no senses?","heading":"9.3 Collocation","text":"first level collocational syntagmatic dimension collocation: clusters dominated one context word group co-occurring context words. likely found Cumulus clouds, also Stratocumulus clouds , vary rarely, Cirrus clouds.","code":""},{"path":"nonsense-or-no-senses.html","id":"heterogeneous-clouds","chapter":"9 Nonsense or no senses?","heading":"9.3.1 Heterogeneous clouds","text":"Albeit infrequently, collocations might transcend senses, , might frequent even distinctive lemma without showing preference specific sense.\nclear example found heilzaam ‘healthy, beneficial,’ can literally mean something beneficial health applied, metaphorically, domains well. clusters typically dominated one context word indicative one sense: mostly werking ‘effect’ effect (adding, models, less frequent invloed ‘influence’). examples shown (5) (8), represent ‘healthy’ broader ‘beneficial’ senses respectively.Het lypoceen , een bestanddeel dat bijdraagt aan de rode kleur , zou een heilzame werking hebben op de prostaat .  De stof opgenomen voedingssupplementen . (Volkskrant, 2003-11-08, Art. 14)Het lypoceen , een bestanddeel dat bijdraagt aan de rode kleur , zou een heilzame werking hebben op de prostaat .  De stof opgenomen voedingssupplementen . (Volkskrant, 2003-11-08, Art. 14)Voor politici met dadendrang een gruwel , maar als men de casus van de Betuwelijn nog voor de geest haalt dan zou het advocatensysteem zijn heilzame werking hebben kunnen bewijzen .  Voorts verhoogt het advocatensysteem de integriteit van het (Volkskrant, 2002-03-29, Art. 79)Voor politici met dadendrang een gruwel , maar als men de casus van de Betuwelijn nog voor de geest haalt dan zou het advocatensysteem zijn heilzame werking hebben kunnen bewijzen .  Voorts verhoogt het advocatensysteem de integriteit van het (Volkskrant, 2002-03-29, Art. 79)vastgesteld dat alcoholconsumptie tot een vermindering van atherosclerose leidt .  Pierik beschrijft de heilzame effecten van alcoholgebruik op de bloedvaten en de bloeddruk , op mogelijke beroerten , galstenen , lichaamsgewicht , vruchtbaarheid , zwangerschap , botontkalking , kanker , verkoudheid , suikerziekte en seniele dementie . (NRC Handelsblad, 1999-11-27, Art. 148)vastgesteld dat alcoholconsumptie tot een vermindering van atherosclerose leidt .  Pierik beschrijft de heilzame effecten van alcoholgebruik op de bloedvaten en de bloeddruk , op mogelijke beroerten , galstenen , lichaamsgewicht , vruchtbaarheid , zwangerschap , botontkalking , kanker , verkoudheid , suikerziekte en seniele dementie . (NRC Handelsblad, 1999-11-27, Art. 148)de fictie-categorie alleen een feestelijke verliezer krijgen . De kwestie heeft alvast één heilzaam effect : het profiel van commerciële boekenprijzen staat opnieuw ter discussie .  Tom (NA, 1999-03-27, Art. 133)de fictie-categorie alleen een feestelijke verliezer krijgen . De kwestie heeft alvast één heilzaam effect : het profiel van commerciële boekenprijzen staat opnieuw ter discussie .  Tom (NA, 1999-03-27, Art. 133)model shown Figure 9.1: clusters dominated werking ‘effect,’ effect invloed ‘influence’ shown yellow, light blue green, respectively, manually annotated senses mapped shapes: literal ‘healthy’ senses coded circles, general sense, triangles.\nWithin werking cluster, literal tokens ((5)) majority tend towards left side cloud, general ones (like (6)) tend towards right side. preference literal sense, especially considering across full sample general sense frequent, far homogeneous. balance even striking within effect cluster, tokens senses can found.picture pervasive across multiple models heilzaam ‘beneficial.’ necessarily case capture words representative ‘physical health,’ vague organization within werking ‘effect’ cluster suggests. salient context words precisely discriminative two senses.\nFigure 9.1: Cloud heilzaam: heilzaam.BOWbound10all.PPMIweight.LENGTHFOC.SOCPOSall.\nissue come modelling expecting lexical collocates, werking ‘werking,’ effect, invloed ‘influence,’ unequivocally represent different dictionary senses. hand, ben ‘’ werk ‘work, effect’ (werking nominalisation), co-occur tokens orange cluster, dominated general sense, less outside cluster; see examples (9) (10).\nwords, frequent nouns modified heilzaam ‘beneficial’ tend occur attributive constructions (particularly een heilzame werking hebben ‘beneficial/healing effect/power’ de heilzame werking van ‘beneficial/healing effect/power ’) either sense, whereas predicative constructions present wider variety nouns stronger tendency towards general sense.ten goede komen .  Versterking van de politieke controle op de Commissie kan heilzaam zijn maar de huidige ongenuanceerde discussie gevaarlijk voor Europees beleid en besluitvorming .  (NA, 1999-03-18, Art. 45)ten goede komen .  Versterking van de politieke controle op de Commissie kan heilzaam zijn maar de huidige ongenuanceerde discussie gevaarlijk voor Europees beleid en besluitvorming .  (NA, 1999-03-18, Art. 45)een vervolg op een project met Ensemble Loos onderzoekt het gezelschap Blood floor wederom de samenwerking tussen frank en vrij improviserende jazzmuzikanten enerzijds en dapper maten tellende en genoteerde noten spelende musici anderzijds heilzaam kan werken .  Turnage heeft de zaak naar eigen zeggen niet op de (Het Parool, 1999-03-23, Art. 79)een vervolg op een project met Ensemble Loos onderzoekt het gezelschap Blood floor wederom de samenwerking tussen frank en vrij improviserende jazzmuzikanten enerzijds en dapper maten tellende en genoteerde noten spelende musici anderzijds heilzaam kan werken .  Turnage heeft de zaak naar eigen zeggen niet op de (Het Parool, 1999-03-23, Art. 79)","code":""},{"path":"nonsense-or-no-senses.html","id":"dictionary-clouds","chapter":"9 Nonsense or no senses?","heading":"9.3.2 Dictionary clouds","text":"cases can see clusters characterized one dominant context word perfectly match sense, least clustered tokens. normally fixed expressions, least degree: definition may require specific expression, representatieve staal ‘representative sample.’interesting example shown Figure 9.2, model noun schaal ‘scale, dish.’ plot, ‘scale’ homonym represented circles (‘range values, e.g. scale Richter, scale 1 5’), squares (‘magnitude, e.g. large scale’) triangles (‘ratio, e.g. scale 1:20’), whereas ‘dish’ homonym represented crosses (‘shallow wide dish’) crossed squares (‘dish scale’).\n‘range’ ‘dish scale’ senses, exemplified (11) (12), perfect match (almost) HDBSCAN cluster, represented context word perfect F-score. schaal tokens co-occurring Richter grouped red cluster, cover almost full range attestations ‘range’ sense, tokens co-occurring gewicht ‘weight’ grouped light blue cluster cover attestations ‘dish scale’ sense.Wenen , Beneden-Oostenrijk en Burgenland zijn dinsdagochtend opgeschrikt door een aardschok van 4,8 op de schaal van Richter . De bevolking van de hoofdstad werd daardoor bij het krieken (NA, 2000-07-12, Art. 4)Wenen , Beneden-Oostenrijk en Burgenland zijn dinsdagochtend opgeschrikt door een aardschok van 4,8 op de schaal van Richter . De bevolking van de hoofdstad werd daardoor bij het krieken (NA, 2000-07-12, Art. 4)Daarom het van belang dat Nederland zich deze week achter de VS heeft geschaard , ook al legt ons land natuurlijk minder gewicht de schaal dan Duitsland het Europese debat de al dan niet noodzakelijke toestemming van de Veiligheidsraad voor militaire actie tegen Irak . (NRC Handelsblad, 2002-09-07, Art. 160)Daarom het van belang dat Nederland zich deze week achter de VS heeft geschaard , ook al legt ons land natuurlijk minder gewicht de schaal dan Duitsland het Europese debat de al dan niet noodzakelijke toestemming van de Veiligheidsraad voor militaire actie tegen Irak . (NRC Handelsblad, 2002-09-07, Art. 160)way, phenomenon indicates fixed, idiomatic expression: combination two words fully represents sense. However, picture nuanced.\nFirst, technically, ‘range’ sense can potentially occur context words Richter. fact, one examples given annotators schaal van Celsius ‘Celsius scale,’ well pattern like one found (13), one orange circles top Figure 9.2. However, corpus used studies, Celsius co-occur schaal symmetric window 4; moreover, 32 tokens sense attested model, 22 co-occur Richter, 3 match pattern (13), rest exhibit less fixed patterns infrequent glijdende schaal ‘slippery slope’ construction. matching (13) readily clustered tokens co-occurring preposition op, (14). words, register newspapers, ‘range’ sense schaal almost completely exhausted schaal van Richter ‘Richter scale’ expression. \" Misschien deelt de computer mij op grond van statistische analyses op een schaal van 1 tot 12 categorie 3 ’ , zegt woordvoerder B. Crouwers van de registratiekamer . (NRC Handelsblad, 1999-01-09, Art. 10) \" Misschien deelt de computer mij op grond van statistische analyses op een schaal van 1 tot 12 categorie 3 ’ , zegt woordvoerder B. Crouwers van de registratiekamer . (NRC Handelsblad, 1999-01-09, Art. 10).  Die stad vormde de opmaat tot de latere collectieve regelingen op nationale schaal , stellen de auteurs , navolging van socioloog prof. dr. Abram de Swaan . (Volkskrant, 2003-05-03, Art. 253).  Die stad vormde de opmaat tot de latere collectieve regelingen op nationale schaal , stellen de auteurs , navolging van socioloog prof. dr. Abram de Swaan . (Volkskrant, 2003-05-03, Art. 253)Second, ‘dish scale’ sense need used metaphorical expression illustrated (12), indeed case data. Next gewicht ‘weight,’ tokens also mostly co-occur leg ‘lie, place’ , lesser degree, werpen ‘throw.’ Even models, cluster tends built around co-occurrence gewicht ‘weight,’ normally excluding tokens co-occur leg ‘lie, place,’ belong sense .\nFigure 9.2: Cloud schaal: schaal.BOWnobound5all.PPMIweight.LENGTHFOC.SOCPOSall.\nexamples don’t disprove possibility clouds dominated collocate perfectly covering sense, long keep mind characteristics limitations corpus studying difference describing “sense used” \"sense used particular corpus.","code":""},{"path":"nonsense-or-no-senses.html","id":"prototypical-context","chapter":"9 Nonsense or no senses?","heading":"9.3.3 (Proto)typical context","text":"frequent phenomenon — especially among Cumulus clouds — cluster dominated one context word group co-occurring context words represents (proto)typical context sense. may prototypical context, rest sense discarded noise spread around less clear clusters, might also find multiple clusters representing different typical contexts sense. Neither t-SNE HDBSCAN can tell whether one contexts central , least sense expect prototype theory. Denser areas tokens, perceived HDBSCAN, many tokens similar . tokens similar, similar , denser area. see example, good proxy prototypicality.One clear examples phenomenon found heffen ‘levy/lift,’ whose typical objects also characteristic two main senses (see Figure 9.3). one hand, ‘levy’ sense occurs mostly belasting ‘tax,’ tol ‘toll’[^Typical Netherlandic sources, since tolls levied Flanders.], accijns ‘excise,’ shown (15) (17). frequencies large enough form three distinct clusters, tend merge following levels HDBSCAN hierarchy, , closer clusters sense. hand, ‘lift’ sense occurs glas ‘glass,’ final expression een glas(je) heffen op takes metonymical meaning ‘give toast ’ (see (18)), body-parts hand, arm vinger ‘finger,’ might take metonymical meanings. latter group really belong “collocation” category “semantic preference” (see Section 9.5).Op het inkomen boven die drie miljoen gulden wil De Waal honderd procent belasting heffen .  De opbrengst gaat naar de allerarmsten .  Ah , een (Het Parool, 2001-05-02, Art. 99)Op het inkomen boven die drie miljoen gulden wil De Waal honderd procent belasting heffen .  De opbrengst gaat naar de allerarmsten .  Ah , een (Het Parool, 2001-05-02, Art. 99)Mobiliteitsproblemen , rekeningrijden , op een andere manier het gebruik van de weg belasten , kilometers tellen , tol heffen - de mogelijkheden om de ingebouwde chip te benutten zijn vrijwel onbeperkt .  (NRC Handelsblad, 1999-10-02, Art. 31)Mobiliteitsproblemen , rekeningrijden , op een andere manier het gebruik van de weg belasten , kilometers tellen , tol heffen - de mogelijkheden om de ingebouwde chip te benutten zijn vrijwel onbeperkt .  (NRC Handelsblad, 1999-10-02, Art. 31)De accijnsheffingen tussen de verschillende landen variëren zeer sterk ten opzichte van elkaar , waardoor er aan weerszijden van het door Bolkestein voorgestelde minimum een discrepantie komt : landen als Groot-Brittannië ( waar de accijnzen op 742 euro per 1.000 liter liggen ) , Italië en Duitsland ( die beide accijnzen boven de 400 euro heffen ) komt de harmonisering ten goede van de transportsector , terwijl andere landen ( zoals Spanje , Ierland , Oostenrijk , Finland en België , waar de accijnzen rond de 300 euro schommelen ) de overheid een voordeel heeft . (NA, 2002-07-25, Art. 104)De accijnsheffingen tussen de verschillende landen variëren zeer sterk ten opzichte van elkaar , waardoor er aan weerszijden van het door Bolkestein voorgestelde minimum een discrepantie komt : landen als Groot-Brittannië ( waar de accijnzen op 742 euro per 1.000 liter liggen ) , Italië en Duitsland ( die beide accijnzen boven de 400 euro heffen ) komt de harmonisering ten goede van de transportsector , terwijl andere landen ( zoals Spanje , Ierland , Oostenrijk , Finland en België , waar de accijnzen rond de 300 euro schommelen ) de overheid een voordeel heeft . (NA, 2002-07-25, Art. 104)met het vertrouwde pintje .  Nog twaalf andere deelnemers konden maandagavond het glas heffen op de hoogste winst .  De dertien deelnemers die 5-9-15-23-29-32 hadden aangekruist , (NA, 2004-10-20, Art. 150)met het vertrouwde pintje .  Nog twaalf andere deelnemers konden maandagavond het glas heffen op de hoogste winst .  De dertien deelnemers die 5-9-15-23-29-32 hadden aangekruist , (NA, 2004-10-20, Art. 150)can see Figure 9.3, model successful separating two senses, clusters semantically homogeneous: relevant collocates heffen ‘levy/lift’ distinctive one senses. Crucially, single cluster even close covering full sense; instead, represents prototypical pattern stands due frequency, internal coherence distinctiveness.\nseems reasonable map clusters prototypical patterns frequency distinctiveness, careful apply results modelling kind semantic analysis. perspective prototype theory, feature category central frequent, .e. shared members, member central exhibits defining features categories. , within ‘levy’ sense, belasting heffen ‘levy taxes’ pattern central, tokens instantiating pattern central. contrast, HDBSCAN prioritises dense areas, , groups tokens similar . Thus, membership probabilities, might tempted use proxy centrality, indicate internal consistency, lack variation. perspective, given belasting heffen ‘levy taxes’ frequent applies wider variety contexts two patterns ‘levy,’ area less dense, tokens lower membership probabilities within compound ‘levy’ clusters.words, models can offer us typical patterns lemma senses tell us distinctive much internal variation present. Beyond information, don’t map straightforward manner understanding prototypicality.\nFigure 9.3: Cloud heffen: heffen.BOWbound10all.PPMIweight.LENGTHFOC.SOCPOSnav.\nmust noted clusters defined collocations may just characterized one single context word, multiple partially co-occurring context words. clear example hachelijk ‘dangerous’ (Figure 9.4), senses characterized prototypical contexts, exemplified (19) (24): onderneming ‘undertaking,’ zaak ‘business’ avontuur ‘adventure’ ‘potentially dangerous’ sense, moment, situatie ‘situation,’ positie ‘position’ ‘critical’ sense.\nsix frequent context words paradigmatic alternatives , taking slot modified noun, entity characterized dangerous critical. However, unlike type-level near neighbour situatie ‘situation,’ positie ‘position’ may also co-occur bevrijd ‘free’ (uit ‘’) , additionally, brandweer ‘firefighter,’ typically Belgian contexts. frequency co-occurrences sample, next type-level dissimilarity three lexical items, splits co-occurrences positie ‘position’ three clusters (light blue, green red Figure 9.4), based combinations.Het geen gewaagde stelling dat de deelname van de LPF aan de regering een hachelijke onderneming blijft .  De situatie waarin de LPF terechtgekomen , het (Volkskrant, 2002-08-05, Art. 46)Het geen gewaagde stelling dat de deelname van de LPF aan de regering een hachelijke onderneming blijft .  De situatie waarin de LPF terechtgekomen , het (Volkskrant, 2002-08-05, Art. 46)Daar baseerden de media zich op slechts één bron , en elke journalist weet dat dat een hachelijke zaak . ’  Jacques Wallage , burgemeester van Groningen : ’ Vroeger (Volkskrant, 2004-05-05, Art. 42)Daar baseerden de media zich op slechts één bron , en elke journalist weet dat dat een hachelijke zaak . ’  Jacques Wallage , burgemeester van Groningen : ’ Vroeger (Volkskrant, 2004-05-05, Art. 42)Het stadsautootje voelt zich beter thuis op het gladde asfaltlint van de snelweg en zolang er geen fikse zijwind staat - want hij daar door z’n relatief hoge bouw én achterwielaandrijving erg gevoelig voor , met storm opzij het inhalen van een vrachtwagen een hachelijk avontuur - kan je daar heel relaxed grote afstanden mee afleggen .  Je (Het Parool, 2000-03-17, Art. 34)Het stadsautootje voelt zich beter thuis op het gladde asfaltlint van de snelweg en zolang er geen fikse zijwind staat - want hij daar door z’n relatief hoge bouw én achterwielaandrijving erg gevoelig voor , met storm opzij het inhalen van een vrachtwagen een hachelijk avontuur - kan je daar heel relaxed grote afstanden mee afleggen .  Je (Het Parool, 2000-03-17, Art. 34)de reguliere competitie viel er toch iets te beleven . Kortrijk beleefde enkele hachelijke momenten tegen Brussels , dat zijn ondiep bad bewees zijn vierde plaats de play-offs waard te zijn . (NA, 2001-05-14, Art. 375)de reguliere competitie viel er toch iets te beleven . Kortrijk beleefde enkele hachelijke momenten tegen Brussels , dat zijn ondiep bad bewees zijn vierde plaats de play-offs waard te zijn . (NA, 2001-05-14, Art. 375)als interne Palestijnse factoren .  Kort maar krachtig staat er : \" De hachelijke situatie van Palestina vooral een interne aangelegenheid , hoewel de bezetting en de confrontatie met Israël er de context voor schept . (NA, 2004-10-02, Art. 162)als interne Palestijnse factoren .  Kort maar krachtig staat er : \" De hachelijke situatie van Palestina vooral een interne aangelegenheid , hoewel de bezetting en de confrontatie met Israël er de context voor schept . (NA, 2004-10-02, Art. 162)Nederlandse Wendelien van Oldenborgh .  Zij toont knappe filmpjes , opgenomen vanuit de hachelijke positie van een deltavlieger , ze doorkruist de ruimte met een betreedbare loopbrug om ten slotte met haar ’ pin drawings ’ een wervelend veld van spelden te prikken op een piepschuimen plattegrond van de exporuimte de centrale bib . (NA, 1999-06-07, Art. 126)Nederlandse Wendelien van Oldenborgh .  Zij toont knappe filmpjes , opgenomen vanuit de hachelijke positie van een deltavlieger , ze doorkruist de ruimte met een betreedbare loopbrug om ten slotte met haar ’ pin drawings ’ een wervelend veld van spelden te prikken op een piepschuimen plattegrond van de exporuimte de centrale bib . (NA, 1999-06-07, Art. 126)hard argue relative centrality three positie clusters. result combination three features, cluster exhibits different degree membership based many overlapping features co-occurs . time, distinctive regional distribution. Based data, might said prototypical context hachelijke posities ‘dangerous/critical positions’ Flanders situation firefighters free someone/something , core present, least nearly relevant, Netherlandic data. might also say situation typical hachelijke situaties ‘dangerous/critical situations,’ therefore presents (local) distributional difference two types otherwise, corpus level, near neighbours.\nFigure 9.4: Cloud hachelijk: hachelijk.BOWbound5all.PPMIweight.LENGTHFOC.SOCPOSall.\n","code":""},{"path":"nonsense-or-no-senses.html","id":"profiling","chapter":"9 Nonsense or no senses?","heading":"9.3.4 Profiling","text":"Clusters dominated context word may represent typical context within sense, also one highlights different dimension sense clusters. extremely frequent requires extra layer interpretation, additional explanation clustering solutions.One example given ‘substance’ meaning stof.\nWithin sense, tend find clusters dominated gevaarlijk ‘dangerous,’ schadelijk ‘harmful’ (also attracts kankerwekkend ‘carcinogenic’) giftig ‘poisonous’ (often attracts chemisch ‘chemical’). dominant context words nearest neighbours type-level, clusters govern belong branch HDBSCAN hierarchy.However, can find additional information, among context words co-occur , suggests frequency responsible separated clusters. Concretely, tokens cluster dominated schadelijk ‘harmful’ tend focus environment composition substances, indicated co-occurrence uitstoot ‘emissions,’ lucht ‘air,’ stank ‘stench’ bevat ‘contain’; meanwhile, cluster dominated giftig ‘poisonous’ focus context drugs profile liberation substances, context words vorm ‘form,’ kom_vrij ‘released’ drugsbebruik ‘drug use.’\neffect less frequent context words one consequences less restrictive models: levels analysis, one word (gevaarlijk ‘dangerous,’ schadelijk ‘harmful’…) might enough disambiguate target, extra information enriches understanding words actually used. also contextualized information: just stof ‘substance’ used means, used (means) combination certain frequent collocates.","code":""},{"path":"nonsense-or-no-senses.html","id":"colligation","chapter":"9 Nonsense or no senses?","heading":"9.4 Lexically instantiated colligation","text":"Even without relying part--speech tags dependency relationships features models, can obtain grammatical information lexical collocates. example, passive auxiliary word indicates passive constructions, well somewhat less frequent preposition door, indicates explicit agent, much like English. constructions might also indicated key function words, om te — roughly — Dutch equivalent -Infinitive clause, dat ‘’ relative clauses, dan ‘’ comparatives, prepositions. patterns emerge clusters lexically instantiated colligation may cross boundaries dictionary senses, resulting heterogeneous clusters, match senses, indicate prototypical configuration within sense. following subsections explore examples different phenomena.","code":""},{"path":"nonsense-or-no-senses.html","id":"heterogeneous-clusters","chapter":"9 Nonsense or no senses?","heading":"9.4.1 Heterogeneous clusters","text":"verb herstructureren ‘restructure’ annotated three sense tags emerging combination specialisation, .e. whether ’s specifically applied companies, argument structure, distinguishing transitive intransitive herstructureren. intransitive sense always specific — companies restructure, undergo process restructure.Models typically successful disentangling three senses, one , matter. Instead, clusters emerge tend highlight either semantic syntactic dimension, disregarding one.lexical items frequently dominate clusters herstructureren ‘restructure’ passive auxiliary word, bedrijf ‘company,’ grondig ‘thorough(ly),’ pair prepositions om te, illustrated (25) (27).OK-score deelt bedrijven op tien klassen ; klasse 1 blaakt van gezondheid , klasse 10 op sterven na dood , ofwel , staat op de rand van faillissement en moet grondig worden geherstructureerd .  OK-score kent een OK-solvabiliteitsratio en een OK-ratio .  Bij de (Het Parool, 2003-04-16, Art. 69)OK-score deelt bedrijven op tien klassen ; klasse 1 blaakt van gezondheid , klasse 10 op sterven na dood , ofwel , staat op de rand van faillissement en moet grondig worden geherstructureerd .  OK-score kent een OK-solvabiliteitsratio en een OK-ratio .  Bij de (Het Parool, 2003-04-16, Art. 69)Schulpe en Dominique Vercraeye via een management buy-de leiding . Ze herstructureerden het bedrijf en loodsten het de internationale groep Taylor Nelson Sofres ( TNS ) binnen . (NA, 2004-01-06, Art. 59)Schulpe en Dominique Vercraeye via een management buy-de leiding . Ze herstructureerden het bedrijf en loodsten het de internationale groep Taylor Nelson Sofres ( TNS ) binnen . (NA, 2004-01-06, Art. 59)Uiteindelijk dat de regering , want toen de crisis uitbrak nam de overheid een belang de banken om ze te herstructureren en uiteindelijk weer te verkopen .  \" Deze regering wàs het begin (NRC Handelsblad, 2000-11-07, Art. 11)Uiteindelijk dat de regering , want toen de crisis uitbrak nam de overheid een belang de banken om ze te herstructureren en uiteindelijk weer te verkopen .  \" Deze regering wàs het begin (NRC Handelsblad, 2000-11-07, Art. 11)two nouns never co-occur, occasionally co-occur word om te construction, co-occur times. grondig ‘thorough(ly)’ bedrijf ‘company’ good cues company-specific senses, may occur either transitive intransitive constructions. contrast, word good cue transitive (specifically, passive) constructions, may occur either company-specific general sense. Finally, om te may attested either three senses. stark separation clusters Figure 9.5 seem suggest opposite poles, case semantic level. fact, unlike Figures 9.3 9.4, example, clusters merely slightly denser areas rather uniform, noise mass tokens, much harder naked human eye capture without HDBSCAN input. Instead, cluster indicates us poles contextual behaviour may code semantic dimension, case bedrijf ‘company’ cluster, syntactic one, lexically instantiated colligation clusters.\nFigure 9.5: Cloud herstructureren: herstructureren.BOWbound3all.PPMIselection.LENGTHFOC.SOCPOSall.\n","code":""},{"path":"nonsense-or-no-senses.html","id":"dictionary-clouds-1","chapter":"9 Nonsense or no senses?","heading":"9.4.2 Dictionary clouds","text":"rare thing, might able find cluster dominated grammatical pattern matches dictionary sense. One clear case reflexive sense herhalen ‘repeat,’ characterized co-occurrence zich ‘,’ FOC-POS:| LEMMAREL models, especially PPMI:weight6. model shown Figure 9.6, clearest cluster, isolated group red squares. Looking closely, can see made two halves: small one left, tokens also co-occur geschiedenis, bigger one right, . particular model restrictive: normally captures one two context words per token, need capture particular sense.\nFigure 9.6: Cloud herhalen: herhalen.LEMMAREL1.PPMIselection.LENGTHFOC.SOCPOSall.\nexpected result lemmas purely reflexive senses well, easy achieve. case diskwalificeren ‘disqualify,’ contrast, infrequent reflexive sense typically (always) absorbed within transitive sense matches semantically, .e. non sports-related sense.\nAlternatively, lexically instantiated colligation may prefer certain sense without exhausting attestations: case, represents prototypical context, shown following section.","code":""},{"path":"nonsense-or-no-senses.html","id":"prototypical-context-1","chapter":"9 Nonsense or no senses?","heading":"9.4.3 (Proto)typical context","text":"verb herinneren two main senses defined well defined constructions: either intransitive construction co-occurring preposition aan, meaning ‘remind,’ reflexive construction meaning ‘remember’; third, transitive sense also attested infrequently.\npractice, sometimes rendered three equally sized clouds, shown Figure 9.7: orange cluster characterized preposition aan (see (28)), green one subject reflexive first person pronouns ik (see (29)), yellow one third person reflexive pronoun zich (see (30)). smaller group tokens co-occurring eraan, compound particle er aan (see example (28)), may form clusters, like light blue one Figure 9.7, absorbed one larger ones.benaderde tijdens de verkiezingscampagne , werd hij beticht van stigmatisering . \"  Vinocur herinnert aan een tekening van Plantu L’Express .  Een vrouw wordt van haar (Het Parool, 2002-05-18, Art. 101)benaderde tijdens de verkiezingscampagne , werd hij beticht van stigmatisering . \"  Vinocur herinnert aan een tekening van Plantu L’Express .  Een vrouw wordt van haar (Het Parool, 2002-05-18, Art. 101): ondermaatse vertolkingen doen hem pijn en maken hem woedend .  ( Ik herinner een concert waarop hij hevig gesticulerend applaus ontvangst kwam nemen .  (Het Parool, 2003-11-14, Art. 79): ondermaatse vertolkingen doen hem pijn en maken hem woedend .  ( Ik herinner een concert waarop hij hevig gesticulerend applaus ontvangst kwam nemen .  (Het Parool, 2003-11-14, Art. 79)het Oostenrijkse Klagenfurt .  \" Het die dag bloedheet \" , herinnert de atlete uit Sint-Andries zich nog levendig .  \" Maar van extreme temperaturen (NA, 2001-08-08, Art. 192)het Oostenrijkse Klagenfurt .  \" Het die dag bloedheet \" , herinnert de atlete uit Sint-Andries zich nog levendig .  \" Maar van extreme temperaturen (NA, 2001-08-08, Art. 192)zoals waterverf , acrylaatverf , Oost-Indische inkt en olieverf .  zijn voorwoord herinnert Manara eraan dat deze meisjes hun tijd vaak met toegeknepen oogjes werden aanschouwd . (NA, 2001-11-10, Art. 40)zoals waterverf , acrylaatverf , Oost-Indische inkt en olieverf .  zijn voorwoord herinnert Manara eraan dat deze meisjes hun tijd vaak met toegeknepen oogjes werden aanschouwd . (NA, 2001-11-10, Art. 40)shape coding plot indicates, clusters semantically homogeneous7, function words perfect cues senses. rest co-occurring context words make difference: strong enough, face pronouns prepositions, originate salient structure. Nonetheless, aan eraan clusters one side, pronoun-based clusters , belong sense. Thus, lexically instantiated colligation clusters represent typical salient pattern within sense.\nFigure 9.7: Cloud herinneren: herinneren.BOWbound10all.PPMIweight.LENGTH5000.SOCPOSnav.\n","code":""},{"path":"nonsense-or-no-senses.html","id":"profiling-1","chapter":"9 Nonsense or no senses?","heading":"9.4.4 Profiling","text":"Like clusters defined collocations, clusters defined lexically instantiated colligations can also represent typical context highlights specific dimension sense target. One case found ‘horde’ sense horde, whose salient collocates corpus toerist ‘tourist’ journalist. two collocates quite similar type-level, rest context words clusters point towards different dimension ‘horde’ sense: hordes journalists, photographers fans (nouns present cluster) surround follow celebrities, suggested co-occurrence omring ‘surround,’ wacht_op ‘wait’ achtervolg ‘chase,’ among others. contrast, hordes tourists instead flood move around city, words stroom_toe ‘flood’ stad ‘city.’stands, situation equivalent case stof ‘substance’ described . However, models capture function words like one shown Figure 9.8, profiling clusters strengthened lexically instantiated colligations. journalist cluster dominated preposition door, signals explicit agents passive constructions, indicated orange cluster; passive auxiliary word also occurs, albeit less frequently. Meanwhile, toerist ‘tourist’ cluster includes tokens co-occurring naar ‘towards.’ prepositions coherent dimensions ‘horde’ highlighted clusters. Crucially, don’t co-occur tokens also co-occur journalist toerist ‘tourist’ respectively, nouns prepositions complement instead.\nFigure 9.8: Cloud horde: horde.BOWbound5all.PPMIselection.LENGTHFOC.SOCPOSall.\n","code":""},{"path":"nonsense-or-no-senses.html","id":"semantic-preference","chapter":"9 Nonsense or no senses?","heading":"9.5 Semantic preference","text":"Clusters clearly dominated one context word group co-occurring context words, lexical collocations lexically instantiated colligations, may still result coherent distributional semantic patterns. Representing first-order context words type-level vectors allows infrequent near neighbours join forces approximate effect one context word cumulative frequency. context words may occur one four times sample, , one every hundred occurrences target, together similar context words, form visible pattern.","code":""},{"path":"nonsense-or-no-senses.html","id":"heterogeneous-clusters-1","chapter":"9 Nonsense or no senses?","heading":"9.5.1 Heterogeneous clusters","text":"Just like can clusters dominated one context word characteristic one sense, can clusters dominated multiple similar context words characteristic sense. case names colours clothing terms8 co-occurring grijs ‘gray,’ model like one show Figure 9.9 also includes haar ‘hair.’\nresult, grijs ‘gray’ tokens referring concrete grey objects general , specifically, grey/white hair, form light blue cluster top right figure. Note , visually, two senses occupy opposite halves cluster: haar ‘hair’ tokens occupy space, type-level similarity context word names colours clothing terms makes indistinguishable HDBSCAN.\nFigure 9.9: Cloud grijs: grijs.BOWbound5all.PPMIno.LENGTHFOC.SOCPOSall.\nsecond example set juridical terms herroepen, means ‘retract’ object statement opinion, ‘annul’ law decision. newspaper corpus, often used broad legal juridical context. However, one frequent collocates herroepen within field uitspraak, can either mean ‘verdict,’ therefore invoking ‘annul’ sense, ‘statement,’ ‘retract’ applies (see (32) (33)). Unfortunately, broader context clear enough models disambiguate appropriate meaning uitspraak herroepen instance. type-level, uitspraak close number context words juridical field, namely rechtbank ‘court,’ vonnis ‘sentence,’ veroordeling ‘conviction,’ etc. Together, constitute semantic preference light blue cluster Figure 9.10, , similar grijs haar ‘gray/white hair’ situation , visually split tokens co-occurring uitspraak co-occurring rest juridical terms.2002-05-04mr , lcp KV Mechelen krijgt licentie  BRUSSEL - Het beroepscomité herriep gisteren de uitspraak van de licentiecommissie en besliste om KV Mechelen toch zijn licentie te geven . (NA, 2002-05-04, Art. 95)2002-05-04mr , lcp KV Mechelen krijgt licentie  BRUSSEL - Het beroepscomité herriep gisteren de uitspraak van de licentiecommissie en besliste om KV Mechelen toch zijn licentie te geven . (NA, 2002-05-04, Art. 95)Onder druk van Commissievoorzitter Prodi heeft Nielson verklaard dat hij verkeerd geïnterpreteerd , maar hij heeft zijn uitspraak niet herroepen .  Hij vanavond uitgenodigd door de fractievoorzitters van het Europees Parlement om (NRC Handelsblad, 2001-10-04, Art. 79)Onder druk van Commissievoorzitter Prodi heeft Nielson verklaard dat hij verkeerd geïnterpreteerd , maar hij heeft zijn uitspraak niet herroepen .  Hij vanavond uitgenodigd door de fractievoorzitters van het Europees Parlement om (NRC Handelsblad, 2001-10-04, Art. 79)result understandable interpretable: context words co-occurring tokens light blue cluster belong semantically coherent set distributional near neighbours. problem , sample, sense uitspraak occurs juridical one like (32) ‘statement’ like (33), therefore representing different sense herroepen juridical siblings. models, two groups split different clusters, like one shown Figure 9.10, generate heterogeneous cluster generated semantic preference.Interestingly, verklaring ‘statement’ bekentenis ‘confession’ considered part semantic field well, broad terms. However, belong different frame within field legal action — different stage process —, , correspondingly, type-level vectors different tend represent distinct, homogeneous clusters (green figure).\nFigure 9.10: Cloud herroepen: herroepen.BOWbound3all.PPMIselection.LENGTHFOC.SOCPOSall.\n","code":""},{"path":"nonsense-or-no-senses.html","id":"dictionary-clusters","chapter":"9 Nonsense or no senses?","heading":"9.5.2 Dictionary clusters","text":"senses can completely clustered groups similar context words.\nOne cases already discussed context schaal ‘scale’ tokens: models exclude Richter part--speech tag name, tokens co-occurring can alternatively grouped kracht ‘power,’ aardbeving ‘earthquake’ related context words. case Richter dominating collocate, semantic field earthquakes part definition ‘range’ sense schaal, dominating semantic pattern within corpus study.Another example found haken, ‘make someone trip’ sense characterized variety football-related terms (strafschop ‘penalty kick,’ penalty, scheidsrechter ‘referee,’ etc.), infrequent ‘crochet’ sense, brei ‘knit,’ naai ‘sew,’ hobby similar words. represented dark blue squares light blue crossed squares Figure 9.11 respectively. indicated name dark blue cluster, passive auxiliary word also characteristic ‘make someone trip’ cluster rarely occurs outside : lexically instantiated colligation working together clear semantic preference cloud.\nFigure 9.11: Cloud haken: herroepen.BOWbound3all.PPMIselection.LENGTHFOC.SOCPOSall.\n","code":""},{"path":"nonsense-or-no-senses.html","id":"prototypical-context-2","chapter":"9 Nonsense or no senses?","heading":"9.5.3 (Proto)typical context","text":"several examples clusters defined semantically similar infrequent context words representing typical contexts sense. Figure 9.9, example, dark blue cluster represented cars, mostly indicated Mercedes Opel, next brands. case lemmas like dof ‘dull,’ models might dedicate different clusters specific collocates, klink ‘sound,’ knal ‘bang,’ klap ‘clap,’ dreun ‘pounding,’ others group together one large cluster defined semantic preference indicative sense, e.g. sounds.typical semantic group attested different lemmas culinary: found schaal ‘dish’ heet ‘hot,’ red cluster Figure 9.12. case heet ‘hot,’ almost tokens co-occurring cluster refer literally hot foods drinks, although full expression might idiomatic, like (34), belong much less frequent sense ‘spicy.’ models, tokens co-occurring soep ‘soup’ /co-occurring water tokens might form separate clusters.Hoogstwaarschijnlijk zal Poetin Ruslands afgeknapte westerse partners discreet laten weten dat zodra hij eenmaal het Kremlin zit , de soep minder heet gegeten zal worden .  Dat echter een zeer schrale troost .  (Volkskrant, 1999-12-21, Art. 22)addition, aardappel ‘potato’ type-level near neighbour context words semantic group, still tends form cluster, due frequency distinctiveness larger cotext (e.g. co-occurrence schuif_door ‘pass ’). Like expressions annotated ‘hot touch’ sense (circles figure), including hete hangijzer ‘hot irons’ yellow hete adem (de nek) ‘hot breath (neck)’ light blue, hete aardappel ‘hot potato’ used metaphorically. strict combination adjective noun, meaning heet proper still ‘hot touch’: combination metaphorised (see Geeraerts 2006: 198–220 discussion).\n\ncontext words frequent distinctive enough generate clusters tokens co-occur , aardappel ‘potato’ tends stick close culinary cluster even merge .\nFigure 9.12: Cloud heet: heet.BOWbound5all.PPMIno.LENGTHFOC.SOCPOSall.\n","code":""},{"path":"nonsense-or-no-senses.html","id":"profiling-2","chapter":"9 Nonsense or no senses?","heading":"9.5.4 Profiling","text":"adjective geldig ‘valid’ can relate legal regulated acceptability, frequent sense sample, may broader application, entities like redenering ‘reasoning.’ definition, like lemmas studied , sense matches form semantic preference. addition, models lemma reveal semantic preference patterns within frequent, specific sense, , turns, highlights different dimension sense. patterns may identified areas t-SNE plots , models like one shown Figure 9.13, clusters.green cluster characterized context words rijbewijs ‘driving license,’ paspoort ‘passport’ forms identification, well verbs like leg_voor ‘present,’ heb ‘’ bezit ‘possess.’ words, represents contexts someone demonstrate possession valid identification document, shown (35). light blue yellow clusters, hand, co-occur kinds documents (ticket, abonnement ‘subscription’), euro, preposition tot ‘,’ times (maand ‘month,’ jaar ‘year,’ numbers, etc.). case, price documents duration validity salient, illustrated (36).naar Groot-Brittannië te smokkelen .  Aan de incheckbalie kon de Somaliër echter geen geldige papieren voorleggen .  Hij en de Ethiopiër werden opgepakt .  De (NA, 2001-08-24, Art. 64)naar Groot-Brittannië te smokkelen .  Aan de incheckbalie kon de Somaliër echter geen geldige papieren voorleggen .  Hij en de Ethiopiër werden opgepakt .  De (NA, 2001-08-24, Art. 64)Klanten van Kunst Huis zijn bovendien zeker van variatie : wie lid , kan elke maand een ander werk uitkiezen , het abonnement blijft een leven lang geldig en de maandelijkse huurprijs van 250 frank ook niet bepaald hoog te noemen . (NA, 1999-05-29, Art. 41)Klanten van Kunst Huis zijn bovendien zeker van variatie : wie lid , kan elke maand een ander werk uitkiezen , het abonnement blijft een leven lang geldig en de maandelijkse huurprijs van 250 frank ook niet bepaald hoog te noemen . (NA, 1999-05-29, Art. 41)\nFigure 9.13: Cloud geldig: geldig.BOWbound10lex.PPMIselection.LENGTHFOC.SOCPOSall.\n","code":""},{"path":"nonsense-or-no-senses.html","id":"openchoice","chapter":"9 Nonsense or no senses?","heading":"9.6 Near-open choice","text":"Cirrus clouds, well Cumulonimbus, really grouped one dominant context word set similar words. clear brings tokens together. Naturally, mostly leads heterogeneous clouds, occasionally might find homogeneous ones among . principle behind category much clusters bad, lemmas seem follow open-choice principle: wider variety options, powerful collocates barely group couple tokens. definition aren’t patterns, represent prototypical contexts sense, clusters happen quite homogeneous.","code":""},{"path":"nonsense-or-no-senses.html","id":"heterogeneous","chapter":"9 Nonsense or no senses?","heading":"9.6.1 Heterogeneous","text":"common situation clusters explained dominant context word semantic preference, especially Cumulonimbus, semantically heterogeneous. One example Cumulonimbus (large cloud) helpen Figure 9.14, formed opposition smaller Stratocumulus, also heterogeneous cloud formed semantic preference kinship terms.\nFigure 9.14: Cloud helpen.\n","code":""},{"path":"nonsense-or-no-senses.html","id":"one-sense","chapter":"9 Nonsense or no senses?","heading":"9.6.2 One sense","text":"Cumulonimbus clouds sort bag ‘rest’ powerful context words defined takes make cluster. Typically, heterogeneous. However, case huldigen, ‘hold (opinion)’ sense strong patterns ‘pay homage’ sense covers rest tokens. Figure 9.15 can see, next small Cumulus Stratocumulus characterized principe, standpunt opvatting (typical ‘hold (opinion)’ sense), large Cumulonimbus. dense core (hail) made tokens co-occur worden larger, diffuse area characterized different combinations worden, sports-related terms (kampioen, winnaar, sportsraad) well town administration terms (stadsbestuur, gemeentebestuur…). form one semantic field, instead come different areas co-occur context ‘pay homage’: ceremonies organized sports city organizations public places, honour successful athletes.\nFigure 9.15: Cloud huldigen.\n","code":""},{"path":"nonsense-or-no-senses.html","id":"part-of-a-sense","chapter":"9 Nonsense or no senses?","heading":"9.6.3 Part of a sense","text":"models tend diffuse clusters, might cluster holds together unclear reasons yet represents part sense fairly well. certainly frequent co-occurrence, might indicate sense-related organization space, however strong enough stand defined cluster.data, find “best” medoid hoop, ‘heap’ tokens, united een, form rather diffuse island, slightly separated ‘hope’ tokens (Figure 9.16). spite visually clear separation made t-SNE, HDBSCAN manages capture patches form weak clusters. One cluster captures ‘heap’ tokens clustered, number lost noise. , een perfect recall cluster low precision; meanwhile, rest context words involved form pattern .\nFigure 9.16: Cloud hoop.\n","code":""},{"path":"nonsense-or-no-senses.html","id":"summary","chapter":"9 Nonsense or no senses?","heading":"9.7 Summary","text":"","code":""},{"path":"no-sky-fits-all.html","id":"no-sky-fits-all","chapter":"10 No sky fits all","heading":"10 No sky fits all","text":"","code":""},{"path":"cloudspotters-guide.html","id":"cloudspotters-guide","chapter":"11 Cloudspotter’s guide","heading":"11 Cloudspotter’s guide","text":"[General tips ]","code":""},{"path":"avenues-for-further-research.html","id":"avenues-for-further-research","chapter":"12 Avenues for further research","heading":"12 Avenues for further research","text":"","code":""},{"path":"conclusion.html","id":"conclusion","chapter":"13 Conclusion","heading":"13 Conclusion","text":"","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""},{"path":"definitions.html","id":"definitions","chapter":"A Definitions","heading":"A Definitions","text":"","code":""},{"path":"definitions.html","id":"hoopvol","chapter":"A Definitions","heading":"hoopvol","text":"senseDutchEnglishhoopvol_1(van personen, uitingen, gedragingen etc.) blijk gevend van hoop, vol hoop, optimistisch: een hoopvolle stemming, dat stemt mij hoopvol(people, expressions, behaviors, etc.) giving impression hope, full hope, optimistic: hopeful mood, brings hope (makes hopeful)hoopvol_2reden tot hoop gevend, beloftevol: hoopvolle perspectievengiving reason hope, promising: hopeful perspectives","code":""},{"path":"definitions.html","id":"geestig","chapter":"A Definitions","heading":"geestig","text":"senseDutchEnglishgeestig_1scherpzinnig en humoristisch van aard: een geestige collegaof witty humoristic nature: witty colleaguegeestig_2blijk gevend van, uitdrukking gevend aan, gekenmerkt door scherpzinnigheid en humor: een geestig boek, een geestige blik, een geestige opmerkinggiving impression , expressing, characterized wittiness humor: witty book, witty look, witty remarkgeestig_3: perceived funny (witty?): find funny","code":""},{"path":"definitions.html","id":"hachelijk","chapter":"A Definitions","heading":"hachelijk","text":"senseDutchEnglishhachelijk_1met kans op een ongunstige afloop, (potentieel) gevaarlijk: een hachelijke ondernemingwith chances unfavorable outcome, (potentially) dangerous: dangerous enterprisehachelijk_2(reëel) gevaarlijk, netelig, kritiek, benard: een hachelijke situatie(really) dangerous, trick, critical, dire: dangerous situation","code":""},{"path":"definitions.html","id":"hoekig","chapter":"A Definitions","heading":"hoekig","text":"senseDutchEnglishhoekig_1(van voorwerpen, figuren e.d.) met hoeken scherpe kanten: een hoekige tekening, een hoekig gezicht(objects, figures, etc.) angles sharp edges: angulous drawing, angulous facehoekig_2(van bewegingen, ritmes e.d.) niet vloeiend: een hoekig melodietje(movements, rhythms, etc.) fluent: broken melodyhoekig_3(van personen) houterig, stijf, onhandig de omgang: een hoekig karakter(people) rigid, stiff, clumsy: clumsy character","code":""},{"path":"definitions.html","id":"dof","chapter":"A Definitions","heading":"dof","text":"senseDutchEnglishdof_1(van kleuren en zichtbare dingen) mat, zonder glans, vaal: een doffe blik(colours visible things) matte, without shine, pale: dull gazedof_2(van geluiden) niet luid scherp, onderdrukt, gesmoord: een doffe kreet(sounds) loud sharp, suppressed, smothered: dull crydof_3(van personen, gevoelens e.d.) niet opgewekt, lusteloos, zonder energie: doffe onverschilligheid, doffe ellende(people, feelings, etc.) cheerful, apathetic, without energy: dull apathy, dull miserydof_4(van denkbeelden e.d.) niet scherp voor de geest staand: een doffe herinnering(ideas ) sharp mind: dull memory","code":""},{"path":"definitions.html","id":"heilzaam","chapter":"A Definitions","heading":"heilzaam","text":"senseDutchEnglishheilzaam_1(letterlijk) bijdragend tot gezondheid en lichamelijk welzijn: een heilzaam dieet(literal) brings health physical wellbeing: healthy dietheilzaam_2(figuurlijk) nuttig, een gunstig effect hebbend: een heilzaam besluit(figurative) necessary, beneficial effect: beneficial decision","code":""},{"path":"definitions.html","id":"gekleurd","chapter":"A Definitions","heading":"gekleurd","text":"senseDutchEnglishgekleurd_1met kleur, letterlijke zin (het bijzonder, niet zwart, wit grijs): gekleurde wangenwith color, literal sense (particular, black, white gray): colored cheeksgekleurd_2(van personen e..) niet blank: de gekleurde medemens, van gekleurde afkomst zijn(people related) white: fellow colored man, colored origingekleurd_3(van uitspraken, opvattingen e.d.) niet neutraal, tendentieus: een gekleurde voorstelling van zaken(expressions, concepts) neutral, tendentious: colored representation things","code":""},{"path":"definitions.html","id":"geldig","chapter":"A Definitions","heading":"geldig","text":"senseDutchEnglishgeldig_1van kracht, van toepassing, van waarde zijnde volgens wettelijke andere regels: een geldig vervoerbewijs, betaalmiddel, juridisch bewijsvalid, acceptable, value according legal rules: valid driving license, currency, legal evidencegeldig_2van kracht, van toepassing, van waarde ruimere zin: een geldige redeneringvalid, acceptable, value general sense: valid reasoning","code":""},{"path":"definitions.html","id":"hemels","chapter":"A Definitions","heading":"hemels","text":"senseDutchEnglishhemels_1betrekking hebbend op de hemel: de hemelse Vader, de hemelse boodschaprelated heaven: de heavenly Father, heavenly messagehemels_2verrukkelijk, heerlijk, zalig, goddelijk: een hemelse verschijning, een hemelse stemdelightful, lovely, blissful, divine: heavenly appearance, heavenly voice","code":""},{"path":"definitions.html","id":"goedkoop","chapter":"A Definitions","heading":"goedkoop","text":"senseDutchEnglishgoedkoop_1laag prijs, betaalbaar, voordelig: goedkope wijnof low price, affordable, advantageous: cheap winegoedkoop_2geen hoge prijzen vragend: een goedkoop winkeltje, een goedkope loodgieternot asking high price: cheap shop, cheap plumbergoedkoop_3waar de prijzen laag zijn: een goedkope buurtwhere prices low: cheap neighborhoodgoedkoop_4van weinig waarde, makkelijk verkregen, oppervlakkig, banaal: goedkope lof, goedkoop succes, goedkope argumentenwith little value, received easily, superficial, banal: cheap praise, cheap success, cheap arguments","code":""},{"path":"definitions.html","id":"heet","chapter":"A Definitions","heading":"heet","text":"senseDutchEnglishheet_1(van dingen) zeer warm: een gloeiend hete kachel(things) warm: hot stoveheet_2(van het lichaam) warm aanvoelend, een hogere temperatuur dan normaal hebbend: hete wangen, het heet hebben(body) feeling warm, higher temperature normal: hot cheeks, feel hotheet_3(van het weer) zeer warm: hete dagen, hete zomer(weather) warm: hot days, hot summerheet_4(van voedsel) pikant: hete sauzen(food) spicy: hot sauceheet_5(van personen) sexueel hartstochtelijk, geil: een hete bok(people) sexually attractive, horny: hot buckheet_6(van gebeurtenissen, periodes e.d.) gekenmerkt door heftige strijd: het ging er heet aan toe, een hete herfst(events, periods, etc.) characterized fierce conflict: getting hot, hot autumnheet_7: popular, interesting/new, recent: ","code":""},{"path":"definitions.html","id":"grijs","chapter":"A Definitions","heading":"grijs","text":"senseDutchEnglishgrijs_1met een kleur die ligt tussen wit en zwart; vaalwit, grauw: grijs van het stof, de grijze dolfijnwith color white black, pale white: gray dust, gray dolphingrijs_2(van periodes e.d.) zonder veel zonneschijn, bewolkt, betrokken: een grijze dag(periods ) without much sunlight, cloudy, covered: gray daygrijs_3(van haar) zijn kleur verloren hebbend, m.n. door gevorderde leeftijd: een grijs baardje(hair) lost color, namely old age: gray beardgrijs_4(van personen e..) grijsharig, en vandaar, betrekking hebbend op ouderen: de grijze golf(people related) gray haired, thus, related old people: gray wavegrijs_5saai, kleurloos, vervelend: een grijze buurtboring, colorful, tedious: gray neighborhoodgrijs_6niet helemaal volgens de wet de regels, halflegaal: de grijze economienot exactly following law rules, half legal: gray economy","code":""},{"path":"definitions.html","id":"gemeen","chapter":"A Definitions","heading":"gemeen","text":"senseDutchEnglishgemeen_1gemeenschappelijk gebruik bezit, gedeeld: gemene kosten, een gemene muurcommon property common use, shared: common costs, common wallgemeen_2openbaar, publiek: de gemene zaakpublic: public businessgemeen_3alledaags, gewoon, tot de middelmaat behorend: het gemene volk, de gemene mancommonplace, normal, mediocre: common people, common mangemeen_4boosaardig, kwaadaardig, laaghartig, malicieus: een gemene streekmalicious, evil, mean: mean trickgemeen_5ordinair, plat, onkies, vulgair: gemene praatjesordinary, flat, indecent, vulgar: mean conversationsgemeen_6: cool, awesome, badass?: ","code":""},{"path":"definitions.html","id":"blik","chapter":"A Definitions","heading":"blik","text":"senseDutchEnglishblik_11.1 oogopslag: een blik werpen op iets, een blik van verstandhouding1.1 gaze: throw look something, look understandingblik_21.2 gezichtsvermogen: een scherpe blik1.2 sight: sharp sightblik_31.3 inzicht, intellectuele zin: een brede blik1.3 perspective, intellectual sense: wide viewblik_42.1 dun geplet metaal, .h. bijz. vertind dun plaatstaal: dozen uit blik2.1 thin flattened metal, particular thin tin-plated steel: boxes tinblik_52.2 voorwerp (.h.bijz. doos voor voedsel) vervaardigd uit zulk materiaal: stoffer en blik, een blik erwtjes, een maaltijd uit blik2.2 object (particular food container) made tin: brush dustpan, can peas, canned mealblik_62.3 voedsel bewaard een voorwerp als bedoeld 2.2: eet je niet teveel blik?2.3 food contained object described 2.2: eat much canned food?","code":""},{"path":"definitions.html","id":"hoop","chapter":"A Definitions","heading":"hoop","text":"senseDutchEnglishhoop_11.1 ongeordende stapel: een hoop rommel, gooi maar op de hoop1.1 unordered mass: pile junk, just drop pilehoop_21.2 grote hoeveelheid: een hoop mensen, een hele hoop geld1.2 great quantity: bunch people, lot moneyhoop_32 positieve verwachting, vertrouwen op iets positiefs: hoop koesteren, de hoop uitspreken dat...2 positive expectation, trust something positive: nurture hope, express hope ...","code":""},{"path":"definitions.html","id":"spot","chapter":"A Definitions","heading":"spot","text":"senseDutchEnglishspot_11 oneerbiedige, ridiculiserende uitspraak behandeling: de spot drijven met, bijtende spot1 disrespectful, mocking expression behaviour: mock someone, sarcasmspot_22.1 reclameboodschap via radio, televisie, bioscoop: een spotje voor tandpasta2.1 advertisement via radio, television, cinema: spot toothpastespot_32.2 schijnwerper: de spots richten op2.2 spotlight: direct spotlights onspot_4: 2.3 metaphorical spotlight: likes spotlightheadline: (section magazine?): Spot","code":""},{"path":"definitions.html","id":"staal","chapter":"A Definitions","heading":"staal","text":"senseDutchEnglishstaal_11.1 zeer hard ijzer met laag koolstofgehalte: twaalf ton staal, ijzer en staal, een man van staal1.1 hard iron low carbon content: twelve tons steel, iron steel, man steelstaal_1b: 1.3 steel industry: steel strikingstaal_21.2 voorwerp deel van een voorwerp uit zulk metaal: het staal van de velgen verroest1.2 object part object made metal: steel rims rustedstaal_32.1 monster van een stof materiaal, bij wijze van proef: een staal vragen, goederen op staal verkopen2.1 sample substance material, evidence proof: ask sample, buy sample goodsstaal_42.2 proef, voorbeeld, bewijs: een staaltje van hun kunnen, een staaltje van bewaamheid2.2 proof, example, evidence: sample abilities, proof competencestaal_5: 2.3 sample taken population statistical analysis: representative sample","code":""},{"path":"definitions.html","id":"stof","chapter":"A Definitions","heading":"stof","text":"senseDutchEnglishstof_11.1 materie, substantie van een bepaald type: giftige stoffen, vaste stof, grijze stof1.1 matter, substance certain kind: poisonous substances, solid substances, gray matterstof_21.2 weefsel: wollen en katoenen stoffen1.2 fabrics: woolen cotton fabricsstof_31.3 onderwerp waarover men spreekt, schrijft, nadenkt etc.: stof voor een roman, stof tot onenigheid1.3 topic people talk, write, think, etc.: material novel, topic disagreementstof_42.1 massa zeer kleine droge deeltjes van verschillende oorsprong, door de lucht meegevoerd: een wolk stof, stof afnemen2.1 mass small dry particles various origin, floating air: cloud dust, clean dust (=dust)stof_52.2 massa zeer kleine deeltjes als toestand van een specifieke substantie: iets tot stof vermalen, tot stof verpulveren2.2 mass small particles state specific substance: bring something duststof_6: 2.3 idiomatic uses \"dust\": lift dust","code":""},{"path":"definitions.html","id":"horde","chapter":"A Definitions","heading":"horde","text":"senseDutchEnglishhorde_11 bende, ordeloze groep personen: een woeste horde1 band, unordered group people: ferocious hordehorde_1b: 1.2 unordered group non-people: horde computershorde_22.1 materiële hindernis, m.n. houten raamwerk gebruikt bij het hordelopen: de 400m horden bij de vrouwen2.1 material obstacle, namely wooden frames used hurdling: 400m hurdles womenhorde_32.2 hindernis figuurlijke zin: een horde nemen2.2 obstacle figurative sense: take hurdle","code":""},{"path":"definitions.html","id":"schaal","chapter":"A Definitions","heading":"schaal","text":"senseDutchEnglishschaal_11.1 een geordende reeks cijfers, afstanden, hoeveelheden e.d. waarmee iets gemeten wordt: de schaal van Celsius, Richter, op een schaal van 1 tot 51.1 ordered list numbers, distances, quantities , something measured: scale Celsius, Richter, scale 1 5schaal_21.2 de verhouding tussen de grootte van iets en de weergave ervan een kaart, model, grafiek etc.: een schaal van 1:20, een schaal van 10 km1.2 ratio size something representation map, model, graph etc.: scale 1:20, scale 10kmschaal_31.3 grootteorde, omvang: de schaal van een probleem, op grote/kleine schaal1.3 magnitude, size: scale problem, large/small scaleschaal_42.1 harde buitenbekleding van zekere organische zaken: de schaal van een ei, de schalen van een mossel2.1 hard exterior certain organic things: shell egg, shell musselschaal_52.2 ondiepe en wijde schotel: een schaal met vruchten2.2 shallow wide dish: platter fruitsschaal_62.3 elk van de beide schotels die aan de armen van een balans hangen: gewicht de schaal leggen2.3 dishes hanging arms scale: lay weight (dish ) scale","code":""},{"path":"definitions.html","id":"spoor","chapter":"A Definitions","heading":"spoor","text":"senseDutchEnglishspoor_11.1 afdruk door iets iemand op z'n weg achtergelaten: het spoor van een fiets op een zandweg, een spoor van vernieling: spoor_21.2 blijk van aanwezigheid door iets iemand (ongewild) achtergelaten: naar sporen zoeken, iemand op het spoor komen: spoor_31.3 kleine hoeveelheid: sporen van lood het leidingwater: spoor_41.4. te volgen gevolgde weg figuurlijke zin: het juiste spoor: spoor_52.1 weg met twee rijen metalen staven waarover treinen e.d. rijden: niet op het spoor lopen!: spoor_62.2 de trein als vervoermiddel: met het spoor reizen: spoor_72.3 spoorwegbedrijf: bij het spoor werken, het spoor staakt: spoor_83 metalen punt wieltje aan de hiel van een rijlaars, gebruikt om het rijdier te prikkelen: zijn sporen verdienen: ","code":""},{"path":"definitions.html","id":"herstellen","chapter":"A Definitions","heading":"herstellen","text":"senseDutchEnglishherstellen_1(trans.) repareren, de eraan ontstane schade wegwerken: het dak herstellen(trans.) repair, get rid damage something: repair roofherstellen_2(trans.) tot de vorige toestand terugbrengen, doen terugkeren: de goede verstandhouding herstellen(trans.) bring back, make return previous state: repair understandingherstellen_3(trans.) goedmaken, weer doen vergeten: een fout herstellen(trans.) make good, make forget: fix mistakeherstellen_4(reflex.) tot de oorspronkelijke toestand terugkeren: de rust herstelt zich(reflex.) return original state: peace restoredherstellen_5(intrans.) genezen: van een ziekte herstellen(intrans.) heal: heal diseaseherstellen_6: (intrans.) financial/economic entity, recover: ","code":""},{"path":"definitions.html","id":"harden","chapter":"A Definitions","heading":"harden","text":"senseDutchEnglishharden_1(trans.) hard maken, letterlijke zin: staal harden(trans.) make hard, literal sense: harden steelharden_2(intrans.) hard worden, letterlijke zin: snel hardende verven(intr.) become hard, literal sense: quickly hardening paintharden_3(trans.) hard maken figuurlijke zin; weerstand en veerkracht bijbrengen: een kind harden tegen het klimaat(trans.) make hard figurative sense; impart resistance resilience: toughen child weatherharden_4(reflex.) bij zichzelf weerstand en veerkracht aankweken: zich harden tegen het lot(reflex.) develop resistance resilience oneself: toughen oneself fateharden_5(trans.) uithouden, verdragen: niet te harden(trans.) endure, tolerate: unbearable ('bear')","code":""},{"path":"definitions.html","id":"herinneren","chapter":"A Definitions","heading":"herinneren","text":"senseDutchEnglishherinneren_1(met 'aan') weer te binnen brengen, het geheugen terugroepen: iemand aan iets herinneren(_aan_ '') bring back mind, memory: remind someone somethingherinneren_2(reflex.) het geheugen aanwezig hebben, niet vergeten: zich een gebeurtenis, een persoon herinneren(reflex.) present memory, forget: remember event, personherinneren_3(trans.) met een plechtigheid, monument o..d. gedenken: herinneren vandaag de Slag bij Ronceval(trans.) remember celebration, monument : today remember Battle Roncevaux Passherinneren_3: (trans.) construction \"herinnered worden als\", keep collective memory: ","code":""},{"path":"definitions.html","id":"herhalen","chapter":"A Definitions","heading":"herhalen","text":"senseDutchEnglishherhalen_1(trans.) m.b.t. handelingen activiteiten: opnieuw uitvoeren: een experiment, een les, een bezoek herhalen(trans.) w.r.t. acts activities: perform : repeat experiment, lesson, visitherhalen_2(trans.) m.b.t. zinnen, boodschappen e.d.: opnieuw uitspreken: kunt u dat even herhalen?(trans.) w.r.t. utterances, messages : pronounce : please repeat ?herhalen_3(reflex.) zich opnieuw voordoen: de geschiedenis herhaalt zich(reflex.) occur : history repeats itselfherhalen_4: (trans.) show episode, broadcast : ","code":""},{"path":"definitions.html","id":"herstructureren","chapter":"A Definitions","heading":"herstructureren","text":"senseDutchEnglishherstructureren_1(trans.) reorganiseren, een nieuwe structuur geven: je kunt deze tekst maar beter herstructureren(trans.) reorganizz, give new structure: restructure textherstructureren_2(trans.) m.b.t. bedrijven problemen: activiteiten personeel afstoten, downsizen: Bayer herstructureert zijn plasticdivisie(trans.) w.r.t. businesses difficulties: remove activities personeel, downsize: Bayer restructures plastic divisionherstructureren_3(intrans.) van bedrijven problemen: activiteiten personeel afstoten, downsizen: de chemie moet zich herstructureren(intrans.) businesses difficulties: remove activities personeel, downsize: chemistry must restructure ()","code":""},{"path":"definitions.html","id":"herkennen","chapter":"A Definitions","heading":"herkennen","text":"senseDutchEnglishherkennen_1(trans.) iets iem. identificeren als dezelfde als bij een vorige ontmoeting: ik herken het, dit heb ik al eerder gezien(trans.) identify someone something previous encounter: recognize , seen beforeherkennen_2(trans.) iets identificeren als afkomstig van behorend bij een specifieke persoon zaak: ik herken haar handschrift(trans.) identify something coming belonging specific person issue: recognize handwritingherkennen_3(trans.) iets iem. identificeren als exemplaar van een bepaalde categorie: je kunt de specht herkennen aan zijn snavel(trans.) identify someone something exemplar certain category: can recognize woodpecker beakherkennen_4(reflex.) zich  inleven een ander persoon een gebeurtenis: ik herken hun jeugdige enthousiasme(reflex.) empathize another person event: recognize youthful enthousiasm","code":""},{"path":"definitions.html","id":"diskwalificeren","chapter":"A Definitions","heading":"diskwalificeren","text":"senseDutchEnglishdiskwalificeren_1(trans.) ongeschikt verklaren en uitsluiten van een bepaalde functie positie: een getuige diskwalificeren(trans.) declare unsuitable exclude certain function position: disqualify witnessdiskwalificeren_2(trans.) wegens onregelmatigheden uitsluiten bij een wedstrijd: FC De Trappers werd gediskwalificeerd wegens wangedrag(trans.) exclude competition irregularities: FC De Trappers disqualified misbehaviourdiskwalificeren_3(reflex.) zichzelf buiten spel zetten, zich onmogelijk maken: met zulk gedrag diskwalificeer je jezelf(reflex.) exclude oneself, make oneself impossible: behaviour disqualify ","code":""},{"path":"definitions.html","id":"helpen","chapter":"A Definitions","heading":"helpen","text":"senseDutchEnglishhelpen_1(trans.) ondersteunen materiële morele zin, bijstaan: met raad en daad helpen, een helpende hand, uit de nood helpen(trans.) support material moral sense, assist: help word deed, helping hand, help outhelpen_2(trans.) iem. assisteren door met hem samen te werken: helpen met het huiswerk; heb je dat alleen gedaan heeft iemand je geholpen?(trans.) assist someone collaborating : help homework, someone help ?helpen_3(intrans.) voordeel opleveren, nuttig zijn: dat drankje heeft goed geholpen(intrans.) yield advantage, useful: drink helped lothelpen_4: (trans.) inanimate entities, helpful, useful: helpen_5: (_aan_) provide: ","code":""},{"path":"definitions.html","id":"haten","chapter":"A Definitions","heading":"haten","text":"senseDutchEnglishhaten_1(trans.) iem. haat toedragen, een sterk gevoel van afkeer en vijandschap t.o.v. iem. hebben: waarom haat hij mij zo?(trans.) feel hatred, strong feeling aversion enmity towards someone: hate much?haten_2(trans.) iets onaangenaam, verfoeilijk, verwerpelijk vinden: hoe zou iemand de taalkunde kunnen haten?(trans.) consider something unpleasant, detestable, reprehensible: someone hate linguistics?","code":""},{"path":"definitions.html","id":"huldigen","chapter":"A Definitions","heading":"huldigen","text":"senseDutchEnglishhuldigen_1(trans.) iets iem. eer bewijzen, vieren: huldigen de uitvinder van de herbruikbare broodzak(trans.) celebrate, pay homage someone something: honor inventor reusable bread baghuldigen_2(trans.) erkennen, aankleven, toegedaan zijn: een opvatting, mening, theorie huldigen(trans.) acknowledge, follow, commited : hold view, opinion, theory","code":""},{"path":"definitions.html","id":"heffen","chapter":"A Definitions","heading":"heffen","text":"senseDutchEnglishheffen_1(trans.) m.b.t. materiële zaken: de hoogte brengen, optillen: met geheven hoofd; hij heft met gemak 80 kilo de hoogte(trans.) w.r.t. material objects: move higher position, lift: lifting head; easily lifted 80 kgheffen_2(trans.) m.b.t. geld e.d.: invorderen, eisen, opleggen: belasting, rente, accijns heffen(trans.) w.r.t. money : collect, demand, impose: collect tax, interest, excise","code":""},{"path":"definitions.html","id":"herroepen","chapter":"A Definitions","heading":"herroepen","text":"senseDutchEnglishherroepen_1(trans.) m.b.t. wetten, besluiten e.d.: intrekken, niet langer geldig verklaren: een besluit, volmacht, decreet herroepen(trans.) w.r.t. laws, decisions : withdraw, declare valid anymore: annul decision, power attorney, decreeherroepen_2(trans.) m.b.t. uitspraken, meningen e.d.: terugnemen en rechtzetten: Trump moest weer een van zijn dwaze tweets herroepen(trans.) w.r.t. statements, opinions : retract correct: Trump retract one crazy tweets ","code":""},{"path":"definitions.html","id":"haken","chapter":"A Definitions","heading":"haken","text":"senseDutchEnglishhaken_1(trans.) met als met een haak vastmaken (aan, , achter iets): een wagen aan een locomotief haken, een sleutel een ring haken(trans.) fix something hook (, , behind something): hook wagon locomotive, key key ringhaken_2(intrans.) met als met een haak vastraken: de doornen haakten aan haar jas, haar paraplu bleef haken aan de deurknop(intrans.) get stuck hook: thorns got stuck coat, umbrella got stuck doorknobhaken_3(trans.) een uitgestoken doen struikelen: hij werd gehaakt de elfmeter, iemand pootje haken(trans.) make trip stuck leg: made trip penalty kick, make someone triphaken_4(intrans., met 'blijven') van gedachten, blikken e.d.: haperen, telkens terugkeren (aan bij iets): ik bleef haken bij de herinnering aan mijn broer(intrans., _blijven_ 'keep') thoughts, gazes : falter, come back (something): kept going back memory brotherhaken_5(intrans./trans.) zeker handwerk maken door met een staafje met een weerhaak lussen samen te weven: haken tijdens het televisiekijken, hoe ontspannend!, een babymutsje haken(intrans./trans.) make handcraft weaving loops together hooked needle: crochetting watching tv, relaxing!, crochet baby hathaken_6: (_naar_ '') desire, aim : ","code":""}]
