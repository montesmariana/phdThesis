[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"\nresearch described dissertation part Nephological Semantics research project qlvl research group KU Leuven,\naims develop tools large-scale corpus-based semantic analysis.\ncore aspect project involves representing semantic structure distributional models,\ncomputational tool currently requires deeper understanding inner workings\nresults relate cognitive theories meaning.Context-counting distributional models represent words1 vectors co-occurrence frequencies multidimensional space\n(Turney & Pantel 2010; Lenci 2018). Basically, word represented \nassociation strength words.\ncan generated type token level (Heylen, Speelman & Geeraerts 2012; Heylen et al. 2015; De Pascale 2019).\ntype level, two words represented similar attracted \ncontextual features (e.g. words) repelled contextual features. \nallow us identify semantic fields relationships words, collapses full\nrange contexts word one representation.\ntoken level, instead, look individual occurrences define similar \nwords contexts attracted repelled contextual features.\nway able map internal variation behaviour individual words,\n.e. semasiological structure.Within larger Nephological Semantics project, particular work package dedicated\nunderstanding token-level distributional models tool\nstudy polysemy. Concretely, explored number parameter settings models\n(.e. ways defining context used represent token) impact \nresulting representation, means visual analytics.\nManually annotated sense tags used heuristic, without\nconsidering golden standard. Instead, aim map parameter settings various\nsemantic phenomena coded annotations, \nmeaning granularity (e.g. distinguishing homonyms senses within homonyms).\ndistributional models, take form large matrices,\ncan reduced two dimensions via different methods,\nt-sne (van der Maaten & Hinton 2008; van der Maaten 2014).\ncoordinates can mapped onto scatterplot, resulting variety \nshapes, call clouds.workflow applied set 32 Dutch nouns, verbs adjectives exhibiting\nrange semantic phenomena. , 240-320 concordance lines extracted\ncorpus Dutch Flemish newspapers,\nannotated modelled. combination parameter settings, included syntactic\ninformation, resulted 200-212 different models per lemma. models clustered Partition\nAround Medoids (Kaufman & Rousseeuw 1990; Maechler et al. 2021) manageable, representative set explored\ndepth, particular visualizing t-sne representations.contributions dissertation twofold. one hand, exploration \npossibilities limits distributional models lexicological research resulted \nwarnings, suggestions guidelines practical studies. words, offers\nassessment interpretation distributional models perspective descriptive linguistics.\nhand, presents visualization tool designed exploration \ntoken-level distributional models perspective (Montes & QLVL 2021). interactive quality makes\nchallenging describe adequately printed text, strongly\nrecommend visiting virtual home explore .web-based version dissertation, plan fix typos add notes/disclaimers (highlighted like ).\ncan find original, submitted approved pdf version .cite work, can use following bibtex:","code":"\n@phdthesis{montes_2021,\n  type = {{{PhD Dissertation}}},\n  title = {Cloudspotting: Visual Analytics for Distributional Semantics},\n  author = {Montes, Mariana},\n  year = {2021},\n  address = {{Leuven}},\n  abstract = {This PhD study belongs to WP1 of the KU Leuven C1 research programme 'Nephological Semantics', (PI Dirk Geeraerts) which explores the use of distributional semantic methods for linguistic semantics. Specifically, the study aims at a realistic assessment of the possibilities and limitations of vector space semantics and word embeddings. The project will take the form of a number of case studies comparing polysemy analyses under three methods: a definitional lexicographical analysis, a 'behavioral profile' approach, and a semantic vector space approach. In general, the methodological goal of WP1 is to bring together a number of distributional methods that were developed in different contexts, and to refine, complement and systematize them, in order to turn them into an overarching, methodologically unified toolset in support of the analysis of various types of interplay between onomasiological, semasiological, and lectal variation. For validation and descriptive purposes, the methods are applied in case studies on English and Dutch lexical items.},\n  collaborator = {Geeraerts, Dirk and Speelman, Dirk and Szmrecsanyi, Benedikt},\n  copyright = {All rights reserved},\n  langid = {english},\n  school = {KU Leuven}\n}\n"},{"path":"acknowledgements.html","id":"acknowledgements","chapter":"Acknowledgements","heading":"Acknowledgements","text":"words pages, thoughts try convey, result years thinking, discussing, learning. voice weaves together,\ndraws many sources encouraged growth, stood , fed curiosity, passion enthusiasm everything makes text.support ideas, like thank supervisors Dirk Geeraerts, Dirk Speelman Benedikt Szmrecsanyi. Thank trusting , allowing part amazing research project.\nDirk Geeraerts deserves special acknowledgement patience trust. honour share interesting, long discussions semantics research.\nEvery time talked became excited passionate research, confident happy. Hartelijk bedankt.\nalso grateful Freek Van de Velde, Tim Van de Cruys, Martin Hilpert Thomas Herbst willingness participate jury.Research eminently collaborative, can feel lonely. always appreciate company support colleagues Linguistics Department KU Leuven, especially research group, qlvl. particular, like thank members Nephological Semantics project, shared much excitement frustrations common project. ’d like acknowledge Tao Chen amazing work Python code helping understand Stefania Marzo always making feel like done something right. past year half, weekly meetings Dirk Dirk, Kris, Karlien, Stefano Weiwei intense also kept grounded. constantly learning, rethinking, trying new things. grateful collaboration advice, letting know research matters. Kris unstoppable source ideas, Karlien great partner spontaneous experiments, Stefano helpful shared methodological obstacles (thank proofreading!).colleagues become friends. first Danqing, shares experience studying making life far home, kindly agreed proofreading spite busy schedule. also immensely grateful Marlieke Pedro, proofreading efforts invaluable help translations examples also, importantly, company friendship. Thank Ola, Caro, Araceli Manuel standing even distance. Paula, thank challenging , encouraging , making better researcher better person.friends move family. honestly wouldn’t today weren’t parents. taught learn teach, face challenges, fear mathematics programming. siblings strength, thank , thank mates, talks, hugs. cousin Alex deserves special acknowledgement holding hand discovered web design helping disentangle whole new field. Muchas gracias, che.Finally, like thank partner, Taihou, kept alive finishing text, always listened ramblings, held fell, rejoiced succeeded., forever grateful. thanks , hope make proud.","code":""},{"path":"intro.html","id":"intro","chapter":"1 Introduction","heading":"1 Introduction","text":"meaning found created use, corpora language use, can find meaning corpora? field usage-based semantics large rich, answer question clearly positive. Corpora offer immense amount usage data carry analyses, even barely scratch surface amount language actually produced — desirable tempting tap vast ocean obtain detailed, reliable, thorough information. crucial bottleneck comes semantic analysis: annotation time- energy-consuming. long instruct automatic system disambiguate word corpus — like tokenize lemmatize, .e. identify counts word root , even assign parts speech syntactic relations — semantic annotation performed humans. Humans slower computers; get tired, get confused, need eat think things beyond semantic annotation weel. also disagree sometimes — sense? two things really ?Automatic disambiguation systems exist. Word Sense Disambiguation important task within Natural Language Processing (nlp). notion task crucial importance : nlp algorithms typically concerned concrete applications evaluated terms applications. exists correct answer algorithm must return. directly applicable situation lexicological lexicographical research — study meanings words relationships — especially Cognitive Linguistics point view, hard, dichotomous answers rare. let’s suppose moment can conciliate approaches, counts answer nlp point view answer lexicological perspective. use automatic disambiguation procedures make heavy lifting semantic annotation growing body corpus data use results partial description language. long know answer nlp algorithm returning , better yet, ask want know. Maybe tuning algorithm outputs nlp point view wrong can result complementary answers richer lexicological description. qualitative perspective, trying interpret just whether computational model matches target also (), also requires appropriate analytical tools. One tool represents internal semantic structure item, derived computational models, 2d scatterplot instances occurring similar context shown together, forming clusters clouds.dissertation concerned application distributional methods lexicological research exploration means visual analytics. methodology tested illustrated set 32 Dutch lemmas, concordance lines extracted corpus newspapers.\nDistributional models, developed within field Computational Linguistics, introduced Section 1.1. Section 1.2 discuss relevance Cognitive Semantics Section 1.3 offer overview visual analytics dimension.\nstudy described part larger research project within Quantitative Lexicology Variational Linguistics research group (qlvl) KU Leuven. brief history project dissertation fits offered Section 1.4. Finally, Section 1.5 present structure dissertation.","code":""},{"path":"intro.html","id":"comp","chapter":"1 Introduction","heading":"1.1 Distributional Semantics and Computational Linguistics","text":"Distributional semantics usage-based model meaning underlies various computational methods semantic representation\n(Sahlgren 2008; Lenci 2018): educational program computers lets pretend understand human languages. relies called Distributional Hypothesis, according lexemes similar meanings similar distributions, .e. occur similar contexts. core idea typically attributed Harris (1954) Firth (1957), exactly enthusiastic sight current implementations disputed: Tognini-Bonelli (2001: 157) remarks Firth favour electronic corpora, Geeraerts (2017) offers comprehensive comparison Harris’ position current distributional semantics. attribution issue notwithstanding, idea meaning can modelled means distributional information pervasive nlp core every form Distributional Semantics. important question mean meaning semantics begin (Sahlgren 2006; Lenci 2008), research informed Cognitive Linguistics framework. Beyond particular attention semantic side distributional semantics, dissertation sets apart mainstream computational approaches three core aspects: motivation, definition units reliance context-counting models.","code":""},{"path":"intro.html","id":"motivation","chapter":"1 Introduction","heading":"1.1.1 Motivation","text":"Computational Linguistics typically task-oriented: aims solve concrete challenges information retrieval, question answering, sentiment analysis, machine translation, etc. purpose, benchmarks gold standards developed models tested . example, Baroni, Dinu & Kruszewski (2014) test different kinds models datasets tailored evaluate semantic relatedness, synonym detection, concept categorization, selectional preferences analogy; see Agirre & Edmonds (2007) Raganato, Camacho-Collados & Navigli (2017) evaluation systems sense disambiguation. understandable appropriate task-oriented workflow: comes output, really matter model reached answer, long answer seek. contrast, investigating structure semantic representations, .e. process, calls different approach (see example Baroni & Lenci 2011; Wielfaert et al. 2019). one hand, assume one correct answer assume one question. Beyond “two words similar?” interested : “synonyms?” “co-hyponyms?” “regionally specific expressions concept?” forth. Different models may focus different dimensions semantic structure thus answer different questions. reason, dataset collected research covers wide range semantic phenomena, hope tuning distributional models identification. hand, confident questions unequivocal answer either. Chapter 4 show, annotators often agree sense utterance, always. Hence, manual annotations serve guideline interpretation models, law judge accuracy.","code":""},{"path":"intro.html","id":"units-of-analysis","chapter":"1 Introduction","heading":"1.1.2 Units of analysis","text":"Whereas computational models typically work type-level often word forms, dissertation focuses token-level models lemmas units.\nType-level modelling represents lexical unit, word, aggregated distributional behaviour occurrences, e.g. see word tends preceded . Patterns can found accumulating classifying contextual information thousands millions events. profile type can subsequently compared profiles types, e.g. can see sentence also tends preceded , walking . representation conflates variation within range application item part one overall tendency, therefore suited study polysemy. Even context contain disambiguating cues, “Can word?” “word dictionary,” type-level representation cover . spite shortcomings, computational approaches modelling polysemy try find patterns type-level representations, e.g. Koptjevskaja-Tamm & Sahlgren (2014). contrast, work presented relies token-level modelling, represents individual instances, e.g. comparing two occurrences word examples . approach originate computational linguistics (Schütze 1998) far less popular type-level approaches, considered default introductory descriptions distributional models (Lenci 2018; Turney & Pantel 2010; Bolognesi 2020).Apart distinction modelling types tokens, crucial difference approach many studies computational linguistics unit analysis lemma instead word form. one hand, relying word forms avoids layers preprocessing already incorporate certain interpretation terms counts word, different forms go together classified grammatically. Sinclair (1991) also argues along lines usage word forms lexical units corpus linguistics. , admittedly, different word forms given lemma might exhibit diverging distributional semantic profiles. However, lexicological lexicographical perspective, centring lemma — combination stems grammatical category — common practice. Moreover, mismatch word forms lemmas — therefore either meanings — highly dependent language describe words . Therefore, lemmas unit analysis dissertation. say workflow depends decision, way depend Dutch language corpus. methodology presented pages applied word forms centre, degree conclusions reached applicable empirical question.","code":""},{"path":"intro.html","id":"context-counting-and-context-predicting","chapter":"1 Introduction","heading":"1.1.3 Context-counting and context-predicting","text":"Currently, popular approach distributional semantics relies neural networks, .e. context-predicting models. methodology followed project relies instead count-based context-counting models: values vectors, .e. numerical representations lexical units, (relatively) directly derived frequency counts. contrast, approach initiated Mikolov et al. (2013) taken nlp, .e. word embeddings, context-predicting architecture. Neural networks trained predict empty slots fragment text: given fixed window target item middle, cbow models given surrounding context order predict target item, whereas skip-gram models try predict context based item middle. training consists long sequence trial error: right answer, .e. actual corpus, algorithm starts guessing receives feedback, iteratively adapts guessing strategy minimise error. strategy consists weights hidden layer neural network; weights used represent target item. words, context-counting model define distributional profile word along lines “tends co-occur chocolate cookies mycorrhyza algorithm,” context-predicting models say, less, “feel/brain see word.” latter , sense, line core meaning introspective experience defies definitions restrictions, although computational models far actually understanding language. Exploring degree models approximate humans’ assessments lies purview research programmes involving psycholinguistic experiments. Studies carried compare performance context-counting context-predicting models — terms, course, accuracy regards popular benchmarks. Baroni, Dinu & Kruszewski (2014) found word2vec architecture outperformed context-counting models, much disappointment. contrast, Levy, Goldberg & Dagan (2015) fine-tuned context-counting models based hyperparameters word embedding found performance differences local even insignificant.purpose understand meaning, anything, can found text data, interpretation context-counting models much transparent. can trace composition vectors concrete frequencies instances. see second part dissertation, supposedly transparent models already quite opaque, especially added transformation type-level token-level models. said, workflow described can also combined context-predicting models.years since Mikolov et al. (2013) seen rapid enthusiastic growth field word embeddings nlp, new models continually surpassing previous ones. One bert (Devlin et al. 2019), , spite indubitable relevance approach proposed , explored. Bidirectional Encoder Representations Transformers (bert) machine-learning technique can represent individual instances sentences: unlike context-predicting models, can used token-level representations. like context-predicting models, output somewhat less interpretable context-counting models. tested typical task-based benchmarks time- resources-consuming nlp researchers typically use pre-trained embeddings fine-tune specific tasks rather generate scratch. principle, combining model bert family workflow described impossible: long occurrences represented vectors can derive pairwise distances, rest analysis stays . However, crucial differences remain: know elements context informed models’ decision, based word forms word forms based different tokenizer. instance, brief test bertje (de Vries et al. 2019), Dutch counterpart bert, section dataset used project revealed () lemmas bertje’s answer might closer human perspective, (ii) lemmas deeper investigation order (iii) lemmas modelled discrepancy tokenization procedure2. words, even combining methodologies possible, actual implementation requires planning, specific decisions tailoring procedure extract much can backstage operations context-predicting models.","code":""},{"path":"intro.html","id":"cog","chapter":"1 Introduction","heading":"1.2 Distributional Semantics and Cognitive Semantics","text":"computational approach, distributional semantics intrinsically linked particular linguistic theory. usage-based essence makes natural fit approaches describe parole along langue (terms de Saussure 1971), Cognitive Linguistics. introduction Oxford Handbook Cognitive Linguistics, described asan approach analysis natural language originated late seventies early eighties work George Lakoff, Ron Langacker, Len Talmy, focuses language instrument organizing, processing, conveying information. (Geeraerts & Cuyckens 2007a: 3)stands contrast frameworks uphold strict separation semantics pragmatics, structure usage, lexical knowledge world knowledge (Geeraerts 2010a). introduction composition Handbook shows, well compilations along lines (Rudzka-Ostyn 1988; Kristiansen et al. 2006; Ibarretxe-Antuñano & Valenzuela 2016), diverse field Cognitive Linguistics guided number principles derived central notion language categorization. Among principles, three particular constitute theoretical cornerstones study: () emphasis meaning, (ii) notion fuzzy prototypical categories (iii) usage-based approach.","code":""},{"path":"intro.html","id":"everything-is-semantics","chapter":"1 Introduction","heading":"1.2.1 Everything is semantics","text":"Understanding language categorization function organization communication knowledge necessarily places focus meaning (Geeraerts & Cuyckens 2007b; Geeraerts 2016). Cognitive Linguistics perspective, linguistic structures — just lexical items also syntactic patterns — considered inherently meaningful (Langacker 2008; Lemmens 2015). Moreover, meaning Cognitive Linguistics goes beyond traditional semantics — .e. distinguishing linguistic nonlinguistic features — includes encyclopedic knowledge pragmatics (Glynn 2010; Geeraerts 1997). crucially cognitive phenomenon involving conceptualization, takes place mind physical, embodied beings perceive, understand, interact world: meaning embodied neither limited separated reference (Rohrer 2007).centrality semantics Cognitive Linguistics led strong body work meaning traditional notions fit cognitive principles.\nexample, line work initiated ’80s Lakoff & Johnson (2003) developed along different lines Raymond Gibbs Jr., Gerard Steen, Zoltán Kövecses, Elena Semino many others (see example Gibbs & Steen 1999; Gibbs Jr. 2008; Semino 2008; Kövecses 2015) builds understanding traditional linguistic concept, .e. metaphor, tools Cognitive Linguistics. terms, metaphor refers ways thinking, understanding, conceptualizing, manifest linguistic behaviour also permeate areas everyday life.Along lines, relationships senses understood cognitive mechanisms need restricted linguistic behaviour extralinguistic reference. Semantic categories metaphor, metonymy, specialization, homonymy prototypicality crucial tools make sense variety relationships understand senses. unique Cognitive Linguistics, framework understands meaning property linguistic structure covering linguistic extralinguistic features allows us look meaning distributional models without expecting exhaust semantic description.Cognitive Linguistics also incorporates combination semasiological onomasiological perspective, previous frameworks defined either one possibility (Geeraerts 2010a). semasiological perspective, predominant research described , starts form expression investigates range meanings applications, e.g. study polysemy. onomasiological perspective, hand, starts concept describes forms used express , e.g. synonymy. dissertation takes semasiological perspective, token-level distributional models can used perspectives, shown De Pascale (2019).","code":""},{"path":"intro.html","id":"prototypicality","chapter":"1 Introduction","heading":"1.2.2 Prototypicality","text":"Among important notions Cognitive Linguistics understanding categorization find prototypicality salience (Rosch 1978). Categories always described terms necessary sufficient conditions; instead, may characterized clusters co-occurring properties apply members degree. may even fuzzy boundaries, unclear range application. property categorization, property language, Cognitive Linguistics embraces, incorporating quantitative dimension study meaning (Geeraerts 2010a). point, quantitative perspective immediately require statistical methods, refers shift understanding counts meaning description. notion prototypicality makes interesting, inevitable, look uneven distribution importance different features members category, done, example, Geeraerts, Grondelaers & Bakema (1994) Geeraerts (1997):…essence prototype theory lies fact highlights importance flexibility (absence clear demarcational boundaries) salience (differences structural weight) semantic structure linguistic categories. (Geeraerts 2006: 74)Given set meanings form can express, .e. intensional level, salient others. example, given current lifestyle, ‘device control cursor screen’ salient meaning mouse ‘small rodent’; , crucially, might case contexts, speakers. Given range application form meaning (.e. extensional level), may typical members others. instance, black, minimalist computer mouse might typical wavy, wider gaming mouse bright green drawing dragon. situations represent intensional extensional nonequality, respectively: senses members category better representatives category others. dimensions may overlap: typical computer mouse concentrates typical features category, regarding functionality, size, shape colour; conversely, typical feature defined occurring frequently members category. two characteristics prototypicality, complemented intensional extensional non discreteness, .e. lack single set necessary sufficient conditions fuzzy boundaries categories. expected, even prototypicality prototypical category, four features need co-exist. relative salience two senses mouse mean might find unknown entity doubt whether mouse; meanwhile, discussions whether tomato fruit might easily ensue. Geeraerts (2006Ch. 4) offers typology salience phenomena application prototype theory beyond semasiological structure. example, semasiological perspective interested describing frequent (salient) apples referents word fruit, onomasiological perspective interested frequently word fruit used refer apples (compared saying apple).notion (semasiological) prototypicality relevant interpretation modelling Chapter 6. , also permeates understanding meaning underlies research. one hand, fuzzy boundaries degrees membership invite us rethink usefulness reified senses: ambiguous examples overlapping features expected. Instead, bottom-procedure rather capture configurations features (Glynn 2014); assigning discrete senses corpus data imposes categorical structure know inappropriate (see also Geeraerts 1993). hand, distributional models, quantitative approach measures similarity entities, particularly adequate non-discrete representation.dissertation continue talk senses extract discrete patterns non-discrete representations terms clusters, order manipulate talk abstract entities, without implying ontological reality beyond explanatory purposes. comes senses, considered gold standard, unique solution semasiological description lexical item; instead, guides operationalization certain research questions. clusters, hand, generated algorithm forced produce discrete groups assign elements different degrees membership (see Section 2.2.4). Finally, overall approach describes tendencies, preferences, probabilities: level categories typologies offered dissertation discrete uniform. tried, language resists.","code":""},{"path":"intro.html","id":"a-usage-based-approach","chapter":"1 Introduction","heading":"1.2.3 A usage-based approach","text":"Cognitive Linguistics presents usage-based approach , , entirely compatible bottom-, empirical, quantitative methodology distributional semantics. Quantitative cognitive semantics now established field, shown contributions gathered Gries & Stefanowitsch (2006), Glynn & Fischer (2010) Glynn & Robinson (2014), among others. However, Cognitive Linguistics — especially Cognitive Semantics — relies empirical methods: introspection still main source information much foundational sources (see example discussion illustrated Geeraerts 1999). practice, introspection empirical methods required scientific research, albeit applied different stages aspects investigation (Geeraerts 2010b).\nInterpretation needed order formulate hypotheses guide data collection analysis interpret results: data speak . empirical steps, contrast, facilitate reproducibility falsifiability: describing concrete corpus, method collection quantitative methods applied , study can replicated different researchers results compared.\ntime, large-scale quantitative methods distributional semantics delegate time consuming computationally expensive tasks, reading comparing thousands attestations word, automatic system can perform faster systematically humans, leaving researcher dedicate energies tasks humans best : interpretation creativity. precisely long-term goal research: offer empirical, quantitative workflow transforms huge amounts data, finds relevant patterns provides linguist interpretation formulation hypotheses.Empirical research semantics can take different shapes: corpus-based methods, case research, also experimental referential methods. Geeraerts (2015: 242–243) argues, approaches captures different aspect meaning, namely textual patterns, -line processing referential properties. Meaning, especially maximalist perspective taken Cognitive Linguistics, complex fully described one methods isolation (see also Arppe et al. 2010; Stefanowitsch 2010). , high expectations distributional semantics — part question : models say?\nConcretely, expect distributional models provide information think, community speaks categorises: “‘language cognition’ encompasses shared socially distributed knowledge just individual ideas experiences” (Geeraerts 2016: 533). pool shared practices knowledge corpora offers distributional semantics tries model.Moreover, despite large corpora, advanced quantitative techniques sophisticated visualization tools dissertation built, study limits. restricted specific corpus, specific varieties specific language, specific genre period time, written text; restricted limited set lexical items investigated; restricted precise samples collected, precise questions asked, precise techniques used answer . importantly, thorough possible stating conditions research carried choices made along way. result, limits just warnings range applicability results conclusions, also importantly sources possibilities, inspiration similar studies facilitated empirical nature investigation.","code":""},{"path":"intro.html","id":"viz","chapter":"1 Introduction","heading":"1.3 Visual analytics","text":"Distributional models return mathematical representations lexical items — , case token-level models, attestations. mathematical representations arrays numbers , best-case scenario, can interpret co-occurrence information, unsorted list collocations. need additional step transform individual representations similarities, operationalize Distributional Hypothesis mentioned . However, even , output matrix many rows columns items comparing; depending magnitude sample subtlety structure, scanning visually can taxing, entirely vain. , .word sense disambiguation, evaluation normally involve clustering algorithm, benchmark measure accuracy. clustering algorithm take vectors similarity matrix return clusters: groups similar items different . measure accuracy report agreement clustering solution benchmark: closer , better model. However, measures say nothing qualitative differences models, .e. whether misclassified items differ benchmark. Even take gold standard actual ground truth correct solution — case study — ideal situation.responding concerns visualization tool exploration token-level models envisaged (Wielfaert et al. 2019). tool developed Wielfaert context Nephological Semantics project takes output dimensionality reduction algorithm, .e. procedure tries map distances based multiple dimensions 2d 3d space, surrounds visual representation interactive features. additional features, tailored exploration distributional models, set tool apart static scatterplot, even default interactive plot.put Card, Mackinlay & Shneiderman (1999: 6)’s words: “‘purpose visualization insight, pictures.’ main goals insight discovery, decision making explanation”3. Indeed, kind qualitative exploration achieved tool extremely hard without , impossible.\nfirst place, tool sets workflow goes exploration similarity models role parameter settings qualitative comparison selections models detailed exploration individual models. built facilitate fluid exploration interconnection levels analysis. tool offers simultaneous, interconnected access actual output model (coordinates 2d plane), variation parameter settings, semantic annotation, metadata corpora frequency data context words. interaction different aspects distributional models practical visual interface makes patterns insights accessible found way., visualization tool key component dissertation. scatterplots find clouds: clusters similar tokens come together denser areas (reduced) semantic space. actual case study involving methodological workflow presented , lot technicalities go generating clouds, large part analysis involves looking finding shapes: cloudspotting.","code":""},{"path":"intro.html","id":"nephosem","chapter":"1 Introduction","heading":"1.4 Nephological Semantics","text":"research presented dissertation part larger project within qlvl research unit, bof C1-project (3H150305) “Nephological Semantics: using token clouds meaning detection variationist linguistics,” Dr. Prof. Dirk Geeraerts Principal Investigator. Python module creation models, written Tao Chen, visualization tools analysis, designed Thomas Wielfaert , products project. Moreover, dissertation without integration case studies, questions insights discussed branches project, without feedback loop ideas, tests thoughts different techniques.main objective project develop — understand — appropriate methods retrieval semantic information corpus data, addressing concerns stem longer tradition usage-based lexical research. Geeraerts, Grondelaers & Bakema (1994) Geeraerts, Grondelaers & Speelman (1999) embark comprehensive, detailed lexicological analyses lexical fields clothing football terms Dutch. approach referential: Geeraerts, Grondelaers & Bakema (1994), instance, collect pictures descriptions garments Dutch Flemish magazines describe clothing item terms variety features, length sleeve. Based relationship (configurations ) features items used name objects, developed model lexical variation takes account prototypicality salience terms semasiological, onomasiological contextual variation. However, manual detailed identification features large enough scale painstaking time consuming, feasible. contrast, machine-readable linguistic material available, less accessible , given right resources, processable. provide kind information referential approach, easily scalable large amounts data.context project, token-level models semasiological research introduced Heylen, Speelman & Geeraerts (2012) Heylen et al. (2015). Another work-package, culminating De Pascale (2019)’s PhD dissertation, applies technique lexical lectometric research, .e. measuring distances language varieties based naming choices different concepts. visualization tool, mentioned , first described Wielfaert et al. (2019). work, dissertation case studies taking place last year, project covering application token-level vector space models semasiological, onomasiological lectometric studies varieties Dutch Mandarin, synchronic diachronic level.","code":""},{"path":"intro.html","id":"str","chapter":"1 Introduction","heading":"1.5 Structure of the dissertation","text":"product Nephological Semantics project, dissertation aims contribute development understanding distributional models lexical semasiological research.\nbrings together theoretical perspective semantics Cognitive Linguistics computational methods visual analytics hope paving way future research along lines.\nmind, three chapters first part dissertation, cloudspotter’s toolkit, focus technical methodological side project.\nChapter 2 describe procedure create clouds parameter settings explored, taking care thorough specific technical decisions resulted final models.\n, Chapter 3 showcase visualization tool designed Thomas Wielfaert well ShinyApp extension provides additional functionalities.\nFinally, Chapter 4 illustrate dataset models tested: selection lemmas questions try address, collection data annotation procedure.notion behind token-level models, .e. can represent meaning differences terms distributional differences, particular image scatterplot translates intuitions interpretable picture, sounds good.\nAlas, reality bright wished , skies distributional semantics stable weather. Hopefully, dissertation can offer guide researchers dare tread waters. Therefore, three chapters second part, cloudspotter’s handbook, discuss results analyses, emphasis crucial assumptions clash data. First, Chapter 5 debunks idea perfect cloud emerging ocean corpus. Clouds come many different shapes, caused different phenomena distributional behaviour, thus chapter offers classification might encounter. Chapter 6 follows linguistic perspective variation shapes discusses can find models. Finally, Chapter 7 shows set parameter settings offers best solution across board — even close. Instead, parameter settings may result different shapes different lemmas, tailored specific lemma capture relevant semantic structure.enthusiastic hopeful aspiring cloudspotter might feel discouraged variability — bordering unpredictability — clouds. wouldn’t blame . However, spite diversity shapes, semantic phenomena parameter settings explore, methodology can offer interesting insights. partial insights, insights nonetheless, know expect clouds, can focus acquiring . perspective, third final part dissertation, cloudspotter’s cheatsheet, close general practical guide, summary suggestions research overall conclusion.","code":""},{"path":"workflow.html","id":"workflow","chapter":"2 From corpora to clouds","heading":"2 From corpora to clouds","text":"main goal methodological framework presented explore semasiological structure textual data.\nstarting point corpus, .e. selection texts, one tangible outputs call clouds: visual representation textual patterns dense areas 2d scatterplot.\nchapter explain generate clouds raw, seemingly indomitable ocean corpus.First, describe token-level vector space models created: mathematical representations occurrences lexical item.\nfocus context-counting models, means viable path.\ntechniques, BERT (Devlin et al. 2019)4, can also generate vectors individual instances word, used first stage workflow.\n\nSection 2.1 describe process rationale without assuming strong mathematical background reader, leaving deeper technicalities Section 2.2. Section 2.3, break apart workflow multiple choices researcher needs make result potentially infinite number models, Section 2.4 briefly presents method select representative models. Finally, Section 2.5 summarizes chapter.","code":""},{"path":"workflow.html","id":"vector-creation","chapter":"2 From corpora to clouds","heading":"2.1 A cloud machine","text":"core vector space models, aka distributional models, find Distributional Hypothesis, often linked Harris’s observation “difference meaning correlates difference distribution” (1954: 156), also Firth’s “shall know word company keeps” (1957: 11) Wittgenstein’s “meaning word use language”5 (1958: 20).\nwords, items occur similar contexts given corpus semantically similar, occur different contexts semantically different (Jurafsky & Martin 2020, Ch. 6; Lenci 2018). Crucially, imply can describe individual item distributional properties, comparing distribution two items can tell us something semantic relatedness (Sahlgren 2006: 19).Firth (1957) inspired generations corpus linguists look collocations part semantic description lemma. Birmingham school, pioneered John Sinclair, used co-occurrence frequency information describe lexical item\n\nset context words attracted . Due skewed distribution word frequencies, known Zipf’s law, attraction measured terms raw co-occurrence frequencies. example, frequent lemma (Dutch) corpus used research, discarding punctuation, de ‘(fem./masc.),’ occurs 28.1 million times. second frequent lemma, van ‘,’ occurs 12.6 milion times, followed het ‘(neutral)’ een ‘, ,’ corresponding frequencies 11.7 11.1 million times . every 100 words corpus, excluding punctuation, \\(14\\) one four words. total 4.6 million different words, 61% hapax legomena, .e. occur , 172 lemmas cover 50% occurrences. consequence, co-occurrences frequent words informative less frequent words, hence raw co-occurrence frequencies transformed measures association strength, mutual information (see Section 2.2.1) t-score, among others (overview see Evert 2009; Gablasova, Brezina & McEnery 2017).\ncollocational studies, researchers typically set threshold association strength look context words surpass .core, context-counting vectors lists association strength values. word represented association strength long array words might co-occur , shown Table 2.1. Unlike collocation studies, low values — even lack co-occurrence — excluded, used comparison words might. Going back Firthian motto, collocational study describe list people talk , whereas distributional model compare someone else based either us talks often talk . people common, similar , people neither us talks impact comparison.Table 2.1 shows small vectors representing English nouns linguistics, lexicography, research chocolate, well adjective computational, co-occurrence information obtained GloWbE (Global Word-based English) corpus. values association strength pmi lemmas columns: higher values, stronger attraction word row word column (See Section 2.2.1). collocational perspective, linguistics strongly attracted language English, .e. occur often span 10 words , considering individual frequencies; less attracted word speak, co-occur either eat Flemish within window, corpus.\nTable 2.1: Small example type-level vectors, pmi values based symmetric window 10. Frequency data extracted GloWbE.\nrow Table 2.1 vector coding distributional information lemma represents. lemma refer combination stem part speech, e.g. chocolate/n covers chocolate, chocolates, Chocolate, etc.\n\n\n\nvectors meant code distributional behaviour linguistic forms represent — case lemmas —, order operationalize notion distributional similarity , consequently, model meaning. example, Table 2.1 first two rows, representing linguistics lexicography, similar : words similar attraction language English, even values word speak different. importantly, similar rows table, lower values four columns might even co-occur Flemish eat well.\nDistributional Hypothesis expresses observation words distributionally similar, like linguistics lexicography, semantically similar related, whereas words distributionally different, like linguistics chocolate, semantically different unrelated.rows table type-level vectors: aggregates attestations given lemma given corpus build overall profile. result, collapses internal variation lemma, .e. different senses semasiological structure. order uncover information, need build vectors individual instances tokens, relying principle: items occurring similar contexts semantically similar. instance, might want model three (artificial) occurrences study (1) (3), target item bold context words italics.like study lexicography?study computational linguistics well.eat chocolate study.Given , aggregate level, word can co-occur thousands different words, type-level vectors can include thousands values. contrast, token-level vectors can many nonzero values individual window size comprises, drastically reduces chances overlap vectors. fact, three examples don’t share item target. solution, inspired Schütze (1998), (selection ) context words around token replaced respective type-level vectors (Heylen, Speelman & Geeraerts 2012; Heylen et al. 2015; De Pascale 2019).\nConcretely, example (1) represented vector context word lexicography, , second row Table 2.1; example (2) sum vectors linguistics (row 1) computational (row 3); example (3) vector chocolate (row 5). solves sparsity issue, ensuring overlap vectors, also allows us find similarity (1) (2) based similarity vectors lexicography linguistics. see Section 2.3, can even use association strength context words target type, .e. study, give weight context words characteristic lemma try model.\nresult procedure co-occurrence matrix like one shown Table 2.2. row represents instance target lemma, e.g. study, column, lemma occurring corpus6; values (sum ) association strength words occur around token, .e. first-order context words, words columns, .e. second-order context words. addition, negative missing values value set zero, due unreliability negative pmi values (see Section 2.2.1).\nTable 2.2: Small example token-level vectors three artificial instances study.\nnext step workflow compare items . can achieve computing cosine distances vectors (see Section 2.2.2 technical description). resulting distance matrix, shown Table 2.3, tells us different token , takes minimum value 0, tokens, maximum value 1. can see (1) (2) similar , co-occur similar context words, .e. linguistics lexicography, drastically different (3), modelled based chocolate. specific selection context words crucial: selected computational lexicography model (2), resulted larger difference (1). series choices can make made research project discussed Section 2.3.\nTable 2.3: Cosine distance matrix three artificial instances study.\nTable 2.3 small simple, hundreds tokens? items compare one another, larger complex distance matrix becomes. order interpret , need stages processing. one hand, dimensionality reduction techniques mds, t-sne umap, discussed Section 2.2.3, offer us way visualizing distances models projecting 2d space. can represent model scatterplot, like plots Figure 2.1, point represents token, distances 2d space approximate distances multidimensional space co-occurrence matrix. Visual analytics, tool described Chapter 3, can help us explore scatterplot figure tokens distributed space, form groups form, etc.Word Sense Disambiguation\n\nmakes use clustering algorithms extract clusters similar tokens models. idea behind , distributional similarity correlates semantic similarity, groups similar tokens share sense different sense groups tokens. Chapter 6 see degree assumption holds data methods.final step workflow , , combination dimensionality reduction clustering, results right plot Figure 2.1: means dimensionality reduction, tokens located scatterplot distributional similarities approximated spatial similarities, groups similar tokens assigned different colours.\nprevious research, integrate clustering procedures manner, term cloud used refer full model (Heylen et al. 2015; Wielfaert et al. 2019; De Pascale 2019; Montes & Heylen 2022). study, instead, cloud refer clusters, identified colours scatterplot.\nFigure 2.1: 2d representation Dutch hachelijk ‘dangerous/critical.’\n","code":""},{"path":"workflow.html","id":"formulae","chapter":"2 From corpora to clouds","heading":"2.2 The chemistry of cloud making","text":"typical vector space model item--feature matrix: rows code items, columns code features, cells code information related frequency items features co-occur. first distributional models counted occurrences words documents represented word--document matrices; models described token--feature matrices, rows attestations lexical item features second-order co-occurrences, .e. context words context words token. Turney & Pantel (2010) offer overview different kinds matrices, based items modelled features used describe .\nBesides matrices, vector space models can tensors, generalisations matrices dimensions can allow complex interactions, e.g. subject-verb-object triples Van de Cruys, Poibeau & Korhonen (2013); see also Lenci (2018).Models can based co-occurrence counts, case studies, machine-learning algorithms trained predict context around word fill empty slot given words around . context-predicting models use weights neural networks features vectorial representations words predict. number papers explored kind models work best different tasks, uncertain results (Baroni, Dinu & Kruszewski 2014; Levy, Goldberg & Dagan 2015).\nexplained , context-predicting models explored dissertation, although integration interesting avenues research.workflow described previous section relies mathematical principles obtain linguistic patterns (mostly) raw corpus. full understanding formulae underlie step necessary grasp gist methodology, required appropriate implementation.\nsection, take deeper look technical aspects machinery behind process, particular association strengths, similarity metrics, dimensionality reduction techniques clustering algorithms.","code":""},{"path":"workflow.html","id":"pmi","chapter":"2 From corpora to clouds","heading":"2.2.1 Association strength: PMI","text":"distribution words corpus follows power law: items extremely frequent, items extremely infrequent. Association measures transform raw frequency information measure attraction two items taking account relative frequencies occur. typically manipulate, different ways, frequency node \\(f(n)\\), frequency collocate \\(f(c)\\), frequency co-occurrence \\(f(n,c)\\) size corpus \\(N\\). Evert (2009) Gablasova, Brezina & McEnery (2017) offer overview different measures computed used corpus linguistics; Kiela & Clark (2014)\n\ncompare measures used distributional models.studies discussed , use (positive) pointwise mutual information, (p)pmi (Church & Hanks 1989), one popular measures collocation studies distributional semantics (Bullinaria & Levy 2007; Kiela & Clark 2014; Jurafsky & Martin 2020; Lapesa & Evert 2014).\nformula shown equation (2.1), \\(p(n) = \\frac{f(n)}{N}\\), .e. proportion occurrences corpus correspond \\(n\\).\\[\\begin{equation}\n  (n, c) = \\log \\frac{p(n,c)}{p(n)p(c)} = \\log \\left( \\frac{f(n,c)}{f(n)f(c)} N \\right)\n  \\tag{2.1}\n\\end{equation}\\]Negative pmi values tend unreliable, positive pmi ppmi used, negative pmi values turned zeros (Bullinaria & Levy 2007; Kiela & Clark 2014; De Pascale 2019; Jurafsky & Martin 2020: 109).\nFurthermore, pmi known bias towards infrequent events: either \\(p(n)\\) \\(p(c)\\) low, pmi tends high. collocation studies, bias may counteracted combining pmi filters measures favour frequent co-occurrences, t-scores log-likelihood ratio (McEnery, Xiao & Tono 2010). distributional semantics, accuracy models rely ppmi seems affected issue presented bias;\nmoreover, studies lemma \\(f(n) < 217\\), .e. occurring less every two million tokens, excluded, avoid sparse, uninformative vectors.","code":""},{"path":"workflow.html","id":"cosine","chapter":"2 From corpora to clouds","heading":"2.2.2 Similarities and distances: cosine","text":"obtaining token--feature matrices, distances vectors must computed. Typically, implementations dimensionality reduction clustering can take item--feature matrices input compute distances --hood, necessarily offer option computing distance measure choice, cosine.Cosine measure similarity vectors \\(\\mathbf{v}\\) \\(\\mathbf{w}\\) defined equation (2.2); coincides normalised dot product vectors (Jurafsky & Martin 2020: 105).\\[\\begin{equation}\n  \\mathrm{cosine}(\\mathbf{v}, \\mathbf{w}) = \\frac{\\mathbf{v} \\cdot \\mathbf{w}}{\\left|\\mathbf{v}\\right|\\left|\\mathbf{w}\\right|} = \\frac{\\sum\\limits_{=1}^N v_iw_i}{\\sqrt{\\sum\\limits_{=1}^N v_i^2}\\sqrt{\\sum\\limits_{=1}^N w_i^2}}\n  \\tag{2.2}\n\\end{equation}\\]positive values, e.g. using ppmi, cosine similarity ranges 0 1: 1 identical vectors 0 orthogonal vectors, share nonzero dimensions, like study\\(_1\\) study\\(_3\\) Table 2.2. Cosine sensitive angle vectors, magnitude: similarity study\\(_1\\) vector created multiplying cells study\\(_1\\) constant still 1.Cosine similarity common metric distributional models (Jurafsky & Martin 2020: 105) shown outperform measures, especially combined ppmi (Kiela & Clark 2014; Lapesa & Evert 2014; Bullinaria & Levy 2007)7. One ways used semantic similarity tasks: nearest neighbours item extracted, selecting vectors highest cosine similarity target vector. studies, similarities usually transformed distances inverting scale (\\(\\mathrm{cosine}_{\\mathrm{dist}} = 1- \\mathrm{cosine}_{\\mathrm{sim}}\\)), identical vectors — vector — cosine distance 0 orthogonal vectors cosine distance 1, shown Table 2.3.applying dimensionality reduction clustering algorithms, cosine distances transformed aim giving weight short distances, .e. nearest neighbours, decreasing impact long distances. token vector \\(\\mathbf{v}\\) \\(n\\) dimensions, define transformed vector \\(\\mathbf{v}_{\\mathrm{transformed}}\\) \\(\\mathbf{v}_{\\mathrm{transformed}_i} = \\log (1 + \\log rank(\\mathbf{v})_i)\\) \\(\\), \\(1 \\le \\le n\\), \\(rank(\\mathbf{v})_i\\) similarity rank \\(\\)th value \\(\\mathbf{v}\\). example, originally distances \\(\\mathbf{v} = [0, 0.2, 0.8, 0.3]\\), rank transformation returns \\(rank(\\mathbf{v}) = [1, 2, 4, 3]\\), first logarithm transformation becomes \\([0, 0.693, 1.39, 1.099]\\) , second transformation, \\(\\mathbf{v}_{\\mathrm{transformed}} = [0, 0.52, 0.86, 0.74]\\). one hand, magnitude distance important ranking among nearest neighbours. , lower ranking, smaller impact: difference final values ranks 1 2 larger ranks 2 3.\nnew matrix, row \\(\\mathbf{v}\\) replaced \\(\\mathbf{v}_{\\mathrm{transformed}}\\), converted euclidean distances.cosine distances used measure similarity token-level vectors, euclidean distances used compare two vectors token across models, thus compare models . Concretely, let’s say two matrices, \\(\\mathbf{}\\) \\(\\mathbf{B}\\), two models sample tokens, built different parameter settings, want know similar , .e. much difference parameter settings make. values already transformed cosine distances. given token \\(\\) vector \\(\\mathbf{}_i\\) matrix \\(\\mathbf{}\\) vector \\(\\mathbf{b}_i\\) matrix \\(\\mathbf{B}\\). example, \\(\\) example (2) , vector \\(\\mathbf{}\\) based co-occurrence computational linguistics, shown Table 2.2, vector \\(\\mathbf{B}\\) based computational. euclidean distance \\(\\mathbf{}_i\\) \\(\\mathbf{b}_i\\) computed formula shown equation (2.3). running comparison tokens, distance models \\(\\mathbf{}\\) \\(\\mathbf{B}\\) computed mean tokenwise distances across tokens modelled : \\(d(\\mathbf{},\\mathbf{B}) = \\frac{\\sum_{=1}^nd(\\mathbf{}_i, \\mathbf{b}_i)}{N}\\). Alternatively, distances models come procrustes analysis8, like Wielfaert et al. (2019) , advantage returning value 0 1. However, method much faster returns comparable results.\\[\\begin{equation}\n    d(\\mathbf{}_i, \\mathbf{b}_i) = \\sqrt{\\sum\\limits_{=j}^n(a_j-b_j)^2}\n    \\tag{2.3}\n\\end{equation}\\]","code":""},{"path":"workflow.html","id":"dim-reduction","chapter":"2 From corpora to clouds","heading":"2.2.3 Dimensionality reduction for visualization: t-SNE","text":"Dimensionality reduction algorithms try reduce number dimensions high-dimensional entity retaining much information possible. distributional models, two main applications: one reduces thousands dimensions hundred, one reduces two.first application dimensionality reduction, techniques like svd (Singular Value Decomposition), meant deal sparsity high-dimensional vectors. Due frequency distribution discussed , many words never occur vicinity , resulting many zeros context-counting representations therefore inflated differences vectors. particular, techniques like Latent Semantic Analysis (Landauer & Dumais 1997) based observation dimensions obtained process semantically interpretable.\n\n\nalso used token-level spaces, comparisons discussed De Pascale (2019: 246) indicate don’t necessarily perform better non reduced spaces.\n\ndimensionality reduction techniques neural networks suggested ways condensing long, sparse vectors (Jurafsky & Martin 2020; Bolognesi 2020).\ngo technical aspects techniques implemented studies described . Instead, compared vectors different lengths based selection methods second-order features. Combining svd possible avenue future comparisons.second application dimensionality reduction used visualization purposes. token--feature matrix can understood multidimensional space: columns dimension space values cells coordinates items dimensions. can use cosine distances, measures angles: draw vector origin (zero dimensions) point coordinates, diverges vectors given angle grows wider vectors diverge, leading larger cosine distances. can mentally picture even draw positions, vectors angles 3 dimensions, distributional models hundreds thousands dimensions. applications dimensionality reduction, , built project distances items multidimensional space euclidean distances low-dimensional space can visualize. different implementations can receive token--feature matrix input, typically compute cosine distances items, distance matrix provided input instead.\nliterature tends go either multidimensional scaling (mds) t-stochastic neighbour embeddings (t-sne); recently, interesting alternative called umap introduced, ’ll discuss shortly.first option, mds, ordination technique, like principal components analysis (pca). used decades multiple areas (e.g. Cox & Cox 2008); relevant application case, non-metric multidimensional scaling, developed Kruskal (1964). tries different low-dimensional configurations aiming maximize correlation pairwise distances high-dimensional space low-dimensional space: items close together one space stay close together , items far apart one space stay far apart .\noutput mds can evaluated means stress level, .e. complement correlation coefficient: smaller stress, better correlation measures.\nUnlike pca, however, dimensions meaningful per se; two different runs mds may result plots mirror representing thing. Nonetheless, R implementation vegan::metaMDS() (Oksanen et al. 2020) rotates plot horizontal axis represents maximum variation.\ncognitive linguistics literature metric (Koptjevskaja-Tamm & Sahlgren 2014; Hilpert & Correia Saavedra 2017; Hilpert & Flach 2020)\nnon-metric mds (Heylen, Speelman & Geeraerts 2012; Heylen et al. 2015; Perek 2016; De Pascale 2019) used.second technique, t-sne (van der Maaten & Hinton 2008; van der Maaten 2014), also incorporated cognitive distributional semantics (Perek 2018; De Pascale 2019).\nalso popular computational linguistics (Smilkov et al. 2016; Jurafsky & Martin 2020); R, can implemented Rtsne::Rtsne() (Krijthe 2018).\nalgorithm quite different mds: transforms distances probability distributions relies different functions approximate . Moreover, prioritises preserving local similarity structure rather global structure: items close together high-dimensional space stay close together low-dimensional space, far apart high-dimensional space may even farther apart low-dimensional space.\nCompared mds, obtain nicer, tighter clouds (see Figure 2.2), distance less interpretable: even trust tokens close also similar high-dimensional space, extract meaningful information distance groups.addition, seem points far away high-dimensional space might show close together low-dimensional space (Oskolkov 2021).\ncontrast, Uniform Manifold Approximation Projection, umap (McInnes, Healy & Melville 2020), penalizes sort discrepancies. interesting avenue research, test current data reveal substantial improvements t-sne umap warrant replacement technique within duration project (see Figure 2.2 example default parameters. models, differences include longer shapes). known advantages increased speed observed small samples consideration — fact, R implementation umap (Konopka 2020) even slower.\nFigure 2.2: Two 2d representations model hachelijk ‘dangerous/critical’: bound5all-ppmiweight-focall. Non-metric mds top left, t-sne right umap bottom. Colours indicate hdbscan clusters.\nUnlike mds, t-sne requires setting parameter called perplexity, roughly indicates many neighbours preserved local structure cover. Low values perplexity lead numerous small groups items, higher values perplexity return uniform, round configurations (Wattenberg, Viégas & Johnson 2016). explored perplexity values 10, 20, 30 50, dataset 30 — default value R implementation — proved stable meaningful. Unless otherwise stated, figures text — including Figure 2.1 — illustrate t-sne token-level representations perplexity 30. represent distances models, instead, non-metric mds used (Section 3.2).mds t-sne need state desired number dimensions running algorithm — visualization purposes, useful choice 2. Three dimensions difficult interpret projected 2d space, screen paper (Card, Mackinlay & Shneiderman 1999; Wielfaert et al. 2019).\n\nmentioned , dimensions meaningless, hence axes axis ticks included plots. However, scales coordinates kept fixed: given three points \\(=(1, 1.5)\\), \\(b=(1, 0.5)\\) \\(c=(0, 1.5)\\), distance \\(\\) \\(b\\) (1 unit along \\(x\\)-axis) distance \\(\\) \\(c\\) (1 unit along \\(y\\)-axis).","code":""},{"path":"workflow.html","id":"hdbscan","chapter":"2 From corpora to clouds","heading":"2.2.4 Clustering: HDBSCAN","text":"word sense disambiguation tasks, vectorial representations different attestations clustered groups similar tokens. variety clustering algorithms, appropriate different kinds data structures. offer overview options, describe techniques used studies. section dedicated hdbscan, algorithm returns coloured clusters Figures 2.1 2.2. Section 2.4 discuss pam, uses select representative models.Hierarchical Density-Based Spatial Clustering Applications Noise, hdbscan friends (Campello, Moulavi & Sander 2013), clustering algorithm, .e. procedure identify groups similar items different groups. Unlike better-known cousins, try place items sample different groups, instead assumes dataset might noisy items may various degrees membership respective clusters. addition, density-based algorithm, tries discriminate dense areas, .e. groups elements similar , sparse areas, .e. larger distances elements.\nhdbscan, density area find point \\(\\) estimated calculating \ncore distance \\(core_{k}()\\), distance \\(k\\) nearest neighbour, \\(k\\) parameter \\(minPts - 1\\).\nmeasure base mutual reachability distance, shown equation (2.4), used compute new distance matrix single-linkage hierarchical clustering algorithm. result, items organised hierarchical tree, clusters selected based \\(minPts\\) requirement densities. related notion \\(core_k()\\) \\(\\varepsilon\\), defined radius around point \\(minPts - 1\\) can found.\\[\\begin{equation}\n    d_{mreach}(,b) = \\max(core_{k}(), core_{k}(b), d(,b))\n    \\tag{2.4}\n\\end{equation}\\]dbscan, need set \\(minPts\\) \\(\\varepsilon\\) threshold; procedure different, result equivalent cutting hierarchical tree hdbscan fixed \\(\\varepsilon\\), items threshold discarded noise, grouped respective clusters. contrast, hierarchical version, hdbscan, implements variable thresholds maximize stability clusters, therefore requires us input \\(minPts\\)9.R, algorithm can implemented dbscan::hdbscan() (Hahsler & Piekenbrock 2021). input can item--feature matrix , like case, distance matrix. output includes, among things, cluster assignment, noise points assigned cluster 0, membership probability values, core distances normalized per cluster, \\(\\varepsilon\\) values, can used estimate density.","code":""},{"path":"workflow.html","id":"params","chapter":"2 From corpora to clouds","heading":"2.3 Making it your own: parameter settings","text":"Building models implies making number choices, source data unit analysis, definition counts context, techniques parameters visualization clustering. Making decisions explicit crucial: one hand, necessary interpret models , , essential reproducibility.32 lemmas studied project, 200-212 models created, resulting combination parameter settings meant define first-order second-order contexts. choices kept fixed across models study, various reasons, among practicality best performance literature. parameter space virtually infinite, exploring even variations increased number models exponentially made kind thorough, qualitative descriptions performed infeasible. Admittedly, variable parameters remained fixed, fixed parameters varied. paths remain open future projects.\nsection, discuss decisions: ones remained fixed across studies variations characterize multiple models study. Fixed decisions specified names models; variable parameters, distinguish models , coded names. mentioned sections, described three parts: first-order parameters (Section 2.3.2), PPMI (Section 2.3.3) second-order parameters (Section 2.3.4). values parameter settings set monospace.","code":""},{"path":"workflow.html","id":"corpus","chapter":"2 From corpora to clouds","heading":"2.3.1 Fixed decisions","text":"First, analyses presented dissertation performed corpus Dutch Flemish newspapers: mode written genre, journalistic. Called QLVLNewsCorpus (De Pascale 2019: 30), combines parts Twente Nieuws Corpus Netherlandic Dutch (Ordelman et al. 2007) yet unpublished Leuven Nieuws Corpus. comprises articles published 1999 2004, belonging popular quality sources regions equal proportion10 amounting total 520 million tokens, including punctuation. corpus lemmatized tagged part--speech dependency relations Alpino (van Noord 2006).Second, unit analysis, lemma, defined combination stem part--speech11. applies items levels: definition target, first-order context features second-order features; co-occurrence frequencies association strength measures always computed lemma unit. distributional models traditions collocation research may use word forms instead12. one hand, stemming tagging add layer processing interpretation text; , word forms lemma tend behave different ways. lexicographic lexicological perspective, however, makes sense use lemma unit. head dictionary entries typical unit linguistic analysis. Furthermore, (mis)match word forms lemmas strongly depends language study: languages like Spanish, French, Japanese Dutch, verbs can take many different forms English; conversely, Mandarin lacks morphological variation even spaces count words. Concretely, word form hoop Dutch can correspond noun meaning either ‘hope’ ‘heap,’ verb meaning ‘hope,’ can also take forms hopen, hoopt, hoopte gehoopt depending person, number tense. interest, lexicological perspective, lies line studying behaviour noun hoop meanings, conflating noun one verbal forms homographic verb.respect, practical note order. target items study represented dictionary forms italics, followed approximate English translations single quotation marks: e.g. hoop ‘hope/heap,’ heilzaam ‘healthy/beneficial,’ herstructureren ‘restructure.’ Context words might represented figures stem part--speech combination used lemmas, e.g. word/verb, mentioned text part--speech excluded, e.g. passive auxiliary word. English translations belong part--speech Dutch term italics unambiguous possible. Dutch term English translations written way, translation included, e.g. journalist.Third, context words first-order second-order can, principle, part speech — except punctuation — must minimum relative frequency 1 2 million (absolute frequency 227) discarding punctuation token count full QLVLNewscorpus. 60533 lemmas corpus.Finally, described Section 2.2.1, attraction types measured ppmi, computed full co-occurrence matrix, .e. across full corpus, based symmetric window 4 tokens either side, including punctuation; see Turney & Pantel (2010) Kiela & Clark (2014) alternatives. Token-level vectors made adding type-level vectors context words.13\nvector comparison, cosine distances used transformed, explained Section 2.2.2. transformed cosine distances used input visualization techniques clustering algorithm. non-metric mds t-sne perplexity values 10, 20, 30 50 explored, analyses discussed second part dissertation based output solutions perplexity 30. Clustering performed hdbscan setting \\(minPts = 8\\).","code":""},{"path":"workflow.html","id":"foc","chapter":"2 From corpora to clouds","heading":"2.3.2 First-order selection parameters","text":"immediate context token first order context: therefore, first-order parameters influence elements immediate environment token included modelling said token. performed two stages: one dependent whether syntactic information used, discussed section, one independent , shown Section 2.3.3.decisions based mix literature (e.g. Kiela & Clark 2014), tradition within Nephological Semantics project, linguistic intuition generalisations annotation concordance lines. see Chapter 4, manual annotation procedure included selecting words context token helpful disambiguation. window spans dependency information chosen context words used inform decisions .first stage, main distinction made models based bag--words (BOW), .e. care word order syntactic relationship, based dependency (.e. syntactic) information. Within former group, models may vary based whether sentence boundaries respected, length window size, part--speech filters. latter group includes models select context words based distance target terms syntactic relationships ((LEMMA)PATH models), models find context word match specific, predefined templates ((LEMMA)REL). parameters described detail .first split BOW models distinguishes include words outside sentence target (nobound) (bound). goal make models comparable dependency-based models, definition include words sentence target. However, models differ respect parameter tend extremely similar.\nrelevant window size: models can select context words symmetric window 3, 5, 10 tokens either side target, including punctuation. Window sizes typically larger token-level models type-level models (e.g. Schütze 1998; De Pascale 2019), , time, great majority context words selected annotation within span 3 words either side. practice, small span tends restrictive.\nFinally, models refine first-order selection part--speech filters: lex models include common nouns, adjectives, verbs adverbs, models implement restrictions. selection defined lex result trial errors, use refinement future studies, e.g. expanding lexical set proper names, pronouns certain prepositions. Moreover, useful distinguish modal verbs auxiliaries, one side, kinds verbs, information coded part--speech tags used corpus. practice, models tend behave similarly dependency-based models, lex tends redundant ppmi-based selection, described later.\nBag--words models indicated sequence three values pointing three parameters: e.g. bound5all indicates model respects boundaries, window span 5 words side part--speech filter.distinction BOW dependency-based models doesn’t depend much context words selected tailored selection specific\ntokens. example, closed-class element like preposition may distinctive particular usage patterns term might occur. However, frequent, multifunctional word easily occur immediate raw context target without actually related . Unfortunately, just narrowing window span doesn’t solve problem, since also drastically reduce number context words available token token model.\ncontrast, might also interested context words tightly linked target syntactic terms separated many words , widening window include imply much noise token token model.\ndependency-based model, instead, include context words certain syntactic relationship target, regardless number words BOW perspective.\nexemplify, let’s look (4), herhalen ‘repeat,’ bold, target, items italics captured PATH model.Als de geschiedenis zich werkelijk mocht herhalen, zijn Vitales dagen geteld. (De Morgen, 2004-08-02, Art. 98)\n‘[] history really repeated , Vitales’ days counted.’Als de geschiedenis zich werkelijk mocht herhalen, zijn Vitales dagen geteld. (De Morgen, 2004-08-02, Art. 98)‘[] history really repeated , Vitales’ days counted.’PATH models count steps target words syntactically related base selection according distance. one-step dependency path either head target direct dependent (parent child, kinship terms): case (4) includes reflexive pronoun zich modifying adverb werkelijk ‘really,’ depend directly herhalen ‘repeat,’ well modal mocht, target depends.\ntwo-step dependency path either head head target (grandparent), dependent dependent (grandchild), sibling. (4) includes subject geschiedenis ‘history,’ linked target modal, Als ‘.’ PATH models include features one-step two-step path target.\nthree-step dependency path either head head head target (great-grandparent), sibling head head (great-aunt), dependent dependent dependent (great-grandchild), dependent sibling (niece). (4) corresponds de ‘,’ depends geschiedenis ‘history,’ geteld ‘counted,’ als ‘’ depends . PATHselection2 models include three-steps path, none PATH models include context words beyond steps. threshold set based frequent syntactic distance lemmas case studies context words selected relevant disambiguation. Next selection2, PATH models take two formats. selection3 models include context words 3 steps away target, PATHweight models also incorporate distance information give weight context words directly closely target syntactic path.Finally, REL models base selection specific, predefined patterns. purpose, templates tailored parts speech target designed, based relationships annotated types context words selected informative annotation process. restrictive model, RELgroup1, selects following patterns:nouns: modifiers determiners target; items target modifier determiner, verbs target object subject.adjectives: nouns modified target direct modifiers (except prepositions); subject direct objects verbs target direct modifier predicate complement, one modal auxiliary .verbs: direct objects; active passive subjects (two modals active one); reflexive complement, prepositions depending directly target.typically restrictive: many lemmas, responsible loss large proportion tokens context words match patterns, remaining tokens often one two context words left. RELgroup2 models expand selection follows:nouns: conjuncts target (without conjunction); objects modifier target, items target depends via modifier.adjectives: object preposition modifying target; conjunct target (without conjunction); prepositional object verb modified target (modifier prepositional complement).verbs: conjuncts target; complementizers; nouns depending preposition; verbal complements, elements target verbal complement.Finally, nouns also RELgroup3 setting incorporates following relations:Objects modifiers items target subject modifier; subjects modifiers items target object modifier; modifiers modifiers target, items whose modifier target modifier.first-order parameters procure filters select context words environment token used model . Alternatively, dependency information included feature dimension. example, instead selecting zich ‘’ context word token (4) based bag--word distance, part--speech filter dependency relation target, use (zich, se) .e. “zich reflexive subject” first-order feature. type-level vector information verbs take geschiedenis ‘history’ subject. technical practical reasons, implemented studies discussed , fruitful path research.remainder dissertation, BOW used refer bag--words based models, opposed dependency-based models; PATH REL also umbrella terms models use different kinds dependency-based selection, specific terms, e.g. PATHweight used finer grained distinctions.","code":""},{"path":"workflow.html","id":"pmisel","chapter":"2 From corpora to clouds","heading":"2.3.3 PPMI selection and weighting","text":"PPMI parameter14 taken outside set first-order parameters applies BOW dependency-based models, although also affects selection first order context words. rationale behind words vicinity target token, regardless part--speech distance, equally informative meaning target. example, (4) geschiedenis ‘history’ zich ‘’ informative meaning herhalen ‘repeat’ werkelijk ‘really’ als ‘.’ Association strength measures like ppmi used give influence informative context words; indeed, given symmetric windowsize 4 ppmi computation QLVLNewsCorpus, ppmi geschiedenis ‘history’ zich ‘’ herhalen ‘repeat’ 3.79 1.97 respectively, values werkelijk ‘really’ als ‘’ 0.06 0.112.\nHeylen et al. (2015) weight contribution context word ppmi target, De Pascale (2019) adds ppmi llr (log-likelihood ratio) thresholds selection context words. However, measures meant represent relationship types, distinguish senses type: context word may indicative sense word yet particularly attracted word whole. example English verb go, due high frequency strong attraction noun church, yet necessary distinguish specific sense ‘religious service’ go church.reason, models can take three different settings relation PPMI parameter: weight, selection . weight selection apply additional filter output first-order parameters select context words positive pmi target. distinct PPMIno models, apply thresholds. difference first two weight also multiplies type-level vector context word pmi target, giving words strongly associated target type greater impact final vector target. three settings applied models resulting first-order combinations, one exception: PATHweight models combine PPMIweight.","code":""},{"path":"workflow.html","id":"soc","chapter":"2 From corpora to clouds","heading":"2.3.4 Second-order selection","text":"selection second-order features influences shape vectors: selected first-order features represented. Next fixed window size association measure used calculate values vectors, two variable parameters. First, part--speech filter may applied. value nav, second-order features extracted pool 13771 nouns, adjectives verbs used De Pascale (2019)15. alternative, , applies filters. Second, might reduce length vector, .e. number second-order features. One values, 5000, selects 5000 frequent features pool remaining part--speech filter. Pilot studies also explored models 10000 dimensions, similar ones 5000 dimensions.16 value vector length FOC, stands “first-order context,” uses union first-order context words tokens second-order dimensions. consequence, second-order dimensions tailored context sample, necessarily frequent, numbers remain hundreds, rarely surpassing 1500. practice, much difference models different second-order parameters, except 5000all models, tend perform worst. Examination distance matrices type-level vectors context words reveals cosine distances really large, probably due sparseness vectors. sense, interesting compare svd matrices based 5000 models already smaller (presumably denser) FOC models.","code":""},{"path":"workflow.html","id":"pam","chapter":"2 From corpora to clouds","heading":"2.4 The chosen ones: PAM","text":"multiple variable parameters return large number models: 212 nouns — additional REL templates — 200 verbs adjectives. see Chapter 3, can combine distances models dimensionality reduction techniques represent similarities models 2d space. addition, wanted evaluate models relation manual annotation, rank accuracy clustering solutions. However, want understand qualitative effect parameter settings modelling, especially consider manual annotation ground truth, need examine clouds individually, feasible human look hundreds models lemma.One approach efficient exploration parameter space identify settings make greater differences models. example, see models different PPMI settings different models different vector-length settings, prioritize looking models differ former parameter, setting latter constant value. Unfortunately, quantitative effect parameters straightforward. First, parameters tend make big difference modelling include choice dependency BOW , within , window size part--speech filters, well distinction REL PATH. resulting combinations still numerous examine simultaneously (see Chapter 3). Second, relevant parameters interact : PPMI often makes little difference among lex models — tends redundant, since open-class items captured lex tend higher ppmi — makes greater difference among dependency-based models. Finally, various parameter settings impact within lemma, revised lemmas study.approach based quantitative effect parameter settings distances models reduce number models examine, great degree. Given limited number models can look simultaneously still making sense — around 8 9 — need cover multiple combinations strong parameters, still need look four five partially overlapping sets 8-9 models per lemma. example, set 9 models generated taking bound3 bound10 models PPMIweight FOCnav second-order vectors, order look effect part--speech filter little window-size variation, PATH REL. , PPMIweight switched PPMIno look effect new conditions, resulting 9 models. effect indeed different, likely, different set 8-9 models generated different values PPMI, keeping part--speech constant value. groups maximally different : due interaction parameters, many models extremely similar, proper qualitative description becomes challenging. Moreover, given set models reveal pattern captured previous set models, researcher might want go back look .alternative approach use clustering algorithm , next selecting groups similar models, identifies models represent clusters. Partition Around Medoids, pam (Kaufman & Rousseeuw 1990), implemented R cluster::pam() (Maechler et al. 2021), exactly . Unlike hdbscan clustering algorithms, requires us set number clusters beforehand, tries find organization maximizes internal similarity within cluster distances clusters.\npurpose, settled 8 medoids lemma. number meant achieve best clustering solutions — number applied lemmas equal success, given variability differences models. goal, instead, set models small enough visualize simultaneously (screen, reasonable size) big enough cover variation across models. lemmas, might much variation, medoids, .e. representative models, might redundant . However, long can cover () visible variation across models medoids reasonably good representatives models corresponding clusters, method fulfilling goal.representativeness medoids lemmas studied tested different ways.\n\ndon’t require clusters models different , long medoids represent properly. Instead, priority check patterns within models represented medoid, e.g. terms accuracy towards annotated senses. example, medoid tends group senses together well (measured example kNN SIL, explained Chapter 5 applied clustering solutions), models represents similar tendencies well.\nimportantly, different patterns previously identified plots exploring models first approach looked medoid selection, corroborate medoids covered least much variation time- energy-consuming approach. patterns found. addition, small random samples within cluster models visually scanned — thoroughly examined — assess similarity representative medoid. great majority cases comparison satisfactory. wonderful effect visual exploration, lets us focus 8-9 models quite different instead multiple sets models less variation. Visually, medoids approach informative less tiresome.result explorations, qualitative analyses based medoids: representative models selected pam. clustering algorithm, order avoid confusion clusters tokens, take centre stage, avoid referring clusters models — , , specify clusters models. preferred name “models represented medoid.” Given clustering algorithm used tokens hdbscan, medoid always refer representative model.","code":""},{"path":"workflow.html","id":"workflow-summary","chapter":"2 From corpora to clouds","heading":"2.5 Summary","text":"process token-level vector space models clouds studied particular created, takes number transformative steps. chapter broken process detailed layers mathematical linguistic processing lying raw corpus final clouds. Next overall description workflow, technical background important aspects introduced detail. Afterwards, explained parameter settings characterize models analyzed project.\nChoices made alternatives suggested: path taken one many possible alternatives. fact, core research project exploration alternatives, investigation effect variable parameters final linguistic representation, search clues, guidelines, recipe clouds seek. exploration combines quantitative techniques — heart process cloud creation — qualitative analyses meant describe clouds really modelling.combining vector representations visualization techniques /clustering algorithms, can make sense patterns otherwise escape us. Visual analytics provides us tools explore output comfortable, intuitive — sometimes deceiving — ways. next chapter, look two visualization tools developed within larger project Nephological Semantics enable support qualitative analyses.","code":""},{"path":"nephovis.html","id":"nephovis","chapter":"3 Visualization tools","heading":"3 Visualization tools","text":"Clouds prime matter study. condensed, information-rich representations patterns found corpus , according Distributional Hypothesis, tell us something meaning words examination. don’t tell us anything : need develop implement tools extract information. Chief among tools web-based visualization tool (Montes & QLVL 2021), originally developed Thomas Wielfaert within Nephological Semantics project (see Wielfaert et al. 2019), continued myself17. chapter present rationale features offers, elaboration Montes & Heylen (2022).Section 3.1 offer overview rationale behind tool minimal path researcher take levels. Sections 3.2 3.4 zoom levels, describing current features still waiting wish list. Section 3.5 follows description ShinyApp (Chang et al. 2021): extension18 third level visualization additional features tailored exploring relationship 2d representations hdbscan output. Finally, conclude summary Section 3.6.","code":""},{"path":"nephovis.html","id":"nepho-overview","chapter":"3 Visualization tools","heading":"3.1 Flying through the clouds","text":"visualization tool described , call NephoVis, written Javascript, making heavy use d3.js library, designed beautiful web-based data-driven visualization (Bostock, Ogievetsky & Heer 2011). d3 library allows designer link elements page, circles svg, dropdown buttons titles, data structures arrays data frames, manipulate visual elements based values linked data items. addition, offers handy functions scaling mapping, .e. fit relatively arbitrary ranges coordinates pixels screen, map colour palette19 set categorical values.seen Chapter 2, final output modelling procedure 2d representation distances tokens, can visualized scatterplot. Crucially, interested exploring individual models, comparing range models generated variable parameters. Section 2.2.2 discussed procedure measure distance models, can provided input non-metric mds, Section 2.4 presented technique used select representative models, medoids. result, access following datasets lemmas:distance matrix models.data frame one row per model, nmds coordinates based distance matrix, columns coding different variable parameters pieces useful information, number modelled tokens.data frame one row per token, 2d coordinates models information sense annotation (see Chapter 4), country, type newspaper, selection context words concordance line.data frame one row per first-order context word useful frequency information.practice, data frame tokens split multiple data frames coordinates corresponding different dimensionality reduction algorithms, nmds t-sne different perplexity values, another data frame rest information. addition, one recent features visualization tool includes possibility compare individual token-level model representation type-level modelling first-order context words. However, feature still development within NephoVis can better explored ShinyApp extension (Section 3.5).order facilitate exploration information, NephoVis organized three levels, following Shneiderman’s Visual Information Seeking Mantra: “Overview first, zoom filter, details--demand” (1996: 97). core tool interactive, zoomable scatterplot, goal functionality adapted three levels.\nLevel 1 scatterplot represents full set models allows user explore quantitative effect different parameter settings select small number models detailed exploration Level 2.\nsecond level shows multiple token-level scatterplots — one selected models —, therefore offers possibility compare shape organization groups tokens across different models. selecting one models, user can examine Level 3, focuses one time. Shneiderman (1996)’s mantra underlies flow across levels features within : level zoomed , filtered version level ; individual plots Levels 1 3 literally zoomable; cases possible select items detailed inspection. Finally, number features — tooltips pop-tables — show details demand, names models Level 1 context tokens two levels.\nFigure 3.1: Portal https://qlvl.github.io/NephoVis/ July 2021.\nCurrently, https://qlvl.github.io/NephoVis/ hosts portal shown Figure 3.1, eventually leads user Level 1 page lemma choice20, shown Figure 3.2 described detail Section 3.2. exploring scatterplot models, user can look structure distribution parameters plot.\nexample, colour coding may reveal models nouns, adjectives, verbs adverbs first-order context words (lex) different without strong filters part--speech, mapping values colours reveals distinct groups plot. contrast, mapping sentence boundaries restriction (bound/nobound) might result mix dots different colours, like fallen bag m&m’s, meaning parameter makes little difference. Depending whether user wants compare models similar different , parameters like keep fixed, use individual selection buttons choose models Level 2. \nSelect medoids\nbutton21 quickly identifies predefined medoids. clicking \nLEVEL 2 button,\nLevel 2 opened new tab, shown Figure 3.3.Level 2, user can already compare shapes models take respective plots, distribution categories like sense labels, number lost tokens. multiple dimensionality reduction techniques used, \nSwitch solution button allows user select one watch models readjust new coordinates short animation. addition, \nDistance matrix button offers heatmap pairwise distances selected models.\nSection 3.3 explore relevant features aid comparison across models, brushing sections model find tokens different models accessing table frequency information context words co-occurring selected tokens. Either clicking name model \nGo model dropdown menu, user can access Level 3 explore scatterplot individual model. Section 3.4 show, Level 2 Level 3, built around token-level scatterplots, share large number functionalities. difference lies possibility examining features particular model, reading annotated concordance lines highlighting information captured model selecting tokens based words co-occur . practice, user switch back forth Level 2 Level 3: comparing number models digging particular models.\nFigure 3.2: Level 1 heffen ‘levy/lift’.\n\nFigure 3.3: Level 2 medoids heffen ‘levy/lift.’\ngoing detailed description level, note order. already mentioned Section 2.2.3, dimensions resulting nmds — used levels — t-sne — used levels 2 3 — meaningful. consequence, axes axis ticks plots. However, units kept constant within plot: one unit \\(x\\)-axis length pixels one unit \\(y\\)-axis within scatterplot; equality, however, valid across plots. Finally, code open-source available https://github.com/qlvl/NephoVis.","code":""},{"path":"nephovis.html","id":"nepho1","chapter":"3 Visualization tools","heading":"3.2 Level 1","text":"protagonist Level 1 interactive zoomable scatterplot glyph, default steel blue wye (“Y”), represents one model. scatterplot aims represent similarity models coded nmds output allows user select models inspect according different criteria. Categorical variables (e.g. whether sentence boundaries used) can mapped colours shapes, shown Figure 3.4, numerical variables (e.g. number tokens model) can mapped size.\nFigure 3.4: Level 1 heffen ‘levy/lift’; plot colour-coded first-order part--speech settings; NA stands dependency-based models.\nselection buttons left panel, well legends colour shape, can used filter models certain parameter setting. options generated automatically reading columns data frame models interpreting column names starting foc_ representing first-order parameter settings, starting soc_ second-order parameter settings. Different settings parameter interact relationship, since mutually exclusive, settings different parameters combine relationship. example, clicking grey bound lex buttons bottom left, BOW models part--speech filter sentence boundary limits22 selected. clicking lex , BOW models selected, regardless part--speech filter, dependency-based models (part--speech relevant) excluded. counter , circled Figure 3.5, keeps track number selected items, since Level 2 allows 9 models comparison23. procedure meant aid selection based relevant parameters, described Section 2.4. Figure 3.5, instead, Select medoids button used quickly capture medoids obtained pam.\nModels can also manually selected clicking glyphs represent .\nFigure 3.5: Level 1 heffen ‘levy/lift’ medoids highlighted.\n","code":""},{"path":"nephovis.html","id":"nepho2","chapter":"3 Visualization tools","heading":"3.3 Level 2","text":"Level 2 shows array small scatterplots, represents token-level model. glyphs, default steel blue circles, stand individual tokens, .e. attestations chosen lemma given sample. original code level inspired Mike Bostock’s brushable scatterplot matrix, scatterplot matrix , current implementation somewhat different.dropdown menus sidebar (Figure 3.3) read columns data frame variables, can include sort information tokens, sense annotation, sources, number context words model, concordance lines, etc. Categorical variables can used colour- shape-coding, shown Figure 3.8, senses chosen lemma mapped colours; numerical variables, number context words selected given lemma, can mapped size. Note mapping applied equally selected models: current code allow variables — coordinates — adapt specific model scatterplot. purview Level 3.examining scatterplots, small note made distance matrix mentioned . heatmap corresponding medoids heffen ‘levy/lift’ shown Figure 3.6.\nnmds representation Level 1 tried find patterns keep relative distances models faithful original positions possible, transformation always loses information. Given restricted selection models, however, actual distances can examined compared easily. heatmap maps range values intensity colours, making patterns similar/different objects easier identify. example, Figure 3.6 shows sixth medoid different medoids except seventh, second medoids quite different others except first. Especially model selection followed criterion based strong parameter settings, e.g. keeping PPMI constant look interaction window size part--speech filters, heatmap reveal patterns slightly distorted dimensionality reduction Level 1 even hard pinpoint visually comparing scatterplots. even medoid selection, aims find representatives maximally different (least core elements maximally different groups), heatmap can show whether medoids drastically different, conversely, similar others.\nreference, heatmap particularly useful check hypotheses visual similarity models. example, unlike heffen ‘levy/lift’ Figure 3.8, colour-code medoids haten ‘hate’ manual annotation (Figure 3.7), models look equally messy. see , can brush sections plot see , least, tokens close together one medoid also close together another (spoiler alert: case). heatmap distances confirms models equally different , indeed, messy particular way.\nFigure 3.6: Heatmap distances medoids heffen ‘levy/lift.’\n\nFigure 3.7: 2D representation medoids haten ‘hate,’ colour-coded senses, next heatmap distances models.\nNext colour-coding, Figure 3.8 also illustrates hovering token shows corresponding identifier24 concordance line. Figure 3.9, hand, showcases brush--link functionality. brushing specific model, tokens found area highlighted rest made transparent. functionality missing Level 1, also available Level 3. Level 2 enhances power feature selecting tokens rest models, whatever area occupy. Thus, can see whether tokens close together one model still close together different model, specially handy uniform plots, like one haten ‘hate’ Figure 3.7. Figure 3.9 reveals tokens selected second medoid , indeed, quite well grouped five medoids around , different degrees compactness. also highlights two glyphs right margin bottom right plot. Level 2, margin gathers tokens selected modelling lost model question due lack context words. case medoid 6, combination bound3lex PPMIselection, extremely selective, tokens context words captured.\nFigure 3.8: Level 2 medoids heffen ‘levy/lift,’ colour-coded categories manual annotation. Hovering token shows concordance line.\n\nFigure 3.9: Level 2 medoids heffen, colour coded categories manual annotation. Brushing area plot selects tokens area positions models.\ngiven model, expect tokens close together share context word, /context words distributionally similar : type-level vectors near neighbours. Therefore, inspecting model, might want know context word(s) pull certain tokens together, tokens expect together far apart instead. individual models, can best achieved via ShinyApp described Section 3.5, NephoVis also includes features explore effect context words, frequency tables.\nLevel 2, comparing different models, frequency table one row per context word one two columns per selected model, e.g. medoids. table shown Figure 3.10.\ncolumns table computed NephoVis based lists context words per token per model. Next column name context word, default table shows two columns called “total” two per model, headed corresponding number either “+” “-” sign. “+” columns indicate many selected tokens model co-occur word row; “-” columns indicate number non selected tokens co-occur word. “total” columns indicate, respectively, number selected non-selected tokens context word captured least one model.\ncrucial understand , comes distributional modelling, context word simply word can found concordance line token, item captured given model. Therefore, word can context word model, excluded different model stricter filters. example, screenshot25 Figure 3.10 gives us glimpse frequency table corresponding tokens selected already Figure 3.9. frequent context word 31 selected tokens, .e. first row table, noun glas ‘glass,’ used expressions een glas heffen op iemand ‘toast someone, lit. lift glass someone.’ columns models 1 2 show glas ‘glass’ captured models 31 selected tokens. column 3, however, positive column reads 29, indicates model missed co-occurrence glas ‘glass’ two tokens. names top plots reveal first two models window size 10, third restricts 5, meaning two missed tokens glas ‘glass’ occurs 6 10 slots away target. likely orange tokens bit far right main highlighted area third plot. Finally, fourth model, hidden behind table, glas ‘glass’ missed one 31 tokens captured 2 tokens excluded selection. moved window table see PATHweight model: missed co-occurrence must within bow window span far dependency path, wile two captured co-occurrences “-” column must within three steps dependency path beyond bow window span 10. useful frequency information available context words captured least one model selected tokens. addition, Select information dropdown menu gives access range transformations based frequencies, odds ratio, Fisher Exact cue validity.\nFigure 3.10: Level 2 medoids heffen ‘levy/lift,’ frequency table context words co-occurring selected tokens across models.\nlayout Level 2, showing multiple plots time linking tokens across models, fruitful source information, limits. exploit model-specific information, go Level 3.","code":""},{"path":"nephovis.html","id":"nepho3","chapter":"3 Visualization tools","heading":"3.4 Level 3","text":"Level 3 visualization tool shows zoomable, interactive scatterplot glyph, default steel blue circle, represents token, .e. attestation target lexical item. optional second plot added right, glyph, default steel blue star, represents first-order context word, coordinates derive applying dimensionality reduction technique type-level cosine distances context words.\nname model, coding parameter settings, indicated top, followed information dimensionality reduction technique. Like two levels, possible map colours shapes categorical variables, e.g. sense labels, sizes numerical variables, e.g. number available context words, legends clickable, allowing user quickly select items given value.Figure 3.11 shows Level 3 looks like access clicking name second model Figure 3.9. Colour-coding selection transferred levels, can keep working information wish . Conversely, change mappings selections Level 3, based model-specific information, return Level 2 (refresh page) compare result across models. example, frequency table Figure 3.10 shown us glas ‘glass’ also captured tokens outside selection, reason believe selected tokens co-occurred glas ‘glass’ model, input glas/noun Features model field order select tokens glas ‘glass’ captured model, . maybe like find tokens glasje ‘small glass’ occurs, sure lemmatized, can input glasje Context words field find tokens include word form concordance line, regardless whether lemma captured model26.sum, (groups ) tokens can selected different ways, either searching words, inputting id token, clicking glyphs brushing plots.27 Given selection, clicking Open frequency table call pop-table one row per context word, column indicating many selected tokens occurs, columns pre-computed information pmi (see Figure 3.12). values can interesting like strengthen weaken filters smarter selection context words.Like Level 2, Level 3 also offers concordance line token hovering . unlike Level 2, concordance can tailored specific model focus, shown Figure 3.11. visualization tool generate tailored concordance line model, finds column data frame starts _ctxt matches beginning name model identify relevant format. similar system used find appropriate list context words captured model token. models, selected context words shown boldface , PPMIweight models one shown Figure 3.11, ppmi values target, e.g. heffen, shown superscript.\nFigure 3.11: Level 3 second medoid heffen ‘levy/lift’: bound10all-ppmiweight-5000all selected tokens. Hovering token shows tailored concordance line.\n\nFigure 3.12: Level 3 second medoid heffen ‘levy/lift’: bound10all-ppmiweight-5000all. frequency table gives additional information context words co-occurring selected tokens.\nseen along chapter, modelling pipeline returns wealth information requires complex visualization tool make sense exploit efficiently. Javascript tool described now, NephoVis, developed used people within Nephological Semantics projects, meant deployed much broader audience benefit multiple features. can still grow, open-source code makes possible anyone adapt develop . Nevertheless, practicality reasons, extension developed different language: R. dashboard described next section elaborates ideas originally thought NephoVis particularly tailored explore relationship t-sne solutions hdbscan clusters individual medoids.","code":""},{"path":"nephovis.html","id":"shiny","chapter":"3 Visualization tools","heading":"3.5 ShinyApp","text":"visualization tool discussed section written R shiny library (Chang et al. 2021), provides R functions return html, css Javascript interactive web-based interfaces. interactive plots rendered plotly (Sievert et al. 2021). Unlike NephoVis, tool requires R server run, hosted shinyapps.io instead static Github Page28. takes form dashboard, shown Figure 3.13, tabs, multiple boxes dropdown menus explore different lemmas medoids. functionalities described page dashboard, relevant features described illustrated.sidebar dashboard offers range controls. Next choice viewing dashboard reading documentation, two dropdown menus offer available lemmas medoids, number. selecting one, full dashboard adapts return appropriate information, including name model orange header top. bottom half sidebar gives us control definition relevant context words terms minimum frequency, recall precision, explained .\nFigure 3.13: Starting view ShinyApp dashboard, extension Level 3.\nmain tab, t-SNE, contains four collapsable boxes: blue ones focus tokens green ones, first-order context words. top boxes (Figure 3.14) show t-sne representations (perplexity 30) tokens context words respectively, like find Level 3 NephoVis. However, differences NephoVis crucial.First, colours match pre-computed hdbscan clusters (\\(minPts = 8\\)) changed; addition, transparency tokens reflects \\(\\varepsilon\\). goal dashboard , , combine 2d visualization hdbscan clustering better understanding models. functionality currently available NephoVis , unlike sense tags, model-dependent categorical variable29.Second, type-level plot use stars lemmas context words . importantly, matched hdbscan clusters based measures frequency, precision recall. short, context words can deemed relevant definition characterization cluster clearly visible assigned colour cluster represent best; rest context words faded background. radio button sidebar offers option highlight context words “relevant” noise tokens well.Third, tooltips offer different information NephoVis: list captured context words case tokens, relevance measures well nearest neighbours context word type-level plot. example, left side Figure 3.14 see token-level model shown Figure 3.11. Hovering one tokens bottom left light blue cluster, can see list context words model caputes : seen bold NephoVis rendering hovering token. Among , glas/noun ‘glass’ highlighted, one surpasses relevance thresholds set. right side figure, .e. type-level plot can see similarities context words surpass thresholds cluster, hovering one provides us additional information. case glas/noun ‘glass,’ first line reports represents 31 tokens light blue hdbscan clusters, recall 0.94, .e. co-occurs 94% tokens cluster, precision 1, .e. co-occurs tokens cluster. see list nearest neighbours, , context words similar type-level cosine similarity. fact similarity nearest neighbour 0.77 (range 0 1) worrisome.\nFigure 3.14: Top boxes t-SNE tab ShinyApp dashboard, active tooltips.\ntwo bottom boxes tab show, respectively, concordance lines highlighted context words information cluster sense, scatterplot mapping context word precision, recall frequency cluster. darker lines inside plot guide towards threshold: case, relevant context words need minimum precision recall 0.5, modified lines move accordingly. colours indicate cluster context word represents, size frequency , also reported tooltip. Unlike type-level plot , can see whether context words co-occur tokens different clusters. Figure 3.15 shows right-side box next top token-level box. one dots clicked, context words co-occurring context word — regardless cluster — highlighted token-level plot, table concordance lines filtered selection tokens.\nFigure 3.15: Token-level plot bottom plot context words t-SNE tab ShinyApp dashboard, one context word selected.\nfirst tab dashboard extremely useful tool explore hdbscan clusters, (mis)match t-sne representation role context words. addition, HDBSCAN structure tab provides information proportion noise per medoid relationship \\(\\varepsilon\\) sense distribution cluster. Finally, Heatmap tab illustrates type-level distances relevant context words, ordered coloured cluster, shown Figure 3.16. cases, confirms patterns found type-level plot; others, like model, shows context words extremely different , forming clear patterns. typical result 5000all models like one shown tends lead bad token-level models well.\nFigure 3.16: Heatmap type-level distances relevant context words ShinyApp dashboard.\n","code":""},{"path":"nephovis.html","id":"nepho-summary","chapter":"3 Visualization tools","heading":"3.6 Summary","text":"chapter two visualization tools exploration token-level distributional models described. open-source, web-based interactive. developed within Nephological Semantics projects KU Leuven constitute backbone research described dissertation.Data visualization can beautiful contribute successful communication, main goal provide insight (Card, Mackinlay & Shneiderman 1999). Indeed, tools provided valuable interface otherwise inscrutable mass data.\nNephoVis offers informative path organization models organization tokens, representing abstract differences generated complicated algorithms intuitive distances points screen. Selecting different kinds models moving back forth different levels granularity just click away incorporates various sources information simultaneously: find models window size 5, look side side, zoom prettiest one, read token, read token next , find sense annotation, go back selection models… Abstract corpus-based similarities instances word, ways representing similarities (.e. models) become tangible, colourful clouds screen.\npoints discussed second part dissertation simply impossible tools. Hopefully, prove least half valuable future research projects.","code":""},{"path":"dataset.html","id":"dataset","chapter":"4 Case studies","heading":"4 Case studies","text":"Every empirical study needs dataset. methodological orientation project means aim linguistic description phenomenon , development tool aid description. Therefore, order test workflow described Chapter 2 visualization tools described Chapter 3, methodology applied dataset. purpose, 32 Dutch nouns, adjectives verbs exemplifying range semasiological phenomena selected. phenomena include: homonymy case nouns, interaction semantic variation argument structure case verbs , parts speech, metaphor, metonymy generalization/specialization. goal explore phenomena revealed distributional models whether related certain parameter settings.Homonymy occurs lemma two (sets ) senses semantically etymologically related. rest relationships senses can broadly classified generalization/specialization, metaphor, metonymy. Specialization generalization two sides coin: one senses involved applied particular context situation, much broader application. Crucially, process involves additional semantic feature. example, herstructureren ‘restructure’ can applied range situations, applies companies parts companies particular mean ‘change structure something’ also ‘reduce personnel,’ missing general application. direction relationship, .e. whether first sense generalization second way around, relevant purposes study. relevance instead linked expectation specialized senses easily identified general ones.\nWithin Cognitive Linguistics, metaphor metonymy understood cognitive principles influence semantic structure, rather mere expressive tools. found interact , time, distinction always unambiguous\n(Lakoff & Johnson 2003; Barcelona 2015; Lemmens 2015; Geeraerts 2003).\nmetaphor described terms comparison, similarity mapping different domains, metonymy described terms reference, contiguity mappings within domain\n(Lemmens 2015).\nexample, grijs ‘gray’ applied weather-related term, e.g. grijze avond ‘gray evening,’ colour overcast sky stands weather metonymical mapping; applied abstract entity like buurt ‘neighbourhood’ metaphorical sense ‘boring, sad’ activated instead. However, definition counts domain without problems, leaving boundaries metaphor metonymy challenging define well (Croft 2003). purposes case studies, distinction relevant extent metonymical senses likely metaphorical senses occur contexts literal counterparts.practice, situation even complicated. case structural metaphors\n(Lakoff & Johnson 2003),\nmetaphorical extensions might elaborated means longer expressions. example, richten de spots op de zoektocht naar kandidaten ‘aim spotlights towards search candidates,’ richten ‘direct’ op ‘’ can co-occur either literal metaphorical senses spots ‘spotlight,’ zoektocht ‘search’ cue makes literal sense less appropriate. leads us situation already discussed \nGeeraerts (2003)\nregarding interaction metaphor metonymy idiomatic composite expressions. case like hete aardappel ‘hot potato,’ sample always refers delicate situations nobody wants deal , adjective ‘hot’ literal metaphorical? Following Geeraerts’ prismatic model composite expressions,\nexplained combination literal heet ‘hot touch’ literal aardappel ‘potato’ together metaphorically understood delicate situation; reinterpretation complete mapping potato situation, property hot touch delicate avoided. degree reinterpreted mappings match systematic metaphorical metonymical mappings individual elements separate issue: argued heet, ‘conflictive’ meaning non idiomatic constructions, aardappel ‘potato.’ rule, cases annotated literal, understanding situation whole metaphorical.noted criteria argumentative justify selection lemmas, go . unfortunate, intriguing question mapping parameter settings phenomena negative answer. second part dissertation show, factors play role formation clouds, relegating traditional semantic categories secondary place, extras show. Nevertheless, phenomena accounted , questions asked , matter unsatisfactorily, answered.Hence, chapter focuses selection, collection annotation dataset methodology tested. First, Section 4.1 introduce 32 selected lemmas senses, making explicit aforementioned phenomena exhibit. discuss lemma detail; instead, expand used illustration Part II becomes relevant. Section 4.2 focus concordance lines collected manual annotation procedure. Relevant information regarding annotation also provided. Finally, Section 4.3 rounds description technical part dissertation.","code":""},{"path":"dataset.html","id":"selection","chapter":"4 Case studies","heading":"4.1 The lemmas","text":"selection lemmas aimed cover wide range phenomena: metaphor, metonymy, generalization/specialization, . nouns chosen exhibit homonymy polysemy: unrelated (groups ) meanings least one presents finer distinctions. selection adjectives also includes different kinds semantic extension mostly related kind noun modified . Finally, verbs combine syntactic semantic dimensions. definitions provided annotators respective examples translations English listed tables, examples shown chapter. Instead, relevant tokens contexts reproduced second part dissertation illustrate results analyses. Empty cells Dutch columns definitions indicate sense tags present original selection senses instead included annotation procedure — assigned second stage — based results annotation . Dutch definitions adaptations made Dirk Geeraerts based consultation dictionaries (e.g. Sterkenburg 1991; Boon, Geeraerts & Arts 2007) pilot surveys small concordances corpus.selection phenomena attached certain expectations. expected specific senses easier identify general senses, .e. identifiable context. regard nouns, homonyms expected discriminated easily internal distinctions. verbs, instead, expectation find confusion senses either shared semantic syntactic dimension senses .\nalso expected metonymical senses harder disambiguate synaesthetic metaphorical senses, since likely overlapping context concrete, literal senses.","code":""},{"path":"dataset.html","id":"nouns","chapter":"4 Case studies","heading":"4.1.1 The nouns","text":"set 7 nouns selected exhibit homonymy polysemy least one homonyms30, shown Table 4.1. purpose selection examine models dealt granularity, .e. hierarchies senses: homonyms easier disambiguate senses, since apply different contexts, maybe possible tune parameter settings different levels granularity, like adjusting focus camera.\nTable 4.1: Definitions examples senses 7 analysed nouns. sense, first number indicates homonym , second number, sense within homonym.\nThree nouns one frequent, monosemous homonym less frequent, polysemous one: hoop ‘hope/heap,’ spot ‘ridicule/show spotlight’ horde ‘horde/hurdle.’ polysemy phenomena varied. First, horde ‘hurdle’ can refer literal hurdles, e.g. races, sense metaphorical: abstract difficulties talked obstacles surpassed. addition, annotation new sense tag derived ‘horde’ included, cases members horde human beings, insects, cars entities.\nSecond, one hoop ‘heap’ senses refers literal heaps things can form pile, one generalization large quantities, e.g. een hoop werk ‘lot work.’ Finally, polysemous homonym spot two main senses linked metonymy, namely ‘short video,’ e.g. advertisement spot, ‘spotlight.’ ‘spotlight’ sense can also used either literally metaphorically (‘spotlight’); distinction included original definitions, annotators pointed added afterwards.31The four nouns two polysemous homonyms: schaal ‘scale/dish,’ blik ‘gaze/tin,’ stof ‘substance/dust…,’ staal ‘steel/sample.’\nFirst, frequent homonym blik (‘gaze’) concrete sense two metaphoric extensions: ‘intellectual look,’ attested sample, ‘perspective,’ quite infrequent. infrequent homonym, ‘tin,’ can either refer material , object made material (‘tin can’) content (‘canned food’); due low frequency difficulty part annotators distinguish senses, two last senses later combined one.\nSecond, frequent homonym stof two concrete, referentially distinct senses (‘substance’ ‘fabric’) abstract one (‘topic, material’). contrast, less frequent homonym distinguished two senses presenting subtle, context-specific difference: ‘dust (air)’ ‘dust’ ‘reducing something dust, pulverize.’ last sense infrequent excluded, another distinction emerged annotation, namely literal ‘dust’ ‘dust’ idiomatic expressions, stof doen opwaaien ‘controversial, lit. stir dust.’ new sense added , even though within idiomatic expression meaning stof still ‘dust,’ annotators kept confusing ‘topic, material’ sense, actually refers expressions stof voor een roman ‘material novel.’\nThird, schaal exhibits subtle perspective shifts one homonym (‘scale’) refers different concrete objects second ‘shell/dish,’ distinctive ‘shell’ sense removed due low frequency.\nFinally, staal ‘steel’ refer, like blik ‘tin,’ either material part object made — latter infrequent among sample, instead another sense identified, namely ‘steel industry.’ ‘sample’ homonym, hand, originally presented metaphorical distinction material samples ‘evidence’ abstract characteristics, modified annotation specialization distinction general samples, e.g. urine sample, (statistically) representative samples.can see, nouns present variety semantic phenomena finer granularity homonymy: metaphor case blik ‘gaze,’ horde ‘hurdle’ spot ‘spotlight,’ metonymy case horde ‘horde,’ blik ‘tin,’ staal ‘steel’ spot ‘videoclip/spotlight,’ generalization/specialization case staal ‘sample,’ schaal ‘dish’ hoop ‘heap,’ perspective shifts schaal ‘scale’ relationships frequent stof homonym.","code":""},{"path":"dataset.html","id":"adjs","chapter":"4 Case studies","heading":"4.1.2 The adjectives","text":"selection adjectives includes 13 lemmas presenting different kinds polysemy phenomena (Table 4.2). purpose selection examine models dealt semantic relationships whether extract different nouns modified target adjective.Three adjectives metonymic reading: hoopvol ‘hopeful,’ geestig ‘witty’ hachelijk ‘dangerous/critical.’\ngeestig hoopvol, one senses anthropocentric, .e. ’s mainly exclusively applied people: witty people witty things say , people express hope things inspire .\nhachelijk’s case, difference matter temporal telic perspective: things might go wrong situations already problematic.\nTable 4.2: Definitions examples senses 13 analysed adjectives.\nFour adjectives metaphoric readings: hoekig ‘angular,’ dof ‘dull,’ heilzaam ‘healthy/beneficial’ gekleurd ‘colourful/person colour/tainted.’\nHeilzaam two senses, distinguishing things literally healing, beneficial health, things metaphorically healing, beneficial general.\nHoekig gekleurd present three sense distinctions, one particularly concrete frequent, ‘angular form’ ‘colourful’ respectively, another one explicitly anthropocentric: ‘clumsy’ ‘non white.’ third sense distinction different quality: synaesthetic hoekig, applied rhythms, metaphoric gekleurd, meaning ‘tainted, corrupted.’\nFinally, dof concrete sense applied visual domain, synaesthetic extension applied sounds, abstract meaning applied feelings emotions; fourth meaning listed table attested.Three adjectives present form similarity readings: geldig ‘valid,’ hemels ‘heavenly’ gemeen ‘shared/mean….’\nGeldig ‘valid’ hemels ‘heavenly’ offer two options: one restricted specific context (laws reglaments geldig Heaven hemels) one much broader.\ncase gemeen quite complex, involving number rather subtle distinctions often co-exist attestation: .e. ‘common’ ‘shared,’ ‘average’ ‘ordinary.’Finally, remaining three adjectives present complex picture: heet ‘hot’ goedkoop ‘cheap’ literal senses different kinds entities also metaphorical extensions, grijs ‘grey’ metaphorical metonymical extensions.\nHeet ‘hot’ presents, first, three concrete senses differ perspective: temperatures objects, weather felt body; three senses metaphorical, .e. objects heet applied physically hot. Crucially, exclusive sense tag idiomatic expressions combination heet ‘hot’ concrete object (e.g. hang_ijzer ‘iron,’ aardappel ‘potato’) used metaphorically. Goedkoop, hand, presents modest set 4 sense distinctions: concrete, prototypical frequent sense (.e. cheap products), two perspectival shifts (.e. cheap shops cheap area) clear metaphor (.e. little values).\nFinally, grijs presents frequent, concrete sense, three specific metonymic extensions — weather hair, old people generations — two metaphorical ones — ‘boring’ ‘half legal.’ practice, ‘boring’ reading can include ‘sad, cheerful,’ ‘half legal’ sense general, applying ‘gray areas’ two poles.sum, adjectives include simple semasiological structures one kind semantic extension involved well complex interactions phenomena.","code":""},{"path":"dataset.html","id":"verbs","chapter":"4 Case studies","heading":"4.1.3 The verbs","text":"criterion select 12 verbs analysed cover range combinations syntactic semantic variation, goal exploring different parameter settings dealt interaction whether certain types models focus one aspect.32 senses translations shown Table 4.3.Four verbs always transitive senses can distinguished objects can take: people objects haten ‘hate,’ people opinions huldigen ‘honour/believe,’ concrete objects taxes heffen ‘levy/lift,’ statements decisions herroepen ‘recant/void.’Two verbs can transitive, distinction based direct object, intransitive: helpen ‘help’ herstructureren ‘restructure.’ cases intransitive sense semantically similar one transitive senses. example, intransitive sense one transitive senses herstructureren apply companies, connotation personnel reduced, transitive sense much general application.Three verbs can transitive, distinction based direct object, reflexive: diskwalificeren ‘disqualify,’ herhalen ‘repeat’ herinneren ‘remember/remind.’ case diskwalificeren ‘disqualify’ , lesser degree, herhalen ‘repeat,’ opposition can interpreted specific situation object subject coincide.\ncontrast, herinneren means ‘remember’ reflexive construction ‘remind’ transitive construction preposition aan; transitive construction without preposition can also attested (e.g. ik word herinnered als, ‘remembered ’) infrequently.\nTable 4.3: Definitions examples senses 12 analysed verbs.\nTwo verbs can transitive, intransitive reflexive, semantic distinctions within transitive structure: harden ‘make become hard/ tolerate’ herstellen ‘repair/ heal….’ senses harden can split two main groups. One closely related property ‘hardness,’ .e. turn something someone hard become hard, literal figurative sense, different constructions: intransitive literal sense om hun kaas te laten harden ‘order make cheese harden’ transtive figurative one Verdriet heeft haar gehard ‘Grief hardened .’ second group, however, includes one transitive construction specific pattern frequent sample others combined: (niet) te harden (‘() tolerate,’ always negative).Finally, haken ‘hook’ presents semantic distinctions within transitive intransitive structures. can refer literally metaphorically hooking something remaining hooked, also two specific senses: one characteristic football context, meaning ‘make someone trip (placing foot front ),’ ‘crochet.’sum, set verbs includes cases kind direct object plays role disambiguation cases interacts syntactic patterns. Moreover, specific ways kinds direct objects defined differ across verbs: animacy agency case haten concreteness case heffen. semantic distinctions can also rely broader context: diskwalificeren typically people direct object, sports-related context defines specific sense, characterised distinct motivations consequences.","code":""},{"path":"dataset.html","id":"extraction","chapter":"4 Case studies","heading":"4.2 The dataset","text":"32 lemmas listed , 300 tokens collected QLVLNewsCorpus (described Section 2.3.1). attestations manually annotated least three different people based definitions found Dutch column Tables 4.1, 4.2 4.3. Next sense assignment, later revised uniformity — include senses emerging annotation , mentioned — annotation included confidence assignment selection disambiguating context words.selection lemmas involved introspection well consultation lexical resources corpus data: thinking potential candidates, checking senses reported dictionaries (Sterkenburg 1991; Boon, Geeraerts & Arts 2007) estimating relative frequencies small concordances. tried avoid extremely skewed distributions approximating monosemous structure numerous infrequent senses unlikely stand model.33 end, see, sense frequency really issue, clouds don’t model senses anyways.exploration samples concordances also served calculation number tokens model annotate. Regardless actual frequency items corpus, minimum sample contained 240 tokens; raised 280 senses relative frequency 20% sample, 320 10%, 360 many senses therefore low frequency (e.g. heet). lower upper bound estimated pilot studies clouds large enough amount warrant use methodology small enough make sense visualization tool. Table 4.4 shows absolute frequency (520mw QLVLNewsCorpus) selected lemma, size sample distribution senses: boxplot rightmost column goes right, frequent one senses. example, long boxplots blik hoop indicate skewed distribution, .e. sense high frequency senses low frequencies, narrow, centred boxplots hachelijk hemels indicate senses equally frequent.\nsample extraction almost completely random, restriction two instances lemma extracted file. , however, duplicates, due repetition fragment different dates.\nTable 4.4: Absolute frequency lemmas corpus, number batches distribution senses. number next boxplots indicate number different senses.\ntokens concordance line extracted 15 words either side. Bachelor students Linguistics KU Leuven recruited hired manually annotate samples selected lemmas. tasked annotating 40 tokens 12 types (least three nouns, four adjectives four verbs, plus one either categories)34: total 480 tokens35, annotate 6 weeks. total, 9600 tokens annotated least three annotators; 10% annotated four. lemma split 6-9 batches 40 tokens, annotated different group annotators. annotators offered introductory meeting, video tutorial written guidelines, procedure performed individually.lemmas batches assigned randomly, keeping mind part--speech distribution. intention shuffle samples lemma splitting batches, something went wrong code ordered source; batch mostly tokens different newspaper.\nannotation involved three tasks:Assign sense predefined set definitions, namely Dutch column Tables 4.1 4.3. none tags apply, select “None ” explain ;Express confidence decision scale 6 values;Identify words context helped disambiguation.Since entering textual information spreadsheet can easily lead typos inconsistencies , furthermore, annotating helpful context words particularly challenging tool, user-friendly visual interface designed received input buttons returned output json format.\ninterface, available original form , menu list lemmas two tabs: overview concordance lines selected type annotation workspace (Figure 4.1). annotation workspace focused one concordance line36 (token) time, offering\nfirst text, series long radio buttons definitions examples, star rating option confidence evaluation, followed clickable reproduction text, text input field comments. long radio buttons meant annotators full definitions examples disposal every time assign sense given lemma, final output transformed decisions manageable codes, sense_1, sense_2, etc. clickable concordance lines let select context words deemed useful annotation procedure simply clicking ; program translated array positions relative target, e.g. [\"R1\", \"L2\"] first word right second left selected.37 Finally, text input field bottom available leave sort comment compulsory “None ” selected.\nFigure 4.1: Screenshot options annotation tool.\ndataset obtained procedure rich interesting variety purposes. token sense assignment, confidence evaluation selection informative cues least three different independent annotators, well comments least cases receive sense. Agreement annotators can measured coefficients Fleiss’ \\(\\kappa\\) (Fleiss 1971), illustrated Figure 4.2, resulting picture may unnecessarily complex. First, disagreement susceptible granularity: annotators might disagree senses noun homonyms, except confusion idiomatic senses stof ‘dust’ ‘topic, material’ sense. Second, annotators sensitive grammatical distinctions (e.g. transitive intransitive senses), strong reason disagreement herstructureren, helpen, haken herstellen. Third, disagreements sometimes concentrated one annotator, showed strong preference certain sense; , indicator ambiguity token misunderstandings part annotator. annotators exhibited almost excessive attention nuances, others much less thorough.importantly, great majority tokens\n(83.8%)\nmajority annotators agreed one tag remained official sense token.\ngathering exploring data, tokens reread final decision made sense tags. Figure 4.3 shows number tokens full agreement, majority agreement (.e. one annotator disagreed) agreement whether chosen sense kept final annotation, another tag applied token removed (e.g. tokens heet corresponded verb heten). category includes new senses suggested annotators well corrections misunderstandings, second original sense blik, annotators interpreted different ways actually attested dataset. cases agreement tokens annotated four annotators two selected senses remained, two disagreed.\nFigure 4.2: Agreement annotators per batch per lemma, computed irr::kappam.fleiss() (Gamer et al. 2019).\n\nFigure 4.3: Number tokens per lemma full, partial (majority) agreement, split whether majority sense kept changed. Removed tokens included.\naddition, final sense distribution significantly different much smaller pilot samples. Distribution across batches, instead, affected regional variation. example, Belgian sources include sports-related articles Netherlandic sources, leading variation sense distribution lemmas sense (diskwalificeren ‘disqualify,’ haken ‘make someone trip’ horde ‘hurdle’) across regions. discrepancy distribution across batches avoided tokens properly shuffled.Around 4% assigned tags “None ,” clearly uneven distribution. lemmas largest amount haken, 117 tokens three annotators chose “None ” 72 two . Heet harden follow 69 90 tokens 3 tags 14 10 two. Many due wrong lemmatization: concordance haken many instances afhaken ‘stop’ met haken en ogen, idiomatic expression noun; concordances heet harden included instances verb heten ‘call, named’ adjective hard respectively. similar way, many tokens concordance heffen instances opheffen ‘lift/cancel,’ annotators always catch cases. verbs afhaken opheffen separable verbs Dutch: constructions, prefix separated root, syntactic parser might confuse different verb preposition. Next issues, annotators assigned “None ” cases tokens match suggested senses, especially cases idiomatic expressions hete aardappel ‘hot potato.’ annotations classified four categories: wrong_lemma, cases wrongly selected concordance lines, assigned 413; not_listed, assigned 421 times, indicated lemma correct none suggestions applied; unclear (240 times) used token parsed annotator, (45 cases) referred doubt two given options. different classes informed later decisions whether add remove senses tokens.Tokens removed different reasons. Next cases concordance line belong begin (including adverbial uses adjectives), indecipherable tokens, extremely infrequent senses (e.g. 4, 5 tokens 250) duplicated tokens. total, 424 tokens removed, 109 belonged haken.Confidence values explored used, tend similar across batches, lemmas senses, tendency towards highest values variation across annotators instead: low confidence high confidence others. Figure 4.4 breaks terms degree agreement whether assigned tag matched one senses offered . Note top facet, “None ,” much lower counts lower facet. expect confidence ratings lower annotations agree votes token , relative terms, case. Confidence assignment “None ” tag ambiguous: annotators tend give minimum confidence confident meaning concordance line, others assign high value confident none options applies.\nFigure 4.4: Distribution confidence values across annotations, whether annotators agreed another token whether selected sense “None .”\nselection cues consulted defining parameter settings (Section 2.3): two annotators agreed sense tag context word given token, context word considered official cue sense. relative position representing cue output annotation tool, information available corpus extracted counted, lemma context word, dependency relation (distance) target bow distance target. example, Tables 4.5 4.6 list frequent dependency paths, lemmas window sizes across official cues heilzaam ‘healthy/beneficial’ senses. see Section 6.2.1, lemma characterised frequent nouns modified target, namely werking ‘effect,’ effect invloed ‘influence,’ ambiguous terms senses heilzaam: sentence de heilzame werking van look ‘healing power garlic,’ garlic better cue ‘health/beneficial’ distinction werking ‘effect, power.’ Nonetheless, annotators select context words cues senses, realising distinctive one sense. pattern fulfilled garlic example indeed captured cues, shown third line Table 4.5, much less frequent.\nTable 4.5: Four frequent dependency paths among cues heilzaam, counts per sense. NA indicates cue sentence target. path, CW stands cue T stands target: head left \\(\\rightarrow\\) dependents right, preceded name dependency relation.\n\nTable 4.6: Six frequent lemmas window spans among cues heilzaam, counts per sense.\n","code":""},{"path":"dataset.html","id":"ann-summary","chapter":"4 Case studies","heading":"4.3 Summary","text":"chapter looked dataset used test explore workflow visualization tools. selection lemmas described along semantic phenomena allow us test. Afterwards, annotation procedure delineated, extraction concordances assignment senses, confidence values cues.mentioned , lemmas, 200-212 models generated following workflow described Chapter 2. cues selected annotators informed decisions involved parameter settings. sense annotation applied assess well models performed disambiguation: initially, try match senses clustering solutions, looked spatial configuration might hide subtle relationships. examples Chapter 3 shown, much straightforward lemmas others.range semantic phenomena meant provide different possible aspects meaning distributional models might able capture. lexicological point view, “similarity distribution correlates similarity meaning” enough. similarity meaning?38 mean granular distinctions, senses within homonyms, difficult capture coarser distinctions, .e. homonyms ? metonymy, metaphor specialization modelled parameter settings? Can discriminated, can fine-tune models capture one ? role constructions: argument structure interfere modelling senses?\nquestions case studies presented tried address, following part dissertation present answers.","code":""},{"path":"shapes.html","id":"shapes","chapter":"5 A cloud atlas","heading":"5 A cloud atlas","text":"Clouds come many shapes. Like cotton-like masses droplets see skies, clouds word occurrences generated token-level distributional models may take different forms, depending density, size distinctiveness. “Meaning use,” “Differences usage correlate differences meaning,” “shall know word company keeps”39 catchy slogans sound intuitively accurate, hide wealth complexity variation. Like meaning, context far orderly, myriad words different characteristics interact generate variation see clouds.chapter, try make sense nephological topology, .e. variety shapes clouds may take. purpose, classify hdbscan clusters mapped t-sne representations way can help us understand see see cloud. starting point shape researcher sees t-sne plot, visually likened types meteorological clouds described technical terms.Section 5.1 discuss rationale behind particular classification tools used operationalize decisions. detailed description cloud type technical interpretations follows Section 5.2, Section 5.3 zooms back compare characteristics different types. Finally, summarize chapter Section 5.4.","code":""},{"path":"shapes.html","id":"theo2-rationale","chapter":"5 A cloud atlas","heading":"5.1 Rationale of the classification","text":"look t-sne plot token-level model, might see different kinds shapes. example, Figure 5.1 shows t-sne solution parameter configuration six different lemmas. clear, neat islands stand large mass, others look smooth uniform. Even uniformity might take rounder angular shapes, bursts density three four tokens get together. mentioned , t-sne solution looks uniform typically means perplexity high, whereas many small islands suggest low. However, models never seem look better perplexity values explored40.\nFigure 5.1: Uncoloured t-sne representations parameter settings (bound5lex-ppmiselection-focall) across six different lemmas.\nMapping hdbscan clustering solution \\(minPts = 8\\), like Figure 5.2 models shown Figure 5.1, proved decent system identifying structure see clouds. Clusters tend match tighter islands see, highlight dense areas might subtle eyes. cases, clustering solution visualization agree, e.g. clusters spread around overlap. can taken sign uncertainty, indication group tokens involved much harder describe model others algorithms agree.stage distance matrix, can establish, tokens, similarity token model. similarities independent : transform , even need respect triangle inequality41. contrast, clustering visualization add layer processing meant find patterns similar tokens different tokens. relationships different pairs tokens independent : nearest neighbours nearest tokens farther away. Sometimes patterns easy find, leads nice, interpretable clouds, like top plots Figure 5.2; sometimes hard find, resulting lots noise /less defined clouds, like last two plots.\nFigure 5.2: T-sne representations parameter settings (bound5lex-ppmiselection-focall) across six different lemmas, coloured coded hdbscan clustering. heet clusters gray clusters colours can clearly distinguish.\nchapter look classification possible shapes, know genesis can interpret . term cloud refer hdbscan cluster noise: coloured patches plots Figure 5.2. model , like picture sky, might present multiple clouds different types.see Chapter 6 well, factors interact produce group similar tokens include frequency context words, whether co-occur within sample type-level similarity. Clusters dominated one context word may look similar clusters dominated group similar context words, yet different semantic interpretations. Along way, keep mind patterns observed tendencies, rather rules: first map around unknown land still calls adventurous explorers.clouds classified five main categories additional, orthogonal feature. classification based combination t-sne visualization (perplexity 30) hdbscan (\\(minPts = 8\\)) probably different visualization techniques clustering algorithms used.main categories, described detailed Section 5.2, , descending degree clarity:Cumulus: defined clusters, revealing strong patterns t-sne hdbscan agree ;Stratocumulus: slightly looser definition still decent clouds;Cirrus: weakest, smallest, less defined clouds, resulting weaker patterns might immediately evident without colour coding;Cumulonimbus: massive clouds;Cirrostratus: hdbscan noise.inspiration names types clouds visual: shapes find mapping hdbscan clusters t-sne solution resemble shapes different types meteorological clouds. Admittedly, familiar meteorological types clouds, necessarily salient feature. Altitude, temperature composition, instead, relevant categorizing metereological clouds. see Section 5.3, possible map \\(\\varepsilon\\) (epsilon) values altitudes clouds, might already take metaphor far.Technical criteria defined order automatically categorize large number clusters. result theoretical reasoning trial error, final classification matches intuitions derived visual inspection. words: classification help us understand looking based shapes identify, technical, objective criteria designed approximate intuitions larger scale analysis.\ncriteria make use () noise category hdbscan, (ii) relative size cluster, (iii) separability indices, (iv) cosine distances tokens (v) \\(\\varepsilon\\) values.Criteria () (ii) straightforward. Criterion (iii) refers two measures developed within semvar package (Speelman & Heylen 2014; Speelman & Heylen 2017), kNN SIL: assess well items clustered based distance matrix. case, looking match hdbscan clusters, take role classes, euclidean distances within t-sne plot. Let’s see work.first measure, kNN, separability index developed Speelman & Heylen (2014) based proportion “class items” among \\(k\\) nearest neighbours item. answers following question: looking hdbscan clusters mapped t-sne plot: pure clusters? form tight groups colour, overlap (maybe noise tokens)? Recall bearing semantic composition cluster: instead, refers visual homogeneity cluster mapped plot.purposes, makes sense set \\(k\\) 8, minimum number tokens cluster based current hdbscan parameters. result, token \\(x\\) cluster \\(C\\), 8 tokens closest \\(x\\) t-sne plot belong hdbscan cluster \\(C\\), kNN = 1, none , kNN = 0, regardless class(es) items belong . proportions mixed, ranking neighbours plays role: tokens closest \\(x\\) belong \\(C\\), kNN higher; instead belong another class, kNN lower. kNN value cloud (\\(C\\)) mean kNN assigned members. high kNN means instances different class mixed among tokens cloud: words, cloud quite compact pure.\nproblem kNN biased favour large clouds. larger cloud , higher proportion tokens entirely surrounded items cluster. However, clusters kNN different sizes different shapes. order counteract bias, include SIL threshold.\nSIL, silhouette, popular measure cluster quality takes account distances members cluster members outside cluster (Rousseeuw 1987). tokens inside cloud much closer tokens outside cloud, SIL highest, upper bound 1. cloud spread /clouds close , e.g. overlap, SIL go . Thus, combination high kNN high SIL results compact, homogeneous, isolated clouds.Criteria (iv) (v) distances tokens belonging cluster \\(\\varepsilon\\) values respectively. former refer original cosine distances tokens cluster: lower , similar tokens . may different euclidean distances based t-sne plot.\nFinally, \\(\\varepsilon\\) values extracted hdbscan clustering explained Chapter 2.2.4. lower \\(\\varepsilon\\), denser area token, .e. smaller area covered nearest neighbours. Noise tokens typically highest \\(\\varepsilon\\) values: disperse, therefore radius required find 8 near neighbours larger. members cluster might variety \\(\\varepsilon\\) values: lower \\(\\varepsilon\\), closer core, .e. denser area cluster. clear, making claims technical semantic interpretation \\(\\varepsilon\\) right now. brief discussion given Chapter 6. Instead, utility values lies straightforward mapping visual effects plot. \\(\\varepsilon\\) values clustered token close noise tokens, cluster , way, submerged noise: hdbscan finding patterns t-sne . contrary, \\(\\varepsilon\\) values much lower noise tokens, cloud stands .five criteria combined following algorithm classify different clusters.noise categorised Cirrostratus cloud.clusters cover least 50% modelled tokens (including noise) Cumulonimbus clouds.clearest, roundest, densest clusters Cumulus clouds. must least kNN \\(\\ge\\) 0.75, SIL \\(\\ge\\) 0.5 mean cosine distance \\(\\le\\) 0.5. addition, less 10% tokens cluster may higher \\(\\varepsilon\\) lowest noise \\(\\varepsilon\\), noise model must cover less 10% tokens.smallest clusters, .e covering less 10% modelled tokens, 75% model noise kNN < 0.7, Cirrus clouds.decent remaining clusters Stratocumulus clouds. must kNN \\(\\ge\\) 0.7, SIL \\(\\ge\\) 0.5 mean distance \\(\\le\\) 0.2. addition, either half tokens lower \\(\\varepsilon\\) noise tokens 10% modelled tokens noise.remaining clusters Cirrus clouds.addition, category Hail groups clouds least 8 identical tokens; can belong classes.Table 5.1 shows number clouds, either medoid models across models, belonging categories. definition, almost models Cirrostratus cloud, .e. noise tokens, one Cumulonimbus cloud, .e. massive cloud. rest clouds may occur model. number clouds also belongs Hail category given parentheses.\nTable 5.1: Number clouds type per medoid model general; parenthesis, number Hail clouds specified.\n","code":""},{"path":"shapes.html","id":"cloud-types","chapter":"5 A cloud atlas","heading":"5.2 Types of clouds","text":"section, different cloud shapes described detail. general look plot compared pictures meteorological clouds offer technical interpretation .going descriptions, explanation one measures takes part technical interpretation order: \\(F\\)-score.\nClouds can represented set context words co-occurring tokens compose . relationship context word \\(cw\\) cluster may described terms precision recall, already mentioned Section 3.5: precision indicates proportion tokens co-occurring \\(cw\\) also belong cluster, recall indicates proportion tokens within cluster co-occur \\(cw\\). example, tokens cluster co-occur definite determiner de, de recall 1 cluster; likelihood, tokens constitute around 40% tokens co-occurring de across sample, resulting precision 0.4. values can summarized \\(F\\)-score, defined (weighted) harmonic mean precision recall. case, unweighted \\(F\\), , precision recall deemed equally important, equals 0.57. higher \\(F\\), better representativeness context word relation cluster: \\(F\\) 1 indicates tokens co-occurring word belong cluster, tokens cluster co-occur word, \\(F\\) 0 indicates absolute lack overlap domain context word clouds.\ncontext word high \\(F\\) relation cluster, cluster dominated context word. handy term come frequently describe types clouds, especially Chapter 6. general, context words co-occur least two tokens within cluster considered, avoid inflating value hapax legomena.","code":""},{"path":"shapes.html","id":"cumulus-clouds","chapter":"5 A cloud atlas","heading":"5.2.1 Cumulus clouds","text":"meteorological terms, Cumulus clouds look puffy: prototypical ideal images clouds. token-level clouds, also correspond ideal images clusters: mostly roundish, visually salient density isolation. able find even without colour-coding: t-sne hdbscan agree tokens belong together.\nFigure 5.3, four rightmost clusters, green, light blue, yellow blue, Cumulus; rest Stratocumulus clouds.\nFigure 5.3: Example Cumulus cloud: inspiration left, plot example right (nobound10lex-ppmiweight-focall dof). Picture Glg, edited User:drini - photo taken Glg, CC -SA 2.0 de, https://commons.wikimedia.org/w/index.php?curid=3443830.\nCumulus clouds defined number different measures strict values, excluding Cirrostratus (noise) Cumulonimbus (massive clouds).\nFirst, clusters need kNN \\(\\ge\\) 0.75 SIL \\(\\ge\\) 0.5, well mean pairwise cosine distance tokens 0.5 lower. combination three strict thresholds ensures quite pure, compact, isolated clusters: don’t visually overlap clusters noise. final requirement makes sure cloud stands noise. One ways can achieve \\(\\varepsilon\\) lower minimum noise \\(\\varepsilon\\) least 90% tokens: least 9 10 tokens stand . However, models without noise little, noise \\(\\varepsilon\\) values might particularly high, threshold applied models less 10% noise.clouds characterized one context word high precision recall cluster. fact, 75% clouds context word \\(F\\) \n0.72 higher, 75% rest clouds highest \\(F\\) lower . top context words also tend high pmi, may even negative pmi.lemmas highest proportion Cumulus clouds heffen ‘levy/lift,’ hachelijk ‘dangerous/critical,’ schaal ‘scale/dish,’ gemeen ‘common/mean…’ stof ‘substance/dust….’ cases strong collocational patterns kind discussed Section 6.2. Lemmas repel Cumulus clouds, hand, haten ‘hate,’ geestig ‘witty,’ gekleurd ‘coloured’ hoekig ‘angular,’ lack collocational patterns instead form uniform, fuzzy pictures.","code":""},{"path":"shapes.html","id":"stratocumulus-clouds","chapter":"5 A cloud atlas","heading":"5.2.2 Stratocumulus clouds","text":"meteorological terms, Stratus clouds flat smooth clouds: Stratocumulus clouds flatter, less compact version Cumulus clouds discussed . Figure 5.4, three clouds Stratocumulus: large, disperse light blue cloud, stretched orange one compact green cloud lost three points bottom right.\nFigure 5.4: Example Stratocumulus cloud: inspiration left, plot example right (bound5all-ppmino-focall heffen). Picture Joydeep - work, CC -SA 3.0, https://commons.wikimedia.org/w/index.php?curid=20357040.\ndefinition Stratocumulus clouds takes number different measures applies less strict thresholds Cumulus clouds. First Cirrostratus, Cumulonimbus Cumulus must classified, smallest clouds, either noisy models without high kNN, must reserved Cirrus. remaining clouds apply two filters. First, must either kNN \\(\\ge\\) 0.7, SIL \\(\\ge\\) 0.5 mean pairwise cosine distance \\(\\le\\) 0.2. Second, either half tokens \\(\\varepsilon\\) value minimum noise \\(\\varepsilon\\) value percentage noise tokens model lower 10%.Stratocumulus clouds generally large: 75% either Cumulus Cirrus \n28 tokens fewer, half Stratocumulus 26 .\nHowever, comparison Cirrus tend lower type-token ratio context words42 higher \\(F\\) values representative context words. addition, mean cosine distance tokens tend comparable Cirrus clouds, spite difference size: words, larger compact clearly defined.lemmas prefer Cumulus clouds tend avoid Cirrus clouds vice versa, relationship Stratocumulus straightforward. preference Cumulus tends go hand hand preference Stratocumulus, case heffen ‘levy/lift,’ necessarily case. gemeen ‘common/mean…’ stof ‘substance/dust…’ prefer Cumulus either Cirrus Stratocumulus, haten ‘hate,’ prefers Cirrus Cumulus, slight preference Stratocumulus . One lemma prefers Stratocumulus anything else heilzaam ‘healthy/beneficial,’ described Section 6.2.1: even though clusters tend dominated clear collocates target, semantically heterogeneous.","code":""},{"path":"shapes.html","id":"cirrus-clouds","chapter":"5 A cloud atlas","heading":"5.2.3 Cirrus clouds","text":"meteorological perspective, Cirrus clouds high wispy. plots, description translate typically small, disperse clouds might able isolate without help hdbscan. Figure 5.5, clouds belong category.\nFigure 5.5: Example Cirrus cloud: inspiration left, plot example right (bound5all-ppmiselection-focall herstructureren). Picture Dmitry Makeev - work, CC -SA 4.0, https://commons.wikimedia.org/w/index.php?curid=85153684.\nCirrus clouds defined small clouds noisy models low kNN, .e. substantial overlap cloud clusters noise tokens, well remainder clouds defining four categories.\ngenerally small, like Cumulus clouds: cases cover 100 points, considered Stratocumulus SIL higher either kNN percentage tokens noise higher .\nspite size, high type-token ratio context words context words low \\(F\\), even compared larger Stratocumulus clouds: words, tend represented single powerful collocates, instead tokens co-occur many different, infrequent words.weakness patterns seen tendency, rather law. likely Cumulus clouds semantically heterogeneous hard interpret, necessarily case. lemmas tendency uniform internal structure, Cirrus clouds may group patterns emerge .\nLemmas prefer Cirrus clouds, geestig ‘witty,’ gekleurd ‘coloured,’ hoekig ‘angular’ haten ‘hate,’ precisely characterized uniform-looking plots, low frequency collocates weak patterns overall.","code":""},{"path":"shapes.html","id":"cumulonimbus-clouds","chapter":"5 A cloud atlas","heading":"5.2.4 Cumulonimbus clouds","text":"physical world, Cumulonimbus clouds puffy (indicated prefix Cumulo-) bring rain storm (nimbus). massive, towering clouds may lie low Cumulus clouds reach high Cirrus clouds. models, Cumulonimbus category (largest cluster Figure 5.6) least frequent, occur, dominates picture.Cumulonimbus clouds minimally defined clouds cover least 50% modelled tokens, including discarded noise. practice, half cover least 58.7% model , reaching much 95.7%.\nNext , typically one cluster (85.6% cases);\noccasionally may two (11.1%) even 5.\nsmaller cluster next massive Cumulonimbus tends Cumulus, combinations attested.\nFigure 5.6: Example Cumulonimbus cloud: inspiration left, plot example right (bound10all-ppmiweight-focall stof). Picture fir0002flagstaffotos [] gmail.comCanon 20D + Canon 17-40mm f/4 L, GFDL 1.2, https://commons.wikimedia.org/w/index.php?curid=887553.\ntypical situation encounter Cumulonimbus cloud small group tokens tight, different everything else, rest tokens distinctive enough form different clusters. tokens grouped large, normally disperse Cumulonimbus cloud, may seem inner structure captured t-sne hdbscan. small group tokens may brought together set similar context words (see Section 6.4), typically represent idiomatic expression.fact, lemmas strong preference format, Cumulonimbus third models, clear idiomatic expression responsible small Cumulus clouds, differences among rest tokens smoothed. gemeen ‘common/mean…,’ stof ‘substance/dust…’ schaal ‘scale/dish.’ contrast, lemmas barely Cumulonimbus clouds (less 5% models), herroepen ‘recant/void,’ hoekig ‘angular,’ diskwalificeren ‘disqualify’ horde ‘horde/hurdle,’ lack strong pattern groups similar frequencies mutual differences instead.case gemeen ‘common/mean…,’ tight cloud represents expression grootste gemene deler ‘greatest common divisor’: groot ‘big, great’ deler ‘divisor’ co-occur large number tokens , type-level, different everything else. result, token-level vectors grootste gemene deler ‘greatest common divisor’ tokens similar tokens instantiating expression, different everything else. Similarly, pattern frequently tied phenomenon case stof ‘substance/dust…’ stof doen opwaaien ‘lit. stir dust,’ idiomatic expression referring controversial actions situations. Schaal ‘scale/dish,’ hand, two main idiomatic contexts generate Cumulonimbus clouds, discussed Section 6.2.2.rest tokens, .e. Cumulonimbus cloud , defined either strong dominating context word group similar context words, instead defined stronger, small cloud. Cumulonimbus clouds huge clouds similar tokens, mass tokens structured enough opposition distinctive small cloud next . may dense areas inside , semantically linked . reason cluster tokens similar , much tokens small partner coherent different everything else. mean distance tokens Cumulonimbus cloud typically large, sometimes large within Cirrostratus (noise), significantly larger within kinds clouds — although examples Cirrus Stratocumulus co-occurring Cumulonimbus also relatively large mean distances.\ndiscussion semantic interpretation clouds, see Section 6.5.","code":""},{"path":"shapes.html","id":"cirrostratus-clouds","chapter":"5 A cloud atlas","heading":"5.2.5 Cirrostratus clouds","text":"meteorological terms, Cirrostratus clouds high (Cirro-), flat smooth (-stratus) clouds. purposes, just indicate noise tokens. lie background (almost) clouds constitute 100% two medoids. Considering entirety models, 146 (2.3%) fully Cirrostratus clouds (Figure 5.7).\nFigure 5.7: Example Cirrostratus cloud: inspiration left, model 100% noise right (nobound10lex-ppmino-focall hoopvol). CC -SA 3.0, https://commons.wikimedia.org/w/index.php?curid=100381.\nmight interesting cluster subset tokens make clouds, least lemmas, pursued studies. require deeper investigation hdbscan works models, tokens sometimes clustered interacts parameters like \\(minPts\\). try semantically interpret clouds, always present affect clouds defined.","code":""},{"path":"shapes.html","id":"hail","chapter":"5 A cloud atlas","heading":"5.2.6 Hail","text":"final, orthogonal category can apply cloud, often describes section rather full cloud. responds special criterion, highlight occasional phenomenon superdense clusters. Figure 5.8, three clouds (light blue, yellow red) Cumulus, rest Stratocumulus; yellow green clouds present Hail, , extremely tight, dense circles identical tokens. clouds least 8 identical tokens, defined cosine distance lower \\(10^{-6}\\).can see blue cloud, one cluster may one piece Hail, case Cumulonimbus clouds. fact, relative numbers, cloud type higher tendency generate Hail Cumulonimbus\n(21.56% cases), fitting cloud brings storms. Overall,\n5% clouds, 924 different models, characteristics.\n\n\nFigure 5.8: Example cloud hail: inspiration left, plot example right (rel1-ppmiselection-focall heet). Picture Tiia Monto, CC -SA 3.0, https://commons.wikimedia.org/w/index.php?curid=88743807\nconditions prompted low number context words per token low type-token ratio (ttr) context words (see Figure 5.9).\nTTR measure complexity computed number different context words, .e. types, divided total number occurrences, .e tokens. ttr 1 indicates words used , lower ttr results different words occurring multiple times. case, higher ttr, richer variety context words captured model tokens cluster.\nHail covers minority clouds, clear ttr number context words per token play role, lower values Hail clouds.\nHail tends emerge restrictive models many tokens can grouped together identical vectors: shared words survived thresholds. often reveal strongest context words, .e. also dominate clouds. see Section 6.2, dominating context word always indicative sense. Moreover, larger variation context can give us richer, nuanced picture distributional behaviour target word.\nFigure 5.9: Mapping type-token ratio context words mean number context words per token cluster medoid, whether cloud Hail.\nmight tempted consider clouds idiomatic expressions: match, visually, think representation idiomatic expressions like. Instead, match groups context words occur frequently short distance (either terms bag--words dependency relations) target. tells us something bigrams: often niet ‘’ occurs close harden ‘tolerate’; van ‘’ staal ‘steel/sample,’ op ‘’ spot ‘spotlight,’ hang_ijzer ‘iron’ heet ‘hot.’ time, harden ‘tolerate’ tokens co-occurring niet ‘’ brought together one pattern disregards possible co-occurrence, possible internal variation.","code":""},{"path":"shapes.html","id":"cloud-patterns","chapter":"5 A cloud atlas","heading":"5.3 Patterns across types of clouds","text":"Beyond features used formal criteria define types clouds, can find patterns across relevant features. features technical properties can extracted automatically dataset: representativeness context words \\(F\\), pmi target lemma, type-token ratio context words co-occurring tokens cluster (ttr), \\(\\varepsilon\\) values. addition, take advantage semantic annotation look entropy clouds, .e. homogeneous terms dictionary senses. figures section represent clusters medoids, including models results cluttered version patterns.First, look properties representative context word cluster, defined context word minimum frequency 2 within cluster highest \\(F\\)-score (explained Section 5.2). Figure 5.10 plots context words’ \\(F\\) horizontal axis , vertical axis, pmi corresponding target lemma, based symmetric window 4 words either side. types clouds mapped colour points fill marginal boxplots. Therefore, bright purple spot \\(x = 0.941\\) \\(y = 9.89\\) represents Cumulus cloud whose representative context word, e.g. deler ‘divisor,’ \\(F\\) 0.941, .e. good cue, pmi lemma model, e.g. gemeen, equal 9.8, high.can see Cirrostratus clouds (noise) tend low \\(F\\) context words, tend low pmi values targets. Cumulus clouds, side, highest \\(F\\), .e. tend dominated one context word, context words tend high pmi. Cirrus Cumulonimbus clouds lower values Cumulus clouds across dimensions, Stratocumulus spans . Moreover, correlation \\(F\\) pmi moderate weak, higher value among Cumulus clouds (Spearman’s \\(\\rho\\) = 0.55, p-value < 0.001) much lower /less significant Cumulonimbus Cirrostratus\n(\\(\\rho\\) = 0.05, p-value \\(\\approx\\) 0.085 \\(\\rho\\) = -0.15, p-value < 0.001, respectively), minimal changes different PPMI settings.\nFigure 5.10: Mapping highest \\(F\\) clouds medoids context word context word’s pmi target, coloured cloud type.\nSecond, look relationship highest \\(F\\)-score type-token ratio (ttr, described Section 5.2.6). mapped horizontal vertical axes respectively Figure 5.11. can see, Cirrus Cirrostratus clouds tend higher ttr rest; indeed, also tend Hail (see Table 5.1). general, different context words find cluster — higher ttr —, lower representativity strongest context word — lower \\(F\\) —, really wide range variation, type cloud different profile. Cirrostratus clouds higher ttr lower \\(F\\), opposite defines Cumulus clouds; Stratocumulus Cumulonimbus clouds similar ttr Cumulus lower much lower \\(F\\), ttr Cirrus clouds comparable Cirrostratus, much higher \\(F\\)-score.\nshort, variety context words co-occurring tokens cluster \\(F\\)-score relevant play role shape clouds take. relationship notwithstanding, note factors also intervene, constitution clusters semantic interpretation, representativeness context words type-level distances .\nFigure 5.11: Mapping highest \\(F\\) context word cluster type-token ratio (ttr) context words cluster, coloured cloud type.\nThird, look \\(\\varepsilon\\) values across different cloud types. part definition, insofar proportion tokens lower \\(\\varepsilon\\) lower noise \\(\\varepsilon\\) criterion Cumulus, Stratocumulus Cirrus clouds. Nevertheless, useful summarize resulting patterns. spirit, Figure 5.12 shows, clusters medoids, minimum, mean maximum \\(\\varepsilon\\) within cluster. Note gives us insight relationship \\(\\varepsilon\\) tokens cluster values tokens, either clustered noise.\nexpect, Cirrostratus clouds tend highest \\(\\varepsilon\\): tokens disperse, far away tokens. Cumulus, Stratocumulus Cirrus tend relatively similar values, although Cumulus clouds quite low Cirrus clouds quite flat never low. differences likely found relationship noise \\(\\varepsilon\\). Cumulus clouds stand dense areas disperse (.e. high \\(\\varepsilon\\)) background, whereas Cirrus clouds just slightly denser rest clouds surroundings. Think uniform plots haten hoop Figure 5.1 hdbscan interpretation Figure 5.2: tokens look, roughly, equally disperse. Finally, Cumulonimbus clouds exhibit widest range : tokens vary dense areas, .e. low \\(\\varepsilon\\), disperse ones, .e. high \\(\\varepsilon.\\)\nFigure 5.12: Range \\(\\varepsilon\\) values within clouds different types. Lines join points belonging cluster.\ncharacteristics can roughly mapped altitude clouds meteorological perspective (see Figure 5.13). Figure 5.12 relies common everyday metaphor: high values , low values . counts high low rather arbitrary: low \\(\\varepsilon\\) indicates dense area plots, , token can find 7 nearest neighbours small radius, high \\(\\varepsilon\\) indicates sparse area, large distances token nearest neighbours. time, metaphor altitude also coherent original goal mapping: low values, high densities, stand viewer closer. Similarly, look clouds sky , lower clouds going stand : case Cumulus, Stratocumulus , naturally, Cumulonimbus clouds.\nFigure 5.13: Graphical representation meteorological clouds different altitudes. Christopher M. Klaus w:en:Argonne National Laboratory - work en:User:Klaus, Public Domain, https://commons.wikimedia.org/w/index.php?curid=2760873\nFinally, Figure 5.14 shows entropy43 clouds different types terms manually annotated senses, entropy across whole model. Entropy measure information, case works follows: higher entropy, variation senses balanced frequencies; lower entropy, one sense dominates. like entropy cluster (\\(y\\)-axis Figure 5.14) low possible, , cluster homogeneous possible terms senses. time, models higher initial entropy — due sense distribution lemmas model — likely clusters higher entropy.one hand, horizontal boxplots show clouds types equally likely emerge model regardless sense distribution. consistent point make Chapter 6 clouds model senses. hand, vertical boxplots show different cloud types tend exhibit different entropy values. Cumulus clouds homogeneous, Cumulonimbus clouds tend heterogeneous Cirrostratus (noise) — might even higher entropy models whole. Cumulus clouds particular, sometimes also Stratocumulus maybe Cirrus, may completely homogeneous regardless sense composition model , can also higher entropy. Stratocumulus clouds tend slightly lower entropy Cirrus clouds, .e. tend homogeneous, even though also tend larger.\nFigure 5.14: Mapping entropy medoid cluster cloud type.\n","code":""},{"path":"shapes.html","id":"theo2-summary","chapter":"5 A cloud atlas","heading":"5.4 Summary","text":"Token-level distributional models process wealth complex, messy information try return clear, interpretable patterns. patterns take different forms: sometimes clear, isolated, dense groups similar tokens, like ideal image clouds clear sky; times, pattern harder find, barely catch clear wisps overcast sky. clouds one model independent , depending power leading context words might merge larger masses split smaller groups; powerful small Cumulus clouds may force everything else huge Cumulonimbus clouds, tension semantic fields might even create Hail.chapter seen variety shapes emerges distributional models, particular interaction t-sne visualization perplexity 30 hdbscan clustering \\(minPts = 8\\). linked visual results variety context words representativeness, found patterns semantic homogeneity. know lemmas exhibit types clouds, different proportions, related tendency towards strong collocational patterns. next chapter, delve linguistic interpretation clouds, , collocational properties relationship manually annotated dictionary senses.","code":""},{"path":"semantic-interpretation.html","id":"semantic-interpretation","chapter":"6 The language of clouds","heading":"6 The language of clouds","text":"linguistic terms, clouds may provide us different types information, syntagmatic paradigmatic level. syntagmatic level, may illustrate cases collocation, colligation, semantic preference even tendencies towards open-choice principle. paradigmatic level, hand, codes relationship clusters dictionary senses, heterogeneous clusters represent (proto)typical contexts sense.Given naive understanding correlation context meaning, mostly expect, paradigmatic perspective, clusters equal senses: cloud cover occurrences dictionary sense occurrences sense. However, even relax requirements, expecting mostly homogeneous clusters covering clustered tokens, arise often. Instead, even homogeneous clusters group typical contexts within sense, , syntagmatic level, tend correspond collocations. case, see chapter, full picture complex, can obtain much richer information just lexical collocations representing typical contexts within sense.chapter, look types syntagmatic paradigmatic information clouds offer. Section 6.1 starts overview different levels dimension mentions examples interaction contingency table. elaborate detailed examples situation sections 6.2 6.5, round overall summary Section 6.6.","code":""},{"path":"semantic-interpretation.html","id":"infotypes","chapter":"6 The language of clouds","heading":"6.1 Types of information","text":"linguistic information obtainable clusters can understood syntagmatic perspective co-occurrence patterns different kinds, paradigmatic perspective relation dictionary senses. dimensions interlace, resulting number specific phenomena may encounter. relationship summarized Table 6.1; syntagmatic collocational dimension represented columns discussed Section 6.1.1, paradigmatic semantic dimension represented rows discussed Section 6.1.2.","code":""},{"path":"semantic-interpretation.html","id":"collocationally","chapter":"6 The language of clouds","heading":"6.1.1 Collocational perspective","text":"order interpret different levels information syntagmatic collocational perspective may offer us, can make use theoretical concepts foundations Corpus Linguistics. terms already coined Firth (1957), integrated framework corpus analysis Sinclair (1998: 124–125) publications. framework includes, next node, .e. targets, four key components: one obligatory — semantic prosody, discussed — three help us make sense observed output clouds: collocation, colligation semantic preference.simplest form, collocations defined co-occurrence two words within certain span (Firth 1957: 13; Sinclair 1991: 170; Sinclair 1998: 15; Stubbs 2009: 124). might filtered statistical significance co-occurrence frequency strength attraction; pmi (see McEnery & Hardie 2012: 122–133 discussion). Even though collocational relationship asymmetric, , co-occurrence frequent word B may important less frequent word B, measures used described often symmetrical (Gries 2013).\ncomes interpretation clouds, category takes different form definitely asymmetric. Considering models built around target term node, frequent, distinct context words bound make tokens co-occur similar different rest: generate clusters. context words tend high pmi target, , crucially, stand salient feature among occurrences target, independently salient target modelling collocate.\nConcretely, talking clusters defined one context word group co-occurring context words high \\(F\\)-score relation cluster: context words can interpreted collocates target.\nUnlike collocational studies, study list words co-occur (significantly) frequently target node, vector space models allow see whether context words exclude also co-occur within context target. fact, might even find complex collocational patterns, including multiple context words.Whereas collocation understood relationship words (, traditionally, relationship word forms), colligation defined relationship word grammatical categories syntactic patterns (Firth 1957: 14; Sinclair 1998: 15; Stubbs 2009: 124). order capture proper colligations clusters, need models parts speech maybe dependency patterns used features, case studies. However, rejecting strict separation syntax lexis\n(everything semantics Cognitive Linguistics),\ncan make grammatically-oriented interpretation collocations function words, frequent prepositions passive auxiliary. Given caveat, talk lexically instantiated colligations encounter clusters dominated items indicate specific grammatical function.Semantic preference defined relationship word semantically similar words (Sinclair 1998: 16; Stubbs 2009: 125; McEnery & Hardie 2012: 138–140). Within traditional collocational studies, implies grouping collocates, , already frequently co-occurring items, based semantic similarity, much colligation can result grouping collocates based grammatical categories. Compared collocation, identification requires interpretation part researcher.\ninterpretation individual clusters, semantic preference appears clusters dominated single collocate group co-occurring collocates, instead defined group infrequent context words similar type-level vectors can give semantic interpretation. (Cases similar context words without semantic interpretation quite rare, normally involve pronouns adverbs.) key contribution token-level distributional models may remain inaccessible traditional collocational studies: next powerful collocates group virtually identical occurrences, can identify patterns context words exact similar enough emulate collocate.three notions described assume identifiable patterns: occurrences similar enough substantial number occurrences, different enough occurrences, generate cluster. Going back Sinclair (1991)’s founding notions, assuming domination idiom principle:…language user available large number semi-preconstructed phrases constitute single choices, even though might appear analysable segments. (Sinclair 1991: 110)opposite situation given open-choice principle:point unit completed (word phrase clause), large range choice opens restraint grammaticalness. (Sinclair 1991: 109)idiom principle open-choice principle supposed organise lexicon production utterances. , instead, understood poles continuum collocational behaviour, can help us interpret variety shapes encounter within across lemmas. Lemmas tend find identifiable clusters, strong collocations, lexically instantiated colligations sets semantic preference, can said respond idiom principle. contrast, lemmas exhibit large proportions noise tokens, small, diffuse clusters (Cirrus clouds, mostly), can said approximate open-choice principle. don’t necessarily lack structure, whatever structure less clear lemmas, harder capture models.\nreasoning, next three categories described , include near-open choice fourth category, meant include clouds conform either clearer formats.","code":""},{"path":"semantic-interpretation.html","id":"semantically","chapter":"6 The language of clouds","heading":"6.1.2 Semantic perspective","text":"terms relationship hdbscan clusters manually annotated dictionary senses, can initially distinguish heterogeneous clusters, .e. exhibit clear preference one sense, homogeneous clusters. Secondly, homogeneous clusters may cover (clustered) tokens given sense, part , .e. (proto)typical context sense. Additionally, said (proto)typical context may highlight certain aspect dimension meaning target, different highlighted different context.result, semantic dimension covers four different types situations. first one, .e. heterogeneous clusters clusters multiple senses, normally interpreted bad modelling, consider senses gold standard target models. also frequent interpretation near-open choice clouds. Nonetheless, can also occur kinds clouds, illustrate mismatch contextual semantic structure: clear contextual patterns imply dictionary senses.\nsecond type situation, .e. clusters perfectly match senses, ideal situation initially expect distributional models. Instead, quite rare often indicative fixed expressions particular meanings.\nRather full senses, contextual patterns tend represent (proto)typical contexts sense.already described Section 1.2.2, notion prototypicality Cognitive Semantics related principle categories need discrete uniform application semasiological structure lemmas meanings (Geeraerts 1988; Geeraerts 1997). extensional level, case covers domains contexts application target item, categories may defined varied set overlapping features (.e. context words) fuzzy boundaries /degrees membership. central prototypical members category exhibit overlapping features; fewer features co-occur item, weaker connection category.\nappear clouds, sense may exhibit one typical context much frequent clear rest, multiple typical contexts similar frequencies. Unfortunately, neither t-sne hdbscan provide reliable mapping quantitative properties relative centrality clusters. contrast, can identify central cases within hdbscan cluster based membership probability, , briefly mentioned , normalized core distance within cluster. Items higher membership probability lie denser area hdbscan cluster, therefore items similar items sparser areas. necessarily occur euclidean centre t-sne plot, might form one dense cores closer towards edge instead. addition, can distinguish rather uniform clusters, members similar weight, diverse clusters dense cores sparse peripheries.Extensional prototypicality works multiple levels. identify (proto)typical instances/contexts lemma, particular sense, dimension sense. last case, run interaction intensional prototypicality. one hand, find multiple extensionally prototypical patterns, .e. two groups attestations instantiate different patterns. , patterns correlates different semantic dimension aspect, wich means meaning dimension salient (intensional prototypicality) pattern.","code":""},{"path":"semantic-interpretation.html","id":"interaction-between-dimensions","chapter":"6 The language of clouds","heading":"6.1.3 Interaction between dimensions","text":"can see Table 6.1, interaction four levels dimension result 4x4 table two cells filled least one example. Naturally, combinations equally frequent interesting; salient one certainly collocation indicates prototypical context sense. mean rest phenomena ignored: can still find interesting useful information shapes clouds, contextual patterns, semantic structure.following sections, look detail examples attested combination. section focus one level collocational dimension, subdivided levels semantic dimension.\nexamples illustrated scatterplots colours represent hdbscan clusters, shapes indicate manually annotated dictionary senses, transparency, \\(\\varepsilon\\) value hdbscan. senses specified legends, clusters named context word represents best (see Section 5.2). Textual reproductions tokens also offered; cases target bold face context words captured relevant model, italics. name newspaper, date publication number article follow original text, following paragraph reproduce English translation simple inverted commas.\nTable 6.1: Contingency table collocational semantic perspectives, examples.\n","code":""},{"path":"semantic-interpretation.html","id":"collocation","chapter":"6 The language of clouds","heading":"6.2 Collocation","text":"first level collocational syntagmatic dimension collocation: clusters dominated one context word group co-occurring context words. likely found Cumulus clouds, also Stratocumulus clouds , rarely, Cirrus clouds.","code":""},{"path":"semantic-interpretation.html","id":"heilzaam","chapter":"6 The language of clouds","heading":"6.2.1 Heterogeneous clouds","text":"Albeit infrequently, collocations might transcend senses, , might frequent even distinctive lemma without showing preference specific sense.\nclear example found heilzaam ‘healthy/beneficial,’ can mean something literally beneficial health applied, metaphorically, domains well. clusters tend dominated one context word indicative one sense: mostly werking ‘effect’ effect, adding models less frequent invloed ‘influence.’ examples shown (5) (6) ‘healthy’ sense (7) (8) ‘beneficial’ sense.Het lypoceen, een bestanddeel dat bijdraagt aan de rode kleur, zou een heilzame werking hebben op de prostaat. (De Volkskrant, 2003-11-08, Art. 14)\n‘Lypocene, component contributes red colour, healing power prostate.’Het lypoceen, een bestanddeel dat bijdraagt aan de rode kleur, zou een heilzame werking hebben op de prostaat. (De Volkskrant, 2003-11-08, Art. 14)‘Lypocene, component contributes red colour, healing power prostate.’Pierik beschrijft de heilzame effecten van alcoholgebruik op de bloedvaten en de bloeddruk, op mogelijke beroerten, galstenen, lichaamsgewicht, vruchtbaarheid, zwangerschap, botontkalking, kanker, verkoudheid, suikerziekte en seniele dementie. (NRC Handelsblad, 1999-11-27, Art. 148)\n‘Pierik describes healing powers alcohol consumption [] blood vessels [] blood pressure, potential strokes, gallstones, body weight, fertility, pregnancy, osteoporosis, cancer, cold, diabetes senile dementia.’Pierik beschrijft de heilzame effecten van alcoholgebruik op de bloedvaten en de bloeddruk, op mogelijke beroerten, galstenen, lichaamsgewicht, vruchtbaarheid, zwangerschap, botontkalking, kanker, verkoudheid, suikerziekte en seniele dementie. (NRC Handelsblad, 1999-11-27, Art. 148)‘Pierik describes healing powers alcohol consumption [] blood vessels [] blood pressure, potential strokes, gallstones, body weight, fertility, pregnancy, osteoporosis, cancer, cold, diabetes senile dementia.’Voor politici met dadendrang een gruwel, maar als men de casus van de Betuwelijn nog voor de geest haalt dan zou het advocatensysteem zijn heilzame werking hebben kunnen bewijzen. (De Volkskrant, 2002-03-29, Art. 79)\n‘politicians thirst action abomination, one recalls (lit. `brings spirit’) case Betuwe line lawyer system able prove beneficial effect.’Voor politici met dadendrang een gruwel, maar als men de casus van de Betuwelijn nog voor de geest haalt dan zou het advocatensysteem zijn heilzame werking hebben kunnen bewijzen. (De Volkskrant, 2002-03-29, Art. 79)‘politicians thirst action abomination, one recalls (lit. `brings spirit’) case Betuwe line lawyer system able prove beneficial effect.’De kwestie heeft alvast één heilzaam effect: het profiel van commerciële boekenprijzen staat opnieuw ter discussie. (De Standaard, 1999-03-27, Art. 133)\n‘matter certainly beneficial effect: profile commercial book prizes discussion.’De kwestie heeft alvast één heilzaam effect: het profiel van commerciële boekenprijzen staat opnieuw ter discussie. (De Standaard, 1999-03-27, Art. 133)‘matter certainly beneficial effect: profile commercial book prizes discussion.’model shown Figure 6.1: clusters dominated werking ‘effect,’ effect invloed ‘influence’ shown yellow, light blue green, respectively, manually annotated senses mapped shapes: literal ‘healthy’ sense coded circles, general sense, triangles. invloed ‘invloed’ cluster, Cumulus, Stratocumulus clouds.Within werking ‘effect’ cluster, literal tokens ((5)) majority tend towards left side cloud, whereas general ones (like (7)) tend towards right side. preference literal sense, especially considering across full sample general sense frequent, far homogeneous. balance even striking within effect cluster.\npicture pervasive across multiple models heilzaam ‘healthy/beneficial.’ vague organization within werking ‘effect’ cluster suggests necessarily case models capture words representative ‘physical health,’ compete salient context words, precisely discriminative two senses.\nFigure 6.1: Cloud heilzaam: bound10all-ppmiweight-focall. Circles ‘healthy, healing,’ triangles ‘beneficial’ general.\nissue come distributional semantics expecting lexical collocates, werking ‘werking,’ effect, invloed ‘influence,’ unequivocally represent different dictionary senses. hand, ben ‘’ werk ‘work, effect’ (werking nominalization), co-occur tokens orange cluster, dominated general sense, less outside cluster; see examples (9) (10).\nwords, frequent nouns modified heilzaam ‘beneficial’ tend occur attributive constructions (particularly een heilzame werking hebben ‘beneficial/healing effect/power’ de heilzame werking van ‘beneficial/healing effect/power ’) either sense, whereas predicative constructions present wider variety nouns stronger tendency towards general sense.Versterking van de politieke controle op de Commissie kan heilzaam zijn maar de huidige ongenuanceerde discussie gevaarlijk voor Europees beleid en besluitvorming. (De Morgen, 1999-03-18, Art. 45)\n‘Reinforcement politicial control Commission can beneficial, current unnuanced discussion dangerous European policy decision-making.’Versterking van de politieke controle op de Commissie kan heilzaam zijn maar de huidige ongenuanceerde discussie gevaarlijk voor Europees beleid en besluitvorming. (De Morgen, 1999-03-18, Art. 45)‘Reinforcement politicial control Commission can beneficial, current unnuanced discussion dangerous European policy decision-making.’Ten slotte nog één fundamentele bedenking: ook de permanente actualiteit van de thematiek de media werkt heilzaam op de weggebruikers. (De Morgen, 2001-02-28, Art. 107)\n‘conclude, one final fundamental thought: permanent presence topic media beneficial effect (lit. `works beneficially’) road users.’Ten slotte nog één fundamentele bedenking: ook de permanente actualiteit van de thematiek de media werkt heilzaam op de weggebruikers. (De Morgen, 2001-02-28, Art. 107)‘conclude, one final fundamental thought: permanent presence topic media beneficial effect (lit. `works beneficially’) road users.’models heilzaam ‘healthy/beneficial’ show take granted collocations representative senses. , illustrate neither high pmi selection cues human annotators guarantee context word distinguishes predefined senses, given words high pmi heilzaam ‘healthy/beneficial’ often selected cues annotators (recall Tables 4.5 4.6 Chapter 4) .\ncomes pmi, understandable: measure meant indicate distinctive context word type whole, comparison types. take account distinctive group occurrences another group occurrences type.\ncomes cueness annotation, however, expected reliable selection, apparently salience context words high annotators notice distinctive different senses.","code":""},{"path":"semantic-interpretation.html","id":"schaal","chapter":"6 The language of clouds","heading":"6.2.2 Dictionary clouds","text":"cases can see clusters characterized one dominant context word perfectly match sense, least clustered tokens. normally fixed expressions, least degree: definition sense may specify required expression, representatieve staal ‘representative sample.’interesting example shown Figure 6.2, model noun schaal ‘scale/dish.’ plot, ‘scale’ homonym represented circles (‘range values, e.g. scale Richter, scale 1 5’), squares (‘magnitude, e.g. large scale’) triangles (‘ratio, e.g. scale 1:20’), whereas ‘dish’ homonym represented crosses (‘shallow wide dish’) crossed squares (‘dish scale’).\n‘range’ ‘dish scale’ senses, exemplified (11) (12), perfect match (almost) hdbscan cluster, represented context word perfect \\(F\\)-score. schaal tokens co-occurring Richter grouped red Cumulus cloud, cover almost full range attestations ‘range’ sense, tokens co-occurring gewicht ‘weight’ grouped light blue Cumulus cloud cover attestations ‘dish scale’ sense. blue cloud crosses also homogeneous Cumulus dedicated ‘shallow wide dish’ sense, dominated collocate, rest variably homogeneous Stratocumulus clouds representing parts ‘magnitude’ sense.Wenen, Beneden-Oostenrijk en Burgenland zijn dinsdagochtend opgeschrikt door een aardschok van 4,8 op de schaal van Richter. (Het Nieuwsblad, 2000-07-12, Art. 4)\n‘Vienna, Lower Austria Burgenland scared Tuesday morning earthquake 4.8 Richter scale.’Wenen, Beneden-Oostenrijk en Burgenland zijn dinsdagochtend opgeschrikt door een aardschok van 4,8 op de schaal van Richter. (Het Nieuwsblad, 2000-07-12, Art. 4)‘Vienna, Lower Austria Burgenland scared Tuesday morning earthquake 4.8 Richter scale.’Daarom het van belang dat Nederland zich deze week achter de VS heeft geschaard, ook al legt ons land natuurlijk minder gewicht de schaal dan Duitsland het Europese debat de al dan niet noodzakelijke toestemming van de Veiligheidsraad voor militaire actie tegen Irak. (NRC Handelsblad, 2002-09-07, Art. 160)\n‘Therefore important Netherlands united behind US week, even though country course less influence (lit. `places less weight dish scale’) Germany European debate potentially necessary permission Security Council military action Iraq.’Daarom het van belang dat Nederland zich deze week achter de VS heeft geschaard, ook al legt ons land natuurlijk minder gewicht de schaal dan Duitsland het Europese debat de al dan niet noodzakelijke toestemming van de Veiligheidsraad voor militaire actie tegen Irak. (NRC Handelsblad, 2002-09-07, Art. 160)‘Therefore important Netherlands united behind US week, even though country course less influence (lit. `places less weight dish scale’) Germany European debate potentially necessary permission Security Council military action Iraq.’way, phenomenon indicates fixed, idiomatic expression: combination two words fully represents sense. However, picture nuanced.\nFirst, technically, ‘range’ sense can potentially occur context words Richter. fact, one examples given annotators schaal van Celsius ‘Celsius scale,’ well pattern like one found (13), one orange circles top Figure 6.2. However, corpus used studies, Celsius co-occur schaal symmetric window 4; moreover, 32 tokens sense attested model, 22 co-occur Richter, 3 follow pattern (13), rest exhibit less fixed patterns infrequent glijdende schaal ‘slippery slope’ construction. matching (13) readily clustered tokens co-occurring preposition op ‘,’ (14). words, register newspapers, ‘range’ sense schaal almost completely exhausted schaal van Richter ‘Richter scale’ expression.\"Misschien deelt de computer mij op grond van statistische analyses op een schaal van 1 tot 12 categorie 3\", zegt woordvoerder B. Crouwers van de registratiekamer. (NRC Handelsblad, 1999-01-09, Art. 10)\n‘\"Maybe computer basis statistical analyses scale 1 12 puts category 3\", says spokesperson B. Crouwers registration chamber.’\"Misschien deelt de computer mij op grond van statistische analyses op een schaal van 1 tot 12 categorie 3\", zegt woordvoerder B. Crouwers van de registratiekamer. (NRC Handelsblad, 1999-01-09, Art. 10)‘\"Maybe computer basis statistical analyses scale 1 12 puts category 3\", says spokesperson B. Crouwers registration chamber.’Die stad vormde de opmaat tot de latere collectieve regelingen op nationale schaal, stellen de auteurs, navolging van socioloog prof. dr. Abram de Swaan. (De Volkskrant, 2003-05-03, Art. 253)\n‘city prelude later collective arrangements national level (lit. `national scale’), state authors, accordance sociologist Prof. Dr. Abram de Swaan.’Die stad vormde de opmaat tot de latere collectieve regelingen op nationale schaal, stellen de auteurs, navolging van socioloog prof. dr. Abram de Swaan. (De Volkskrant, 2003-05-03, Art. 253)‘city prelude later collective arrangements national level (lit. `national scale’), state authors, accordance sociologist Prof. Dr. Abram de Swaan.’Second, ‘dish scale’ sense need used metaphorical expression illustrated (12), indeed case data. Next gewicht ‘weight,’ tokens also mostly co-occur leg ‘lie, place’ , lesser degree, werp ‘throw.’ Even models, cluster tends built around co-occurrence gewicht ‘weight,’ normally excluding tokens co-occur leg ‘lie, place,’ belong sense .\nFigure 6.2: Cloud schaal: nobound5all-ppmiweight-focall. Within ‘scale’ homonym, circles ‘range’; triangles, ‘ratio,’ squares, ‘magnitude’; ‘dish’ homonym, crosses represent ‘dish’ crossed squares, ‘dish scale.’\nexamples don’t disprove possibility clouds dominated collocate perfectly covering sense, long keep mind characteristics limitations corpus studying difference describing “sense used” “sense used particular corpus.”","code":""},{"path":"semantic-interpretation.html","id":"prototypical-clouds","chapter":"6 The language of clouds","heading":"6.2.3 (Proto)typical contexts","text":"frequent phenomenon among Cumulus Stratocumulus clouds cluster dominated one context word group co-occurring context words represents (proto)typical context sense. may prototypical context, rest sense discarded noise spread around less clear clusters, might also find multiple clusters representing different typical contexts sense. Neither t-sne hdbscan can tell whether one contexts central , least sense expect prototype theory. Denser areas tokens, perceived hdbscan, many tokens similar . tokens similar, similar , denser area. see example, good proxy prototypicality.One clear examples phenomenon found heffen ‘levy/lift,’ whose typical objects also characteristic two main senses (see Figure 6.3). one hand, ‘levy’ sense occurs mostly belasting ‘tax,’ tol ‘toll’44, accijns ‘excise,’ shown (15) (17). frequencies large enough form three distinct clusters, tend merge following levels hdbscan hierarchy, , closer clusters sense. hand, ‘lift’ sense occurs glas ‘glass,’ final expression een glas(je) heffen op takes metonymical meaning ‘give toast ’ (see (18)), body-parts hand, arm vinger ‘finger,’ might take metonymical meanings. latter group really belong “collocation” category “semantic preference” (see Section 6.4).Op het inkomen boven die drie miljoen gulden wil De Waal honderd procent belasting heffen. (Het Parool, 2001-05-02, Art. 99)\n‘De Waal wants levy one hundred percent tax incomes three million guilders.’Op het inkomen boven die drie miljoen gulden wil De Waal honderd procent belasting heffen. (Het Parool, 2001-05-02, Art. 99)‘De Waal wants levy one hundred percent tax incomes three million guilders.’Mobiliteitsproblemen, rekeningrijden, op een andere manier het gebruik van de weg belasten, kilometers tellen, tol heffen — de mogelijkheden om de ingebouwde chip te benutten zijn vrijwel onbeperkt. (NRC Handelsblad, 1999-10-02, Art. 31)\n‘Mobility problems, road pricing, taxing use roads different way, counting kilometres, levying taxes — possibilities utilize built-chip almost unlimited.’Mobiliteitsproblemen, rekeningrijden, op een andere manier het gebruik van de weg belasten, kilometers tellen, tol heffen — de mogelijkheden om de ingebouwde chip te benutten zijn vrijwel onbeperkt. (NRC Handelsblad, 1999-10-02, Art. 31)‘Mobility problems, road pricing, taxing use roads different way, counting kilometres, levying taxes — possibilities utilize built-chip almost unlimited.’…landen als Groot-Brittannië (waar de accijnzen op 742 euro per 1.000 liter liggen), Italië en Duitsland (die beide accijnzen boven de 400 euro heffen) komt de harmonisering ten goede van de transportsector. (De Morgen, 2002-07-25, Art. 104)\n‘…countries like Great Britain (excise duties 742 euros per 1,000 liters), Italy Germany (levy excise duties 400 euros) transport sector benefits harmonization.’…landen als Groot-Brittannië (waar de accijnzen op 742 euro per 1.000 liter liggen), Italië en Duitsland (die beide accijnzen boven de 400 euro heffen) komt de harmonisering ten goede van de transportsector. (De Morgen, 2002-07-25, Art. 104)‘…countries like Great Britain (excise duties 742 euros per 1,000 liters), Italy Germany (levy excise duties 400 euros) transport sector benefits harmonization.’Nog twaalf andere deelnemers konden maandagavond het glas heffen op de hoogste winst. (De Standaard, 2004-10-20, Art. 150)\n‘Monday night another twelve participants raise glasses highest profit.’Nog twaalf andere deelnemers konden maandagavond het glas heffen op de hoogste winst. (De Standaard, 2004-10-20, Art. 150)‘Monday night another twelve participants raise glasses highest profit.’can see Figure 6.3, model successful separating two senses clusters semantically homogeneous: relevant collocates heffen ‘levy/lift’ distinctive one senses. Crucially, single cluster even close covering full sense; instead, represents prototypical pattern stands due frequency, internal coherence distinctiveness.\nseems reasonable map clusters prototypical patterns frequency distinctiveness, careful apply results modelling kind semantic analysis. perspective prototype theory, feature category central frequent, .e. shared members, member central exhibits defining features categories. , within ‘levy’ sense, belasting heffen ‘levy taxes’ pattern central, tokens instantiating pattern central. contrast, hdbscan prioritizes dense areas, , groups tokens similar . Thus, membership probabilities, might tempted use proxy centrality, indicate internal consistency, lack variation. perspective, given belasting heffen ‘levy taxes’ frequent applies wider variety contexts two patterns ‘levy,’ area less dense, tokens lower membership probabilities within compound ‘levy’ clusters.\nwords, models can offer us typical patterns lemma senses tell us distinctive much internal variation present. Beyond information, don’t map straightforward manner understanding prototypicality.\nFigure 6.3: Cloud heffen: bound10all-ppmiweight-focnav. Circles ‘lift,’ triangles ‘levy.’\nmust noted clusters defined collocations may just characterized one single context word, multiple partially co-occurring context words. clear example hachelijk ‘dangerous/critical,’ senses characterized prototypical contexts, exemplified (19) (24): onderneming ‘undertaking,’ zaak ‘business’ avontuur ‘adventure’ ‘dangerous, risky’ sense, moment, situatie ‘situation,’ positie ‘position’ ‘critical, hazardous’ sense. model shown Figure 6.4, yellow, orange green clusters Cumulus clouds, rest, Stratocumulus.\nsix frequent context words paradigmatic alternatives , taking slot modified noun, .e. entity characterized dangerous critical. However, unlike near type-level neighbour situatie ‘situation,’ positie ‘position’ may also co-occur bevrijd ‘free’ (uit ‘’) , additionally, brandweer ‘firefighter,’ typically Belgian contexts. frequency co-occurrences sample, next type-level dissimilarity three lexical items, splits co-occurrences positie ‘position’ three clusters (light blue, green red Figure 6.4), based combinations.Het geen gewaagde stelling dat de deelname van de LPF aan de regering een hachelijke onderneming blijft. (De Volkskrant, 2002-08-05, Art. 46)\n‘bold statement participation LPF government remains risky undertaking.’Het geen gewaagde stelling dat de deelname van de LPF aan de regering een hachelijke onderneming blijft. (De Volkskrant, 2002-08-05, Art. 46)‘bold statement participation LPF government remains risky undertaking.’Daar baseerden de media zich op slechts één bron, en elke journalist weet dat dat een hachelijke zaak . (De Volkskrant, 2004-05-05, Art. 42)\n‘media relied one source, every journalist knows dangerous thing .’Daar baseerden de media zich op slechts één bron, en elke journalist weet dat dat een hachelijke zaak . (De Volkskrant, 2004-05-05, Art. 42)‘media relied one source, every journalist knows dangerous thing .’…met storm opzij het inhalen van een vrachtwagen een hachelijk avontuur… (Het Parool, 2000-03-17, Art. 34)\n‘…sidewind conditions overtaking truck risky adventure…’…met storm opzij het inhalen van een vrachtwagen een hachelijk avontuur… (Het Parool, 2000-03-17, Art. 34)‘…sidewind conditions overtaking truck risky adventure…’Kortrijk beleefde enkele hachelijke momenten tegen Brussels, dat zijn ondiep bad bewees zijn vierde plaats de play-offs waard te zijn. (Het Laatste Nieuws, 2001-05-14, Art. 375)\n‘Kortrijk experienced critical moments Brussels, shallow pool proved worthy fourth place play-offs.’Kortrijk beleefde enkele hachelijke momenten tegen Brussels, dat zijn ondiep bad bewees zijn vierde plaats de play-offs waard te zijn. (Het Laatste Nieuws, 2001-05-14, Art. 375)‘Kortrijk experienced critical moments Brussels, shallow pool proved worthy fourth place play-offs.’Kort maar krachtig staat er: ``De hachelijke situatie van Palestina vooral een interne aangelegenheid, hoewel de bezetting en de confrontatie met Israël er de context voor schept.\" (De Standaard, 2004-10-02, Art. 162)\n‘Short powerful, reads: ``critical situation Palestine mostly internal matter, even though occupation confrontation Israel create context .\"’Kort maar krachtig staat er: ``De hachelijke situatie van Palestina vooral een interne aangelegenheid, hoewel de bezetting en de confrontatie met Israël er de context voor schept.\" (De Standaard, 2004-10-02, Art. 162)‘Short powerful, reads: ``critical situation Palestine mostly internal matter, even though occupation confrontation Israel create context .\"’Zij toont knappe filmpjes, opgenomen vanuit de hachelijke positie van een deltavlieger… (De Morgen, 1999-06-07, Art. 126)\n‘shows outstanding videos, taken hazardous position hang glider…’Zij toont knappe filmpjes, opgenomen vanuit de hachelijke positie van een deltavlieger… (De Morgen, 1999-06-07, Art. 126)‘shows outstanding videos, taken hazardous position hang glider…’model give us information relative centrality three positie clusters. result combination three features, cluster exhibits different degree membership based many overlapping features co-occurs . time, distinctive regional distribution. Based data, might said prototypical context hachelijke posities ‘dangerous/critical positions’ Flanders situation firefighters free someone/something , core present, least nearly relevant, Netherlandic data. might also say situation typical hachelijke situaties ‘dangerous/critical situations,’ therefore presents (local) distributional difference two types otherwise, corpus level, near neighbours.\nFigure 6.4: Cloud hachelijk: bound5all-ppmiweight-focall. Circles ‘dangerous, risky’; triangles ‘critical, hazardous.’\n","code":""},{"path":"semantic-interpretation.html","id":"stof","chapter":"6 The language of clouds","heading":"6.2.4 Profiling","text":"Clusters dominated context word may represent typical context within sense, also one highlights different dimension sense clusters. extremely frequent requires extra layer interpretation, additional explanation clustering solutions.One example given ‘substance’ meaning stof, represented circles Figure 6.5.\nWithin sense, tend find clusters dominated gevaarlijk ‘dangerous,’ schadelijk ‘harmful’ (also attracts kankerwekkend ‘carcinogenic’) giftig ‘poisonous’ (often attracts chemisch ‘chemical’). dominant context words nearest neighbours type-level, clusters govern belong branch hdbscan hierarchy.However, can find additional information, among context words co-occur , suggests frequency responsible separated clusters. Concretely, tokens cluster dominated schadelijk ‘harmful’ tend focus environment composition substances, indicated co-occurrence uitstoot ‘emissions,’ lucht ‘air,’ stank ‘stench’ bevat ‘contain’; meanwhile, cluster dominated giftig ‘poisonous’ focus context drugs profile liberation substances, context words vorm ‘form,’ kom_vrij ‘released’ drugs_gebruik ‘drug use.’ clusters distinguished meaning coded dictionary entry, semantic dimensions highlighted contexts hidden others, always latent.\neffect less frequent context words one consequences less restrictive models: levels analysis, one word (gevaarlijk ‘dangerous,’ schadelijk ‘harmful’…) might enough disambiguate target, extra information enriches understanding words actually used. also contextualized information: just stof ‘substance’ used, used combination certain frequent collocates.\nFigure 6.5: Cloud stof: bound5lex-ppmiselection-focall. Within first homonym, circles ‘substance’; triangles, ‘fabric’; filled squares, ‘topic, material.’ second, crosses literal ‘dust’ crossed square, idiomatic expressions.\n","code":""},{"path":"semantic-interpretation.html","id":"colligation","chapter":"6 The language of clouds","heading":"6.3 Lexically instantiated colligation","text":"Even without relying part--speech tags dependency relationships features models, can obtain grammatical information lexical collocates. example, passive auxiliary word indicates passive constructions, well somewhat less frequent preposition door, indicates explicit agent, much like English. constructions might also indicated key function words, om te ‘order ,’ dat ‘’ relative clauses, dan ‘’ comparatives, prepositions. patterns emerge clusters lexically instantiated colligation may cross boundaries dictionary senses — resulting heterogeneous clusters — match senses, indicate prototypical configuration within sense. following subsections explore examples different phenomena.","code":""},{"path":"semantic-interpretation.html","id":"heterogeneous-clusters","chapter":"6 The language of clouds","heading":"6.3.1 Heterogeneous clusters","text":"verb herstructureren ‘restructure’ annotated three sense tags emerging combination specialization, .e. whether ’s specifically applied companies, argument structure, distinguishing transitive intransitive herstructureren. intransitive sense always specific — companies restructure, undergo process restructure.Models typically successful disentangling three senses, one , matter. Instead, clusters emerge tend highlight either semantic syntactic dimension, disregarding one.\nlexical items frequently dominate clusters herstructureren ‘restructure’ passive auxiliary word, bedrijf ‘company,’ grondig ‘thorough(ly),’ pair prepositions om te ‘order ,’ illustrated (25) (27).OK-score deelt bedrijven op tien klassen; klasse 1 blaakt van gezondheid, klasse 10 op sterven na dood, ofwel, staat op de rand van faillissement en moet grondig worden geherstructureerd. (Het Parool, 2003-04-16, Art. 69)\n‘OK-score divides companies ten classes: class 1 brimming health, class 10 good dead, rather, stands edge bankruptcy must thoroughly restructured.’OK-score deelt bedrijven op tien klassen; klasse 1 blaakt van gezondheid, klasse 10 op sterven na dood, ofwel, staat op de rand van faillissement en moet grondig worden geherstructureerd. (Het Parool, 2003-04-16, Art. 69)‘OK-score divides companies ten classes: class 1 brimming health, class 10 good dead, rather, stands edge bankruptcy must thoroughly restructured.’Ze herstructureerden het bedrijf en loodsten het de internationale groep Taylor Nelson Sofres (TNS) binnen. (De Standaard, 2004-01-06, Art. 59)\n‘restructured company steered towards Taylor Nelson Sofres (TNS) international group.’Ze herstructureerden het bedrijf en loodsten het de internationale groep Taylor Nelson Sofres (TNS) binnen. (De Standaard, 2004-01-06, Art. 59)‘restructured company steered towards Taylor Nelson Sofres (TNS) international group.’Uiteindelijk dat de regering, want toen de crisis uitbrak nam de overheid een belang de banken om ze te herstructureren en uiteindelijk weer te verkopen. (NRC Handelsblad, 2000-11-07, Art. 11)\n‘end government, crisis hit authorities took interest banks order restructure eventually sell .’Uiteindelijk dat de regering, want toen de crisis uitbrak nam de overheid een belang de banken om ze te herstructureren en uiteindelijk weer te verkopen. (NRC Handelsblad, 2000-11-07, Art. 11)‘end government, crisis hit authorities took interest banks order restructure eventually sell .’two nouns never co-occur, occasionally co-occur word om te, co-occur times. grondig ‘thorough(ly)’ bedrijf ‘company’ good cues company-specific senses, may occur either transitive intransitive constructions. contrast, word good cue transitive (specifically, passive) constructions, may occur either company-specific general sense. Finally, om te may attested either three senses. stark separation clusters Figure 6.6 seem suggest opposite poles, case semantic level. fact, unlike Figures 6.3 6.4, dominated Cumulus Stratocumulus clouds, clusters merely slightly denser areas rather uniform, noisy mass tokens — green cloud Stratocumulus two Cirrus clouds — much harder naked human eye capture without hdbscan input. Instead, cluster indicates pole contextual behaviour may code semantic dimension, case bedrijf ‘company’ cluster, syntactic one, lexically instantiated colligation clusters.\nFigure 6.6: Cloud herstructureren: bound3all-ppmiselection-focall. Circles indicate transitive, general sense; triangles, transitive companies-specific sense, squares, intransitive (companies-specific) sense.\n","code":""},{"path":"semantic-interpretation.html","id":"dictionary-clouds","chapter":"6 The language of clouds","heading":"6.3.2 Dictionary clouds","text":"rare thing, might able find cluster dominated grammatical pattern matches dictionary sense. One clear case reflexive sense herhalen ‘repeat,’ characterized co-occurrence zich ‘’ BOW models without part--speech filters () REL models, especially PPMIweight applied .45\nmodel shown Figure 6.7, clearest cluster, red Stratocumulus squares bottom. Looking closely, can see made two halves: small one left, tokens also co-occur geschiedenis ‘history,’ bigger one right, . particular model restrictive: normally captures one two context words per token, need capture particular sense.\nFigure 6.7: Cloud herhalen: rel1-ppmiselection-focall. Circles ‘’; triangles, ‘say ’; squares, ‘(reflexive) happen ,’ crosses, ‘broadcast .’\nexpected kind output lemmas purely reflexive senses well, easy achieve. case diskwalificeren ‘disqualify,’ infrequent reflexive sense typically (always) absorbed within transitive sense matches semantically, .e. non sports-related sense.\nAlternatively, lexically instantiated colligation may prefer certain sense without exhausting attestations: case, represents prototypical context, shown following section.","code":""},{"path":"semantic-interpretation.html","id":"prototypical-contexts","chapter":"6 The language of clouds","heading":"6.3.3 (Proto)typical contexts","text":"verb herinneren two main senses defined well defined constructions: either intransitive construction co-occurring preposition aan, meaning ‘remind,’ reflexive construction meaning ‘remember’; third, transitive sense also attested infrequently.\nlemma sometimes rendered three equally sized Stratocumulus clouds, shown Figure 6.8: orange cluster characterized preposition aan (see (28)), green one subject reflexive first person pronouns ik (see (29)), yellow one third person reflexive pronoun zich (see (30)). smaller group tokens co-occurring eraan, compound particle er aan (see example (31), works placeholder connects preposition subordinate clause), may form Cumulus cloud, like light blue one Figure 6.8, absorbed one larger ones.Vinocur herinnert aan een tekening van Plantu L’Express. (Het Parool, 2002-05-18, Art. 101)\n‘Vinocur reminds [spectator] drawing Plantu L’Express.’Vinocur herinnert aan een tekening van Plantu L’Express. (Het Parool, 2002-05-18, Art. 101)‘Vinocur reminds [spectator] drawing Plantu L’Express.’Ik herinner een concert waarop hij hevig gesticulerend applaus ontvangst kwam nemen. (Het Parool, 2003-11-14, Art. 79)\n‘remember concert received round overwhelming applause.’Ik herinner een concert waarop hij hevig gesticulerend applaus ontvangst kwam nemen. (Het Parool, 2003-11-14, Art. 79)‘remember concert received round overwhelming applause.’\"Het die dag bloedheet\", herinnert de atlete uit Sint-Andries zich nog levendig. (Het Nieuwsblad, 2001-08-08, Art. 192)\n‘\"scorching hot day\", remembers athlete Sint-Andries vividly.’\"Het die dag bloedheet\", herinnert de atlete uit Sint-Andries zich nog levendig. (Het Nieuwsblad, 2001-08-08, Art. 192)‘\"scorching hot day\", remembers athlete Sint-Andries vividly.’zijn voorwoord herinnert Manara eraan dat deze meisjes hun tijd vaak met toegeknepen oogjes werden aanschouwd. (De Morgen, 2001-11-10, Art. 40)\n‘preface Manara reminds [reader] back time girls often looked squinted eyes.’zijn voorwoord herinnert Manara eraan dat deze meisjes hun tijd vaak met toegeknepen oogjes werden aanschouwd. (De Morgen, 2001-11-10, Art. 40)‘preface Manara reminds [reader] back time girls often looked squinted eyes.’shape coding plot indicates, clusters semantically homogeneous46, function words perfect cues senses. rest co-occurring context words make difference: strong enough, face pronouns prepositions, originate salient structure. Nonetheless, aan eraan clusters one side, pronoun-based clusters , belong sense. Thus, lexically instantiated colligation clusters represent typical salient pattern within sense.\nFigure 6.8: Cloud herinneren: bound10all-ppmiweight-5000nav. Circles indicate ‘remind’ (aan); triangles, ‘(reflexive) remember,’ () squares, ‘(trans.) remember.’\n","code":""},{"path":"semantic-interpretation.html","id":"profiling","chapter":"6 The language of clouds","heading":"6.3.4 Profiling","text":"Like clusters defined collocations, clusters defined lexically instantiated colligations can also represent typical context highlights specific dimension sense target. One case found ‘horde’ sense horde, whose salient collocates corpus toerist ‘tourist’ journalist. two collocates quite similar type-level, rest context words clusters point towards different dimension ‘horde’ sense: hordes journalists, photographers fans (nouns present cluster) surround follow celebrities, suggested co-occurrence omring ‘surround,’ wacht_op ‘wait’ achtervolg ‘chase,’ among others. contrast, hordes tourists instead flood move around city, words stroom_toe ‘flood’ stad ‘city.’\nstands, situation equivalent case stof ‘substance’ described . However, models capture function words\nlike one shown Figure 6.9,\nprofiling clusters strengthened lexically instantiated colligations. journalist cluster dominated preposition door, signals explicit agents passive constructions;\n\npassive auxiliary word also occurs, albeit less frequently. Meanwhile, toerist ‘tourist’ cluster includes tokens co-occurring naar ‘towards.’ prepositions coherent dimensions ‘horde’ highlighted clusters, .e. aggressivity flow respectively. Interestingly, don’t co-occur tokens also co-occur journalist toerist ‘tourist’ respectively, nouns prepositions complement instead.\nFigure 6.9: Cloud horde: bound5all-ppmiselection-focall. Within ‘horde’ homonym, circles indicate human members triangles, nonhuman members; within ‘hurdle’ homonym, squares show literal sense crosses, metaphorical one.\n","code":""},{"path":"semantic-interpretation.html","id":"semantic-preference","chapter":"6 The language of clouds","heading":"6.4 Semantic preference","text":"Clusters clearly dominated one context word group co-occurring context words, lexical collocations lexically instantiated colligations, may still result coherent distributional semantic patterns. Representing first-order context words type-level vectors allows infrequent near neighbours join forces approximate effect one context word cumulative frequency. context words may occur one four times sample, , one every hundred occurrences target, together similar context words, form visible pattern.","code":""},{"path":"semantic-interpretation.html","id":"uitspraak","chapter":"6 The language of clouds","heading":"6.4.1 Heterogeneous clusters","text":"Just like can clusters dominated one context word characteristic one sense, can clusters dominated multiple similar context words characteristic sense. case names colours clothing terms47 co-occurring grijs ‘gray,’ model like one shown Figure 6.10 also includes haar ‘hair.’\nresult, grijs ‘gray’ tokens referring concrete grey objects general , specifically, grey/white hair, form light blue Stratocumulus cloud top right figure. Note , visually, two senses occupy opposite halves cluster: haar ‘hair’ tokens (squares) occupy space, type-level similarity context word names colours clothing terms makes indistinguishable hdbscan.\nFigure 6.10: Cloud grijs: bound5all-ppmino-focall. Circles represent literal sense; triangles, ‘overcast’; squares crosses, applications hair white-haired people respectively; crossed squares, ‘boring,’ asterisks, ‘half legal.’\nsecond example set juridical terms herroepen, means ‘recant’ object statement opinion, ‘annul, void’ law decision. QLVLNewsCorpus, often used broad legal juridical context. However, one frequent collocates herroepen within field uitspraak, can either mean ‘verdict,’ therefore invoking ‘void’ sense like (32), ‘statement,’ ‘recant’ applies, like (33). Unfortunately, broader context clear enough models disambiguate appropriate meaning uitspraak herroepen instance. type-level, uitspraak close number context words juridical field, namely rechtbank ‘court,’ vonnis ‘sentence,’ veroordeling ‘conviction,’ etc. Together, constitute semantic preference light blue Stratocumulus cloud Figure 6.11, , similar grijs haar ‘gray/white hair’ situation , visually split tokens co-occurring uitspraak co-occurring rest juridical terms.Het beroepscomité herriep gisteren de uitspraak van de licentiecommissie en besliste om KV Mechelen toch zijn licentie te geven. (De Standaard, 2002-05-04, Art. 95)\n‘Yesterday court appeal voided verdict licencing committee instead decided grant KV Mechelen licence.’Het beroepscomité herriep gisteren de uitspraak van de licentiecommissie en besliste om KV Mechelen toch zijn licentie te geven. (De Standaard, 2002-05-04, Art. 95)‘Yesterday court appeal voided verdict licencing committee instead decided grant KV Mechelen licence.’Onder druk van Commissievoorzitter Prodi heeft Nielson verklaard dat hij verkeerd geïnterpreteerd, maar hij heeft zijn uitspraak niet herroepen. (NRC Handelsblad, 2001-10-04, Art. 79)\n‘pressure committee chairman Prodi, Nielson declared misinterpreted, recant statement.’Onder druk van Commissievoorzitter Prodi heeft Nielson verklaard dat hij verkeerd geïnterpreteerd, maar hij heeft zijn uitspraak niet herroepen. (NRC Handelsblad, 2001-10-04, Art. 79)‘pressure committee chairman Prodi, Nielson declared misinterpreted, recant statement.’result understandable interpretable: context words co-occurring tokens light blue cluster belong semantically coherent set distributional near neighbours. problem , sample, sense uitspraak occurs juridical one like (32) ‘statement’ like (33), therefore representing different sense herroepen juridical siblings. models, two groups split different clusters, like one shown Figure 6.11, form heterogeneous cluster generated semantic preference.Interestingly, verklaring ‘statement’ bekentenis ‘confession’ considered part semantic field well, broad terms. However, belong different frame within field legal action — different stage process — , correspondingly, type-level vectors different tend represent distinct, homogeneous clusters (green Cumulus figure).\nFigure 6.11: Cloud herroepen: bound3all-ppmiselection-focall. Circles represent ‘void’; triangles, ‘recant.’\n","code":""},{"path":"semantic-interpretation.html","id":"dictionary-clusters","chapter":"6 The language of clouds","heading":"6.4.2 Dictionary clusters","text":"senses can completely clustered groups similar context words.\nOne cases already discussed context schaal ‘scale’ tokens: models exclude Richter part--speech tag name, tokens co-occurring can alternatively grouped kracht ‘power,’ aardbeving ‘earthquake’ related context words. case Richter dominating collocate, semantic field earthquakes part definition ‘range’ sense schaal, dominating semantic pattern within corpus study.Another example found haken, ‘make someone trip’ sense characterized variety football-related terms (strafschop ‘penalty kick,’ penalty, scheidsrechter ‘referee,’ etc.), infrequent ‘crochet’ sense, brei ‘knit,’ naai ‘sew,’ hobby similar words. represented Stratocumulus dark blue squares Cirrus light blue crossed squares Figure 6.12 respectively. indicated name dark blue cluster, passive auxiliary word also characteristic ‘make someone trip’ cluster rarely occurs outside : , lexically instantiated colligation working together clear semantic preference cloud.\nFigure 6.12: Cloud haken: bound10lex-ppmiselection-focnav. Circles triangles represent transitive intransitive literal ‘hook’; crosses represent figurative (intransitive) sense; filled squares represent ‘make someone trip’; crossed squares, ‘corchet,’ asterisks, ‘strive ’ (naar).\n","code":""},{"path":"semantic-interpretation.html","id":"prototypical-contexts-1","chapter":"6 The language of clouds","heading":"6.4.3 (Proto)typical contexts","text":"several examples clusters defined semantically similar infrequent context words representing typical contexts sense. Figure 6.10, example, dark blue Stratocumulus represented cars, mostly indicated Mercedes Opel, next brands. case lemmas like dof ‘dull,’ models might dedicate different clusters specific collocates, klink ‘sound,’ knal ‘bang,’ klap ‘clap’ dreun ‘pounding,’ others group together one large cluster defined semantic preference indicative sense, e.g. sounds.typical semantic group attested different lemmas culinary: found schaal ‘dish’ — blue Cumulus crosses Figure 6.10 — heet ‘hot,’ red Stratocumulus mostly circles Figure 6.13. case heet ‘hot,’ almost tokens co-occurring cluster refer literally hot foods drinks, although full expression might idiomatic, like (34), belong much less frequent sense ‘spicy.’ models, tokens co-occurring soep ‘soup’ /co-occurring water tokens might form separate clusters.Hoogstwaarschijnlijk zal Poetin Ruslands afgeknapte westerse partners discreet laten weten dat zodra hij eenmaal het Kremlin zit, de soep minder heet gegeten zal worden. (De Volkskrant, 1999-12-21, Art. 22)\n‘probably Putin discretely let Russia’s former western allies know soon Kremlin, things look (lit. `soep eaten less hot’).’Hoogstwaarschijnlijk zal Poetin Ruslands afgeknapte westerse partners discreet laten weten dat zodra hij eenmaal het Kremlin zit, de soep minder heet gegeten zal worden. (De Volkskrant, 1999-12-21, Art. 22)‘probably Putin discretely let Russia’s former western allies know soon Kremlin, things look (lit. `soep eaten less hot’).’addition, aardappel ‘potato’ type-level near neighbour context words semantic group, still tends form cluster, like orange Cumulus figure. due frequency distinctiveness larger cotext, e.g. co-occurrence schuif_door ‘pass .’ Like expressions annotated ‘hot touch’ sense (circles figure), including hete hangijzer ‘hot irons’ yellow hete adem (de nek) ‘hot breath (neck)’ light blue, hete aardappel ‘hot potato’ used metaphorically. strict combination adjective noun, meaning heet proper still ‘hot touch’: combination metaphorized (discussion see Geeraerts 2003).\ncontext words frequent distinctive enough generate clusters tokens co-occur , aardappel ‘potato’ tends stick close culinary cluster even merge .\nFigure 6.13: Cloud heet: bound5all-ppmino-focall. Among literal senses, cricles, filled triangles filled diamonds represent tactile, weather body senses; empty squares triangles represent ‘spicy’ ‘attractive’ respectively; crosses represent ‘conflictive,’ asterisks, ‘popular new.’\n","code":""},{"path":"semantic-interpretation.html","id":"profiling-1","chapter":"6 The language of clouds","heading":"6.4.4 Profiling","text":"adjective geldig ‘valid’ can relate legal regulated acceptability, frequent sense sample, may broader application, entities like redenering ‘reasoning.’ definition, like lemmas studied , sense matches form semantic preference. addition, models lemma reveal semantic preference patterns within frequent, specific sense, , turns, highlights different dimension sense. patterns may identified areas t-sne plots , models like one shown Figure 6.14, clouds.green Stratocumulus characterized context words rijbewijs ‘driving license,’ paspoort ‘passport’ forms identification, well verbs like leg_voor ‘present,’ heb ‘’ bezit ‘possess.’ words, represents contexts someone demonstrate possession valid identification document, shown (35). light blue Cirrus yellow Cumulus, hand, co-occur kinds documents (ticket, abonnement ‘subscription’), euro, preposition tot ‘,’ times (maand ‘month,’ jaar ‘year,’ numbers, etc.). case, price documents duration validity salient, illustrated (36).Aan de incheckbalie kon de Somaliër echter geen geldige papieren voorleggen. (Het Laatste Nieuws, 2001-08-24, Art. 64)\n‘Somali show valid papers check-desk.’Aan de incheckbalie kon de Somaliër echter geen geldige papieren voorleggen. (Het Laatste Nieuws, 2001-08-24, Art. 64)‘Somali show valid papers check-desk.’Klanten van Kunst Huis zijn bovendien zeker van variatie: wie lid , kan elke maand een ander werk uitkiezen, het abonnement blijft een leven lang geldig en de maandelijkse huurprijs van 250 frank ook niet bepaald hoog te noemen. (De Standaard, 1999-05-29, Art. 41)\n‘Moreover, customers Kunst Huis (lit. `Art Home’) guaranteed variation: members can choose different work month; subscription remains valid lifetime monthly fee 250 franks particularly high either.’Klanten van Kunst Huis zijn bovendien zeker van variatie: wie lid , kan elke maand een ander werk uitkiezen, het abonnement blijft een leven lang geldig en de maandelijkse huurprijs van 250 frank ook niet bepaald hoog te noemen. (De Standaard, 1999-05-29, Art. 41)‘Moreover, customers Kunst Huis (lit. `Art Home’) guaranteed variation: members can choose different work month; subscription remains valid lifetime monthly fee 250 franks particularly high either.’\nFigure 6.14: Cloud geldig: bound10lex-ppmiselection-focall. Circles represent specific sense triangles, general one.\n","code":""},{"path":"semantic-interpretation.html","id":"openchoice","chapter":"6 The language of clouds","heading":"6.5 Near-open choice","text":"clouds described now chapter can easily interpreted terms dominating context words semantic domains. expect always case: hdbscan identifies cluster, must structure; structure, must underlying pattern; underlying pattern, can meaningfully interpreted. Unfortunately, always case. hdbscan clusters can also formed opposition: saw case Cumulonimbus clouds, .e. massive clusters covering least half sampled tokens, grouping criterion might negative definition. strong pattern, everything else conform dumped together. situations, whatever structure hdbscan picks faint, compared Cumulus skies may find heffen hachelijk (see Section 6.2.3). present, understand relationship hdbscan token-level distributional models well enough make sense less interpretable clusters emerge meaningful really .One possible interpretations kinds clusters, linguistic point view, patterns closer “open choice” side spectrum, cases discussed Section 6.2 closer “idiom” side. open-choice idiom principle really presented poles continuum, help interpretative tool make sense variation cloud shapes within lemma across lemmas. split data studied models follow idiom principle don’t, degree distributional behaviour lemma can explained idiom principle different.\ngenerate list collocations item, see relevant patterns; read sorted concordances, focus similarities stand ; token-level distributional models, instead, can see strong weak patterns .section look examples clusters interpreted terms dominating context words semantic domains. result heterogeneous clusters, especially Cumulonimbus clouds, can also, occasionally, bring together tokens senses certain characteristics. found cases near-open choice clusters represent semantically homogeneous prototypical contexts.","code":""},{"path":"semantic-interpretation.html","id":"blik","chapter":"6 The language of clouds","heading":"6.5.1 Heterogeneous clusters","text":"common situation clusters explained dominant context word semantic preference, especially Cumulonimbus clouds, semantically heterogeneous. massive clouds occur models small number tokens similar — typically idiomatic expressions, necessarily — stand cluster, everything else either belongs massive cluster noise. many cases barely noise left, others hdbscan seem find difference many, varied tokens Cumulonimbus clouds left noise.One example Cumulonimbus cloud blik Figure 6.15, shown orange. small Cumulus clouds either side represented co-occurrence werp ‘throw’ richt ‘aim,’ indicate prototypical instances blik ‘gaze’ (see (37) (38)). tokens excluded noise — patterns form seem different clustered tokens merge , infrequent qualify cluster .Op zaterdag 27 april zwaait de lokale politie van de zone Kortrijk-Kuurne-Lendelede de deuren wijd open voor al wie een blik wil werpen achter de schermen van het politiewerk. (Het Laatste Nieuws, 2002-04-23, Art. 54)\n‘Saturday 27 April local police Kortrijk-Kuurne-Lendelede zone opens doors wide want look behind scenes police work.’Op zaterdag 27 april zwaait de lokale politie van de zone Kortrijk-Kuurne-Lendelede de deuren wijd open voor al wie een blik wil werpen achter de schermen van het politiewerk. (Het Laatste Nieuws, 2002-04-23, Art. 54)‘Saturday 27 April local police Kortrijk-Kuurne-Lendelede zone opens doors wide want look behind scenes police work.’Maar wat goed genoeg, zo lijkt Staelens zich af te vragen, haar blik strak naar beneden gericht. (De Volkskrant, 2003-09-27, Art. 170)\n‘good enough, Staelens seems wonder, gaze looking straight .’Maar wat goed genoeg, zo lijkt Staelens zich af te vragen, haar blik strak naar beneden gericht. (De Volkskrant, 2003-09-27, Art. 170)‘good enough, Staelens seems wonder, gaze looking straight .’orange cluster may seem homogeneous predominance circles, simply effect large frequency ‘gaze’ sense, can also occur contexts like (39). sense ‘gaze’ homonym, ‘perspective,’ shown (40), ‘tin’ homonym (see (41)), also part massive heterogeneous cluster. anything brings tokens together, fact normally match patterns (37) (38), typically co-occur een ‘, ,’ de ‘,’ met ‘,’ op ‘,’ frequent prepositions, one time. frequent, partially overlapping, meaningful patterns bring tokens together , degree, set apart.Totdat Walsh met een droevige blik zijn ogen vertelt dat hij het moeilijk heeft. (Het Parool, 2004-03-02, Art. 121)\n‘Walsh, sad look eyes, says ’s hard time.’Totdat Walsh met een droevige blik zijn ogen vertelt dat hij het moeilijk heeft. (Het Parool, 2004-03-02, Art. 121)‘Walsh, sad look eyes, says ’s hard time.’IMF en Wereldbank liggen al jaren onder vuur wegens hun vermeend eenzijdige blik op de ontwikkelingsproblemen van Afrika. (Algemeen Dagblad, 2001-02-20, Art. 129)\n‘IMF World Bank attack years alledgedly unilateral view delevopment issues Africa.’IMF en Wereldbank liggen al jaren onder vuur wegens hun vermeend eenzijdige blik op de ontwikkelingsproblemen van Afrika. (Algemeen Dagblad, 2001-02-20, Art. 129)‘IMF World Bank attack years alledgedly unilateral view delevopment issues Africa.’Zijn vader een fabriek waar voedsel blik werd gemaakt. (NRC Handelsblad, 2003-12-05, Art. 120)\n‘father factory canned food (lit. `food tin cans’) made.’Zijn vader een fabriek waar voedsel blik werd gemaakt. (NRC Handelsblad, 2003-12-05, Art. 120)‘father factory canned food (lit. `food tin cans’) made.’\nFigure 6.15: Cloud blik: bound5all-ppmiweight-5000nav. first homonym, circles represent ‘gaze’ triangles, ‘view, perspective’; second, squares represent ‘tin’ crosses, ‘made tin’ ‘canned food.’\n","code":""},{"path":"semantic-interpretation.html","id":"huldigen","chapter":"6 The language of clouds","heading":"6.5.2 Dictionary clusters","text":"might seem pointless look meaning clusters respond either dominating context words semantically similar context words, lemmas, might make sense. case model huldigen shown Figure 6.16.Like transitive verbs, senses lemma characterized kind direct objects can take. direct object huldigen idea opinion, means ‘hold, believe’: sample, typical cases include principe ‘principle,’ standpunt ‘point view’ opvatting ‘opinion’ (see examples (42) (44)). three near neighbours type level, frequent enough lead Cumulus Stratocumulus clouds models, like Figure 6.16.\ncontexts, huldigen means ‘honour, pay homage,’ role patient normally filled human beings (see examples (45) (46)). practice, variety nouns can take place much larger ‘believe,’ result, clusters cover ‘honour’ less compact defined clusters representing sense. yet, Cumulonimbus shown yellow Figure 6.16 almost perfectly represents ‘honour’ sense. possible?Jacques: ``Voor het eerst huldigen het principe dat de vervuiler betaalt.\" (De Morgen, 1999-03-10, Art. 12)\n‘Jacques: ``first time uphold principle polluters must pay.\"’Jacques: ``Voor het eerst huldigen het principe dat de vervuiler betaalt.\" (De Morgen, 1999-03-10, Art. 12)‘Jacques: ``first time uphold principle polluters must pay.\"’De regering Washington huldigt het standpunt dat volgens Amerikaans recht de vader beslist het domicilie van zijn minderjarige zoon. (NRC Handelsblad, 2000-04-03, Art. 97)\n‘government Washington holds view according American law fathers decide primary residence underage sons.’De regering Washington huldigt het standpunt dat volgens Amerikaans recht de vader beslist het domicilie van zijn minderjarige zoon. (NRC Handelsblad, 2000-04-03, Art. 97)‘government Washington holds view according American law fathers decide primary residence underage sons.’…de objectieve stand van zaken de buitenwereld zou kunnen weerspiegelen. Rorty huldigde voortaan de opvatting dat waarheid synoniem voor wat goed voor ons. (De Standaard, 2003-01-09, Art. 93)\n‘…reflect objective state affairs outside world. Ever since Rorty held opinion truth synonym good us.’…de objectieve stand van zaken de buitenwereld zou kunnen weerspiegelen. Rorty huldigde voortaan de opvatting dat waarheid synoniem voor wat goed voor ons. (De Standaard, 2003-01-09, Art. 93)‘…reflect objective state affairs outside world. Ever since Rorty held opinion truth synonym good us.’\"Elk jaar huldigen wij onze kampioenen en sinds enkele jaren richten een jeugdkampioenschap \", zegt voorzitter Eddy Vermoortele. (Het Laatste Nieuws, 2003-04-15, Art. 121)\n‘\"Every year honour champions years ’ve organizing youth championship\", says chairman Eddy Vermoortele.’\"Elk jaar huldigen wij onze kampioenen en sinds enkele jaren richten een jeugdkampioenschap \", zegt voorzitter Eddy Vermoortele. (Het Laatste Nieuws, 2003-04-15, Art. 121)‘\"Every year honour champions years ’ve organizing youth championship\", says chairman Eddy Vermoortele.’Langs de versierde straten zijn naar de kerk gereden en na de plechtigheid hebben Karel nog gehuldigd feestzaal Santro. Hij nog een heel kranige man. (Het Laatste Nieuws, 2003-07-18, Art. 256)\n‘drove ornate streets towards church ceremony honoured Karel party hall Santro. still spry man.’Langs de versierde straten zijn naar de kerk gereden en na de plechtigheid hebben Karel nog gehuldigd feestzaal Santro. Hij nog een heel kranige man. (Het Laatste Nieuws, 2003-07-18, Art. 256)‘drove ornate streets towards church ceremony honoured Karel party hall Santro. still spry man.’\nFigure 6.16: Cloud huldigen: nobound3lex-ppmiselection-focall. Circles represent ‘believe, hold (opinion)’; triangles, ‘honour.’\nOne factors playing role layout model co-occurrences principe ‘principle,’ standpunt ‘point view’ opvatting ‘opinion’ exhaust half attestation ‘believe’ sense. rest tokens varied typically fall noise. variety within ‘honour’ sense compete stark differences clusters everything else. Nonetheless, form structure within sense differentiates equally varied remaining tokens ‘believe,’ family resemblance structure.single semantic field enough cover variety contexts huldigen ‘honour’ occurs sample: instead, find different aspects variations prototypical situation ceremonies organized sports- city organizations public places, honour successful athletes.\norder get better picture syntagmatic relationships context words within cluster, can represent network, show Figure 6.17. node represents one 150 frequent context words co-occurring tokens yellow cloud Figure 6.16, connected context words co-occurs token cluster. thickness edges represents frequency context words co-occur within sample; size nodes summarizes frequency, size label roughly represents frequency context word among tokens cluster.frequent context word passive auxiliary word: context word captured tokens dense core upper right corner cloud, co-occurs half tokens cluster. number different, less frequent context words partially co-occur , kampioen ‘champion,’ stadhuis ‘city hall’ sport_raad ‘sports council.’ subsequently generate productive branches family resemblance network. Crucially, shows might token co-occurs verdienstelijk ‘deserving’ sport_raad ‘sports council’ one co-occurs gemeente_bestuur ‘municipal administration’ officieel ‘official,’ part cluster.Semantically distributionally, context words plotted network belong different, loosely related fields, sports (kampioen ‘champion,’ winnaar ‘winner,’ sport_raad ‘sports council’), town administration (stad_bestuur, gemeente_bestuur ‘city administration’) temporal expressions (jaar ‘year,’ weekend). predominance passive auxiliary word — lexically instantiated colligation — presence unified semantic fields — multiple semantic preferences — family resemblance among tokens, resulting intricate network co-occurrences, work together model subtle, complex semantic structure huldigen ‘honour.’\nFigure 6.17: Network context words huldigen `honour’ cluster.\n","code":""},{"path":"semantic-interpretation.html","id":"theo1-summary","chapter":"6 The language of clouds","heading":"6.6 Summary","text":"Different types clouds offer us different kinds information. ideal result clusters equal dictionary senses rarely found, instead typically find collocations represent (proto)typical contexts within sense. Next typical result, encounter variety phenomena combining syntagmatic paradigmatic aspects. Along collocations, find colligation semantic preference motors behind clusters, also number cases clear distributional pattern can found. phenomena correlate decently types clouds discussed Chapter 5: collocations Cumulus clouds, lexically instantiated colligation Stratocumulus clouds, semantic preference Cumulonimbus, near-open choice Cumulonimbus. , course, deterministic mappings, general tendencies.\nparadigmatic semantic level, next clusters represent typical contexts, find heterogeneous clusters match senses completely. addition, typical contexts may include richer information regarding different semantic dimensions sense highlighted certain contexts, .e. prototypical contextual pattern.chapter seen different combinations syntagmatic paradigmatic phenomena, shapes can take models different lemmas. Clouds necessarily match senses, may offer us types information, depending distributional properties lemma dimensions relevant semasiological structure. following chapter look (lack ) relationship information obtain parameter settings.","code":""},{"path":"no-optimal.html","id":"no-optimal","chapter":"7 No sky is the best sky","heading":"7 No sky is the best sky","text":"magic trick extract neat, semantically homogeneous clouds wild sea corpus attestations. seen Chapter 5, clouds can take number different shapes, depending variability context words co-occur target, frequency diversity. Chapter 6 shows clusters may various interpretations, syntagmatic perspective paradigmatic perspective, resulting diverse net phenomena. also explores role similarity co-occurrence context words. chapter, look relationship results parameter settings produce .consonance previous analyses, golden law drawn . set parameter settings reliably returns best output: specific parts speech, specific semantic phenomena.\nvariability illustrated two sections: Section 7.1 compare medoids hoop ‘hope/heap’ stof ‘substance/dust…’ best model homonymy lemma, Section 7.2 look shape parameter configuration takes many different models.","code":""},{"path":"no-optimal.html","id":"hoopstof","chapter":"7 No sky is the best sky","heading":"7.1 A pile of dust","text":"mentioned Chapter 4, modelled 7 homonymous polysemous nouns, intention studying relationship parameter settings granularity meaning. expected certain parameters better modelling differences homonyms others able capture, least cases, subtle differences senses homonym. However, even though homonymy relatively easy model48, results straightforward. example, let’s look medoids hoop ‘hope, heap’ stof ‘substance, dust…’ successfully model manual annotation.Figure 7.1 shows best medoid lemmas, terms semantic homogeneity clusters. mapping sense tags colours, can see rather well defined, homogeneous area t-sne plot. noted, however, areas relatively uniform, hard pressed find clear structure without colour-coding. fact, hdbscan highlights salient areas, covering, example, center light blue island left plot.\nFigure 7.1: Best medoids hoop (pathweight-ppmino-focall) stof (bound5lex-ppmiselection-focall).\nsenses plotted colours coded numbers avoid cluttering. senses hoop , first homonym, [1] literal ‘heap, pile’ [2] general ‘heap, bunch,’ second homonym, [3] ‘hope.’ first homonym stof includes [1] ‘substance,’ [2] ‘fabric’ [3] ‘topic, material,’ second covers [4] literal ‘dust’ [6] idiomatic ‘dust.’ sense [5], originally ‘(reduced ) dust,’ attested.\nrelevant examples given .parameters result models fact different, although second-order configuration equivalent: union context words captured model also used second-order dimensions. result, dimensionality token-level vectors quite low: 833 hoop 483 stof.model works best hoop medoid manages group tokens ‘heap’ homonym away larger mass ‘hoop’ tokens (green), even neat moat . sacrifice infrequent literal ‘heap’ sense (orange), split indeed outstanding. achieved PATHweight model: uses syntactic information, selects context words connected three steps away target, weights contribution item distance, regardless precise nature syntactic relationship, part--speech information pmi. syntactic distances, .e. number steps target dependency path, illustrated superscripts examples (47) (48).(47), indefinite determiner een modified noun onzin ‘nonsense’ directly linked target hoop dependent head respectively, taken model receive highest weight. first occurrence verb head subject onzin ‘nonsense,’ hence two steps away target: included receives slightly lower weight. particle er, tagged modifier , second instance , head subordinate clause, three steps away target, therefore obtain low weight. rest context ignored model.Example (48) offers much complex picture, particularly link target hoop ‘hope’ verb spreek_uit ‘express’ (split sprak particle uit), short. core dependency tree, main verb opens path many elements sentence.Er3 is2 een1hoop onzin1, talent is3 niet iedereen gegeven. (Algemeen Dagblad, 2001-01-27, Art. 78)\n‘lot nonsense; talent given everyone.’Er3 is2 een1hoop onzin1, talent is3 niet iedereen gegeven. (Algemeen Dagblad, 2001-01-27, Art. 78)‘lot nonsense; talent given everyone.’De3 trainer2 van3 FC Utrecht sprak1 verder2 de1hoop uit2 dat1 hij3 binnenkort weer eens mag2 investeren3 van de clubleiding. (NRC Handelsblad, 2004-05-24, Art. 93)\n‘manager FC Utrecht also expressed hope club management allow invest soon.’De3 trainer2 van3 FC Utrecht sprak1 verder2 de1hoop uit2 dat1 hij3 binnenkort weer eens mag2 investeren3 van de clubleiding. (NRC Handelsblad, 2004-05-24, Art. 93)‘manager FC Utrecht also expressed hope club management allow invest soon.’key point lemma hoop ‘hope,’ represented (48), mass noun, therefore tends occur definite determiner de (40% cases). contrast, hoop ‘heap,’ represented (47), tends occur een ‘(n)’ (64 76 occurrences). correlation hard extract bag--words model, either filter function words determiners, include determiners, related target , thus drowning pattern noise.contrast, parameter settings work best stof bound5lex PPMIselection, .e. capture nouns, verbs, adjectives adverbs within 5 slots side target, long within limits sentence pmi target lemma positive. case (49), example, model selects discussie ‘discussion’ lever_op ‘bring , return,’ italics transcription. Words might follow period excluded model, film ‘movie.’ Within window span 5 words side, die ‘,’ na ‘,’ veel ‘much’ tot ‘’ excluded part--speech filter. Finally, nouns film ‘movie’ afloop ‘end, conclusion,’ survive window size part--speech filters, excluded association strength filter, since pmi value relation stof lower 0.Dit een perfect voorbeeld van een film die na afloop veel stof tot discussie oplevert. (Algemeen Dagblad, 2003-12-11, Art. 58)\n‘perfect example film afterwards provides lot food thought (lit. `stuff discussion’).’Dit een perfect voorbeeld van een film die na afloop veel stof tot discussie oplevert. (Algemeen Dagblad, 2003-12-11, Art. 58)‘perfect example film afterwards provides lot food thought (lit. `stuff discussion’).’generous, can find good representation granularity meaning hoop Figure 7.1. case stof, however, senses quite well distinguished homonyms .\nFirst, idiomatic ‘dust’ tokens group quite nicely sort appendix main cloud. tokens, definition idiomatic uses stof, tend tightly grouped models. example can seen (50). Notably, also include literal tokens also co-occur one defining context words, .e. doe ‘make’ waai_op ‘lift.’Het huwelijk tussen de hervormde Maurits en de katholieke Marylene deed de nodige stof opwaaien. (Algemeen Dagblad, 1999-12-08, Art. 3)\n‘wedding Maurit, Reformed Christian, Marylene, Catholic, inspired much needed debate (lit. `stirred necessary dust’).’Het huwelijk tussen de hervormde Maurits en de katholieke Marylene deed de nodige stof opwaaien. (Algemeen Dagblad, 1999-12-08, Art. 3)‘wedding Maurit, Reformed Christian, Marylene, Catholic, inspired much needed debate (lit. `stirred necessary dust’).’rest tokens seem organized sense subtle borders . frequent sense, ‘substance,’ even includes independent islands top, already discussed Section 6.2.4.interestingly, ‘fabric’ ‘dust,’ light blue yellow respectively, like go together, even though belong different homonyms. fact, hdbscan merges together one cluster, see Figure 7.3. entirely surprising, given senses tend co-occur quite concrete context words, names materials colours (see example (51) (52)), ‘substance’ sense chemically-oriented ‘topic, material’ sense, illustrated (49), co-occurs semantic domain communication instead.Dankzij de nieuwe vlekwerende ``stay clean\"-behandelingen dringen zelfs vloeistoffen zoals olie, vruchtensap water niet de stof. (De Standaard, 2001-01-19, Art. 6)\n‘Thanks new stain-resistant ``stay clean\" treatments even liquids oil, fruit juice water penetrate fabric.’Dankzij de nieuwe vlekwerende ``stay clean\"-behandelingen dringen zelfs vloeistoffen zoals olie, vruchtensap water niet de stof. (De Standaard, 2001-01-19, Art. 6)‘Thanks new stain-resistant ``stay clean\" treatments even liquids oil, fruit juice water penetrate fabric.’Na het stof de douche. De tocht door de Hel zit er op. (De Morgen, 2003-04-15, Art. 65)\n‘dust shower. trip Hell [cobblestone cycling road] .’Na het stof de douche. De tocht door de Hel zit er op. (De Morgen, 2003-04-15, Art. 65)‘dust shower. trip Hell [cobblestone cycling road] .’description suffice understand different parameter configurations necessary model different lemmas. fact homonyms enough: aspects structure, kind contextual features characterize sense homonym, play role.shown models good. come applying parameter settings work best one lemma onto ? see Figure 7.2.\nFigure 7.2: Model hoop parameters work best stof viceversa: bound5lex-ppmiselection-focall hoop pathweight-ppmino-focallfor stof\nIndeed, swapping configurations returns unsatisfying results. case hoop, see similar picture many models: plot overrun ‘hope,’ maybe area ‘literal heap’ tokens, ‘general heap’ tokens, nicely separated Figure 7.1, mixed distributed across one hemisphere. case stof, keep large ‘substance’ area orange, isolated blue section idiomatic ‘dust’ shy green peninsula ‘topic, material’ tokens, concrete senses, ‘fabric’ ‘dust,’ disperse mixed.Even fairly straightforward task discriminating homonyms, parameters succeed one lemma fail . unrelated number frequency senses. Instead, inextricably linked particular distributional behaviour lemma. stof can find collocations semantic preferences , various degrees, represent (parts ) senses, lexical contexts hoop varied generate clear clusters. hand, syntactically informed model can identify determiners relevant feature hoop, information seems less interesting regard stof.\nTable 7.1: Salient parameter settings per lemma.\n","code":""},{"path":"no-optimal.html","id":"paramranking","chapter":"7 No sky is the best sky","heading":"7.2 Weather forecast gone crazy","text":"Parameter settings equal effect across models. Even Level 1, compare models lemma , encounter variety patterns.\nTable 7.1 groups lemmas based three criteria make greatest difference organization Level 1 plots. main columns refer effects first-order part--speech filter ppmi weighting: first group lemmas, lex models occupy specific area Level 1 plot; second isolated next PPMIweight models (sometimes REL well), third, effect part--speech setting found. next level columns distinguishes effect window size among BOW models. radial window configuration means models window 5 lie window 3 window 10. Typically, models smaller windows closer dependency-based models, huldigen exception. Three lemmas really exhibit radial structure, models smallest window tend isolated instead. Finally, rows indicate effect second-order vectors: first row gathers lemmas separate section 5000all second-order configuration; second, lemmas models 5000 vectors simply tendency wrap around rest models (like wings beetle), third row used lemmas second-order parameters special effect organization models. Models 5000all second-order configuration consistently messy, tend make type-level distances pairs context words huge.can see table, patterns related part--speech target semantic phenomena expect . variability different ranges distances models reason selecting medoids reasonable way exploring diversity models.Qualitatively, set parameter settings can generate multiple different solutions, depending distributional properties lemma modelled. already saw comparison Figures 7.1 7.2: works best one lemma necessary give decent result another. section, briefly look models previously plotted Figures 5.1 5.2. cases, parameter settings best model stof:\nbound5lex-ppmiselection-focall. colour-coding matches hdbscan clusters, shapes, annotated senses.Figure 7.3, see model heet ‘hot’ stof ‘substance, dust….’ model heet ‘hot’ 12 clusters, roughly equal proportion Cumulus, Stratocumulus Cirrus clouds. collocation clusters representing typical patterns within sense, also find cases semantic preference heterogeneous near-open choice clusters. stof ‘substance, dust…’ model looks roughly similar, 7 relatively homogeneous clusters: three Stratocumulus upper left collocation clusters discussed Section 6.2.4 , next red Cirrus defined semantic preference, represent typical uses ‘substance’ sense. rest clusters, discussed , heterogeneous. difference two lemmas , homogeneous clouds stof ‘substance’ represent typical uses profile different dimensions sense, typical patterns within heet ‘hot’ constitute idiomatic expressions.\nFigure 7.3: Models heet stof bound5lex-ppmiselection-focall.\nlemmas shown Figure 7.4, dof ‘dull’ huldigen ‘believe/honour,’ look rather similar different ones Figure 7.3. Even though dof ‘dull,’ unlike heet, tends multiple clusters characterized collocations different types sounds, takes different shape model. metaphorical sense represented collocation ellende ‘misery’ forms neat orange Cumulus one side; semantic preference sounds gives rise homogeneous light blue Stratocumulus , rest tokens, related visual sense rest metaphorical ones, gather heterogeneous green Stratocumulus. seen , huldigen also strong collocates, model, tokens ‘believe,’ led principe ‘principle,’ opvatting ‘opinion’ standpunt ‘point view,’ take part extremely homogeneous orange Stratocumulus, ‘pay homage’ sense covers light blue Cumulonimbus, like case described Section 6.5.2.\nFigure 7.4: Models dof huldigen bound5lex-ppmiselection-focall.\nlemmas Figure 7.5, haten ‘hate’ hoop ‘hope/heap,’ show yet another configuration generated parameter settings. Except green Stratocumulus haten, roughly dominated mens ‘human, people,’ rest clouds Cirrus clouds: small, heterogeneous, characterized many different words.\nFigure 7.5: Models haten hoop bound5lex-ppmiselection-focall.\n","code":""},{"path":"no-optimal.html","id":"theo3-summary","chapter":"7 No sky is the best sky","heading":"7.3 Summary","text":"output model directly predictable parameter settings. Clouds can take many shapes, lemmas exhibit different distributional patterns, patterns can different semantic interpretations. parameter settings model one phenomenon best, certain model, necessarily model phenomenon another lemma, anything else interest matter.\nparameter settings can result drastically different shapes across lemmas, even shapes similar result comparable distributional behaviours, might different semantic interpretations.cheerful thoughts, analytical part dissertation comes end. next chapter conclude brief summary findings form guidelines — tips tricks interested cloudspotter — thoughts research.","code":""},{"path":"conclusions-and-guidelines.html","id":"conclusions-and-guidelines","chapter":"8 Conclusions and guidelines","heading":"8 Conclusions and guidelines","text":"focus dissertation methodological: rather describing specific phenomenon language, e.g. metaphorical extensions temperature terms Italian, develops tests workflow used concrete case studies. combines computational techniques Cognitive Semantics framework aim implementing nlp tools lexicological lexicographical research. position, main research questions revolve around possible mappings parameter settings, .e. sets decisions generate different models, semantic phenomena lexicographic interest:parameter settings model senses best?can tailor parameter settings capture homonymy, metaphor, specialization, argument structure…?addition, since manually annotated senses taken unique truth , beyond accuracy, interested makes models (fail ) approximate human-based categories, study incorporates ad hoc visual analytics fluid, quantitatively-rich qualitative analysis.initial presentation foundations study Introduction, Part , Cloudspotter’s toolkit, laid methodological background. Chapter 2 described computational techniques methodological choices, Chapter 3 showcased visualization tools Chapter 4 introduced selected lemmas annotation procedure.Part II, Cloudspotter’s handbook, discussed results analyses. Even though answer original research questions negative, indeed possible learn something models, three chapters elaborate possibilities.\nChapter 5 offered typology nephological shapes, clouds sky white fluffy. shapes result identifiable properties contexts can interpreted different ways.\nChapter 6 followed systematization possible interpretations linguistic perspective. net phenomena woven combination paradigmatic relations — heterogeneous clusters clouds reveal semantic profiling patterns — syntagmatic relations — collocations semantic preference open-choice tendencies. phenomena set investigate initially; although may find metaphor, metonymy, specialization argument structure, greatly depends lemma matches semasiological categories distributional behaviour. enough lemma metaphorical extensions, also correlate salient contextual patterns. Nevertheless, find linguistic properties — particularly kind properties corpus-methods can capture empirical approaches might .\nFinally, Chapter 7 illustrated negative answer main question: set parameter settings works best across board. lemma different semasiological structure terms distributional behaviour, thus applying tool return different results. parameter configuration cookie cutter, various lemmas kinds mixtures: lemon-flavoured cookie dough, dough chips, dough flattened embossed rolling pin… even sourdough cake batter.remainder chapter summarize points emerge dissertation whole. First, Section 8.1 offers possible explanation discrepancy expectations may come distributional models actual results. However, shall stop us: Section 8.2 lists technical guidelines model building, based set models explored , Section 8.3 dedicated general suggestions research based done project. Finally, Section 8.4 summarizes contributions dissertation distributional approaches semantics.","code":""},{"path":"conclusions-and-guidelines.html","id":"naive","chapter":"8 Conclusions and guidelines","heading":"8.1 Types, tokens and clouds","text":"Distributional models rely Distributional Hypothesis: words occur similar contexts tend semantically similar. seems work types, projecting intuition onto token-level sounds straightforward: attestations occurring similar contexts semantically similar, occurring different contexts semantically different. Semantic distinctions attestations word, .e. semasiological variation, normally grouped senses. stands reason can use token-level distributional models find senses (Schütze 1998; Yarowsky 1995). However, line reasoning two issues.one hand, issue patterns.\ntype-level, vector representations aggregate occurrences, building profiles take account patterns attraction avoidance across hundreds, thousands even millions events. Similar words share tendencies; different words prefer different things.\nintuition behind distributional models often illustrated examples like following (Pantel & Lin 2002: 613):bottle tezgüno table.Everyone likes tezgüno.Tezgüno makes drunk.make tezgüno corn.authors make point words context tezgüno suggest may kind alcoholic beverage, alcoholic beverages tend occur similar contexts (Pantel & Lin 2002: 613). indeed, type-level, patterns likely generate distributional profile tezgüno similar beer, example.\n\n\n\neven though actual contexts rarely self-explanatory examples, type-level distributional models — degree least — work.\nType-level models similar words similar overall patterns: tendencies towards certain contexts. individual context enough. examples highlight different properties tezgüno, namely liquid stored bottles, people (positive) opinions , alcoholic made corn. range items occur “context” tezgüno depend contexts take account. Take, example, following replacements:bottle water table.Everyone likes .Whiskey makes drunk.make cornflakes corn.context enough: , set situations meaning meaning dimension fits, dimensions, whatever , backgrounded irrelevant. Type-level models work look contexts together. time, really know tezgüno makes drunk one made corn tezgüno; type-level models build assumption , reason conflate semasiological structure.way, token-level models look patterns, .e. tendencies towards certain contexts context words, much restricted pool variables. First, context token contains fewer variables aggregated context type draw pattern , results polarization less nuance. Frequently co-occurring words dominate define counts pattern, weaker words lack necessary distinctiveness impose patterns. authentic concordances neat, propositional, explanatory descriptions targets, patterns necessarily match senses., fact, second issue. possibility determining counts different senses debatable (Geeraerts 1993; Glynn 2014), look senses first place? Indeed, Geeraerts suggests procedural rather reified conception meaning: “words searchlights highlight, upon application, particular subfield domain application,” adds “distinction can lit time stable” (Geeraerts 2006: 137). terms clouds, context words compete opportunity signal subfield highlighted target moment. result imprecise several reasons.\nFirst, context words represented type-level vectors generalize salient patterns, necessarily relevant dimension context, case uitspraak herroepen ‘recant statement/void verdict’ discussed Section 6.4.1.\nSecond, dimension context words highlight necessarily ones interested ; structure models heilzaam ‘healthy/beneficial’ discussed Section 6.2.1, correspond distinction literally healthy healing metaphorically healthy, .e. beneficial.\nThird, relation issue patterns, context words might infrequent distinctive enough voice reach us.bright side, much variation across patterns shapes alone already interesting information. words can described lists collocations, token-level models reveal strong (weak), distinctive, widespread collocations within scope target. beyond clouds , visualizing models can let us see spatial organization might missed clustering solutions, fact occurrences uitspraak herroepen ‘recant statement/void verdict’ come together staying close instances herroepen ‘void’ juridical context, fact health-specific general attestations heilzame werking ‘beneficial effect’ occupy opposite poles cluster. Distributional models might replicate intuitions semantic distinctions within lemma, offer us different, complementary perspective , scanning organizing hundreds empirical observations, may capture.","code":""},{"path":"conclusions-and-guidelines.html","id":"tips","chapter":"8 Conclusions and guidelines","heading":"8.2 Practical tips","text":"Even infallible parameter settings configuration hard predict output, guidelines possible. section like offer suggestions future case study use distributional semantics , course, visualization tools presented , investigate semasiological structure given lemma. initial research questions go along lines “strong collocational patterns lemma?” example. Given variety results 32 lemmas analysed dissertation, guidelines can offer starting point explore distributional behaviour lemma; steps refine questions fine-tune models depend results initial exploration. broad terms, outline case study follows:Choose lemma(s)49. Nephological Semantics project look ways scaling procedure, suggestions small-scale studies, detailed examination clouds viable.Choose lemma(s)49. Nephological Semantics project look ways scaling procedure, suggestions small-scale studies, detailed examination clouds viable.Set range parameter settings restrictive:\nkeep window sizes 3;\nforget sentence boundaries;\navoid long, unfiltered type-level vectors;\ndon’t bother REL templates;\nSet range parameter settings restrictive:keep window sizes 3;forget sentence boundaries;avoid long, unfiltered type-level vectors;don’t bother REL templates;Generate hundreds models manageable sample tokens based parameters;Generate hundreds models manageable sample tokens based parameters;Explore plot models Level 1 NephoVis (Section 3.2) get idea parameter settings interact;Explore plot models Level 1 NephoVis (Section 3.2) get idea parameter settings interact;Compute 9 medoids pam explore Level 2 NephoVis;\nchose 8 minimum kept enough variation across lemmas, lemma--lemma basis well reduced. 9 medoids difficult visualize simultaneously.\nCompute 9 medoids pam explore Level 2 NephoVis;chose 8 minimum kept enough variation across lemmas, lemma--lemma basis well reduced. 9 medoids difficult visualize simultaneously.Cluster models hdbscan explore ShinyApp, finding types clouds, collocational patterns, etc. classifications Chapters 5 6 useful, example:\nCumulus clouds (tight salient) tend dominated strong collocates represent typical usages sense.\nCumulonimbus clouds (huge ones) normally good noise tokens.\nCirrus clouds (small, wispy ones) salient clusters, capturing little structure . model probably characterized weak collocational patterns.\nCluster models hdbscan explore ShinyApp, finding types clouds, collocational patterns, etc. classifications Chapters 5 6 useful, example:Cumulus clouds (tight salient) tend dominated strong collocates represent typical usages sense.Cumulonimbus clouds (huge ones) normally good noise tokens.Cirrus clouds (small, wispy ones) salient clusters, capturing little structure . model probably characterized weak collocational patterns.Interpret clusters.\nmodels saying? collocates, lexically instantiated colligates, semantic preference, neither? clusters heterogeneous homogeneous? considered different senses?\nmedoids exhibit interpretable structure? parameters represent?50\nmuch data left annotate?\nInterpret clusters.models saying? collocates, lexically instantiated colligates, semantic preference, neither? clusters heterogeneous homogeneous? considered different senses?medoids exhibit interpretable structure? parameters represent?50How much data left annotate?necessary, readjust parameters /incorporate manual annotation start .necessary, readjust parameters /incorporate manual annotation start .Among interpretative questions, one crucial ones : “considered different senses?” already mentioned introduction prototypicality categories leads us sceptical existence discrete senses. Accordingly, clouds offer alternative view semasiological structure lemma: classification neither matches dictionary senses replaces , inform semantic research nonetheless. rest section elaborate recommendations made .First, discourage restrictive models. might tempted remove much noise possible leave context words informative, sounds reasonable theory. even assuming can figure words going informative — e.g. via annotation cues — result might expect. Restrictive models tend generate clouds Hail: dense areas identical tokens, override subtle relationships. less “relevant” context words might harmful, might also make impact whatsoever, even add information expect, like semantic profiling specific patterns. said, lemmas may require strict settings context words captured already varied enough.Concretely, window sizes smaller 5 tend restrictive, window size 10 already bordering noisy. Within dependency-based models, RELgroup1 models often restrictive rarely informative enough. wider variety REL templates useful, case, designing templates fit increasingly complex patterns — especially chains verbs come play — time consuming never good enough. REL models discarded altogether, unless researcher good idea templates useful specific lemma study. example, haten ‘hate’ tends occur active constructions without chains modals (e.g. ik haat het ‘hate ’), herroepen ‘recant, void’ often co-occurs passive auxiliary, modals even (e.g. het nachtverbod moest worden herroepen ‘night ban voided’). result, simple REL template capturing direct object verb enough haten ‘hate’51 miss many herroepen ‘recant, void’ tokens.similar vein, PPMI can restrictive lemmas used care, especially PPMIweight, might enhance influence already powerful context words , example, cause Cumulonimbus clouds. Since filtering power PPMIselection depends range association strength values target context words, straightforward find threshold just restrictive want every lemma. Instead, fruitful test different thresholds — even combine measures — lemma--lemma basis.One parameter setting certainly avoided 5000all, often makes great impact difference models never better. Either applying part--speech filter reducing dimensionality, e.g. using first-order context words second order dimensions (FOC), already gives better results. likely due sparsity /low informativeness dimensions selected 5000all, applying svd afterwards might also help.Finally, ignoring sentence boundaries seem make difference. cases, Level 1 plots place models different parameter right next ; times makes difference, two three parameters already important.tips help selection parameter settings future models, still good idea generate multiple models look medoids. Chapter 7 showed unique recipe tailor model disambiguate certain way. Models find patterns based distributional behaviour lemma — frequent context words , similar , often co-occur, etc. degree patterns match senses general sort semasiological structure — homonymy relations, metaphor, idioms, argument structure… — empirical question, procedure addresses. Fine-tuning can implemented first set medoids traced outline lemma’s structure., medoids can also provide estimation much manual annotation actually needed. Given model like heffen ‘levy/lift’ herinneren ‘remember/remind,’ patterns clear homogeneous checking main context words different clusters concordance lines enough; , need examine noise tokens closely. time, case like heilzaam ‘healthy/beneficial’ immediately see collocation-based clouds semantically heterogeneous, case like haten ‘hate’ might make want rethink life choices. case, don’t need annotate tokens beginning unless priori classification intent finding. Even , ’s best keep 6 categories, becomes really hard distinguish colour-coding visually.suggestions avoid lot trial error case-studies along lines. Interpreting clouds seen , especially, expect clearly-defined islands, quite challenging already. Besides, Geeraerts (2010b: 73) argues, “empirical research involves empirical cycle several rounds data gathering, testing hypotheses, interpretation results follow ,” cloudspotting exception.","code":""},{"path":"conclusions-and-guidelines.html","id":"further","chapter":"8 Conclusions and guidelines","heading":"8.3 To the sky and beyond","text":"choices described Introduction Chapter 2 implied leaving alternatives, well explored future research projects.\nlevel parameter settings, selections part--speech filters, example expanding lex proper names prepositions, offer middle point two options examined, since lex sometimes restrictive, noisy. comes dependency-based models, natural extension incorporate dependency path feature, e.g. “object eat” feature. technically challenging likely result sparser vectors, make connection target second-order dimensions clear. current implementation, relationship target token study\\(_1\\) second-order dimension language/n Table 2.2 given association strength said second-order dimension first-order context word lexicography/n: lexicography/n occurs immediate context study\\(_1\\) ppmi 4.37 language/n, coordinate study\\(_1\\) language/n dimension 4.37. dependency relations built feature, e.g. “object lexicography/n,” dimensions highlighted feature verbs take lexicography/n object.relation issue, precise effect second-order parameters thoroughly explored, techniques devised better understand effect second-order dimensions. Moreover, instead comparing FOC second-order vectors longer ones based frequency, compared FOC vectors based different samples: FOC models transfer context words survived first-order filters second-order dimensions, set parameter-settings different samples — particularly samples different sizes — may result different selections context words. Additionally, compared implicit type-level vectors (Lenci 2018), .e. dimensionality reduced svd nonnegative matrix factorization, even prediction-based vectors. original reason implement keep transparency vectors maximum (Heylen et al. 2015), transition second-order vectors already obscures meaning dimensions great extent.Following reasoning, motivation exclude prediction-based models disappears. one hand, type-level word embeddings incorporated representations first-order context words. , given possibilities offered family bert models, bertje (de Vries et al. 2019) applied tokens . proper comparison methods, new models created word forms units, re-tokenizing corpus bertje’s tokenizer. first goal check well classifications presented Chapters 5 6 can mapped models based word forms degree also apply bertje models. Nonetheless, concerns tokenization addressed: output might useful certain nlp tasks, words captured tokenization breaks (case heilzaam, split heil ##zaam), utility bertje lexicographical purposes decreases. solution might implementation larger units targets features modelling procedure, bigrams. another interesting avenue research, since words work isolation, technically challenging.model-building process, also model-analysis process use deeper exploration. First, possibility implementing umap explored. Based initial comparisons, clarity clusters seem different t-sne output, shapes different relative distances supposed interpretable. addition, hdbscan clustering \\(minPts = 8\\) replicates visually identified patterns quite well, always clear tokens excluded noise distinctive clusters split. said, switching umap, perplexity values t-sne /\\(minPts\\) values hdbscan may void warranty classifications descriptions offered dissertation.","code":""},{"path":"conclusions-and-guidelines.html","id":"contributions","chapter":"8 Conclusions and guidelines","heading":"8.4 Summing up","text":"Distributional semantics addresses issue descriptive linguists like use corpus methods\nsemantic analysis. linguist eager exploit increasingly large available corpora tired manually annotating hundreds concordances sense tags might even appropriate52. Distributional models, hand, present scalable, automatic approach can process large amounts textual data extract patterns semantic correlates. constitute irresistible asset empirical approaches aiming maximize automation laborious, quantitative tasks give researcher energy time creative hermeneutic aspects research.\ndissertation written linguist, good news bad news.bad news , although distributional models can indeed reveal patterns \noffer information might obtain means, necessarily patterns \ninformation expected. results study suggest , use distributional\nsemantics descriptive analyses, blindly.\nUnlike high accuracy scores benchmarks suggest, parameter setting works optimally across board, relevant description one lexical item might another. reason, different configurations parameter settings different effects lemma, highlighting specific aspects may less interesting linguistic perspective. may senses, may something else.good news user-friendly, comprehensive visualization tool available exploration models. Interfaces like ones described turn apparent chaos distributional models concrete visual representations us examine interrogate. Rather despairing face multiple diverse models, can create composite picture based representative models: embrace complexity thus achieve richer, nuanced description. tools offer fluid interaction output models look backstage operations.sum, dissertation illustrates , descriptive linguists, shouldn’t trust distributional models blindly, also can exploit nonetheless. one hand, illustrates workflow investigating distributional modelling : steps followed study can applied alternative implementations better understanding distributional approaches. hand, warnings suggestions, offers framework tools future studies implementing token-level distributional models linguistic research , like call , linguistic cloudspotting.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
