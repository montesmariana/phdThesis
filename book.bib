@incollection{montes_heylen,
	title = {Visualizing {Distributional} {Semantics}},
	isbn = {978-3-11-068734-7},
	language = {en},
	year = {Forthcoming},
	publisher = {Mouton De Gruyter},
	author = {Montes, Mariana and Heylen, Kris},
	editor = {Tay, Dennis and Pan, Molly Xie}
}


@book{levshina_how_2015,
	address = {Amsterdam ; Philadelphia},
	title = {How to do linguistics with {R}: data exploration and statistical analysis},
	isbn = {978-90-272-1224-5 978-90-272-1225-2},
	shorttitle = {How to do linguistics with {R}},
	publisher = {John Benjamins Publishing Company},
	author = {Levshina, Natalia},
	year = {2015},
	keywords = {Computational linguistics, Linguistics, Methodology, Statistical methods, Software}
}


@inproceedings{kiela_systematic_2014,
	address = {Gothenburg},
	title = {A {Systematic} {Study} of {Semantic} {Vector} {Space} {Model} {Parameters}},
	abstract = {We present a systematic study of parameters used in the construction of semantic vector space models. Evaluation is carried out on a variety of similarity tasks, including a compositionality dataset, using
several source corpora. In addition to recommendations
for optimal parameters, we present some novel findings, including a similarity metric that outperforms the alternatives on all tasks considered.},
	booktitle = {Proceedings of the 2nd {Workshop} on {Continuous} {Vector} {Space} {Models} and their {Compositionality}},
	publisher = {ACL},
	author = {Kiela, Douwe and Clark, Stephen},
	month = apr,
	year = {2014},
	pages = {21--30}
}


@article{hilpert_using_2017,
	title = {Using token-based semantic vector spaces for corpus-linguistic analyses: {From} practical applications to tests of theoretical claims},
	volume = {16},
	issn = {1613-7027, 1613-7035},
	shorttitle = {Using token-based semantic vector spaces for corpus-linguistic analyses},
	url = {http://www.degruyter.com/view/j/cllt.ahead-of-print/cllt-2017-0009/cllt-2017-0009.xml},
	doi = {10.1515/cllt-2017-0009},
	abstract = {This paper presents token-based semantic vector spaces as a tool that can be applied in corpus-linguistic analyses such as word sense comparisons, comparisons of synonymous lexical items, and matching of concordance lines with a given text. We demonstrate how token-based semantic vector spaces are created, and we illustrate the kinds of result that can be obtained with this approach. Our main argument is that token-based semantic vector spaces are not only useful for practical corpus-linguistic applications but also for the investigation of theory-driven questions. We illustrate this point with a discussion of the asymmetric priming hypothesis (Jäger and Rosenbach 2008). The asymmetric priming hypothesis, which states that grammaticalizing constructions will be primed by their lexical sources but not vice versa, makes a number of empirically testable predictions. We operationalize and test these predictions, concluding that token-based semantic vector spaces yield conclusions that are relevant for linguistic theory-building.},
	language = {en},
	number = {2},
	urldate = {2018-11-20},
	journal = {Corpus Linguistics and Linguistic Theory},
	author = {Hilpert, Martin and Correia Saavedra, David},
	month = sep,
	year = {2017},
	file = {Hilpert y Correia Saavedra - 2017 - Using token-based semantic vector spaces for corpu.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\RKE3RQAB\\Hilpert y Correia Saavedra - 2017 - Using token-based semantic vector spaces for corpu.pdf:application/pdf}
}

@article{hilpert_disentangling_2020,
	title = {Disentangling modal meanings with distributional semantics},
	issn = {2055-7671},
	url = {https://doi.org/10.1093/llc/fqaa014},
	doi = {10.1093/llc/fqaa014},
	abstract = {This article investigates the collocational behavior of English modal auxiliaries such as may and might with the aim of finding corpus-based measures that distinguish between different modal expressions and that allow insights into why speakers may choose one over another in a given context. The analysis uses token-based semantic vector space modeling (Heylen et al., 2015, Monitoring polysemy. Word space models as a tool for large-scale lexical semantic analysis. Lingua, 157: 153–72; Hilpert and Correia Saavedra, 2017, Using token-based semantic vector spaces for corpus-linguistic analyses: From practical applications to tests of theoretical claims. Corpus Linguistics and Linguistic Theory) in order to determine whether different modal auxiliaries can be distinguished in terms of their collocational profiles. The analysis further examines whether different senses of the same auxiliary exhibit divergent collocational preferences. The results indicate that near-synonymous pairs of modal expressions, such as may and might or must and have to, differ in their distributional characteristics. Also, different senses of the same modal expression, such as deontic and epistemic uses of may, can be distinguished on the basis of distributional information. We discuss these results against the background of previous empirical findings (Hilpert, 2016, Construction Grammar and its Application to English, 2nd edn. Edinburgh: Edinburgh University Press, Flach, in press, Beyond modal idioms and modal harmony: a corpus-based analysis of gradient idiomaticity in modal-adverb collocations. English Language and Linguistics) and theoretical issues such as degrees of grammaticalization (Correia Saavedra, 2019, Measurements of Grammaticalization: Developing a Quantitative Index for the Study of Grammatical Change. PhD Dissertation, Université de Neuchâtel) and the avoidance of synonymy (Bolinger, 1968, Entailment and the meaning of structures. Glossa, 2(2): 119–27).},
	number = {fqaa014},
	urldate = {2020-12-08},
	journal = {Digital Scholarship in the Humanities},
	author = {Hilpert, Martin and Flach, Susanne},
	month = may,
	year = {2020},
	file = {Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\PFI628UU\\Hilpert en Flach - 2020 - Disentangling modal meanings with distributional s.pdf:application/pdf;Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\YXNIE5BL\\5836757.html:text/html}
}

@article{hilpert_meaning_2015,
	title = {Meaning change in a petri dish: constructions, semantic vector spaces, and motion charts},
	volume = {1},
	shorttitle = {Meaning change in a petri dish},
	url = {http://www.degruyter.com/view/journals/lingvan/1/1/article-p339.xml},
	doi = {10.1515/lingvan-2015-0013},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d3008e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}This paper explores how the visualization tool of motion charts can be used for the analysis of meaning change in linguistic constructions. In previous work, linguistic motion charts have been used to represent diachronic frequency trends and changes in the morphosyntactic behavior of linguistic units. The present paper builds on that work, but it shifts the focus to the study of semantic change. How can motion charts be used to visualize semantic change over time? In order to answer this question, we draw on semantic vector space modeling to visualize aspects of linguistic meaning. As an analogy to this approach, the title of this paper alludes to a petri dish in which the growth and development of biological microorganisms can be observed. On the basis of diachronic corpus data, we monitor developments in the semantic ecology of a construction. This allows us to observe processes such as semantic broadening, semantic narrowing, or semantic shift. We illustrate our approach on the basis of a case study that investigates the diachrony of an English construction that we call the ‘many a NOUN’ construction.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {en},
	number = {1},
	urldate = {2020-12-22},
	journal = {Linguistics Vanguard},
	author = {Hilpert, Martin and Perek, Florent},
	month = dec,
	year = {2015},
	note = {Publisher: De Gruyter Mouton
Section: Linguistics Vanguard},
	pages = {339--350},
	file = {Full Text PDF:C\:\\Users\\u0118974\\Zotero\\storage\\3KJSXIKZ\\Hilpert en Perek - 2015 - Meaning change in a petri dish constructions, sem.pdf:application/pdf;Snapshot:C\:\\Users\\u0118974\\Zotero\\storage\\M8SHHQML\\article-p339.html:text/html}
}


@article{lenci_distributional_2018,
	title = {Distributional {Models} of {Word} {Meaning}},
	volume = {4},
	issn = {2333-9683, 2333-9691},
	url = {http://www.annualreviews.org/doi/10.1146/annurev-linguistics-030514-125254},
	doi = {10.1146/annurev-linguistics-030514-125254},
	abstract = {Distributional semantics is a usage-based model of meaning, based on the assumption that the statistical distribution of linguistic items in context plays a key role in characterizing their semantic behavior. Distributional models build semantic representations by extracting co-occurrences from corpora and have become a mainstream research paradigm in computational linguistics. In this review, I present the state of the art in distributional semantics, focusing on its assets and limits as a model of meaning and as a method for semantic analysis.},
	language = {en},
	number = {1},
	urldate = {2019-08-27},
	journal = {Annual Review of Linguistics},
	author = {Lenci, Alessandro},
	month = jan,
	year = {2018},
	pages = {151--171},
	file = {Lenci - 2018 - Distributional Models of Word Meaning.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\YRSW9EUM\\Lenci - 2018 - Distributional Models of Word Meaning.pdf:application/pdf}
}


@article{turney_frequency_2010,
	title = {From {Frequency} to {Meaning}: {Vector} {Space} {Models} of {Semantics}},
	volume = {37},
	abstract = {Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term–document, word–context, and pair–pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a speciﬁc open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the ﬁeld.},
	language = {en},
	journal = {Journal of Artificial Intelligence Research},
	author = {Turney, Peter D and Pantel, Patrick},
	year = {2010},
	pages = {141--188},
	file = {Turney y Pantel - From Frequency to Meaning Vector Space Models of .pdf:C\:\\Users\\u0118974\\Zotero\\storage\\K6IMW9S3\\Turney y Pantel - From Frequency to Meaning Vector Space Models of .pdf:application/pdf}
}


@phdthesis{de_pascale_2019,
	title = {Token-based vector space models as semantic control in lexical lectometry},
	url = {https://lirias.kuleuven.be/retrieve/549451},
	abstract = {Type-based distributional semantics as embodied in vector space models has proven to be a successful method for the retrieval of near-synonyms in large corpora. These words have then been used as variants of lexical sociolinguistic variables (e.g.: return and winst for the concept profit) in lectometric studies, that is, the aggregate-level study of lexical distances between linguistic varieties, in particular pluricentric languages such as Dutch. However, a limitation of type-based vector space models is that all senses of a word are lumped together into one vector representation, making it harder to control for polysemy and subtle contextual distinctions. In addition, operating at the lexeme level, these type-based vector space models are not able to pick out the relevant corpus occurrences that are the input for the lectometric distance calculations. The main goal of this PhD project is to introduce token-based vector space models in lexical lectometric research, in order to gain better semantic control during the composition of lexical variables. Token-based vector space models address the abovementioned shortcomings by disambiguating different senses of lexical variants. This technique is able to model the semantics of individual tokens (i.e. 'usage occurrences') of a word in a corpus and to represent them as token clouds in multidimensional vector space, with clusters of tokens revealing distinct senses of the word. By superimposing the token clouds of the lexical variants, one can distinguish which meanings are shared by near-synonyms and determine the 'semantic envelope of variation' of the lexical alternation. For instance, the variant return is polysemous in Netherlandic Dutch, with the two readings 'profit' and 'return game', but not in Belgian Dutch, where only the 'profit' sense is found. By isolating the cluster of tokens with the meaning 'profit' one can identify the near-synonymous tokens of the variants winst and return. The fine-tuning of vector space model-based lectometry targeted in this PhD contributes to the scaling up of lexical variationist research, by providing methods for dealing with corpora whose size exceeds manual analysis. At the same time, token-based models comply with the need of detailed analysis by allowing to zoom in on the behavior of individual tokens in order to determine more subtle contextual distinctions. This PhD project is situated in a larger research endeavor ("Nephological Semantics - Using token clouds for meaning detection in variationist linguistics", BOF C1 project 3H150305) that aims at detailed understanding of token-based vector representations for lexical, semantic and variational research.},
	language = {eng},
	urldate = {2019-11-08},
	author = {De Pascale, S.},
	collaborator = {Marzo, S. and Speelman, D.},
	year = {2019}
}


@article{heylen_monitoring_2015,
	title = {Monitoring polysemy: {Word} space models as a tool for large-scale lexical semantic analysis},
	volume = {157},
	issn = {00243841},
	shorttitle = {Monitoring polysemy},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0024384114002770},
	doi = {10.1016/j.lingua.2014.12.001},
	language = {en},
	urldate = {2017-08-23},
	journal = {Lingua},
	author = {Heylen, Kris and Wielfaert, Thomas and Speelman, Dirk and Geeraerts, Dirk},
	month = apr,
	year = {2015},
	pages = {153--172}
}

@inproceedings{heylen_looking_2012,
	address = {Avignon},
	title = {Looking at word meaning. {An} interactive visualization of {Semantic} {Vector} {Spaces} for {Dutch} synsets},
	abstract = {In statistical NLP, Semantic Vector Spaces (SVS) are the standard technique for the automatic modeling of lexical semantics. However, it is largely unclear how these black-box techniques exactly capture word meaning. To explore the way an SVS structures the individual occurrences of words, we use a non-parametric MDS solution of a token-by-token similarity matrix. The MDS solution is visualized in an interactive plot with the Google Chart Tools. As a case study, we look at the occurrences of 476 Dutch nouns grouped in 214 synsets.},
	language = {en},
	booktitle = {Proceedings of the eacl 2012 {Joint} {Workshop} of {LINGVIS} \& {UNCLH}},
	author = {Heylen, Kris and Speelman, Dirk and Geeraerts, Dirk},
	year = {2012},
	pages = {16--24},
	file = {Heylen et al. - Looking at word meaning. An interactive visualizat.pdf:C\:\\Users\\u0118974\\Zotero\\storage\\UU62B9N7\\Heylen et al. - Looking at word meaning. An interactive visualizat.pdf:application/pdf}
}

@incollection{wielfaert_visual_2019,
	address = {Stanford, California},
	series = {{CSLI} lecture notes},
	title = {Visual {Analytics} for {Parameter} {Tuning} of {Semantic} {Vector} {Space} {Models}},
	isbn = {978-1-68400-034-0 978-1-68400-033-3 978-1-68400-035-7},
	number = {no. 220},
	booktitle = {{LingVis}: visual analytics for linguistics},
	publisher = {CSLI Publications, Center for the Study of Language and Information},
	author = {Wielfaert, Thomas and Heylen, Kris and Speelman, Dirk and Geeraerts, Dirk},
	editor = {Butt, Miriam and Hautli-Janisz, Annette and Lyding, Verena},
	year = {2019},
	keywords = {Linguistics, Information visualization, LANGUAGE ARTS \& DISCIPLINES / Linguistics / General, Visual analytics},
	pages = {215--245}
}

